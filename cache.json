{"2024-03-20T00:00:00Z":{"Robotics":[{"id":"http://arxiv.org/abs/2403.13801v1","updated":"2024-03-20T17:58:12Z","published":"2024-03-20T17:58:12Z","title":"Natural Language as Polices: Reasoning for Coordinate-Level Embodied\n  Control with LLMs","summary":"  We demonstrate experimental results with LLMs that address robotics action\nplanning problems. Recently, LLMs have been applied in robotics action\nplanning, particularly using a code generation approach that converts complex\nhigh-level instructions into mid-level policy codes. In contrast, our approach\nacquires text descriptions of the task and scene objects, then formulates\naction planning through natural language reasoning, and outputs coordinate\nlevel control commands, thus reducing the necessity for intermediate\nrepresentation code as policies. Our approach is evaluated on a multi-modal\nprompt simulation benchmark, demonstrating that our prompt engineering\nexperiments with natural language reasoning significantly enhance success rates\ncompared to its absence. Furthermore, our approach illustrates the potential\nfor natural language descriptions to transfer robotics skills from known tasks\nto previously unseen tasks.\n","authors":["Yusuke Mikami","Andrew Melnik","Jun Miura","Ville Hautamäki"],"pdf_url":"https://arxiv.org/pdf/2403.13801v1.pdf","comment":"8 pages, 2 figures"},{"id":"http://arxiv.org/abs/2403.13783v1","updated":"2024-03-20T17:44:33Z","published":"2024-03-20T17:44:33Z","title":"A Convex Formulation of Frictional Contact for the Material Point Method\n  and Rigid Bodies","summary":"  In this paper, we introduce a novel convex formulation that seamlessly\nintegrates the Material Point Method (MPM) with articulated rigid body dynamics\nin frictional contact scenarios. We extend the linear corotational hyperelastic\nmodel into the realm of elastoplasticity and include an efficient return\nmapping algorithm. This approach is particularly effective for MPM simulations\ninvolving significant deformation and topology changes, while preserving the\nconvexity of the optimization problem. Our method ensures global convergence,\nenabling the use of large simulation time steps without compromising\nrobustness. We have validated our approach through rigorous testing and\nperformance evaluations, highlighting its superior capabilities in managing\ncomplex simulations relevant to robotics. Compared to previous MPM based\nrobotic simulators, our method significantly improves the stability of contact\nresolution -- a critical factor in robot manipulation tasks. We make our method\navailable in the open-source robotics toolkit, Drake.\n","authors":["Zeshun Zong","Chenfanfu Jiang","Xuchen Han"],"pdf_url":"https://arxiv.org/pdf/2403.13783v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13778v1","updated":"2024-03-20T17:41:35Z","published":"2024-03-20T17:41:35Z","title":"Certified Human Trajectory Prediction","summary":"  Trajectory prediction plays an essential role in autonomous vehicles. While\nnumerous strategies have been developed to enhance the robustness of trajectory\nprediction models, these methods are predominantly heuristic and do not offer\nguaranteed robustness against adversarial attacks and noisy observations. In\nthis work, we propose a certification approach tailored for the task of\ntrajectory prediction. To this end, we address the inherent challenges\nassociated with trajectory prediction, including unbounded outputs, and\nmutli-modality, resulting in a model that provides guaranteed robustness.\nFurthermore, we integrate a denoiser into our method to further improve the\nperformance. Through comprehensive evaluations, we demonstrate the\neffectiveness of the proposed technique across various baselines and using\nstandard trajectory prediction datasets. The code will be made available\nonline: https://s-attack.github.io/\n","authors":["Mohammadhossein Bahari","Saeed Saadatnejad","Amirhossein Asgari Farsangi","Seyed-Mohsen Moosavi-Dezfooli","Alexandre Alahi"],"pdf_url":"https://arxiv.org/pdf/2403.13778v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13777v1","updated":"2024-03-20T17:41:21Z","published":"2024-03-20T17:41:21Z","title":"Embedding Pose Graph, Enabling 3D Foundation Model Capabilities with a\n  Compact Representation","summary":"  This paper presents the Embedding Pose Graph (EPG), an innovative method that\ncombines the strengths of foundation models with a simple 3D representation\nsuitable for robotics applications. Addressing the need for efficient spatial\nunderstanding in robotics, EPG provides a compact yet powerful approach by\nattaching foundation model features to the nodes of a pose graph. Unlike\ntraditional methods that rely on bulky data formats like voxel grids or point\nclouds, EPG is lightweight and scalable. It facilitates a range of robotic\ntasks, including open-vocabulary querying, disambiguation, image-based\nquerying, language-directed navigation, and re-localization in 3D environments.\nWe showcase the effectiveness of EPG in handling these tasks, demonstrating its\ncapacity to improve how robots interact with and navigate through complex\nspaces. Through both qualitative and quantitative assessments, we illustrate\nEPG's strong performance and its ability to outperform existing methods in\nre-localization. Our work introduces a crucial step forward in enabling robots\nto efficiently understand and operate within large-scale 3D spaces.\n","authors":["Hugues Thomas","Jian Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.13777v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06192v5","updated":"2024-03-20T17:36:07Z","published":"2023-06-09T18:45:15Z","title":"Ada-NAV: Adaptive Trajectory Length-Based Sample Efficient Policy\n  Learning for Robotic Navigation","summary":"  Trajectory length stands as a crucial hyperparameter within reinforcement\nlearning (RL) algorithms, significantly contributing to the sample inefficiency\nin robotics applications. Motivated by the pivotal role trajectory length plays\nin the training process, we introduce Ada-NAV, a novel adaptive trajectory\nlength scheme designed to enhance the training sample efficiency of RL\nalgorithms in robotic navigation tasks. Unlike traditional approaches that\ntreat trajectory length as a fixed hyperparameter, we propose to dynamically\nadjust it based on the entropy of the underlying navigation policy.\nInterestingly, Ada-NAV can be applied to both existing on-policy and off-policy\nRL methods, which we demonstrate by empirically validating its efficacy on\nthree popular RL methods: REINFORCE, Proximal Policy Optimization (PPO), and\nSoft Actor-Critic (SAC). We demonstrate through simulated and real-world\nrobotic experiments that Ada-NAV outperforms conventional methods that employ\nconstant or randomly sampled trajectory lengths. Specifically, for a fixed\nsample budget, Ada-NAV achieves an 18\\% increase in navigation success rate, a\n20-38\\% reduction in navigation path length, and a 9.32\\% decrease in elevation\ncosts. Furthermore, we showcase the versatility of Ada-NAV by integrating it\nwith the Clearpath Husky robot, illustrating its applicability in complex\noutdoor environments.\n","authors":["Bhrij Patel","Kasun Weerakoon","Wesley A. Suttle","Alec Koppel","Brian M. Sadler","Tianyi Zhou","Amrit Singh Bedi","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2306.06192v5.pdf","comment":"11 pages, 9 figures, 2 tables"},{"id":"http://arxiv.org/abs/2403.13730v1","updated":"2024-03-20T16:39:48Z","published":"2024-03-20T16:39:48Z","title":"Projection-free computation of robust controllable sets with constrained\n  zonotopes","summary":"  We study the problem of computing robust controllable sets for discrete-time\nlinear systems with additive uncertainty. We propose a tractable and scalable\napproach to inner- and outer-approximate robust controllable sets using\nconstrained zonotopes, when the additive uncertainty set is a symmetric,\nconvex, and compact set. Our least-squares-based approach uses novel\nclosed-form approximations of the Pontryagin difference between a constrained\nzonotopic minuend and a symmetric, convex, and compact subtrahend. Unlike\nexisting approaches, our approach does not rely on convex optimization solvers,\nand is projection-free for ellipsoidal and zonotopic uncertainty sets. We also\npropose a least-squares-based approach to compute a convex, polyhedral\nouter-approximation to constrained zonotopes, and characterize sufficient\nconditions under which all these approximations are exact. We demonstrate the\ncomputational efficiency and scalability of our approach in several case\nstudies, including the design of abort-safe rendezvous trajectories for a\nspacecraft in near-rectilinear halo orbit under uncertainty. Our approach can\ninner-approximate a 20-step robust controllable set for a 100-dimensional\nlinear system in under 15 seconds on a standard computer.\n","authors":["Abraham P. Vinod","Avishai Weiss","Stefano Di Cairano"],"pdf_url":"https://arxiv.org/pdf/2403.13730v1.pdf","comment":"22 pages, 6 figures"},{"id":"http://arxiv.org/abs/2403.13729v1","updated":"2024-03-20T16:39:17Z","published":"2024-03-20T16:39:17Z","title":"Reinforcement Learning for Online Testing of Autonomous Driving Systems:\n  a Replication and Extension Study","summary":"  In a recent study, Reinforcement Learning (RL) used in combination with\nmany-objective search, has been shown to outperform alternative techniques\n(random search and many-objective search) for online testing of Deep Neural\nNetwork-enabled systems. The empirical evaluation of these techniques was\nconducted on a state-of-the-art Autonomous Driving System (ADS). This work is a\nreplication and extension of that empirical study. Our replication shows that\nRL does not outperform pure random test generation in a comparison conducted\nunder the same settings of the original study, but with no confounding factor\ncoming from the way collisions are measured. Our extension aims at eliminating\nsome of the possible reasons for the poor performance of RL observed in our\nreplication: (1) the presence of reward components providing contrasting or\nuseless feedback to the RL agent; (2) the usage of an RL algorithm (Q-learning)\nwhich requires discretization of an intrinsically continuous state space.\nResults show that our new RL agent is able to converge to an effective policy\nthat outperforms random testing. Results also highlight other possible\nimprovements, which open to further investigations on how to best leverage RL\nfor online ADS testing.\n","authors":["Luca Giamattei","Matteo Biagiola","Roberto Pietrantuono","Stefano Russo","Paolo Tonella"],"pdf_url":"https://arxiv.org/pdf/2403.13729v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13714v1","updated":"2024-03-20T16:20:54Z","published":"2024-03-20T16:20:54Z","title":"DBA-Fusion: Tightly Integrating Deep Dense Visual Bundle Adjustment with\n  Multiple Sensors for Large-Scale Localization and Mapping","summary":"  Visual simultaneous localization and mapping (VSLAM) has broad applications,\nwith state-of-the-art methods leveraging deep neural networks for better\nrobustness and applicability. However, there is a lack of research in fusing\nthese learning-based methods with multi-sensor information, which could be\nindispensable to push related applications to large-scale and complex\nscenarios. In this paper, we tightly integrate the trainable deep dense bundle\nadjustment (DBA) with multi-sensor information through a factor graph. In the\nframework, recurrent optical flow and DBA are performed among sequential\nimages. The Hessian information derived from DBA is fed into a generic factor\ngraph for multi-sensor fusion, which employs a sliding window and supports\nprobabilistic marginalization. A pipeline for visual-inertial integration is\nfirstly developed, which provides the minimum ability of metric-scale\nlocalization and mapping. Furthermore, other sensors (e.g., global navigation\nsatellite system) are integrated for driftless and geo-referencing\nfunctionality. Extensive tests are conducted on both public datasets and\nself-collected datasets. The results validate the superior localization\nperformance of our approach, which enables real-time dense mapping in\nlarge-scale environments. The code has been made open-source\n(https://github.com/GREAT-WHU/DBA-Fusion).\n","authors":["Yuxuan Zhou","Xingxing Li","Shengyu Li","Xuanbin Wang","Shaoquan Feng","Yuxuan Tan"],"pdf_url":"https://arxiv.org/pdf/2403.13714v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.05840v2","updated":"2024-03-20T16:18:26Z","published":"2024-02-08T17:17:06Z","title":"uPLAM: Robust Panoptic Localization and Mapping Leveraging Perception\n  Uncertainties","summary":"  The availability of a robust map-based localization system is essential for\nthe operation of many autonomously navigating vehicles. Since uncertainty is an\ninevitable part of perception, it is beneficial for the robustness of the robot\nto consider it in typical downstream tasks of navigation stacks. In particular\nlocalization and mapping methods, which in modern systems often employ\nconvolutional neural networks (CNNs) for perception tasks, require proper\nuncertainty estimates. In this work, we present uncertainty-aware Panoptic\nLocalization and Mapping (uPLAM), which employs pixel-wise uncertainty\nestimates for panoptic CNNs as a bridge to fuse modern perception with\nclassical probabilistic localization and mapping approaches. Beyond the\nperception, we introduce an uncertainty-based map aggregation technique to\ncreate accurate panoptic maps, containing surface semantics and landmark\ninstances. Moreover, we provide cell-wise map uncertainties, and present a\nparticle filter-based localization method that employs perception\nuncertainties. Extensive evaluations show that our proposed incorporation of\nuncertainties leads to more accurate maps with reliable uncertainty estimates\nand improved localization accuracy. Additionally, we present the Freiburg\nPanoptic Driving dataset for evaluating panoptic mapping and localization\nmethods. We make our code and dataset available at:\n\\url{http://uplam.cs.uni-freiburg.de}\n","authors":["Kshitij Sirohi","Daniel Büscher","Wolfram Burgard"],"pdf_url":"https://arxiv.org/pdf/2402.05840v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13701v1","updated":"2024-03-20T16:06:01Z","published":"2024-03-20T16:06:01Z","title":"What Matters for Active Texture Recognition With Vision-Based Tactile\n  Sensors","summary":"  This paper explores active sensing strategies that employ vision-based\ntactile sensors for robotic perception and classification of fabric textures.\nWe formalize the active sampling problem in the context of tactile fabric\nrecognition and provide an implementation of information-theoretic exploration\nstrategies based on minimizing predictive entropy and variance of probabilistic\nmodels. Through ablation studies and human experiments, we investigate which\ncomponents are crucial for quick and reliable texture recognition. Along with\nthe active sampling strategies, we evaluate neural network architectures,\nrepresentations of uncertainty, influence of data augmentation, and dataset\nvariability. By evaluating our method on a previously published Active Clothing\nPerception Dataset and on a real robotic system, we establish that the choice\nof the active exploration strategy has only a minor influence on the\nrecognition accuracy, whereas data augmentation and dropout rate play a\nsignificantly larger role. In a comparison study, while humans achieve 66.9%\nrecognition accuracy, our best approach reaches 90.0% in under 5 touches,\nhighlighting that vision-based tactile sensors are highly effective for fabric\ntexture recognition.\n","authors":["Alina Böhm","Tim Schneider","Boris Belousov","Alap Kshirsagar","Lisa Lin","Katja Doerschner","Knut Drewing","Constantin A. Rothkopf","Jan Peters"],"pdf_url":"https://arxiv.org/pdf/2403.13701v1.pdf","comment":"7 pages, 9 figures, accepted at 2024 IEEE International Conference on\n  Robotics and Automation (ICRA)"},{"id":"http://arxiv.org/abs/2403.13695v1","updated":"2024-03-20T15:57:44Z","published":"2024-03-20T15:57:44Z","title":"Loss Regularizing Robotic Terrain Classification","summary":"  Locomotion mechanics of legged robots are suitable when pacing through\ndifficult terrains. Recognising terrains for such robots are important to fully\nyoke the versatility of their movements. Consequently, robotic terrain\nclassification becomes significant to classify terrains in real time with high\naccuracy. The conventional classifiers suffer from overfitting problem, low\naccuracy problem, high variance problem, and not suitable for live dataset. On\nthe other hand, classifying a growing dataset is difficult for convolution\nbased terrain classification. Supervised recurrent models are also not\npractical for this classification. Further, the existing recurrent\narchitectures are still evolving to improve accuracy of terrain classification\nbased on live variable-length sensory data collected from legged robots. This\npaper proposes a new semi-supervised method for terrain classification of\nlegged robots, avoiding preprocessing of long variable-length dataset. The\nproposed method has a stacked Long Short-Term Memory architecture, including a\nnew loss regularization. The proposed method solves the existing problems and\nimproves accuracy. Comparison with the existing architectures show the\nimprovements.\n","authors":["Shakti Deo Kumar","Sudhanshu Tripathi","Krishna Ujjwal","Sarvada Sakshi Jha","Suddhasil De"],"pdf_url":"https://arxiv.org/pdf/2403.13695v1.pdf","comment":"Preliminary draft of the work published in IEEE conference 2023"},{"id":"http://arxiv.org/abs/2403.13683v1","updated":"2024-03-20T15:41:32Z","published":"2024-03-20T15:41:32Z","title":"DVMNet: Computing Relative Pose for Unseen Objects Beyond Hypotheses","summary":"  Determining the relative pose of an object between two images is pivotal to\nthe success of generalizable object pose estimation. Existing approaches\ntypically approximate the continuous pose representation with a large number of\ndiscrete pose hypotheses, which incurs a computationally expensive process of\nscoring each hypothesis at test time. By contrast, we present a Deep Voxel\nMatching Network (DVMNet) that eliminates the need for pose hypotheses and\ncomputes the relative object pose in a single pass. To this end, we map the two\ninput RGB images, reference and query, to their respective voxelized 3D\nrepresentations. We then pass the resulting voxels through a pose estimation\nmodule, where the voxels are aligned and the pose is computed in an end-to-end\nfashion by solving a least-squares problem. To enhance robustness, we introduce\na weighted closest voxel algorithm capable of mitigating the impact of noisy\nvoxels. We conduct extensive experiments on the CO3D, LINEMOD, and Objaverse\ndatasets, demonstrating that our method delivers more accurate relative pose\nestimates for novel objects at a lower computational cost compared to\nstate-of-the-art methods. Our code is released at:\nhttps://github.com/sailor-z/DVMNet/.\n","authors":["Chen Zhao","Tong Zhang","Zheng Dang","Mathieu Salzmann"],"pdf_url":"https://arxiv.org/pdf/2403.13683v1.pdf","comment":"Accepted by CVPR 2024"},{"id":"http://arxiv.org/abs/2403.13674v1","updated":"2024-03-20T15:32:56Z","published":"2024-03-20T15:32:56Z","title":"Reward-Driven Automated Curriculum Learning for Interaction-Aware\n  Self-Driving at Unsignalized Intersections","summary":"  In this work, we present a reward-driven automated curriculum reinforcement\nlearning approach for interaction-aware self-driving at unsignalized\nintersections, taking into account the uncertainties associated with\nsurrounding vehicles (SVs). These uncertainties encompass the uncertainty of\nSVs' driving intention and also the quantity of SVs. To deal with this problem,\nthe curriculum set is specifically designed to accommodate a progressively\nincreasing number of SVs. By implementing an automated curriculum selection\nmechanism, the importance weights are rationally allocated across various\ncurricula, thereby facilitating improved sample efficiency and training\noutcomes. Furthermore, the reward function is meticulously designed to guide\nthe agent towards effective policy exploration. Thus the proposed framework\ncould proactively address the above uncertainties at unsignalized intersections\nby employing the automated curriculum learning technique that progressively\nincreases task difficulty, and this ensures safe self-driving through effective\ninteraction with SVs. Comparative experiments are conducted in $Highway\\_Env$,\nand the results indicate that our approach achieves the highest task success\nrate, attains strong robustness to initialization parameters of the curriculum\nselection module, and exhibits superior adaptability to diverse situational\nconfigurations at unsignalized intersections. Furthermore, the effectiveness of\nthe proposed method is validated using the high-fidelity CARLA simulator.\n","authors":["Zengqi Peng","Xiao Zhou","Lei Zheng","Yubin Wang","Jun Ma"],"pdf_url":"https://arxiv.org/pdf/2403.13674v1.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2403.13640v1","updated":"2024-03-20T14:43:51Z","published":"2024-03-20T14:43:51Z","title":"LaCE-LHMP: Airflow Modelling-Inspired Long-Term Human Motion Prediction\n  By Enhancing Laminar Characteristics in Human Flow","summary":"  Long-term human motion prediction (LHMP) is essential for safely operating\nautonomous robots and vehicles in populated environments. It is fundamental for\nvarious applications, including motion planning, tracking, human-robot\ninteraction and safety monitoring. However, accurate prediction of human\ntrajectories is challenging due to complex factors, including, for example,\nsocial norms and environmental conditions. The influence of such factors can be\ncaptured through Maps of Dynamics (MoDs), which encode spatial motion patterns\nlearned from (possibly scattered and partial) past observations of motion in\nthe environment and which can be used for data-efficient, interpretable motion\nprediction (MoD-LHMP). To address the limitations of prior work, especially\nregarding accuracy and sensitivity to anomalies in long-term prediction, we\npropose the Laminar Component Enhanced LHMP approach (LaCE-LHMP). Our approach\nis inspired by data-driven airflow modelling, which estimates laminar and\nturbulent flow components and uses predominantly the laminar components to make\nflow predictions. Based on the hypothesis that human trajectory patterns also\nmanifest laminar flow (that represents predictable motion) and turbulent flow\ncomponents (that reflect more unpredictable and arbitrary motion), LaCE-LHMP\nextracts the laminar patterns in human dynamics and uses them for human motion\nprediction. We demonstrate the superior prediction performance of LaCE-LHMP\nthrough benchmark comparisons with state-of-the-art LHMP methods, offering an\nunconventional perspective and a more intuitive understanding of human movement\npatterns.\n","authors":["Yufei Zhu","Han Fan","Andrey Rudenko","Martin Magnusson","Erik Schaffernicht","Achim J. Lilienthal"],"pdf_url":"https://arxiv.org/pdf/2403.13640v1.pdf","comment":"Accepted to the 2024 IEEE International Conference on Robotics and\n  Automation (ICRA)"},{"id":"http://arxiv.org/abs/2309.13139v3","updated":"2024-03-20T14:43:06Z","published":"2023-09-22T18:48:54Z","title":"Exposing the Unseen: Exposure Time Emulation for Offline Benchmarking of\n  Vision Algorithms","summary":"  Visual Odometry (VO) is one of the fundamental tasks in computer vision for\nrobotics. However, its performance is deeply affected by High Dynamic Range\n(HDR) scenes, omnipresent outdoor. While new Automatic-Exposure (AE) approaches\nto mitigate this have appeared, their comparison in a reproducible manner is\nproblematic. This stems from the fact that the behavior of AE depends on the\nenvironment, and it affects the image acquisition process. Consequently, AE has\ntraditionally only been benchmarked in an online manner, making the experiments\nnon-reproducible. To solve this, we propose a new methodology based on an\nemulator that can generate images at any exposure time. It leverages BorealHDR,\na unique multi-exposure stereo dataset collected over 10 km, on 55 trajectories\nwith challenging illumination conditions. Moreover, it includes\nlidar-inertial-based global maps with pose estimation for each image frame as\nwell as Global Navigation Satellite System (GNSS) data, for comparison. We show\nthat using these images acquired at different exposure times, we can emulate\nrealistic images, keeping a Root-Mean-Square Error (RMSE) below 1.78 % compared\nto ground truth images. To demonstrate the practicality of our approach for\noffline benchmarking, we compared three state-of-the-art AE algorithms on key\nelements of Visual Simultaneous Localization And Mapping (VSLAM) pipeline,\nagainst four baselines. Consequently, reproducible evaluation of AE is now\npossible, speeding up the development of future approaches. Our code and\ndataset are available online at this link:\nhttps://github.com/norlab-ulaval/BorealHDR\n","authors":["Olivier Gamache","Jean-Michel Fortin","Matěj Boxan","Maxime Vaidis","François Pomerleau","Philippe Giguère"],"pdf_url":"https://arxiv.org/pdf/2309.13139v3.pdf","comment":"8 pages, 6 figures, submitted to 2024 IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS 2024)"},{"id":"http://arxiv.org/abs/2302.05855v3","updated":"2024-03-20T14:37:54Z","published":"2023-02-12T04:41:59Z","title":"Investigation of Enhanced Inertial Navigation Algorithms by Functional\n  Iteration","summary":"  The defects of the traditional strapdown inertial navigation algorithms\nbecome well acknowledged and the corresponding enhanced algorithms have been\nquite recently proposed trying to mitigate both theoretical and algorithmic\ndefects. In this paper, the analytical accuracy evaluation of both the\ntraditional algorithms and the enhanced algorithms is investigated, against the\ntrue reference for the first time enabled by the functional iteration approach\nhaving provable convergence. The analyses by the help of MATLAB Symbolic\nToolbox show that the resultant error orders of all algorithms under\ninvestigation are consistent with those in the existing literatures, and the\nenhanced attitude algorithm notably reduces error orders of the traditional\ncounterpart, while the impact of the enhanced velocity algorithm on error order\nreduction is insignificant. Simulation results agree with analyses that the\nsuperiority of the enhanced algorithm over the traditional one in the\nbody-frame attitude computation scenario diminishes significantly in the entire\ninertial navigation computation scenario, while the functional iteration\napproach possesses significant accuracy superiority even under sustained lowly\ndynamic conditions.\n","authors":["Hongyan Jiang","Maoran Zhu","Yuanxin Wu"],"pdf_url":"https://arxiv.org/pdf/2302.05855v3.pdf","comment":"12 pages, 3 figs"},{"id":"http://arxiv.org/abs/2309.08854v2","updated":"2024-03-20T13:44:36Z","published":"2023-09-16T03:11:06Z","title":"Intention-Aware Planner for Robust and Safe Aerial Tracking","summary":"  Autonomous target tracking with quadrotors has wide applications in many\nscenarios, such as cinematographic follow-up shooting or suspect chasing.\nTarget motion prediction is necessary when designing the tracking planner.\nHowever, the widely used constant velocity or constant rotation assumption can\nnot fully capture the dynamics of the target. The tracker may fail when the\ntarget happens to move aggressively, such as sudden turn or deceleration. In\nthis paper, we propose an intention-aware planner by additionally considering\nthe intention of the target to enhance safety and robustness in aerial tracking\napplications. Firstly, a designated intention prediction method is proposed,\nwhich combines a user-defined potential assessment function and a state\nobservation function. A reachable region is generated to specifically evaluate\nthe turning intentions. Then we design an intention-driven hybrid A* method to\npredict the future possible positions for the target. Finally, an\nintention-aware optimization approach is designed to generate a\nspatial-temporal optimal trajectory, allowing the tracker to perceive\nunexpected situations from the target. Benchmark comparisons and real-world\nexperiments are conducted to validate the performance of our method.\n","authors":["Qiuyu Ren","Huan Yu","Jiajun Dai","Zhi Zheng","Jun Meng","Li Xu","Chao Xu","Fei Gao","Yanjun Cao"],"pdf_url":"https://arxiv.org/pdf/2309.08854v2.pdf","comment":"8 pages, 10 figures, submitted to 2024 IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS)"},{"id":"http://arxiv.org/abs/2306.11335v4","updated":"2024-03-20T13:18:18Z","published":"2023-06-20T07:06:04Z","title":"Surfer: Progressive Reasoning with World Models for Robotic Manipulation","summary":"  Considering how to make the model accurately understand and follow natural\nlanguage instructions and perform actions consistent with world knowledge is a\nkey challenge in robot manipulation. This mainly includes human fuzzy\ninstruction reasoning and the following of physical knowledge. Therefore, the\nembodied intelligence agent must have the ability to model world knowledge from\ntraining data. However, most existing vision and language robot manipulation\nmethods mainly operate in less realistic simulator and language settings and\nlack explicit modeling of world knowledge. To bridge this gap, we introduce a\nnovel and simple robot manipulation framework, called Surfer. It is based on\nthe world model, treats robot manipulation as a state transfer of the visual\nscene, and decouples it into two parts: action and scene. Then, the\ngeneralization ability of the model on new instructions and new scenes is\nenhanced by explicit modeling of the action and scene prediction in multi-modal\ninformation. In addition to the framework, we also built a robot manipulation\nsimulator that supports full physics execution based on the MuJoCo physics\nengine. It can automatically generate demonstration training data and test\ndata, effectively reducing labor costs. To conduct a comprehensive and\nsystematic evaluation of the robot manipulation model in terms of language\nunderstanding and physical execution, we also created a robotic manipulation\nbenchmark with progressive reasoning tasks, called SeaWave. It contains 4\nlevels of progressive reasoning tasks and can provide a standardized testing\nplatform for embedded AI agents in multi-modal environments. On average, Surfer\nachieved a success rate of 54.74% on the defined four levels of manipulation\ntasks, exceeding the best baseline performance of 47.64%.\n","authors":["Pengzhen Ren","Kaidong Zhang","Hetao Zheng","Zixuan Li","Yuhang Wen","Fengda Zhu","Mas Ma","Xiaodan Liang"],"pdf_url":"https://arxiv.org/pdf/2306.11335v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11552v2","updated":"2024-03-20T13:15:39Z","published":"2024-03-18T08:03:47Z","title":"LLM3:Large Language Model-based Task and Motion Planning with Motion\n  Failure Reasoning","summary":"  Conventional Task and Motion Planning (TAMP) approaches rely on manually\ncrafted interfaces connecting symbolic task planning with continuous motion\ngeneration. These domain-specific and labor-intensive modules are limited in\naddressing emerging tasks in real-world settings. Here, we present LLM^3, a\nnovel Large Language Model (LLM)-based TAMP framework featuring a\ndomain-independent interface. Specifically, we leverage the powerful reasoning\nand planning capabilities of pre-trained LLMs to propose symbolic action\nsequences and select continuous action parameters for motion planning.\nCrucially, LLM^3 incorporates motion planning feedback through prompting,\nallowing the LLM to iteratively refine its proposals by reasoning about motion\nfailure. Consequently, LLM^3 interfaces between task planning and motion\nplanning, alleviating the intricate design process of handling domain-specific\nmessages between them. Through a series of simulations in a box-packing domain,\nwe quantitatively demonstrate the effectiveness of LLM^3 in solving TAMP\nproblems and the efficiency in selecting action parameters. Ablation studies\nunderscore the significant contribution of motion failure reasoning to the\nsuccess of LLM^3. Furthermore, we conduct qualitative experiments on a physical\nmanipulator, demonstrating the practical applicability of our approach in\nreal-world settings.\n","authors":["Shu Wang","Muzhi Han","Ziyuan Jiao","Zeyu Zhang","Ying Nian Wu","Song-Chun Zhu","Hangxin Liu"],"pdf_url":"https://arxiv.org/pdf/2403.11552v2.pdf","comment":"Submitted to IROS 2024. Codes available:\n  https://github.com/AssassinWS/LLM-TAMP"},{"id":"http://arxiv.org/abs/2307.07975v3","updated":"2024-03-20T12:30:01Z","published":"2023-07-16T07:55:35Z","title":"Pseudo-rigid body networks: learning interpretable deformable object\n  dynamics from partial observations","summary":"  Accurate prediction of deformable linear object (DLO) dynamics is challenging\nif the task at hand requires a human-interpretable yet computationally fast\nmodel. In this work, we draw inspiration from the pseudo-rigid body method\n(PRB) and model a DLO as a serial chain of rigid bodies whose internal state is\nunrolled through time by a dynamics network. This dynamics network is trained\njointly with a physics-informed encoder which maps observed motion variables to\nthe DLO's hidden state. To encourage that the state acquires a physically\nmeaningful representation, we leverage the forward kinematics of the PRB model\nas decoder. We demonstrate in robot experiments that the proposed DLO dynamics\nmodel provides physically interpretable predictions from partial observations\nwhile being on par with black-box models regarding prediction accuracy. The\nproject code is available at: http://tinyurl.com/prb-networks\n","authors":["Shamil Mamedov","A. René Geist","Jan Swevers","Sebastian Trimpe"],"pdf_url":"https://arxiv.org/pdf/2307.07975v3.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2403.13541v1","updated":"2024-03-20T12:26:02Z","published":"2024-03-20T12:26:02Z","title":"From One to Many: How Active Robot Swarm Sizes Influence Human Cognitive\n  Processes","summary":"  In robotics, understanding human interaction with autonomous systems is\ncrucial for enhancing collaborative technologies. We focus on human-swarm\ninteraction (HSI), exploring how differently sized groups of active robots\naffect operators' cognitive and perceptual reactions over different durations.\nWe analyze the impact of different numbers of active robots within a 15-robot\nswarm on operators' time perception, emotional state, flow experience, and task\ndifficulty perception. Our findings indicate that managing multiple active\nrobots when compared to one active robot significantly alters time perception\nand flow experience, leading to a faster passage of time and increased flow.\nMore active robots and extended durations cause increased emotional arousal and\nperceived task difficulty, highlighting the interaction between robot the\nnumber of active robots and human cognitive processes. These insights inform\nthe creation of intuitive human-swarm interfaces and aid in developing swarm\nrobotic systems aligned with human cognitive structures, enhancing human-robot\ncollaboration.\n","authors":["Julian Kaduk","Müge Cavdan","Knut Drewing","Heiko Hamann"],"pdf_url":"https://arxiv.org/pdf/2403.13541v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2403.13518v1","updated":"2024-03-20T11:38:30Z","published":"2024-03-20T11:38:30Z","title":"Motion Generation from Fine-grained Textual Descriptions","summary":"  The task of text2motion is to generate motion sequences from given textual\ndescriptions, where a model should explore the interactions between natural\nlanguage instructions and human body movements. While most existing works are\nconfined to coarse-grained motion descriptions (e.g., \"A man squats.\"),\nfine-grained ones specifying movements of relevant body parts are barely\nexplored. Models trained with coarse texts may not be able to learn mappings\nfrom fine-grained motion-related words to motion primitives, resulting in the\nfailure in generating motions from unseen descriptions. In this paper, we build\na large-scale language-motion dataset with fine-grained textual descriptions,\nFineHumanML3D, by feeding GPT-3.5-turbo with delicate prompts. Accordingly, we\ndesign a new text2motion model, FineMotionDiffuse, which makes full use of\nfine-grained textual information. Our experiments show that FineMotionDiffuse\ntrained on FineHumanML3D acquires good results in quantitative evaluation. We\nalso find this model can better generate spatially/chronologically composite\nmotions by learning the implicit mappings from simple descriptions to the\ncorresponding basic motions.\n","authors":["Kunhang Li","Yansong Feng"],"pdf_url":"https://arxiv.org/pdf/2403.13518v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13474v1","updated":"2024-03-20T10:22:22Z","published":"2024-03-20T10:22:22Z","title":"Iterative Active-Inactive Obstacle Classification for Time-Optimal\n  Collision Avoidance","summary":"  Time-optimal obstacle avoidance is a prevalent problem encountered in various\nfields, including robotics and autonomous vehicles, where the task involves\ndetermining a path for a moving vehicle to reach its goal while navigating\naround obstacles within its environment. This problem becomes increasingly\nchallenging as the number of obstacles in the environment rises. We propose an\niterative active-inactive obstacle approach, which involves identifying a\nsubset of the obstacles as \"active\", that considers solely the effect of the\n\"active\" obstacles on the path of the moving vehicle. The remaining obstacles\nare considered \"inactive\" and are not considered in the path planning process.\nThe obstacles are classified as 'active' on the basis of previous findings\nderived from prior iterations. This approach allows for a more efficient\ncalculation of the optimal path by reducing the number of obstacles that need\nto be considered. The effectiveness of the proposed method is demonstrated with\ntwo different dynamic models using the various number of obstacles. The results\nshow that the proposed method is able to find the optimal path in a timely\nmanner, while also being able to handle a large number of obstacles in the\nenvironment and the constraints on the motion of the object.\n","authors":["Mehmetcan Kaymaz","Nazim Kemal Ure"],"pdf_url":"https://arxiv.org/pdf/2403.13474v1.pdf","comment":"This paper is under review in IROS24"},{"id":"http://arxiv.org/abs/2403.13467v1","updated":"2024-03-20T10:17:39Z","published":"2024-03-20T10:17:39Z","title":"CLIPSwarm: Generating Drone Shows from Text Prompts with Vision-Language\n  Models","summary":"  This paper introduces CLIPSwarm, a new algorithm designed to automate the\nmodeling of swarm drone formations based on natural language. The algorithm\nbegins by enriching a provided word, to compose a text prompt that serves as\ninput to an iterative approach to find the formation that best matches the\nprovided word. The algorithm iteratively refines formations of robots to align\nwith the textual description, employing different steps for \"exploration\" and\n\"exploitation\". Our framework is currently evaluated on simple formation\ntargets, limited to contour shapes. A formation is visually represented through\nalpha-shape contours and the most representative color is automatically found\nfor the input word. To measure the similarity between the description and the\nvisual representation of the formation, we use CLIP [1], encoding text and\nimages into vectors and assessing their similarity. Subsequently, the algorithm\nrearranges the formation to visually represent the word more effectively,\nwithin the given constraints of available drones. Control actions are then\nassigned to the drones, ensuring robotic behavior and collision-free movement.\nExperimental results demonstrate the system's efficacy in accurately modeling\nrobot formations from natural language descriptions. The algorithm's\nversatility is showcased through the execution of drone shows in photorealistic\nsimulation with varying shapes. We refer the reader to the supplementary video\nfor a visual reference of the results.\n","authors":["Pablo Pueyo","Eduardo Montijano","Ana C. Murillo","Mac Schwager"],"pdf_url":"https://arxiv.org/pdf/2403.13467v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13455v1","updated":"2024-03-20T10:01:52Z","published":"2024-03-20T10:01:52Z","title":"FACT: Fast and Active Coordinate Initialization for Vision-based Drone\n  Swarms","summary":"  Swarm robots have sparked remarkable developments across a range of fields.\nWhile it is necessary for various applications in swarm robots, a fast and\nrobust coordinate initialization in vision-based drone swarms remains elusive.\nTo this end, our paper proposes a complete system to recover a swarm's initial\nrelative pose on platforms with size, weight, and power (SWaP) constraints. To\novercome limited coverage of field-of-view (FoV), the drones rotate in place to\nobtain observations. To tackle the anonymous measurements, we formulate a\nnon-convex rotation estimation problem and transform it into a semi-definite\nprogramming (SDP) problem, which can steadily obtain global optimal values.\nThen we utilize the Hungarian algorithm to recover relative translation and\ncorrespondences between observations and drone identities. To safely acquire\ncomplete observations, we actively search for positions and generate feasible\ntrajectories to avoid collisions. To validate the practicability of our system,\nwe conduct experiments on a vision-based drone swarm with only stereo cameras\nand inertial measurement units (IMUs) as sensors. The results demonstrate that\nthe system can robustly get accurate relative poses in real time with limited\nonboard computation resources. The source code is released.\n","authors":["Yuan Li","Anke Zhao","Yingjian Wang","Ziyi Xu","Xin Zhou","Jinni Zhou","Chao Xu","Fei Gao"],"pdf_url":"https://arxiv.org/pdf/2403.13455v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13452v1","updated":"2024-03-20T09:53:31Z","published":"2024-03-20T09:53:31Z","title":"Mobile Robot Localization: a Modular, Odometry-Improving Approach","summary":"  Despite the number of works published in recent years, vehicle localization\nremains an open, challenging problem. While map-based localization and SLAM\nalgorithms are getting better and better, they remain a single point of failure\nin typical localization pipelines. This paper proposes a modular localization\narchitecture that fuses sensor measurements with the outputs of off-the-shelf\nlocalization algorithms. The fusion filter estimates model uncertainties to\nimprove odometry in case absolute pose measurements are lost entirely. The\narchitecture is validated experimentally on a real robot navigating\nautonomously proving a reduction of the position error of more than 90% with\nrespect to the odometrical estimate without uncertainty estimation in a\ntwo-minute navigation period without position measurements.\n","authors":["Luca Mozzarelli","Luca Cattaneo","Matteo Corno","Sergio Matteo Savaresi"],"pdf_url":"https://arxiv.org/pdf/2403.13452v1.pdf","comment":"Accepted at IEEE European Control Conference 2024"},{"id":"http://arxiv.org/abs/2403.13443v1","updated":"2024-03-20T09:39:39Z","published":"2024-03-20T09:39:39Z","title":"Fast-Poly: A Fast Polyhedral Framework For 3D Multi-Object Tracking","summary":"  3D Multi-Object Tracking (MOT) captures stable and comprehensive motion\nstates of surrounding obstacles, essential for robotic perception. However,\ncurrent 3D trackers face issues with accuracy and latency consistency. In this\npaper, we propose Fast-Poly, a fast and effective filter-based method for 3D\nMOT. Building upon our previous work Poly-MOT, Fast-Poly addresses object\nrotational anisotropy in 3D space, enhances local computation densification,\nand leverages parallelization technique, improving inference speed and\nprecision. Fast-Poly is extensively tested on two large-scale tracking\nbenchmarks with Python implementation. On the nuScenes dataset, Fast-Poly\nachieves new state-of-the-art performance with 75.8% AMOTA among all methods\nand can run at 34.2 FPS on a personal CPU. On the Waymo dataset, Fast-Poly\nexhibits competitive accuracy with 63.6% MOTA and impressive inference speed\n(35.5 FPS). The source code is publicly available at\nhttps://github.com/lixiaoyu2000/FastPoly.\n","authors":["Xiaoyu Li","Dedong Liu","Lijun Zhao","Yitao Wu","Xian Wu","Jinghan Gao"],"pdf_url":"https://arxiv.org/pdf/2403.13443v1.pdf","comment":"1st on the NuScenes Tracking benchmark with 75.8 AMOTA and 34.2 FPS"},{"id":"http://arxiv.org/abs/2403.13431v1","updated":"2024-03-20T09:18:19Z","published":"2024-03-20T09:18:19Z","title":"Automatic Navigation Map Generation for Mobile Robots in Urban\n  Environments","summary":"  A fundamental prerequisite for safe and efficient navigation of mobile robots\nis the availability of reliable navigation maps upon which trajectories can be\nplanned. With the increasing industrial interest in mobile robotics, especially\nin urban environments, the process of generating navigation maps has become of\nparticular interest, being a labor intensive step of the deployment process.\nAutomating this step is challenging and becomes even more arduous when the\nperception capabilities are limited by cost considerations. This paper proposes\nan algorithm to automatically generate navigation maps using a typical\nnavigation-oriented sensor setup: a single top-mounted 3D LiDAR sensor. The\nproposed method is designed and validated with the urban environment as the\nmain use case: it is shown to be able to produce accurate maps featuring\ndifferent terrain types, positive obstacles of different heights as well as\nnegative obstacles. The algorithm is applied to data collected in a typical\nurban environment with a wheeled inverted pendulum robot, showing its\nrobustness against localization, perception and dynamic uncertainties. The\ngenerated map is validated against a human-made map.\n","authors":["Luca Mozzarelli","Simone Specchia","Matteo Corno","Sergio Matteo Savaresi"],"pdf_url":"https://arxiv.org/pdf/2403.13431v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.04530v2","updated":"2024-03-20T09:12:21Z","published":"2023-12-07T18:50:01Z","title":"Camera Height Doesn't Change: Unsupervised Training for Metric Monocular\n  Road-Scene Depth Estimation","summary":"  In this paper, we introduce a novel training method for making any monocular\ndepth network learn absolute scale and estimate metric road-scene depth just\nfrom regular training data, i.e., driving videos. We refer to this training\nframework as StableCamH. The key idea is to leverage cars found on the road as\nsources of scale supervision but to incorporate them in the training robustly.\nStableCamH detects and estimates the sizes of cars in the frame and aggregates\nscale information extracted from them into a camera height estimate whose\nconsistency across the entire video sequence is enforced as scale supervision.\nThis realizes robust unsupervised training of any, otherwise scale-oblivious,\nmonocular depth network to become not only scale-aware but also metric-accurate\nwithout the need for auxiliary sensors and extra supervision. Extensive\nexperiments on the KITTI and Cityscapes datasets show the effectiveness of\nStableCamH and its state-of-the-art accuracy compared with related methods. We\nalso show that StableCamH enables training on mixed datasets of different\ncamera heights, which leads to larger-scale training and thus higher\ngeneralization. Metric depth reconstruction is essential in any road-scene\nvisual modeling, and StableCamH democratizes its deployment by establishing the\nmeans to train any model as a metric depth estimator.\n","authors":["Genki Kinoshita","Ko Nishino"],"pdf_url":"https://arxiv.org/pdf/2312.04530v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13421v1","updated":"2024-03-20T09:07:23Z","published":"2024-03-20T09:07:23Z","title":"Caching-Augmented Lifelong Multi-Agent Path Finding","summary":"  Multi-Agent Path Finding (MAPF), which involves finding collision-free paths\nfor multiple robots, is crucial in various applications. Lifelong MAPF, where\ntargets are reassigned to agents as soon as they complete their initial\nobjectives, offers a more accurate approximation of real-world warehouse\nplanning. In this paper, we present a novel mechanism named Caching-Augmented\nLifelong MAPF (CAL-MAPF), designed to improve the performance of Lifelong MAPF.\nWe have developed a new map grid type called cache for temporary item storage\nand replacement and designed a lock mechanism for it to improve the stability\nof the planning solution. This cache mechanism was evaluated using various\ncache replacement policies and a spectrum of input task distributions. We\nidentified three main factors significantly impacting CAL-MAPF performance\nthrough experimentation: suitable input task distribution, high cache hit rate,\nand smooth traffic. Overall, CAL-MAPF has demonstrated potential for\nperformance improvements in certain task distributions, maps and agent\nconfigurations.\n","authors":["Yimin Tang","Zhenghong Yu","Yi Zheng","T. K. Satish Kumar","Jiaoyang Li","Sven Koenig"],"pdf_url":"https://arxiv.org/pdf/2403.13421v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.08221v2","updated":"2024-03-20T08:52:04Z","published":"2023-07-17T03:45:47Z","title":"NDT-Map-Code: A 3D global descriptor for real-time loop closure\n  detection in lidar SLAM","summary":"  Loop-closure detection, also known as place recognition, aiming to identify\npreviously visited locations, is an essential component of a SLAM system.\nExisting research on lidar-based loop closure heavily relies on dense point\ncloud and 360 FOV lidars. This paper proposes an out-of-the-box NDT (Normal\nDistribution Transform) based global descriptor, NDT-Map-Code, designed for\nboth on-road driving and underground valet parking scenarios. NDT-Map-Code can\nbe directly extracted from the NDT map without the need for a dense point\ncloud, resulting in excellent scalability and low maintenance cost. The NDT\nrepresentation is leveraged to identify representative patterns, which are\nfurther encoded according to their spatial location (bearing, range, and\nheight). Experimental results on the NIO underground parking lot dataset and\nthe KITTI dataset demonstrate that our method achieves significantly better\nperformance compared to the state-of-the-art.\n","authors":["Lizhou Liao","Wenlei Yan","Li Sun","Xinhui Bai","Zhenxing You","Hongyuan Yuan","Chunyun Fu"],"pdf_url":"https://arxiv.org/pdf/2307.08221v2.pdf","comment":"8 pages, 6 figures, 4 tables"},{"id":"http://arxiv.org/abs/2206.06112v3","updated":"2024-03-20T08:41:49Z","published":"2022-06-13T12:53:54Z","title":"Vision-State Fusion: Improving Deep Neural Networks for Autonomous\n  Robotics","summary":"  Vision-based deep learning perception fulfills a paramount role in robotics,\nfacilitating solutions to many challenging scenarios, such as acrobatic\nmaneuvers of autonomous unmanned aerial vehicles (UAVs) and robot-assisted\nhigh-precision surgery. Control-oriented end-to-end perception approaches,\nwhich directly output control variables for the robot, commonly take advantage\nof the robot's state estimation as an auxiliary input. When intermediate\noutputs are estimated and fed to a lower-level controller, i.e. mediated\napproaches, the robot's state is commonly used as an input only for egocentric\ntasks, which estimate physical properties of the robot itself. In this work, we\npropose to apply a similar approach for the first time -- to the best of our\nknowledge -- to non-egocentric mediated tasks, where the estimated outputs\nrefer to an external subject. We prove how our general methodology improves the\nregression performance of deep convolutional neural networks (CNNs) on a broad\nclass of non-egocentric 3D pose estimation problems, with minimal computational\ncost. By analyzing three highly-different use cases, spanning from grasping\nwith a robotic arm to following a human subject with a pocket-sized UAV, our\nresults consistently improve the R\\textsuperscript{2} regression metric, up to\n+0.51, compared to their stateless baselines. Finally, we validate the in-field\nperformance of a closed-loop autonomous cm-scale UAV on the human pose\nestimation task. Our results show a significant reduction, i.e., 24\\% on\naverage, on the mean absolute error of our stateful CNN, compared to a\nState-of-the-Art stateless counterpart.\n","authors":["Elia Cereda","Stefano Bonato","Mirko Nava","Alessandro Giusti","Daniele Palossi"],"pdf_url":"https://arxiv.org/pdf/2206.06112v3.pdf","comment":"This paper has been accepted for publication in the Journal of\n  Intelligent & Robotic Systems. \\copyright 2024 Springer"},{"id":"http://arxiv.org/abs/2403.13395v1","updated":"2024-03-20T08:35:57Z","published":"2024-03-20T08:35:57Z","title":"Unifying Local and Global Multimodal Features for Place Recognition in\n  Aliased and Low-Texture Environments","summary":"  Perceptual aliasing and weak textures pose significant challenges to the task\nof place recognition, hindering the performance of Simultaneous Localization\nand Mapping (SLAM) systems. This paper presents a novel model, called UMF\n(standing for Unifying Local and Global Multimodal Features) that 1) leverages\nmulti-modality by cross-attention blocks between vision and LiDAR features, and\n2) includes a re-ranking stage that re-orders based on local feature matching\nthe top-k candidates retrieved using a global representation. Our experiments,\nparticularly on sequences captured on a planetary-analogous environment, show\nthat UMF outperforms significantly previous baselines in those challenging\naliased environments. Since our work aims to enhance the reliability of SLAM in\nall situations, we also explore its performance on the widely used RobotCar\ndataset, for broader applicability. Code and models are available at\nhttps://github.com/DLR-RM/UMF\n","authors":["Alberto García-Hernández","Riccardo Giubilato","Klaus H. Strobl","Javier Civera","Rudolph Triebel"],"pdf_url":"https://arxiv.org/pdf/2403.13395v1.pdf","comment":"Accepted submission to International Conference on Robotics and\n  Automation (ICRA), 2024"},{"id":"http://arxiv.org/abs/2401.01657v3","updated":"2024-03-20T08:15:37Z","published":"2024-01-03T10:31:12Z","title":"Distributed Pose-graph Optimization with Multi-level Partitioning for\n  Collaborative SLAM","summary":"  The back-end module of Distributed Collaborative Simultaneous Localization\nand Mapping (DCSLAM) requires solving a nonlinear Pose Graph Optimization (PGO)\nunder a distributed setting, also known as SE(d)-synchronization. Most existing\ndistributed graph optimization algorithms employ a simple sequential\npartitioning scheme, which may result in unbalanced subgraph dimensions due to\nthe different geographic locations of each robot, and hence imposes extra\ncommunication load. Moreover, the performance of current Riemannian\noptimization algorithms can be further accelerated. In this letter, we propose\na novel distributed pose graph optimization algorithm combining multi-level\npartitioning with an accelerated Riemannian optimization method. Firstly, we\nemploy the multi-level graph partitioning algorithm to preprocess the naive\npose graph to formulate a balanced optimization problem. In addition, inspired\nby the accelerated coordinate descent method, we devise an Improved Riemannian\nBlock Coordinate Descent (IRBCD) algorithm and the critical point obtained is\nglobally optimal. Finally, we evaluate the effects of four common graph\npartitioning approaches on the correlation of the inter-subgraphs, and discover\nthat the Highest scheme has the best partitioning performance. Also, we\nimplement simulations to quantitatively demonstrate that our proposed algorithm\noutperforms the state-of-the-art distributed pose graph optimization protocols.\n","authors":["Cunhao Li","Peng Yi","Guanghui Guo","Yiguang Hong"],"pdf_url":"https://arxiv.org/pdf/2401.01657v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.01233v2","updated":"2024-03-20T07:52:35Z","published":"2024-03-02T15:32:15Z","title":"Results and Lessons Learned from Autonomous Driving Transportation\n  Services in Airfield, Crowded Indoor, and Urban Environments","summary":"  Autonomous vehicles have been actively investigated over the past few\ndecades. Several recent works show the potential of autonomous vehicles in\nurban environments with impressive experimental results. However, these works\nnote that autonomous vehicles are still occasionally inferior to expert drivers\nin complex scenarios. Furthermore, they do not focus on the possibilities of\nautonomous driving transportation services in other areas beyond urban\nenvironments. This paper presents the research results and lessons learned from\nautonomous driving transportation services in airfield, crowded indoor, and\nurban environments. We discuss how we address several unique challenges in\nthese diverse environments. We also offer an overview of remaining challenges\nthat have not received much attention but must be addressed. This paper aims to\nshare our unique experience to support researchers who are interested in\nexploring autonomous driving transportation services in various real-world\nenvironments.\n","authors":["Doosan Baek","Sanghyun Kim","Seung-Woo Seo","Sang-Hyun Lee"],"pdf_url":"https://arxiv.org/pdf/2403.01233v2.pdf","comment":"8 pages, 7 figures, 4 tables"},{"id":"http://arxiv.org/abs/2403.13366v1","updated":"2024-03-20T07:51:53Z","published":"2024-03-20T07:51:53Z","title":"Centroidal State Estimation based on the Koopman Embedding for Dynamic\n  Legged Locomotion","summary":"  In this paper, we introduce a novel approach to centroidal state estimation,\nwhich plays a crucial role in predictive model-based control strategies for\ndynamic legged locomotion. Our approach uses the Koopman operator theory to\ntransform the robot's complex nonlinear dynamics into a linear system, by\nemploying dynamic mode decomposition and deep learning for model construction.\nWe evaluate both models on their linearization accuracy and capability to\ncapture both fast and slow dynamic system responses. We then select the most\nsuitable model for estimation purposes, and integrate it within a moving\nhorizon estimator. This estimator is formulated as a convex quadratic program,\nto facilitate robust, real-time centroidal state estimation. Through extensive\nsimulation experiments on a quadruped robot executing various dynamic gaits,\nour data-driven framework outperforms conventional filtering techniques based\non nonlinear dynamics. Our estimator addresses challenges posed by force/torque\nmeasurement noise in highly dynamic motions and accurately recovers the\ncentroidal states, demonstrating the adaptability and effectiveness of the\nKoopman-based linear representation for complex locomotive behaviors.\nImportantly, our model based on dynamic mode decomposition, trained with two\nlocomotion patterns (trot and jump), successfully estimates the centroidal\nstates for a different motion (bound) without retraining.\n","authors":["Shahram Khorshidi","Murad Dawood","Maren Bennewitz"],"pdf_url":"https://arxiv.org/pdf/2403.13366v1.pdf","comment":"Submitted to IROS 2024"},{"id":"http://arxiv.org/abs/2403.13365v1","updated":"2024-03-20T07:48:32Z","published":"2024-03-20T07:48:32Z","title":"ManiPose: A Comprehensive Benchmark for Pose-aware Object Manipulation\n  in Robotics","summary":"  Robotic manipulation in everyday scenarios, especially in unstructured\nenvironments, requires skills in pose-aware object manipulation (POM), which\nadapts robots' grasping and handling according to an object's 6D pose.\nRecognizing an object's position and orientation is crucial for effective\nmanipulation. For example, if a mug is lying on its side, it's more effective\nto grasp it by the rim rather than the handle. Despite its importance, research\nin POM skills remains limited, because learning manipulation skills requires\npose-varying simulation environments and datasets. This paper introduces\nManiPose, a pioneering benchmark designed to advance the study of pose-varying\nmanipulation tasks. ManiPose encompasses: 1) Simulation environments for POM\nfeature tasks ranging from 6D pose-specific pick-and-place of single objects to\ncluttered scenes, further including interactions with articulated objects. 2) A\ncomprehensive dataset featuring geometrically consistent and\nmanipulation-oriented 6D pose labels for 2936 real-world scanned rigid objects\nand 100 articulated objects across 59 categories. 3) A baseline for POM,\nleveraging the inferencing abilities of LLM (e.g., ChatGPT) to analyze the\nrelationship between 6D pose and task-specific requirements, offers enhanced\npose-aware grasp prediction and motion planning capabilities. Our benchmark\ndemonstrates notable advancements in pose estimation, pose-aware manipulation,\nand real-robot skill transfer, setting new standards for POM research. We will\nopen-source the ManiPose benchmark with the final version paper, inviting the\ncommunity to engage with our resources, available at our\nwebsite:https://sites.google.com/view/manipose.\n","authors":["Qiaojun Yu","Ce Hao","Junbo Wang","Wenhai Liu","Liu Liu","Yao Mu","Yang You","Hengxu Yan","Cewu Lu"],"pdf_url":"https://arxiv.org/pdf/2403.13365v1.pdf","comment":"8 pages, 7 figures, submitted to 2024 IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS 2024)"},{"id":"http://arxiv.org/abs/2403.13358v1","updated":"2024-03-20T07:36:43Z","published":"2024-03-20T07:36:43Z","title":"GeRM: A Generalist Robotic Model with Mixture-of-experts for Quadruped\n  Robot","summary":"  Multi-task robot learning holds significant importance in tackling diverse\nand complex scenarios. However, current approaches are hindered by performance\nissues and difficulties in collecting training datasets. In this paper, we\npropose GeRM (Generalist Robotic Model). We utilize offline reinforcement\nlearning to optimize data utilization strategies to learn from both\ndemonstrations and sub-optimal data, thus surpassing the limitations of human\ndemonstrations. Thereafter, we employ a transformer-based VLA network to\nprocess multi-modal inputs and output actions. By introducing the\nMixture-of-Experts structure, GeRM allows faster inference speed with higher\nwhole model capacity, and thus resolves the issue of limited RL parameters,\nenhancing model performance in multi-task learning while controlling\ncomputational costs. Through a series of experiments, we demonstrate that GeRM\noutperforms other methods across all tasks, while also validating its\nefficiency in both training and inference processes. Additionally, we uncover\nits potential to acquire emergent skills. Additionally, we contribute the\nQUARD-Auto dataset, collected automatically to support our training approach\nand foster advancements in multi-task quadruped robot learning. This work\npresents a new paradigm for reducing the cost of collecting robot data and\ndriving progress in the multi-task learning community.\n","authors":["Wenxuan Song","Han Zhao","Pengxiang Ding","Can Cui","Shangke Lyu","Yaning Fan","Donglin Wang"],"pdf_url":"https://arxiv.org/pdf/2403.13358v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13348v1","updated":"2024-03-20T07:19:53Z","published":"2024-03-20T07:19:53Z","title":"MULAN-WC: Multi-Robot Localization Uncertainty-aware Active NeRF with\n  Wireless Coordination","summary":"  This paper presents MULAN-WC, a novel multi-robot 3D reconstruction framework\nthat leverages wireless signal-based coordination between robots and Neural\nRadiance Fields (NeRF). Our approach addresses key challenges in multi-robot 3D\nreconstruction, including inter-robot pose estimation, localization uncertainty\nquantification, and active best-next-view selection. We introduce a method for\nusing wireless Angle-of-Arrival (AoA) and ranging measurements to estimate\nrelative poses between robots, as well as quantifying and incorporating the\nuncertainty embedded in the wireless localization of these pose estimates into\nthe NeRF training loss to mitigate the impact of inaccurate camera poses.\nFurthermore, we propose an active view selection approach that accounts for\nrobot pose uncertainty when determining the next-best views to improve the 3D\nreconstruction, enabling faster convergence through intelligent view selection.\nExtensive experiments on both synthetic and real-world datasets demonstrate the\neffectiveness of our framework in theory and in practice. Leveraging wireless\ncoordination and localization uncertainty-aware training, MULAN-WC can achieve\nhigh-quality 3d reconstruction which is close to applying the ground truth\ncamera poses. Furthermore, the quantification of the information gain from a\nnovel view enables consistent rendering quality improvement with incrementally\ncaptured images by commending the robot the novel view position. Our hardware\nexperiments showcase the practicality of deploying MULAN-WC to real robotic\nsystems.\n","authors":["Weiying Wang","Victor Cai","Stephanie Gil"],"pdf_url":"https://arxiv.org/pdf/2403.13348v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13336v1","updated":"2024-03-20T06:42:12Z","published":"2024-03-20T06:42:12Z","title":"Discretizing SO(2)-Equivariant Features for Robotic Kitting","summary":"  Robotic kitting has attracted considerable attention in logistics and\nindustrial settings. However, existing kitting methods encounter challenges\nsuch as low precision and poor efficiency, limiting their widespread\napplications. To address these issues, we present a novel kitting framework\nthat improves both the precision and computational efficiency of complex\nkitting tasks. Firstly, our approach introduces a fine-grained orientation\nestimation technique in the picking module, significantly enhancing orientation\nprecision while effectively decoupling computational load from orientation\ngranularity. This approach combines an SO(2)-equivariant network with a group\ndiscretization operation to preciously predict discrete orientation\ndistributions. Secondly, we develop the Hand-tool Kitting Dataset (HKD) to\nevaluate the performance of different solutions in handling\norientation-sensitive kitting tasks. This dataset comprises a diverse\ncollection of hand tools and synthetically created kits, which reflects the\ncomplexities encountered in real-world kitting scenarios. Finally, a series of\nexperiments are conducted to evaluate the performance of the proposed method.\nThe results demonstrate that our approach offers remarkable precision and\nenhanced computational efficiency in robotic kitting tasks.\n","authors":["Jiadong Zhou","Yadan Zeng","Huixu Dong","I-Ming Chen"],"pdf_url":"https://arxiv.org/pdf/2403.13336v1.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2403.13331v1","updated":"2024-03-20T06:22:37Z","published":"2024-03-20T06:22:37Z","title":"AMP: Autoregressive Motion Prediction Revisited with Next Token\n  Prediction for Autonomous Driving","summary":"  As an essential task in autonomous driving (AD), motion prediction aims to\npredict the future states of surround objects for navigation. One natural\nsolution is to estimate the position of other agents in a step-by-step manner\nwhere each predicted time-step is conditioned on both observed time-steps and\npreviously predicted time-steps, i.e., autoregressive prediction. Pioneering\nworks like SocialLSTM and MFP design their decoders based on this intuition.\nHowever, almost all state-of-the-art works assume that all predicted time-steps\nare independent conditioned on observed time-steps, where they use a single\nlinear layer to generate positions of all time-steps simultaneously. They\ndominate most motion prediction leaderboards due to the simplicity of training\nMLPs compared to autoregressive networks.\n  In this paper, we introduce the GPT style next token prediction into motion\nforecasting. In this way, the input and output could be represented in a\nunified space and thus the autoregressive prediction becomes more feasible.\nHowever, different from language data which is composed of homogeneous units\n-words, the elements in the driving scene could have complex spatial-temporal\nand semantic relations. To this end, we propose to adopt three factorized\nattention modules with different neighbors for information aggregation and\ndifferent position encoding styles to capture their relations, e.g., encoding\nthe transformation between coordinate systems for spatial relativity while\nadopting RoPE for temporal relativity. Empirically, by equipping with the\naforementioned tailored designs, the proposed method achieves state-of-the-art\nperformance in the Waymo Open Motion and Waymo Interaction datasets. Notably,\nAMP outperforms other recent autoregressive motion prediction methods: MotionLM\nand StateTransformer, which demonstrates the effectiveness of the proposed\ndesigns.\n","authors":["Xiaosong Jia","Shaoshuai Shi","Zijun Chen","Li Jiang","Wenlong Liao","Tao He","Junchi Yan"],"pdf_url":"https://arxiv.org/pdf/2403.13331v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13321v1","updated":"2024-03-20T05:57:20Z","published":"2024-03-20T05:57:20Z","title":"Robotics meets Fluid Dynamics: A Characterization of the Induced Airflow\n  around a Quadrotor","summary":"  The widespread adoption of quadrotors for diverse applications, from\nagriculture to public safety, necessitates an understanding of the aerodynamic\ndisturbances they create. This paper introduces a computationally lightweight\nmodel for estimating the time-averaged magnitude of the induced flow below\nquadrotors in hover. Unlike related approaches that rely on expensive\ncomputational fluid dynamics (CFD) simulations or time-consuming empirical\nmeasurements, our method leverages classical theory from turbulent flows. By\nanalyzing over 9 hours of flight data from drones of varying sizes within a\nlarge motion capture system, we show that the combined flow from all propellers\nof the drone is well-approximated by a turbulent jet. Through the use of a\nnovel normalization and scaling, we have developed and experimentally validated\na unified model that describes the mean velocity field of the induced flow for\ndifferent drone sizes. The model accurately describes the far-field airflow in\na very large volume below the drone which is difficult to simulate in CFD. Our\nmodel, which requires only the drone's mass, propeller size, and drone size for\ncalculations, offers a practical tool for dynamic planning in multi-agent\nscenarios, ensuring safer operations near humans and optimizing sensor\nplacements.\n","authors":["Leonard Bauersfeld","Koen Muller","Dominic Ziegler","Filippo Coletti","Davide Scaramuzza"],"pdf_url":"https://arxiv.org/pdf/2403.13321v1.pdf","comment":"7+1 pages"},{"id":"http://arxiv.org/abs/2403.13318v1","updated":"2024-03-20T05:46:56Z","published":"2024-03-20T05:46:56Z","title":"Workload Estimation for Unknown Tasks: A Survey of Machine Learning\n  Under Distribution Shift","summary":"  Human-robot teams involve humans and robots collaborating to achieve tasks\nunder various environmental conditions. Successful teaming will require robots\nto adapt autonomously to a human teammate's internal state. An important\nelement of such adaptation is the ability to estimate the human teammates'\nworkload in unknown situations. Existing workload models use machine learning\nto model the relationships between physiological metrics and workload; however,\nthese methods are susceptible to individual differences and are heavily\ninfluenced by other factors. These methods cannot generalize to unknown tasks,\nas they rely on standard machine learning approaches that assume data consists\nof independent and identically distributed (IID) samples. This assumption does\nnot necessarily hold for estimating workload for new tasks. A survey of non-IID\nmachine learning techniques is presented, where commonly used techniques are\nevaluated using three criteria: portability, model complexity, and\nadaptability. These criteria are used to argue which techniques are most\napplicable for estimating workload for unknown tasks in dynamic, real-time\nenvironments.\n","authors":["Josh Bhagat Smith","Julie A. Adams"],"pdf_url":"https://arxiv.org/pdf/2403.13318v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13311v1","updated":"2024-03-20T05:23:24Z","published":"2024-03-20T05:23:24Z","title":"Multi-Robot Connected Fermat Spiral Coverage","summary":"  We introduce the Multi-Robot Connected Fermat Spiral (MCFS), a novel\nalgorithmic framework for Multi-Robot Coverage Path Planning (MCPP) that adapts\nConnected Fermat Spiral (CFS) from the computer graphics community to\nmulti-robot coordination for the first time. MCFS uniquely enables the\norchestration of multiple robots to generate coverage paths that contour around\narbitrarily shaped obstacles, a feature that is notably lacking in traditional\nmethods. Our framework not only enhances area coverage and optimizes task\nperformance, particularly in terms of makespan, for workspaces rich in\nirregular obstacles but also addresses the challenges of path continuity and\ncurvature critical for non-holonomic robots by generating smooth paths without\ndecomposing the workspace. MCFS solves MCPP by constructing a graph of isolines\nand transforming MCPP into a combinatorial optimization problem, aiming to\nminimize the makespan while covering all vertices. Our contributions include\ndeveloping a unified CFS version for scalable and adaptable MCPP, extending it\nto MCPP with novel optimization techniques for cost reduction and path\ncontinuity and smoothness, and demonstrating through extensive experiments that\nMCFS outperforms existing MCPP methods in makespan, path curvature, coverage\nratio, and overlapping ratio. Our research marks a significant step in MCPP,\nshowcasing the fusion of computer graphics and automated planning principles to\nadvance the capabilities of multi-robot systems in complex environments. Our\ncode is available at https://github.com/reso1/MCFS.\n","authors":["Jingtao Tang","Hang Ma"],"pdf_url":"https://arxiv.org/pdf/2403.13311v1.pdf","comment":"accepted to ICAPS24"},{"id":"http://arxiv.org/abs/2403.13297v1","updated":"2024-03-20T04:39:15Z","published":"2024-03-20T04:39:15Z","title":"POLICEd RL: Learning Closed-Loop Robot Control Policies with Provable\n  Satisfaction of Hard Constraints","summary":"  In this paper, we seek to learn a robot policy guaranteed to satisfy state\nconstraints. To encourage constraint satisfaction, existing RL algorithms\ntypically rely on Constrained Markov Decision Processes and discourage\nconstraint violations through reward shaping. However, such soft constraints\ncannot offer verifiable safety guarantees. To address this gap, we propose\nPOLICEd RL, a novel RL algorithm explicitly designed to enforce affine hard\nconstraints in closed-loop with a black-box environment. Our key insight is to\nforce the learned policy to be affine around the unsafe set and use this affine\nregion as a repulsive buffer to prevent trajectories from violating the\nconstraint. We prove that such policies exist and guarantee constraint\nsatisfaction. Our proposed framework is applicable to both systems with\ncontinuous and discrete state and action spaces and is agnostic to the choice\nof the RL training algorithm. Our results demonstrate the capacity of POLICEd\nRL to enforce hard constraints in robotic tasks while significantly\noutperforming existing methods.\n","authors":["Jean-Baptiste Bouvier","Kartik Nagpal","Negar Mehr"],"pdf_url":"https://arxiv.org/pdf/2403.13297v1.pdf","comment":"26 pages, 11 figures"},{"id":"http://arxiv.org/abs/2403.13294v1","updated":"2024-03-20T04:25:09Z","published":"2024-03-20T04:25:09Z","title":"Map-Aware Human Pose Prediction for Robot Follow-Ahead","summary":"  In the robot follow-ahead task, a mobile robot is tasked to maintain its\nrelative position in front of a moving human actor while keeping the actor in\nsight. To accomplish this task, it is important that the robot understand the\nfull 3D pose of the human (since the head orientation can be different than the\ntorso) and predict future human poses so as to plan accordingly. This\nprediction task is especially tricky in a complex environment with junctions\nand multiple corridors. In this work, we address the problem of forecasting the\nfull 3D trajectory of a human in such environments. Our main insight is to show\nthat one can first predict the 2D trajectory and then estimate the full 3D\ntrajectory by conditioning the estimator on the predicted 2D trajectory. With\nthis approach, we achieve results comparable or better than the\nstate-of-the-art methods three times faster. As part of our contribution, we\npresent a new dataset where, in contrast to existing datasets, the human motion\nis in a much larger area than a single room. We also present a complete robot\nsystem that integrates our human pose forecasting network on the mobile robot\nto enable real-time robot follow-ahead and present results from real-world\nexperiments in multiple buildings on campus. Our project page, including\nsupplementary material and videos, can be found at:\nhttps://qingyuan-jiang.github.io/iros2024_poseForecasting/\n","authors":["Qingyuan Jiang","Burak Susam","Jun-Jee Chao","Volkan Isler"],"pdf_url":"https://arxiv.org/pdf/2403.13294v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13284v1","updated":"2024-03-20T03:53:20Z","published":"2024-03-20T03:53:20Z","title":"Look Before You Leap: Socially Acceptable High-Speed Ground Robot\n  Navigation in Crowded Hallways","summary":"  To operate safely and efficiently, autonomous warehouse/delivery robots must\nbe able to accomplish tasks while navigating in dynamic environments and\nhandling the large uncertainties associated with the motions/behaviors of other\nrobots and/or humans. A key scenario in such environments is the hallway\nproblem, where robots must operate in the same narrow corridor as human traffic\ngoing in one or both directions. Traditionally, robot planners have tended to\nfocus on socially acceptable behavior in the hallway scenario at the expense of\nperformance. This paper proposes a planner that aims to address the consequent\n\"robot freezing problem\" in hallways by allowing for \"peek-and-pass\" maneuvers.\nWe then go on to demonstrate in simulation how this planner improves robot time\nto goal without violating social norms. Finally, we show initial hardware\ndemonstrations of this planner in the real world.\n","authors":["Lakshay Sharma","Jonathan P. How"],"pdf_url":"https://arxiv.org/pdf/2403.13284v1.pdf","comment":"Submitted to IROS 2024"},{"id":"http://arxiv.org/abs/2403.13281v1","updated":"2024-03-20T03:42:03Z","published":"2024-03-20T03:42:03Z","title":"Waypoint-Based Reinforcement Learning for Robot Manipulation Tasks","summary":"  Robot arms should be able to learn new tasks. One framework here is\nreinforcement learning, where the robot is given a reward function that encodes\nthe task, and the robot autonomously learns actions to maximize its reward.\nExisting approaches to reinforcement learning often frame this problem as a\nMarkov decision process, and learn a policy (or a hierarchy of policies) to\ncomplete the task. These policies reason over hundreds of fine-grained actions\nthat the robot arm needs to take: e.g., moving slightly to the right or\nrotating the end-effector a few degrees. But the manipulation tasks that we\nwant robots to perform can often be broken down into a small number of\nhigh-level motions: e.g., reaching an object or turning a handle. In this paper\nwe therefore propose a waypoint-based approach for model-free reinforcement\nlearning. Instead of learning a low-level policy, the robot now learns a\ntrajectory of waypoints, and then interpolates between those waypoints using\nexisting controllers. Our key novelty is framing this waypoint-based setting as\na sequence of multi-armed bandits: each bandit problem corresponds to one\nwaypoint along the robot's motion. We theoretically show that an ideal solution\nto this reformulation has lower regret bounds than standard frameworks. We also\nintroduce an approximate posterior sampling solution that builds the robot's\nmotion one waypoint at a time. Results across benchmark simulations and two\nreal-world experiments suggest that this proposed approach learns new tasks\nmore quickly than state-of-the-art baselines. See videos here:\nhttps://youtu.be/MMEd-lYfq4Y\n","authors":["Shaunak A. Mehta","Soheil Habibian","Dylan P. Losey"],"pdf_url":"https://arxiv.org/pdf/2403.13281v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13274v1","updated":"2024-03-20T03:17:07Z","published":"2024-03-20T03:17:07Z","title":"UNO Push: Unified Nonprehensile Object Pushing via Non-Parametric\n  Estimation and Model Predictive Control","summary":"  Nonprehensile manipulation through precise pushing is an essential skill that\nhas been commonly challenged by perception and physical uncertainties, such as\nthose associated with contacts, object geometries, and physical properties. For\nthis, we propose a unified framework that jointly addresses system modeling,\naction generation, and control. While most existing approaches either heavily\nrely on a priori system information for analytic modeling, or leverage a large\ndataset to learn dynamic models, our framework approximates a system transition\nfunction via non-parametric learning only using a small number of exploratory\nactions (ca. 10). The approximated function is then integrated with model\npredictive control to provide precise pushing manipulation. Furthermore, we\nshow that the approximated system transition functions can be robustly\ntransferred across novel objects while being online updated to continuously\nimprove the manipulation accuracy. Through extensive experiments on a real\nrobot platform with a set of novel objects and comparing against a\nstate-of-the-art baseline, we show that the proposed unified framework is a\nlight-weight and highly effective approach to enable precise pushing\nmanipulation all by itself. Our evaluation results illustrate that the system\ncan robustly ensure millimeter-level precision and can straightforwardly work\non any novel object.\n","authors":["Gaotian Wang","Kejia Ren","Kaiyu Hang"],"pdf_url":"https://arxiv.org/pdf/2403.13274v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13266v1","updated":"2024-03-20T03:03:22Z","published":"2024-03-20T03:03:22Z","title":"Enhancing Security in Multi-Robot Systems through Co-Observation\n  Planning, Reachability Analysis, and Network Flow","summary":"  This paper addresses security challenges in multi-robot systems (MRS) where\nadversaries may compromise robot control, risking unauthorized access to\nforbidden areas. We propose a novel multi-robot optimal planning algorithm that\nintegrates mutual observations and introduces reachability constraints for\nenhanced security. This ensures that, even with adversarial movements,\ncompromised robots cannot breach forbidden regions without missing scheduled\nco-observations. The reachability constraint uses ellipsoidal\nover-approximation for efficient intersection checking and gradient\ncomputation. To enhance system resilience and tackle feasibility challenges, we\nalso introduce sub-teams. These cohesive units replace individual robot\nassignments along each route, enabling redundant robots to deviate for\nco-observations across different trajectories, securing multiple sub-teams\nwithout requiring modifications. We formulate the cross-trajectory\nco-observation plan by solving a network flow coverage problem on the\ncheckpoint graph generated from the original unsecured MRS trajectories,\nproviding the same security guarantees against plan-deviation attacks. We\ndemonstrate the effectiveness and robustness of our proposed algorithm, which\nsignificantly strengthens the security of multi-robot systems in the face of\nadversarial threats.\n","authors":["Ziqi Yang","Roberto Tron"],"pdf_url":"https://arxiv.org/pdf/2403.13266v1.pdf","comment":"12 pages, 6 figures, submitted to IEEE Transactions on Control of\n  Network Systems"},{"id":"http://arxiv.org/abs/2403.13251v1","updated":"2024-03-20T02:31:23Z","published":"2024-03-20T02:31:23Z","title":"A Rule-Compliance Path Planner for Lane-Merge Scenarios Based on\n  Responsibility-Sensitive Safety","summary":"  Lane merging is one of the critical tasks for self-driving cars, and how to\nperform lane-merge maneuvers effectively and safely has become one of the\nimportant standards in measuring the capability of autonomous driving systems.\nHowever, due to the ambiguity in driving intentions and right-of-way issues,\nthe lane merging process in autonomous driving remains deficient in terms of\nmaintaining or ceding the right-of-way and attributing liability, which could\nresult in protracted durations for merging and problems such as trajectory\noscillation. Hence, we present a rule-compliance path planner (RCPP) for\nlane-merge scenarios, which initially employs the extended\nresponsibility-sensitive safety (RSS) to elucidate the right-of-way, followed\nby the potential field-based sigmoid planner for path generation. In the\nsimulation, we have validated the efficacy of the proposed algorithm. The\nalgorithm demonstrated superior performance over previous approaches in aspects\nsuch as merging time (Saved 72.3%), path length (reduced 53.4%), and\neliminating the trajectory oscillation.\n","authors":["Pengfei Lin","Ehsan Javanmardi","Yuze Jiang","Manabu Tsukada"],"pdf_url":"https://arxiv.org/pdf/2403.13251v1.pdf","comment":"Submitted to IEEE IROS 2024"},{"id":"http://arxiv.org/abs/2403.13245v1","updated":"2024-03-20T02:16:54Z","published":"2024-03-20T02:16:54Z","title":"Federated reinforcement learning for robot motion planning with\n  zero-shot generalization","summary":"  This paper considers the problem of learning a control policy for robot\nmotion planning with zero-shot generalization, i.e., no data collection and\npolicy adaptation is needed when the learned policy is deployed in new\nenvironments. We develop a federated reinforcement learning framework that\nenables collaborative learning of multiple learners and a central server, i.e.,\nthe Cloud, without sharing their raw data. In each iteration, each learner\nuploads its local control policy and the corresponding estimated normalized\narrival time to the Cloud, which then computes the global optimum among the\nlearners and broadcasts the optimal policy to the learners. Each learner then\nselects between its local control policy and that from the Cloud for next\niteration. The proposed framework leverages on the derived zero-shot\ngeneralization guarantees on arrival time and safety. Theoretical guarantees on\nalmost-sure convergence, almost consensus, Pareto improvement and optimality\ngap are also provided. Monte Carlo simulation is conducted to evaluate the\nproposed framework.\n","authors":["Zhenyuan Yuan","Siyuan Xu","Minghui Zhu"],"pdf_url":"https://arxiv.org/pdf/2403.13245v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13235v1","updated":"2024-03-20T01:57:24Z","published":"2024-03-20T01:57:24Z","title":"AMCO: Adaptive Multimodal Coupling of Vision and Proprioception for\n  Quadruped Robot Navigation in Outdoor Environments","summary":"  We present AMCO, a novel navigation method for quadruped robots that\nadaptively combines vision-based and proprioception-based perception\ncapabilities. Our approach uses three cost maps: general knowledge map;\ntraversability history map; and current proprioception map; which are derived\nfrom a robot's vision and proprioception data, and couples them to obtain a\ncoupled traversability cost map for navigation. The general knowledge map\nencodes terrains semantically segmented from visual sensing, and represents a\nterrain's typically expected traversability. The traversability history map\nencodes the robot's recent proprioceptive measurements on a terrain and its\nsemantic segmentation as a cost map. Further, the robot's present\nproprioceptive measurement is encoded as a cost map in the current\nproprioception map. As the general knowledge map and traversability history map\nrely on semantic segmentation, we evaluate the reliability of the visual\nsensory data by estimating the brightness and motion blur of input RGB images\nand accordingly combine the three cost maps to obtain the coupled\ntraversability cost map used for navigation. Leveraging this adaptive coupling,\nthe robot can depend on the most reliable input modality available. Finally, we\npresent a novel planner that selects appropriate gaits and velocities for\ntraversing challenging outdoor environments using the coupled traversability\ncost map. We demonstrate AMCO's navigation performance in different real-world\noutdoor environments and observe 10.8%-34.9% reduction w.r.t. two stability\nmetrics, and up to 50% improvement in terms of success rate compared to current\nnavigation methods.\n","authors":["Mohamed Elnoor","Kasun Weerakoon","Adarsh Jagan Sathyamoorthy","Tianrui Guan","Vignesh Rajagopal","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2403.13235v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2403.12245v2","updated":"2024-03-20T01:48:46Z","published":"2024-03-18T20:51:08Z","title":"Improving Out-of-Distribution Generalization of Learned Dynamics by\n  Learning Pseudometrics and Constraint Manifolds","summary":"  We propose a method for improving the prediction accuracy of learned robot\ndynamics models on out-of-distribution (OOD) states. We achieve this by\nleveraging two key sources of structure often present in robot dynamics: 1)\nsparsity, i.e., some components of the state may not affect the dynamics, and\n2) physical limits on the set of possible motions, in the form of nonholonomic\nconstraints. Crucially, we do not assume this structure is known a priori, and\ninstead learn it from data. We use contrastive learning to obtain a distance\npseudometric that uncovers the sparsity pattern in the dynamics, and use it to\nreduce the input space when learning the dynamics. We then learn the unknown\nconstraint manifold by approximating the normal space of possible motions from\nthe data, which we use to train a Gaussian process (GP) representation of the\nconstraint manifold. We evaluate our approach on a physical differential-drive\nrobot and a simulated quadrotor, showing improved prediction accuracy on OOD\ndata relative to baselines.\n","authors":["Yating Lin","Glen Chou","Dmitry Berenson"],"pdf_url":"https://arxiv.org/pdf/2403.12245v2.pdf","comment":"Accept to ICRA 2024, 6 pages + references"},{"id":"http://arxiv.org/abs/2403.13221v1","updated":"2024-03-20T00:56:27Z","published":"2024-03-20T00:56:27Z","title":"A Contact Model based on Denoising Diffusion to Learn Variable Impedance\n  Control for Contact-rich Manipulation","summary":"  In this paper, a novel approach is proposed for learning robot control in\ncontact-rich tasks such as wiping, by developing Diffusion Contact Model (DCM).\nPrevious methods of learning such tasks relied on impedance control with\ntime-varying stiffness tuning by performing Bayesian optimization by\ntrial-and-error with robots. The proposed approach aims to reduce the cost of\nrobot operation by predicting the robot contact trajectories from the variable\nstiffness inputs and using neural models. However, contact dynamics are\ninherently highly nonlinear, and their simulation requires iterative\ncomputations such as convex optimization. Moreover, approximating such\ncomputations by using finite-layer neural models is difficult. To overcome\nthese limitations, the proposed DCM used the denoising diffusion models that\ncould simulate the complex dynamics via iterative computations of multi-step\ndenoising, thus improving the prediction accuracy. Stiffness tuning experiments\nconducted in simulated and real environments showed that the DCM achieved\ncomparable performance to a conventional robot-based optimization method while\nreducing the number of robot trials.\n","authors":["Masashi Okada","Mayumi Komatsu","Tadahiro Taniguchi"],"pdf_url":"https://arxiv.org/pdf/2403.13221v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.14115v2","updated":"2024-03-20T00:23:39Z","published":"2023-12-21T18:40:34Z","title":"LingoQA: Video Question Answering for Autonomous Driving","summary":"  Autonomous driving has long faced a challenge with public acceptance due to\nthe lack of explainability in the decision-making process. Video\nquestion-answering (QA) in natural language provides the opportunity for\nbridging this gap. Nonetheless, evaluating the performance of Video QA models\nhas proved particularly tough due to the absence of comprehensive benchmarks.\nTo fill this gap, we introduce LingoQA, a benchmark specifically for autonomous\ndriving Video QA. The LingoQA trainable metric demonstrates a 0.95 Spearman\ncorrelation coefficient with human evaluations. We introduce a Video QA dataset\nof central London consisting of 419k samples that we release with the paper. We\nestablish a baseline vision-language model and run extensive ablation studies\nto understand its performance.\n","authors":["Ana-Maria Marcu","Long Chen","Jan Hünermann","Alice Karnsund","Benoit Hanotte","Prajwal Chidananda","Saurabh Nair","Vijay Badrinarayanan","Alex Kendall","Jamie Shotton","Elahe Arani","Oleg Sinavski"],"pdf_url":"https://arxiv.org/pdf/2312.14115v2.pdf","comment":"Benchmark and dataset are available at\n  https://github.com/wayveai/LingoQA/"},{"id":"http://arxiv.org/abs/2403.14041v1","updated":"2024-03-20T23:36:30Z","published":"2024-03-20T23:36:30Z","title":"\"It's Not a Replacement:\" Enabling Parent-Robot Collaboration to Support\n  In-Home Learning Experiences of Young Children","summary":"  Learning companion robots for young children are increasingly adopted in\ninformal learning environments. Although parents play a pivotal role in their\nchildren's learning, very little is known about how parents prefer to\nincorporate robots into their children's learning activities. We developed\nprototype capabilities for a learning companion robot to deliver educational\nprompts and responses to parent-child pairs during reading sessions and\nconducted in-home user studies involving 10 families with children aged 3-5.\nOur data indicates that parents want to work with robots as collaborators to\naugment parental activities to foster children's learning, introducing the\nnotion of parent-robot collaboration. Our findings offer an empirical\nunderstanding of the needs and challenges of parent-child interaction in\ninformal learning scenarios and design opportunities for integrating a\ncompanion robot into these interactions. We offer insights into how robots\nmight be designed to facilitate parent-robot collaboration, including parenting\npolicies, collaboration patterns, and interaction paradigms.\n","authors":["Hui-Ru Ho","Edward Hubbard","Bilge Mutlu"],"pdf_url":"https://arxiv.org/pdf/2403.14041v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14029v1","updated":"2024-03-20T22:57:34Z","published":"2024-03-20T22:57:34Z","title":"Quadcopter Team Configurable Motion Guided by a Quadruped","summary":"  The paper focuses on modeling and experimental evaluation of a quadcopter\nteam configurable coordination guided by a single quadruped robot. We consider\nthe quadcopter team as particles of a two-dimensional deformable body and\npropose a two-dimensional affine transformation model for safe and\ncollision-free configurable coordination of this heterogeneous robotic system.\nThe proposed affine transformation is decomposed into translation, that is\nspecified by the quadruped global position, and configurable motion of the\nquadcopters, which is determined by a nonsingular Jacobian matrix so that the\nquadcopter team can safely navigate a constrained environment while avoiding\ncollision. We propose two methods to experimentally evaluate the proposed\nheterogeneous robot coordination model. The first method measures real\npositions of quadcopters, quadruped, and environmental objects all with respect\nto the global coordinate system. On the other hand, the second method measures\nposition with respect to the local coordinate system fixed on the dog robot\nwhich in turn enables safe planning the Jacobian matrix of the quadcopter team\nwhile the world is virtually approached the robotic system.\n","authors":["Mohammad Ghufran","Sourish Tetakayala","Jack Hughes","Aron Wilson","Hossein Rastgoftar"],"pdf_url":"https://arxiv.org/pdf/2403.14029v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14025v1","updated":"2024-03-20T22:51:29Z","published":"2024-03-20T22:51:29Z","title":"HRI Curriculum for a Liberal Arts Education","summary":"  In this paper, we discuss the opportunities and challenges of teaching a\nhuman-robot interaction course at an undergraduate liberal arts college. We\nprovide a sample syllabus adapted from a previous version of a course.\n","authors":["Jason R. Wilson","Emily Jensen"],"pdf_url":"https://arxiv.org/pdf/2403.14025v1.pdf","comment":"Presented at the Designing an Intro to HRI Course Workshop at HRI\n  2024 (arXiv:2403.05588)"},{"id":"http://arxiv.org/abs/2403.14014v1","updated":"2024-03-20T22:24:52Z","published":"2024-03-20T22:24:52Z","title":"Crowdsourcing Task Traces for Service Robotics","summary":"  Demonstration is an effective end-user development paradigm for teaching\nrobots how to perform new tasks. In this paper, we posit that demonstration is\nuseful not only as a teaching tool, but also as a way to understand and assist\nend-user developers in thinking about a task at hand. As a first step toward\ngaining this understanding, we constructed a lightweight web interface to\ncrowdsource step-by-step instructions of common household tasks, leveraging the\nimaginations and past experiences of potential end-user developers. As evidence\nof the utility of our interface, we deployed the interface on Amazon Mechanical\nTurk and collected 207 task traces that span 18 different task categories. We\ndescribe our vision for how these task traces can be operationalized as task\nmodels within end-user development tools and provide a roadmap for future work.\n","authors":["David Porfirio","Allison Sauppé","Maya Cakmak","Aws Albarghouthi","Bilge Mutlu"],"pdf_url":"https://arxiv.org/pdf/2403.14014v1.pdf","comment":"Published in the companion proceedings of the 2023 ACM/IEEE\n  International Conference on Human-Robot Interaction"},{"id":"http://arxiv.org/abs/2403.02316v2","updated":"2024-03-20T22:05:06Z","published":"2024-03-04T18:52:15Z","title":"Designing Library of Skill-Agents for Hardware-Level Reusability","summary":"  To use new robot hardware in a new environment, it is necessary to develop a\ncontrol program tailored to that specific robot in that environment.\nConsidering the reusability of software among robots is crucial to minimize the\neffort involved in this process and maximize software reuse across different\nrobots in different environments. This paper proposes a method to remedy this\nprocess by considering hardware-level reusability, using\nLearning-from-observation (LfO) paradigm with a pre-designed skill-agent\nlibrary. The LfO framework represents the required actions in\nhardware-independent representations, referred to as task models, from\nobserving human demonstrations, capturing the necessary parameters for the\ninteraction between the environment and the robot. When executing the desired\nactions from the task models, a set of skill agents is employed to convert the\nrepresentations into robot commands. This paper focuses on the latter part of\nthe LfO framework, utilizing the set to generate robot actions from the task\nmodels, and explores a hardware-independent design approach for these skill\nagents. These skill agents are described in a hardware-independent manner,\nconsidering the relative relationship between the robot's hand position and the\nenvironment. As a result, it is possible to execute these actions on robots\nwith different hardware configurations by simply swapping the inverse\nkinematics solver. This paper, first, defines a necessary and sufficient\nskill-agent set corresponding to cover all possible actions, and considers the\ndesign principles for these skill agents in the library. We provide concrete\nexamples of such skill agents and demonstrate the practicality of using these\nskill agents by showing that the same representations can be executed on two\ndifferent robots, Nextage and Fetch, using the proposed skill-agents set.\n","authors":["Jun Takamatsu","Daichi Saito","Katsushi Ikeuchi","Atsushi Kanehira","Kazuhiro Sasabuchi","Naoki Wake"],"pdf_url":"https://arxiv.org/pdf/2403.02316v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14000v1","updated":"2024-03-20T21:57:14Z","published":"2024-03-20T21:57:14Z","title":"Visual Imitation Learning of Task-Oriented Object Grasping and\n  Rearrangement","summary":"  Task-oriented object grasping and rearrangement are critical skills for\nrobots to accomplish different real-world manipulation tasks. However, they\nremain challenging due to partial observations of the objects and shape\nvariations in categorical objects. In this paper, we propose the Multi-feature\nImplicit Model (MIMO), a novel object representation that encodes multiple\nspatial features between a point and an object in an implicit neural field.\nTraining such a model on multiple features ensures that it embeds the object\nshapes consistently in different aspects, thus improving its performance in\nobject shape reconstruction from partial observation, shape similarity measure,\nand modeling spatial relations between objects. Based on MIMO, we propose a\nframework to learn task-oriented object grasping and rearrangement from single\nor multiple human demonstration videos. The evaluations in simulation show that\nour approach outperforms the state-of-the-art methods for multi- and\nsingle-view observations. Real-world experiments demonstrate the efficacy of\nour approach in one- and few-shot imitation learning of manipulation tasks.\n","authors":["Yichen Cai","Jianfeng Gao","Christoph Pohl","Tamim Asfour"],"pdf_url":"https://arxiv.org/pdf/2403.14000v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13988v1","updated":"2024-03-20T21:41:44Z","published":"2024-03-20T21:41:44Z","title":"Goal-Oriented End-User Programming of Robots","summary":"  End-user programming (EUP) tools must balance user control with the robot's\nability to plan and act autonomously. Many existing task-oriented EUP tools\nenforce a specific level of control, e.g., by requiring that users hand-craft\ndetailed sequences of actions, rather than offering users the flexibility to\nchoose the level of task detail they wish to express. We thereby created a\nnovel EUP system, Polaris, that in contrast to most existing EUP tools, uses\ngoal predicates as the fundamental building block of programs. Users can\nthereby express high-level robot objectives or lower-level checkpoints at their\nchoosing, while an off-the-shelf task planner fills in any remaining program\ndetail. To ensure that goal-specified programs adhere to user expectations of\nrobot behavior, Polaris is equipped with a Plan Visualizer that exposes the\nplanner's output to the user before runtime. In what follows, we describe our\ndesign of Polaris and its evaluation with 32 human participants. Our results\nsupport the Plan Visualizer's ability to help users craft higher-quality\nprograms. Furthermore, there are strong associations between user perception of\nthe robot and Plan Visualizer usage, and evidence that robot familiarity has a\nkey role in shaping user experience.\n","authors":["David Porfirio","Mark Roberts","Laura M. Hiatt"],"pdf_url":"https://arxiv.org/pdf/2403.13988v1.pdf","comment":"Published in the proceedings of the 2024 ACM/IEEE International\n  Conference on Human-Robot Interaction"},{"id":"http://arxiv.org/abs/2403.13960v1","updated":"2024-03-20T20:13:39Z","published":"2024-03-20T20:13:39Z","title":"Open Access NAO (OAN): a ROS2-based software framework for HRI\n  applications with the NAO robot","summary":"  This paper presents a new software framework for HRI experimentation with the\nsixth version of the common NAO robot produced by the United Robotics Group.\nEmbracing the common demand of researchers for better performance and new\nfeatures for NAO, the authors took advantage of the ability to run ROS2 onboard\non the NAO to develop a framework independent of the APIs provided by the\nmanufacturer. Such a system provides NAO with not only the basic skills of a\nhumanoid robot such as walking and reproducing movements of interest but also\nfeatures often used in HRI such as: speech recognition/synthesis, face and\nobject detention, and the use of Generative Pre-trained Transformer (GPT)\nmodels for conversation. The developed code is therefore configured as a\nready-to-use but also highly expandable and improvable tool thanks to the\npossibilities provided by the ROS community.\n","authors":["Antonio Bono","Kenji Brameld","Luigi D'Alfonso","Giuseppe Fedele"],"pdf_url":"https://arxiv.org/pdf/2403.13960v1.pdf","comment":"7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2312.02352v2","updated":"2024-03-20T19:57:24Z","published":"2023-12-04T21:32:00Z","title":"Working Backwards: Learning to Place by Picking","summary":"  We present placing via picking (PvP), a method to autonomously collect\nreal-world demonstrations for a family of placing tasks in which objects must\nbe manipulated to specific contact-constrained locations. With PvP, we approach\nthe collection of robotic object placement demonstrations by reversing the\ngrasping process and exploiting the inherent symmetry of the pick and place\nproblems. Specifically, we obtain placing demonstrations from a set of grasp\nsequences of objects initially located at their target placement locations. Our\nsystem can collect hundreds of demonstrations in contact-constrained\nenvironments without human intervention by combining two modules: tactile\nregrasping and compliant control for grasps. We train a policy directly from\nvisual observations through behavioral cloning, using the\nautonomously-collected demonstrations. By doing so, the policy can generalize\nto object placement scenarios outside of the training environment without\nprivileged information (e.g., placing a plate picked up from a table). We\nvalidate our approach in home robotic scenarios that include dishwasher loading\nand table setting. Our approach yields robotic placing policies that outperform\npolicies trained with kinesthetic teaching, both in terms of performance and\ndata efficiency, while requiring no human supervision.\n","authors":["Oliver Limoyo","Abhisek Konar","Trevor Ablett","Jonathan Kelly","Francois R. Hogan","Gregory Dudek"],"pdf_url":"https://arxiv.org/pdf/2312.02352v2.pdf","comment":"Submitted to the IEEE/RSJ International Conference on Intelligent\n  Robotics and Systems (IROS'24), Abu Dhabi, UAE, Oct 14-18, 2024"},{"id":"http://arxiv.org/abs/2401.11061v2","updated":"2024-03-20T19:44:07Z","published":"2024-01-19T23:34:48Z","title":"PhotoBot: Reference-Guided Interactive Photography via Natural Language","summary":"  We introduce PhotoBot, a framework for fully automated photo acquisition\nbased on an interplay between high-level human language guidance and a robot\nphotographer. We propose to communicate photography suggestions to the user via\nreference images that are selected from a curated gallery. We leverage a visual\nlanguage model (VLM) and an object detector to characterize the reference\nimages via textual descriptions and then use a large language model (LLM) to\nretrieve relevant reference images based on a user's language query through\ntext-based reasoning. To correspond the reference image and the observed scene,\nwe exploit pre-trained features from a vision transformer capable of capturing\nsemantic similarity across marked appearance variations. Using these features,\nwe compute pose adjustments for an RGB-D camera by solving a\nperspective-n-point (PnP) problem. We demonstrate our approach using a\nmanipulator equipped with a wrist camera. Our user studies show that photos\ntaken by PhotoBot are often more aesthetically pleasing than those taken by\nusers themselves, as measured by human feedback. We also show that PhotoBot can\ngeneralize to other reference sources such as paintings.\n","authors":["Oliver Limoyo","Jimmy Li","Dmitriy Rivkin","Jonathan Kelly","Gregory Dudek"],"pdf_url":"https://arxiv.org/pdf/2401.11061v2.pdf","comment":"Submitted to the IEEE/RSJ International Conference on Intelligent\n  Robotics and Systems (IROS'24), Abu Dhabi, UAE, Oct 14-18, 2024"},{"id":"http://arxiv.org/abs/2403.04169v2","updated":"2024-03-20T19:28:56Z","published":"2024-03-07T02:58:15Z","title":"Social Robots for Sleep Health: A Scoping Review","summary":"  Poor sleep health is an increasingly concerning public healthcare crisis,\nespecially when coupled with a dwindling number of health professionals\nqualified to combat it. However, there is a growing body of scientific\nliterature on the use of digital technologies in supporting and sustaining\nindividuals' healthy sleep habits. Social robots are a relatively recent\ntechnology that has been used to facilitate health care interventions and may\nhave potential in improving sleep health outcomes, as well. Social robots'\nunique characteristics -- such as anthropomorphic physical embodiment or\neffective communication methods -- help to engage users and motivate them to\ncomply with specific interventions, thus improving the interventions' outcomes.\nThis scoping review aims to evaluate current scientific evidence for employing\nsocial robots in sleep health interventions, identify critical research gaps,\nand suggest future directions for developing and using social robots to improve\npeople's sleep health. Our analysis of the reviewed studies found them limited\ndue to a singular focus on the older adult population, use of small sample\nsizes, limited intervention durations, and other compounding factors.\nNevertheless, the reviewed studies reported several positive outcomes,\nhighlighting the potential social robots hold in this field. Although our\nreview found limited clinical evidence for the efficacy of social robots as\npurveyors of sleep health interventions, it did elucidate the potential for a\nsuccessful future in this domain if current limitations are addressed and more\nresearch is conducted.\n","authors":["Victor Nikhil Antony","Mengchi Li","Shu-Han Lin","Junxin Li","Chien-Ming Huang"],"pdf_url":"https://arxiv.org/pdf/2403.04169v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13941v1","updated":"2024-03-20T19:26:27Z","published":"2024-03-20T19:26:27Z","title":"Sensory Glove-Based Surgical Robot User Interface","summary":"  Robotic surgery has reached a high level of maturity and has become an\nintegral part of standard surgical care. However, existing surgeon consoles are\nbulky and take up valuable space in the operating room, present challenges for\nsurgical team coordination, and their proprietary nature makes it difficult to\ntake advantage of recent technological advances, especially in virtual and\naugmented reality. One potential area for further improvement is the\nintegration of modern sensory gloves into robotic platforms, allowing surgeons\nto control robotic arms directly with their hand movements intuitively. We\npropose one such system that combines an HTC Vive tracker, a Manus Meta Prime 3\nXR sensory glove, and God Vision wireless smart glasses. The system controls\none arm of a da Vinci surgical robot. In addition to moving the arm, the\nsurgeon can use fingers to control the end-effector of the surgical instrument.\nHand gestures are used to implement clutching and similar functions. In\nparticular, we introduce clutching of the instrument orientation, a\nfunctionality not available in the da Vinci system. The vibrotactile elements\nof the glove are used to provide feedback to the user when gesture commands are\ninvoked. A preliminary evaluation of the system shows that it has excellent\ntracking accuracy and allows surgeons to efficiently perform common surgical\ntraining tasks with minimal practice with the new interface; this suggests that\nthe interface is highly intuitive. The proposed system is inexpensive, allows\nrapid prototyping, and opens opportunities for further innovations in the\ndesign of surgical robot interfaces.\n","authors":["Leonardo Borgioli","Ki-Hwan Oh","Alberto Mangano","Alvaro Ducas","Luciano Ambrosini","Federico Pinto","Paula A Lopez","Jessica Cassiani","Milos Zefran","Liaohai Chen","Pier Cristoforo Giulianotti"],"pdf_url":"https://arxiv.org/pdf/2403.13941v1.pdf","comment":"6 pages, 5 figures, 7 tables, submitted to International Conference\n  on Intelligent Robots and Systems (IROS)2024"},{"id":"http://arxiv.org/abs/2403.13929v1","updated":"2024-03-20T19:03:26Z","published":"2024-03-20T19:03:26Z","title":"Safety-Aware Perception for Autonomous Collision Avoidance in Dynamic\n  Environments","summary":"  Autonomous collision avoidance requires accurate environmental perception;\nhowever, flight systems often possess limited sensing capabilities with\nfield-of-view (FOV) restrictions. To navigate this challenge, we present a\nsafety-aware approach for online determination of the optimal sensor-pointing\ndirection $\\psi_\\text{d}$ which utilizes control barrier functions (CBFs).\nFirst, we generate a spatial density function $\\Phi$ which leverages CBF\nconstraints to map the collision risk of all local coordinates. Then, we\nconvolve $\\Phi$ with an attitude-dependent sensor FOV quality function to\nproduce the objective function $\\Gamma$ which quantifies the total observed\nrisk for a given pointing direction. Finally, by finding the global optimizer\nfor $\\Gamma$, we identify the value of $\\psi_\\text{d}$ which maximizes the\nperception of risk within the FOV. We incorporate $\\psi_\\text{d}$ into a\nsafety-critical flight architecture and conduct a numerical analysis using\nmultiple simulated mission profiles. Our algorithm achieves a success rate of\n$88-96\\%$, constituting a $16-29\\%$ improvement compared to the best heuristic\nmethods. We demonstrate the functionality of our approach via a flight\ndemonstration using the Crazyflie 2.1 micro-quadrotor. Without a priori\nobstacle knowledge, the quadrotor follows a dynamic flight path while\nsimultaneously calculating and tracking $\\psi_\\text{d}$ to perceive and avoid\ntwo static obstacles with an average computation time of 371 $\\mu$s.\n","authors":["Ryan M. Bena","Chongbo Zhao","Quan Nguyen"],"pdf_url":"https://arxiv.org/pdf/2403.13929v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.15821v2","updated":"2024-03-20T18:45:54Z","published":"2023-09-27T17:45:49Z","title":"LGMCTS: Language-Guided Monte-Carlo Tree Search for Executable Semantic\n  Object Rearrangement","summary":"  We introduce a novel approach to the executable semantic object rearrangement\nproblem. In this challenge, a robot seeks to create an actionable plan that\nrearranges objects within a scene according to a pattern dictated by a natural\nlanguage description. Unlike existing methods such as StructFormer and\nStructDiffusion, which tackle the issue in two steps by first generating poses\nand then leveraging a task planner for action plan formulation, our method\nconcurrently addresses pose generation and action planning. We achieve this\nintegration using a Language-Guided Monte-Carlo Tree Search (LGMCTS).\nQuantitative evaluations are provided on two simulation datasets, and\ncomplemented by qualitative tests with a real robot.\n","authors":["Haonan Chang","Kai Gao","Kowndinya Boyalakuntla","Alex Lee","Baichuan Huang","Harish Udhaya Kumar","Jinjin Yu","Abdeslam Boularias"],"pdf_url":"https://arxiv.org/pdf/2309.15821v2.pdf","comment":"Our code and supplementary materials are accessible at\n  https://github.com/changhaonan/LG-MCTS"},{"id":"http://arxiv.org/abs/2403.13910v1","updated":"2024-03-20T18:30:12Z","published":"2024-03-20T18:30:12Z","title":"Augmented Reality Demonstrations for Scalable Robot Imitation Learning","summary":"  Robot Imitation Learning (IL) is a widely used method for training robots to\nperform manipulation tasks that involve mimicking human demonstrations to\nacquire skills. However, its practicality has been limited due to its\nrequirement that users be trained in operating real robot arms to provide\ndemonstrations. This paper presents an innovative solution: an Augmented\nReality (AR)-assisted framework for demonstration collection, empowering\nnon-roboticist users to produce demonstrations for robot IL using devices like\nthe HoloLens 2. Our framework facilitates scalable and diverse demonstration\ncollection for real-world tasks. We validate our approach with experiments on\nthree classical robotics tasks: reach, push, and pick-and-place. The real robot\nperforms each task successfully while replaying demonstrations collected via\nAR.\n","authors":["Yue Yang","Bryce Ikeda","Gedas Bertasius","Daniel Szafir"],"pdf_url":"https://arxiv.org/pdf/2403.13910v1.pdf","comment":null}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2403.13808v1","updated":"2024-03-20T17:59:58Z","published":"2024-03-20T17:59:58Z","title":"On Pretraining Data Diversity for Self-Supervised Learning","summary":"  We explore the impact of training with more diverse datasets, characterized\nby the number of unique samples, on the performance of self-supervised learning\n(SSL) under a fixed computational budget. Our findings consistently demonstrate\nthat increasing pretraining data diversity enhances SSL performance, albeit\nonly when the distribution distance to the downstream data is minimal. Notably,\neven with an exceptionally large pretraining data diversity achieved through\nmethods like web crawling or diffusion-generated data, among other ways, the\ndistribution shift remains a challenge. Our experiments are comprehensive with\nseven SSL methods using large-scale datasets such as ImageNet and YFCC100M\namounting to over 200 GPU days. Code and trained models will be available at\nhttps://github.com/hammoudhasan/DiversitySSL .\n","authors":["Hasan Abed Al Kader Hammoud","Tuhin Das","Fabio Pizzati","Philip Torr","Adel Bibi","Bernard Ghanem"],"pdf_url":"https://arxiv.org/pdf/2403.13808v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2403.13805v1","updated":"2024-03-20T17:59:55Z","published":"2024-03-20T17:59:55Z","title":"RAR: Retrieving And Ranking Augmented MLLMs for Visual Recognition","summary":"  CLIP (Contrastive Language-Image Pre-training) uses contrastive learning from\nnoise image-text pairs to excel at recognizing a wide array of candidates, yet\nits focus on broad associations hinders the precision in distinguishing subtle\ndifferences among fine-grained items. Conversely, Multimodal Large Language\nModels (MLLMs) excel at classifying fine-grained categories, thanks to their\nsubstantial knowledge from pre-training on web-level corpora. However, the\nperformance of MLLMs declines with an increase in category numbers, primarily\ndue to growing complexity and constraints of limited context window size. To\nsynergize the strengths of both approaches and enhance the few-shot/zero-shot\nrecognition abilities for datasets characterized by extensive and fine-grained\nvocabularies, this paper introduces RAR, a Retrieving And Ranking augmented\nmethod for MLLMs. We initially establish a multi-modal retriever based on CLIP\nto create and store explicit memory for different categories beyond the\nimmediate context window. During inference, RAR retrieves the top-k similar\nresults from the memory and uses MLLMs to rank and make the final predictions.\nOur proposed approach not only addresses the inherent limitations in\nfine-grained recognition but also preserves the model's comprehensive knowledge\nbase, significantly boosting accuracy across a range of vision-language\nrecognition tasks. Notably, our approach demonstrates a significant improvement\nin performance on 5 fine-grained visual recognition benchmarks, 11 few-shot\nimage recognition datasets, and the 2 object detection datasets under the\nzero-shot recognition setting.\n","authors":["Ziyu Liu","Zeyi Sun","Yuhang Zang","Wei Li","Pan Zhang","Xiaoyi Dong","Yuanjun Xiong","Dahua Lin","Jiaqi Wang"],"pdf_url":"https://arxiv.org/pdf/2403.13805v1.pdf","comment":"Project: https://github.com/Liuziyu77/RAR"},{"id":"http://arxiv.org/abs/2403.13802v1","updated":"2024-03-20T17:59:14Z","published":"2024-03-20T17:59:14Z","title":"ZigMa: Zigzag Mamba Diffusion Model","summary":"  The diffusion model has long been plagued by scalability and quadratic\ncomplexity issues, especially within transformer-based structures. In this\nstudy, we aim to leverage the long sequence modeling capability of a\nState-Space Model called Mamba to extend its applicability to visual data\ngeneration. Firstly, we identify a critical oversight in most current\nMamba-based vision methods, namely the lack of consideration for spatial\ncontinuity in the scan scheme of Mamba. Secondly, building upon this insight,\nwe introduce a simple, plug-and-play, zero-parameter method named Zigzag Mamba,\nwhich outperforms Mamba-based baselines and demonstrates improved speed and\nmemory utilization compared to transformer-based baselines. Lastly, we\nintegrate Zigzag Mamba with the Stochastic Interpolant framework to investigate\nthe scalability of the model on large-resolution visual datasets, such as\nFacesHQ $1024\\times 1024$ and UCF101, MultiModal-CelebA-HQ, and MS COCO\n$256\\times 256$. Code will be released at https://taohu.me/zigma/\n","authors":["Vincent Tao Hu","Stefan Andreas Baumann","Ming Gui","Olga Grebenkova","Pingchuan Ma","Johannes Fischer","Bjorn Ommer"],"pdf_url":"https://arxiv.org/pdf/2403.13802v1.pdf","comment":"Project Page: https://taohu.me/zigma/"},{"id":"http://arxiv.org/abs/2403.13801v1","updated":"2024-03-20T17:58:12Z","published":"2024-03-20T17:58:12Z","title":"Natural Language as Polices: Reasoning for Coordinate-Level Embodied\n  Control with LLMs","summary":"  We demonstrate experimental results with LLMs that address robotics action\nplanning problems. Recently, LLMs have been applied in robotics action\nplanning, particularly using a code generation approach that converts complex\nhigh-level instructions into mid-level policy codes. In contrast, our approach\nacquires text descriptions of the task and scene objects, then formulates\naction planning through natural language reasoning, and outputs coordinate\nlevel control commands, thus reducing the necessity for intermediate\nrepresentation code as policies. Our approach is evaluated on a multi-modal\nprompt simulation benchmark, demonstrating that our prompt engineering\nexperiments with natural language reasoning significantly enhance success rates\ncompared to its absence. Furthermore, our approach illustrates the potential\nfor natural language descriptions to transfer robotics skills from known tasks\nto previously unseen tasks.\n","authors":["Yusuke Mikami","Andrew Melnik","Jun Miura","Ville Hautamäki"],"pdf_url":"https://arxiv.org/pdf/2403.13801v1.pdf","comment":"8 pages, 2 figures"},{"id":"http://arxiv.org/abs/2312.06644v2","updated":"2024-03-20T17:58:05Z","published":"2023-12-11T18:56:37Z","title":"AnyHome: Open-Vocabulary Generation of Structured and Textured 3D Homes","summary":"  Inspired by cognitive theories, we introduce AnyHome, a framework that\ntranslates any text into well-structured and textured indoor scenes at a\nhouse-scale. By prompting Large Language Models (LLMs) with designed templates,\nour approach converts provided textual narratives into amodal structured\nrepresentations. These representations guarantee consistent and realistic\nspatial layouts by directing the synthesis of a geometry mesh within defined\nconstraints. A Score Distillation Sampling process is then employed to refine\nthe geometry, followed by an egocentric inpainting process that adds lifelike\ntextures to it. AnyHome stands out with its editability, customizability,\ndiversity, and realism. The structured representations for scenes allow for\nextensive editing at varying levels of granularity. Capable of interpreting\ntexts ranging from simple labels to detailed narratives, AnyHome generates\ndetailed geometries and textures that outperform existing methods in both\nquantitative and qualitative measures.\n","authors":["Rao Fu","Zehao Wen","Zichen Liu","Srinath Sridhar"],"pdf_url":"https://arxiv.org/pdf/2312.06644v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13799v1","updated":"2024-03-20T17:55:35Z","published":"2024-03-20T17:55:35Z","title":"Reverse Training to Nurse the Reversal Curse","summary":"  Large language models (LLMs) have a surprising failure: when trained on \"A\nhas a feature B\", they do not generalize to \"B is a feature of A\", which is\ntermed the Reversal Curse. Even when training with trillions of tokens this\nissue still appears due to Zipf's law - hence even if we train on the entire\ninternet. This work proposes an alternative training scheme, called reverse\ntraining, whereby all words are used twice, doubling the amount of available\ntokens. The LLM is trained in both forward and reverse directions by reversing\nthe training strings while preserving (i.e., not reversing) chosen substrings,\nsuch as entities. We show that data-matched reverse-trained models provide\nsuperior performance to standard models on standard tasks, and compute-matched\nreverse-trained models provide far superior performance on reversal tasks,\nhelping resolve the reversal curse issue.\n","authors":["Olga Golovneva","Zeyuan Allen-Zhu","Jason Weston","Sainbayar Sukhbaatar"],"pdf_url":"https://arxiv.org/pdf/2403.13799v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13798v1","updated":"2024-03-20T17:55:21Z","published":"2024-03-20T17:55:21Z","title":"Hierarchical NeuroSymbolic Approach for Action Quality Assessment","summary":"  Action quality assessment (AQA) applies computer vision to quantitatively\nassess the performance or execution of a human action. Current AQA approaches\nare end-to-end neural models, which lack transparency and tend to be biased\nbecause they are trained on subjective human judgements as ground-truth. To\naddress these issues, we introduce a neuro-symbolic paradigm for AQA, which\nuses neural networks to abstract interpretable symbols from video data and\nmakes quality assessments by applying rules to those symbols. We take diving as\nthe case study. We found that domain experts prefer our system and find it more\ninformative than purely neural approaches to AQA in diving. Our system also\nachieves state-of-the-art action recognition and temporal segmentation, and\nautomatically generates a detailed report that breaks the dive down into its\nelements and provides objective scoring with visual evidence. As verified by a\ngroup of domain experts, this report may be used to assist judges in scoring,\nhelp train judges, and provide feedback to divers. We will open-source all of\nour annotated training data and code for ease of reproducibility.\n","authors":["Lauren Okamoto","Paritosh Parmar"],"pdf_url":"https://arxiv.org/pdf/2403.13798v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13784v1","updated":"2024-03-20T17:47:08Z","published":"2024-03-20T17:47:08Z","title":"The Model Openness Framework: Promoting Completeness and Openness for\n  Reproducibility, Transparency and Usability in AI","summary":"  Generative AI (GAI) offers unprecedented possibilities but its\ncommercialization has raised concerns about transparency, reproducibility,\nbias, and safety. Many \"open-source\" GAI models lack the necessary components\nfor full understanding and reproduction, and some use restrictive licenses, a\npractice known as \"openwashing.\" We propose the Model Openness Framework (MOF),\na ranked classification system that rates machine learning models based on\ntheir completeness and openness, following principles of open science, open\nsource, open data, and open access. The MOF requires specific components of the\nmodel development lifecycle to be included and released under appropriate open\nlicenses. This framework aims to prevent misrepresentation of models claiming\nto be open, guide researchers and developers in providing all model components\nunder permissive licenses, and help companies, academia, and hobbyists identify\nmodels that can be safely adopted without restrictions. Wide adoption of the\nMOF will foster a more open AI ecosystem, accelerating research, innovation,\nand adoption.\n","authors":["Matt White","Ibrahim Haddad","Cailean Osborne"," Xiao-Yang"," Liu","Ahmed Abdelmonsef","Sachin Varghese"],"pdf_url":"https://arxiv.org/pdf/2403.13784v1.pdf","comment":"45 pages"},{"id":"http://arxiv.org/abs/2403.13780v1","updated":"2024-03-20T17:42:08Z","published":"2024-03-20T17:42:08Z","title":"Information-Theoretic Distillation for Reference-less Summarization","summary":"  The current winning recipe for automatic summarization is using proprietary\nlarge-scale language models (LLMs) such as ChatGPT as is, or imitation learning\nfrom them as teacher models. While increasingly ubiquitous dependence on such\nlarge-scale language models is convenient, there remains an important question\nof whether small-scale models could have achieved competitive results, if we\nwere to seek an alternative learning method -- that allows for a more\ncost-efficient, controllable, yet powerful summarizer. We present InfoSumm, a\nnovel framework to distill a powerful summarizer based on the\ninformation-theoretic objective for summarization, without relying on either\nthe LLM's capability or human-written references. To achieve this, we first\npropose a novel formulation of the desiderata of summarization (saliency,\nfaithfulness and brevity) through the lens of mutual information between the\noriginal document and the summary. Based on this formulation, we start off from\nPythia-2.8B as the teacher model, which is not yet capable of summarization,\nthen self-train the model to optimize for the information-centric measures of\nideal summaries. Distilling from the improved teacher, we arrive at a compact\nbut powerful summarizer with only 568M parameters that performs competitively\nagainst ChatGPT, without ever relying on ChatGPT's capabilities. Extensive\nanalysis demonstrates that our approach outperforms in-domain supervised models\nin human evaluation, let alone state-of-the-art unsupervised methods, and wins\nover ChatGPT in controllable summarization.\n","authors":["Jaehun Jung","Ximing Lu","Liwei Jiang","Faeze Brahman","Peter West","Pang Wei Koh","Yejin Choi"],"pdf_url":"https://arxiv.org/pdf/2403.13780v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.09368v2","updated":"2024-03-20T17:36:35Z","published":"2024-02-14T18:13:51Z","title":"Magic-Me: Identity-Specific Video Customized Diffusion","summary":"  Creating content with specified identities (ID) has attracted significant\ninterest in the field of generative models. In the field of text-to-image\ngeneration (T2I), subject-driven creation has achieved great progress with the\nidentity controlled via reference images. However, its extension to video\ngeneration is not well explored. In this work, we propose a simple yet\neffective subject identity controllable video generation framework, termed\nVideo Custom Diffusion (VCD). With a specified identity defined by a few\nimages, VCD reinforces the identity characteristics and injects frame-wise\ncorrelation at the initialization stage for stable video outputs. To achieve\nthis, we propose three novel components that are essential for high-quality\nidentity preservation and stable video generation: 1) a noise initialization\nmethod with 3D Gaussian Noise Prior for better inter-frame stability; 2) an ID\nmodule based on extended Textual Inversion trained with the cropped identity to\ndisentangle the ID information from the background 3) Face VCD and Tiled VCD\nmodules to reinforce faces and upscale the video to higher resolution while\npreserving the identity's features. We conducted extensive experiments to\nverify that VCD is able to generate stable videos with better ID over the\nbaselines. Besides, with the transferability of the encoded identity in the ID\nmodule, VCD is also working well with personalized text-to-image models\navailable publicly. The codes are available at\nhttps://github.com/Zhen-Dong/Magic-Me.\n","authors":["Ze Ma","Daquan Zhou","Chun-Hsiao Yeh","Xue-She Wang","Xiuyu Li","Huanrui Yang","Zhen Dong","Kurt Keutzer","Jiashi Feng"],"pdf_url":"https://arxiv.org/pdf/2402.09368v2.pdf","comment":"Project Page at https://magic-me-webpage.github.io"},{"id":"http://arxiv.org/abs/2306.06192v5","updated":"2024-03-20T17:36:07Z","published":"2023-06-09T18:45:15Z","title":"Ada-NAV: Adaptive Trajectory Length-Based Sample Efficient Policy\n  Learning for Robotic Navigation","summary":"  Trajectory length stands as a crucial hyperparameter within reinforcement\nlearning (RL) algorithms, significantly contributing to the sample inefficiency\nin robotics applications. Motivated by the pivotal role trajectory length plays\nin the training process, we introduce Ada-NAV, a novel adaptive trajectory\nlength scheme designed to enhance the training sample efficiency of RL\nalgorithms in robotic navigation tasks. Unlike traditional approaches that\ntreat trajectory length as a fixed hyperparameter, we propose to dynamically\nadjust it based on the entropy of the underlying navigation policy.\nInterestingly, Ada-NAV can be applied to both existing on-policy and off-policy\nRL methods, which we demonstrate by empirically validating its efficacy on\nthree popular RL methods: REINFORCE, Proximal Policy Optimization (PPO), and\nSoft Actor-Critic (SAC). We demonstrate through simulated and real-world\nrobotic experiments that Ada-NAV outperforms conventional methods that employ\nconstant or randomly sampled trajectory lengths. Specifically, for a fixed\nsample budget, Ada-NAV achieves an 18\\% increase in navigation success rate, a\n20-38\\% reduction in navigation path length, and a 9.32\\% decrease in elevation\ncosts. Furthermore, we showcase the versatility of Ada-NAV by integrating it\nwith the Clearpath Husky robot, illustrating its applicability in complex\noutdoor environments.\n","authors":["Bhrij Patel","Kasun Weerakoon","Wesley A. Suttle","Alec Koppel","Brian M. Sadler","Tianyi Zhou","Amrit Singh Bedi","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2306.06192v5.pdf","comment":"11 pages, 9 figures, 2 tables"},{"id":"http://arxiv.org/abs/2403.13765v1","updated":"2024-03-20T17:28:17Z","published":"2024-03-20T17:28:17Z","title":"Towards Principled Representation Learning from Videos for Reinforcement\n  Learning","summary":"  We study pre-training representations for decision-making using video data,\nwhich is abundantly available for tasks such as game agents and software\ntesting. Even though significant empirical advances have been made on this\nproblem, a theoretical understanding remains absent. We initiate the\ntheoretical investigation into principled approaches for representation\nlearning and focus on learning the latent state representations of the\nunderlying MDP using video data. We study two types of settings: one where\nthere is iid noise in the observation, and a more challenging setting where\nthere is also the presence of exogenous noise, which is non-iid noise that is\ntemporally correlated, such as the motion of people or cars in the background.\nWe study three commonly used approaches: autoencoding, temporal contrastive\nlearning, and forward modeling. We prove upper bounds for temporal contrastive\nlearning and forward modeling in the presence of only iid noise. We show that\nthese approaches can learn the latent state and use it to do efficient\ndownstream RL with polynomial sample complexity. When exogenous noise is also\npresent, we establish a lower bound result showing that the sample complexity\nof learning from video data can be exponentially worse than learning from\naction-labeled trajectory data. This partially explains why reinforcement\nlearning with video pre-training is hard. We evaluate these representational\nlearning methods in two visual domains, yielding results that are consistent\nwith our theoretical findings.\n","authors":["Dipendra Misra","Akanksha Saran","Tengyang Xie","Alex Lamb","John Langford"],"pdf_url":"https://arxiv.org/pdf/2403.13765v1.pdf","comment":"ICLR 2024 Spotlight Conference Paper"},{"id":"http://arxiv.org/abs/2312.00651v2","updated":"2024-03-20T17:28:02Z","published":"2023-12-01T15:24:38Z","title":"TrackDiffusion: Tracklet-Conditioned Video Generation via Diffusion\n  Models","summary":"  Despite remarkable achievements in video synthesis, achieving granular\ncontrol over complex dynamics, such as nuanced movement among multiple\ninteracting objects, still presents a significant hurdle for dynamic world\nmodeling, compounded by the necessity to manage appearance and disappearance,\ndrastic scale changes, and ensure consistency for instances across frames.\nThese challenges hinder the development of video generation that can faithfully\nmimic real-world complexity, limiting utility for applications requiring\nhigh-level realism and controllability, including advanced scene simulation and\ntraining of perception systems. To address that, we propose TrackDiffusion, a\nnovel video generation framework affording fine-grained trajectory-conditioned\nmotion control via diffusion models, which facilitates the precise manipulation\nof the object trajectories and interactions, overcoming the prevalent\nlimitation of scale and continuity disruptions. A pivotal component of\nTrackDiffusion is the instance enhancer, which explicitly ensures inter-frame\nconsistency of multiple objects, a critical factor overlooked in the current\nliterature. Moreover, we demonstrate that generated video sequences by our\nTrackDiffusion can be used as training data for visual perception models. To\nthe best of our knowledge, this is the first work to apply video diffusion\nmodels with tracklet conditions and demonstrate that generated frames can be\nbeneficial for improving the performance of object trackers.\n","authors":["Pengxiang Li","Kai Chen","Zhili Liu","Ruiyuan Gao","Lanqing Hong","Guo Zhou","Hua Yao","Dit-Yan Yeung","Huchuan Lu","Xu Jia"],"pdf_url":"https://arxiv.org/pdf/2312.00651v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.14456v4","updated":"2024-03-20T17:16:37Z","published":"2023-05-23T18:27:51Z","title":"Having Beer after Prayer? Measuring Cultural Bias in Large Language\n  Models","summary":"  As the reach of large language models (LMs) expands globally, their ability\nto cater to diverse cultural contexts becomes crucial. Despite advancements in\nmultilingual capabilities, models are not designed with appropriate cultural\nnuances. In this paper, we show that multilingual and Arabic monolingual LMs\nexhibit bias towards entities associated with Western culture. We introduce\nCAMeL, a novel resource of 628 naturally-occurring prompts and 20,368 entities\nspanning eight types that contrast Arab and Western cultures. CAMeL provides a\nfoundation for measuring cultural biases in LMs through both extrinsic and\nintrinsic evaluations. Using CAMeL, we examine the cross-cultural performance\nin Arabic of 16 different LMs on tasks such as story generation, NER, and\nsentiment analysis, where we find concerning cases of stereotyping and cultural\nunfairness. We further test their text-infilling performance, revealing the\nincapability of appropriate adaptation to Arab cultural contexts. Finally, we\nanalyze 6 Arabic pre-training corpora and find that commonly used sources such\nas Wikipedia may not be best suited to build culturally aware LMs, if used as\nthey are without adjustment. We will make CAMeL publicly available at:\nhttps://github.com/tareknaous/camel\n","authors":["Tarek Naous","Michael J. Ryan","Alan Ritter","Wei Xu"],"pdf_url":"https://arxiv.org/pdf/2305.14456v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.05666v5","updated":"2024-03-20T16:50:25Z","published":"2023-02-11T11:56:06Z","title":"Jaccard Metric Losses: Optimizing the Jaccard Index with Soft Labels","summary":"  Intersection over Union (IoU) losses are surrogates that directly optimize\nthe Jaccard index. Leveraging IoU losses as part of the loss function have\ndemonstrated superior performance in semantic segmentation tasks compared to\noptimizing pixel-wise losses such as the cross-entropy loss alone. However, we\nidentify a lack of flexibility in these losses to support vital training\ntechniques like label smoothing, knowledge distillation, and semi-supervised\nlearning, mainly due to their inability to process soft labels. To address\nthis, we introduce Jaccard Metric Losses (JMLs), which are identical to the\nsoft Jaccard loss in standard settings with hard labels but are fully\ncompatible with soft labels. We apply JMLs to three prominent use cases of soft\nlabels: label smoothing, knowledge distillation and semi-supervised learning,\nand demonstrate their potential to enhance model accuracy and calibration. Our\nexperiments show consistent improvements over the cross-entropy loss across 4\nsemantic segmentation datasets (Cityscapes, PASCAL VOC, ADE20K, DeepGlobe Land)\nand 13 architectures, including classic CNNs and recent vision transformers.\nRemarkably, our straightforward approach significantly outperforms\nstate-of-the-art knowledge distillation and semi-supervised learning methods.\nThe code is available at\n\\href{https://github.com/zifuwanggg/JDTLosses}{https://github.com/zifuwanggg/JDTLosses}.\n","authors":["Zifu Wang","Xuefei Ning","Matthew B. Blaschko"],"pdf_url":"https://arxiv.org/pdf/2302.05666v5.pdf","comment":"NeurIPS 2023"},{"id":"http://arxiv.org/abs/2403.13741v1","updated":"2024-03-20T16:47:53Z","published":"2024-03-20T16:47:53Z","title":"Hyper Strategy Logic","summary":"  Strategy logic (SL) is a powerful temporal logic that enables strategic\nreasoning in multi-agent systems. SL supports explicit (first-order)\nquantification over strategies and provides a logical framework to express many\nimportant properties such as Nash equilibria, dominant strategies, etc. While\nin SL the same strategy can be used in multiple strategy profiles, each such\nprofile is evaluated w.r.t. a path-property, i.e., a property that considers\nthe single path resulting from a particular strategic interaction. In this\npaper, we present Hyper Strategy Logic (HyperSL), a strategy logic where the\noutcome of multiple strategy profiles can be compared w.r.t. a hyperproperty,\ni.e., a property that relates multiple paths. We show that HyperSL can capture\nimportant properties that cannot be expressed in SL, including\nnon-interference, quantitative Nash equilibria, optimal adversarial planning,\nand reasoning under imperfect information. On the algorithmic side, we identify\nan expressive fragment of HyperSL with decidable model checking and present a\nmodel-checking algorithm. We contribute a prototype implementation of our\nalgorithm and report on encouraging experimental results.\n","authors":["Raven Beutner","Bernd Finkbeiner"],"pdf_url":"https://arxiv.org/pdf/2403.13741v1.pdf","comment":"AAMAS 2024"},{"id":"http://arxiv.org/abs/2403.13729v1","updated":"2024-03-20T16:39:17Z","published":"2024-03-20T16:39:17Z","title":"Reinforcement Learning for Online Testing of Autonomous Driving Systems:\n  a Replication and Extension Study","summary":"  In a recent study, Reinforcement Learning (RL) used in combination with\nmany-objective search, has been shown to outperform alternative techniques\n(random search and many-objective search) for online testing of Deep Neural\nNetwork-enabled systems. The empirical evaluation of these techniques was\nconducted on a state-of-the-art Autonomous Driving System (ADS). This work is a\nreplication and extension of that empirical study. Our replication shows that\nRL does not outperform pure random test generation in a comparison conducted\nunder the same settings of the original study, but with no confounding factor\ncoming from the way collisions are measured. Our extension aims at eliminating\nsome of the possible reasons for the poor performance of RL observed in our\nreplication: (1) the presence of reward components providing contrasting or\nuseless feedback to the RL agent; (2) the usage of an RL algorithm (Q-learning)\nwhich requires discretization of an intrinsically continuous state space.\nResults show that our new RL agent is able to converge to an effective policy\nthat outperforms random testing. Results also highlight other possible\nimprovements, which open to further investigations on how to best leverage RL\nfor online ADS testing.\n","authors":["Luca Giamattei","Matteo Biagiola","Roberto Pietrantuono","Stefano Russo","Paolo Tonella"],"pdf_url":"https://arxiv.org/pdf/2403.13729v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13728v1","updated":"2024-03-20T16:38:26Z","published":"2024-03-20T16:38:26Z","title":"M-HOF-Opt: Multi-Objective Hierarchical Output Feedback Optimization via\n  Multiplier Induced Loss Landscape Scheduling","summary":"  When a neural network parameterized loss function consists of many terms, the\ncombinatorial choice of weight multipliers during the optimization process\nforms a challenging problem. To address this, we proposed a probabilistic\ngraphical model (PGM) for the joint model parameter and multiplier evolution\nprocess, with a hypervolume based likelihood that promotes multi-objective\ndescent of each loss term. The corresponding parameter and multiplier\nestimation as a sequential decision process is then cast into an optimal\ncontrol problem, where the multi-objective descent goal is dispatched\nhierarchically into a series of constraint optimization sub-problems. The\nsub-problem constraint automatically adapts itself according to Pareto\ndominance and serves as the setpoint for the low level multiplier controller to\nschedule loss landscapes via output feedback of each loss term. Our method is\nmultiplier-free and operates at the timescale of epochs, thus saves tremendous\ncomputational resources compared to full training cycle multiplier tuning. We\napplied it to domain invariant variational auto-encoding with 6 loss terms on\nthe PACS domain generalization task, and observed robust performance across a\nrange of controller hyperparameters, as well as different multiplier initial\nconditions, outperforming other multiplier scheduling methods. We offered\nmodular implementation of our method, admitting custom definition of many loss\nterms for applying our multi-objective hierarchical output feedback training\nscheme to other deep learning fields.\n","authors":["Xudong Sun","Nutan Chen","Alexej Gossmann","Yu Xing","Carla Feistner","Emilio Dorigatt","Felix Drost","Daniele Scarcella","Lisa Beer","Carsten Marr"],"pdf_url":"https://arxiv.org/pdf/2403.13728v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.12963v3","updated":"2024-03-20T16:36:06Z","published":"2023-10-19T17:57:39Z","title":"AutoMix: Automatically Mixing Language Models","summary":"  Large language models (LLMs) are now available from cloud API providers in\nvarious sizes and configurations. While this diversity offers a broad spectrum\nof choices, effectively leveraging the options to optimize computational cost\nand performance remains challenging. In this work, we present AutoMix, an\napproach that strategically routes queries to larger LMs, based on the\napproximate correctness of outputs from a smaller LM. Central to AutoMix is a\nfew-shot self-verification mechanism, which estimates the reliability of its\nown outputs without requiring training. Given that verifications can be noisy,\nwe employ a meta-verifier in AutoMix to refine the accuracy of these\nassessments. Our experiments using LLAMA2-13B and GPT-4, on five\ncontext-grounded reasoning datasets demonstrate that AutoMix surpasses\nestablished baselines, improving the incremental benefit per cost by up to 86%.\nOur code and data are available at https://github.com/automix-llm/automix.\n","authors":["Aman Madaan","Pranjal Aggarwal","Ankit Anand","Srividya Pranavi Potharaju","Swaroop Mishra","Pei Zhou","Aditya Gupta","Dheeraj Rajagopal","Karthik Kappaganthu","Yiming Yang","Shyam Upadhyay"," Mausam","Manaal Faruqui"],"pdf_url":"https://arxiv.org/pdf/2310.12963v3.pdf","comment":"The first two authors contributed equally. Work started and partly\n  done during Aman's internship at Google. This version adds results on\n  additional models and datasets"},{"id":"http://arxiv.org/abs/2403.09184v2","updated":"2024-03-20T16:34:37Z","published":"2024-03-14T08:54:19Z","title":"Learning Algorithms for Verification of Markov Decision Processes","summary":"  We present a general framework for applying learning algorithms and\nheuristical guidance to the verification of Markov decision processes (MDPs).\nThe primary goal of our techniques is to improve performance by avoiding an\nexhaustive exploration of the state space, instead focussing on particularly\nrelevant areas of the system, guided by heuristics. Our work builds on the\nprevious results of Br{\\'{a}}zdil et al., significantly extending it as well as\nrefining several details and fixing errors.\n  The presented framework focuses on probabilistic reachability, which is a\ncore problem in verification, and is instantiated in two distinct scenarios.\nThe first assumes that full knowledge of the MDP is available, in particular\nprecise transition probabilities. It performs a heuristic-driven partial\nexploration of the model, yielding precise lower and upper bounds on the\nrequired probability. The second tackles the case where we may only sample the\nMDP without knowing the exact transition dynamics. Here, we obtain\nprobabilistic guarantees, again in terms of both the lower and upper bounds,\nwhich provides efficient stopping criteria for the approximation. In\nparticular, the latter is an extension of statistical model-checking (SMC) for\nunbounded properties in MDPs. In contrast to other related approaches, we do\nnot restrict our attention to time-bounded (finite-horizon) or discounted\nproperties, nor assume any particular structural properties of the MDP.\n","authors":["Tomáš Brázdil","Krishnendu Chatterjee","Martin Chmelik","Vojtěch Forejt","Jan Křetínský","Marta Kwiatkowska","Tobias Meggendorfer","David Parker","Mateusz Ujma"],"pdf_url":"https://arxiv.org/pdf/2403.09184v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13721v1","updated":"2024-03-20T16:29:52Z","published":"2024-03-20T16:29:52Z","title":"Large Language Models meet Network Slicing Management and Orchestration","summary":"  Network slicing, a cornerstone technology for future networks, enables the\ncreation of customized virtual networks on a shared physical infrastructure.\nThis fosters innovation and agility by providing dedicated resources tailored\nto specific applications. However, current orchestration and management\napproaches face limitations in handling the complexity of new service demands\nwithin multi-administrative domain environments. This paper proposes a future\nvision for network slicing powered by Large Language Models (LLMs) and\nmulti-agent systems, offering a framework that can be integrated with existing\nManagement and Orchestration (MANO) frameworks. This framework leverages LLMs\nto translate user intent into technical requirements, map network functions to\ninfrastructure, and manage the entire slice lifecycle, while multi-agent\nsystems facilitate collaboration across different administrative domains. We\nalso discuss the challenges associated with implementing this framework and\npotential solutions to mitigate them.\n","authors":["Abdulhalim Dandoush","Viswanath Kumarskandpriya","Mueen Uddin","Usman Khalil"],"pdf_url":"https://arxiv.org/pdf/2403.13721v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.07915v3","updated":"2024-03-20T16:17:02Z","published":"2023-09-14T17:59:17Z","title":"MMICL: Empowering Vision-language Model with Multi-Modal In-Context\n  Learning","summary":"  Since the resurgence of deep learning, vision-language models (VLMs) enhanced\nby large language models (LLMs) have grown exponentially in popularity.\nHowever, while LLMs can utilize extensive background knowledge and task\ninformation with in-context learning, most VLMs still struggle with\nunderstanding complex multi-modal prompts with multiple images, making VLMs\nless effective in downstream vision-language tasks. In this paper, we address\nthe limitation above by 1) introducing vision-language Model with Multi-Modal\nIn-Context Learning(MMICL), a new approach to allow the VLM to deal with\nmulti-modal inputs efficiently; 2) proposing a novel context scheme to augment\nthe in-context learning ability of the VLM; 3) constructing the Multi-modal\nIn-Context Learning (MIC) dataset, designed to enhance the VLM's ability to\nunderstand complex multi-modal prompts. Our experiments confirm that MMICL\nachieves new state-of-the-art zero-shot performance on a wide range of general\nvision-language tasks, especially for complex benchmarks, including MME and\nMMBench. Our analysis demonstrates that MMICL effectively tackles the challenge\nof complex multi-modal prompt understanding and emerges the impressive ICL\nability. Furthermore, we observe that MMICL successfully alleviates language\nbias in VLMs, a common issue for VLMs that often leads to hallucination when\nfaced with extensive textual context. Our code, dataset, dataset tool, and\nmodel are available at https://github.com/PKUnlp-icler/MIC\n","authors":["Haozhe Zhao","Zefan Cai","Shuzheng Si","Xiaojian Ma","Kaikai An","Liang Chen","Zixuan Liu","Sheng Wang","Wenjuan Han","Baobao Chang"],"pdf_url":"https://arxiv.org/pdf/2309.07915v3.pdf","comment":"Accepted by ICLR2024"},{"id":"http://arxiv.org/abs/2403.12143v2","updated":"2024-03-20T16:12:12Z","published":"2024-03-18T18:01:01Z","title":"Graph Neural Networks for Learning Equivariant Representations of Neural\n  Networks","summary":"  Neural networks that process the parameters of other neural networks find\napplications in domains as diverse as classifying implicit neural\nrepresentations, generating neural network weights, and predicting\ngeneralization errors. However, existing approaches either overlook the\ninherent permutation symmetry in the neural network or rely on intricate\nweight-sharing patterns to achieve equivariance, while ignoring the impact of\nthe network architecture itself. In this work, we propose to represent neural\nnetworks as computational graphs of parameters, which allows us to harness\npowerful graph neural networks and transformers that preserve permutation\nsymmetry. Consequently, our approach enables a single model to encode neural\ncomputational graphs with diverse architectures. We showcase the effectiveness\nof our method on a wide range of tasks, including classification and editing of\nimplicit neural representations, predicting generalization performance, and\nlearning to optimize, while consistently outperforming state-of-the-art\nmethods. The source code is open-sourced at\nhttps://github.com/mkofinas/neural-graphs.\n","authors":["Miltiadis Kofinas","Boris Knyazev","Yan Zhang","Yunlu Chen","Gertjan J. Burghouts","Efstratios Gavves","Cees G. M. Snoek","David W. Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.12143v2.pdf","comment":"In ICLR 2024. Source code: https://github.com/mkofinas/neural-graphs"},{"id":"http://arxiv.org/abs/2403.13705v1","updated":"2024-03-20T16:08:57Z","published":"2024-03-20T16:08:57Z","title":"Research Re: search & Re-search","summary":"  Search algorithms are often categorized by their node expansion strategy. One\noption is the depth-first strategy, a simple backtracking strategy that\ntraverses the search space in the order in which successor nodes are generated.\nAn alternative is the best-first strategy, which was designed to make it\npossible to use domain-specific heuristic information. By exploring promising\nparts of the search space first, best-first algorithms are usually more\nefficient than depth-first algorithms.\n  In programs that play minimax games such as chess and checkers, the\nefficiency of the search is of crucial importance. Given the success of\nbest-first algorithms in other domains, one would expect them to be used for\nminimax games too. However, all high-performance game-playing programs are\nbased on a depth-first algorithm.\n  This study takes a closer look at a depth-first algorithm, AB, and a\nbest-first algorithm, SSS. The prevailing opinion on these algorithms is that\nSSS offers the potential for a more efficient search, but that its complicated\nformulation and exponential memory requirements render it impractical. The\ntheoretical part of this work shows that there is a surprisingly\nstraightforward link between the two algorithms -- for all practical purposes,\nSSS is a special case of AB. Subsequent empirical evidence proves the\nprevailing opinion on SSS to be wrong: it is not a complicated algorithm, it\ndoes not need too much memory, and it is also not more efficient than\ndepth-first search.\n","authors":["Aske Plaat"],"pdf_url":"https://arxiv.org/pdf/2403.13705v1.pdf","comment":"PhD thesis Aske Plaat 20 June 1996. AlphaBeta, SSS*, MTD(f)"},{"id":"http://arxiv.org/abs/2403.13703v1","updated":"2024-03-20T16:07:04Z","published":"2024-03-20T16:07:04Z","title":"Fostc3net:A Lightweight YOLOv5 Based On the Network Structure\n  Optimization","summary":"  Transmission line detection technology is crucial for automatic monitoring\nand ensuring the safety of electrical facilities. The YOLOv5 series is\ncurrently one of the most advanced and widely used methods for object\ndetection. However, it faces inherent challenges, such as high computational\nload on devices and insufficient detection accuracy. To address these concerns,\nthis paper presents an enhanced lightweight YOLOv5 technique customized for\nmobile devices, specifically intended for identifying objects associated with\ntransmission lines. The C3Ghost module is integrated into the convolutional\nnetwork of YOLOv5 to reduce floating point operations per second (FLOPs) in the\nfeature channel fusion process and improve feature expression performance. In\naddition, a FasterNet module is introduced to replace the c3 module in the\nYOLOv5 Backbone. The FasterNet module uses Partial Convolutions to process only\na portion of the input channels, improving feature extraction efficiency and\nreducing computational overhead. To address the imbalance between simple and\nchallenging samples in the dataset and the diversity of aspect ratios of\nbounding boxes, the wIoU v3 LOSS is adopted as the loss function. To validate\nthe performance of the proposed approach, Experiments are conducted on a custom\ndataset of transmission line poles. The results show that the proposed model\nachieves a 1% increase in detection accuracy, a 13% reduction in FLOPs, and a\n26% decrease in model parameters compared to the existing YOLOv5.In the\nablation experiment, it was also discovered that while the Fastnet module and\nthe CSghost module improved the precision of the original YOLOv5 baseline\nmodel, they caused a decrease in the mAP@.5-.95 metric. However, the\nimprovement of the wIoUv3 loss function significantly mitigated the decline of\nthe mAP@.5-.95 metric.\n","authors":["Danqing Ma","Shaojie Li","Bo Dang","Hengyi Zang","Xinqi Dong"],"pdf_url":"https://arxiv.org/pdf/2403.13703v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.16296v4","updated":"2024-03-20T15:52:49Z","published":"2023-03-28T20:35:38Z","title":"Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels","summary":"  The soft Dice loss (SDL) has taken a pivotal role in numerous automated\nsegmentation pipelines in the medical imaging community. Over the last years,\nsome reasons behind its superior functioning have been uncovered and further\noptimizations have been explored. However, there is currently no implementation\nthat supports its direct utilization in scenarios involving soft labels. Hence,\na synergy between the use of SDL and research leveraging the use of soft\nlabels, also in the context of model calibration, is still missing. In this\nwork, we introduce Dice semimetric losses (DMLs), which (i) are by design\nidentical to SDL in a standard setting with hard labels, but (ii) can be\nemployed in settings with soft labels. Our experiments on the public QUBIQ,\nLiTS and KiTS benchmarks confirm the potential synergy of DMLs with soft labels\n(e.g. averaging, label smoothing, and knowledge distillation) over hard labels\n(e.g. majority voting and random selection). As a result, we obtain superior\nDice scores and model calibration, which supports the wider adoption of DMLs in\npractice. The code is available at https://github.com/zifuwanggg/JDTLosses\n","authors":["Zifu Wang","Teodora Popordanoska","Jeroen Bertels","Robin Lemmens","Matthew B. Blaschko"],"pdf_url":"https://arxiv.org/pdf/2303.16296v4.pdf","comment":"MICCAI 2023"},{"id":"http://arxiv.org/abs/2403.13684v1","updated":"2024-03-20T15:41:39Z","published":"2024-03-20T15:41:39Z","title":"SPTNet: An Efficient Alternative Framework for Generalized Category\n  Discovery with Spatial Prompt Tuning","summary":"  Generalized Category Discovery (GCD) aims to classify unlabelled images from\nboth `seen' and `unseen' classes by transferring knowledge from a set of\nlabelled `seen' class images. A key theme in existing GCD approaches is\nadapting large-scale pre-trained models for the GCD task. An alternate\nperspective, however, is to adapt the data representation itself for better\nalignment with the pre-trained model. As such, in this paper, we introduce a\ntwo-stage adaptation approach termed SPTNet, which iteratively optimizes model\nparameters (i.e., model-finetuning) and data parameters (i.e., prompt\nlearning). Furthermore, we propose a novel spatial prompt tuning method (SPT)\nwhich considers the spatial property of image data, enabling the method to\nbetter focus on object parts, which can transfer between seen and unseen\nclasses. We thoroughly evaluate our SPTNet on standard benchmarks and\ndemonstrate that our method outperforms existing GCD methods. Notably, we find\nour method achieves an average accuracy of 61.4% on the SSB, surpassing prior\nstate-of-the-art methods by approximately 10%. The improvement is particularly\nremarkable as our method yields extra parameters amounting to only 0.117% of\nthose in the backbone architecture. Project page:\nhttps://visual-ai.github.io/sptnet.\n","authors":["Hongjun Wang","Sagar Vaze","Kai Han"],"pdf_url":"https://arxiv.org/pdf/2403.13684v1.pdf","comment":"Accepted as a conference paper at ICLR 2024; Project page:\n  https://visual-ai.github.io/sptnet"},{"id":"http://arxiv.org/abs/2403.13682v1","updated":"2024-03-20T15:40:18Z","published":"2024-03-20T15:40:18Z","title":"Threats, Attacks, and Defenses in Machine Unlearning: A Survey","summary":"  Recently, Machine Unlearning (MU) has gained considerable attention for its\npotential to improve AI safety by removing the influence of specific data from\ntrained Machine Learning (ML) models. This process, known as knowledge removal,\naddresses concerns about data such as sensitivity, copyright restrictions,\nobsolescence, or low quality. This capability is also crucial for ensuring\ncompliance with privacy regulations such as the Right To Be Forgotten (RTBF).\nTherefore, strategic knowledge removal mitigates the risk of harmful outcomes,\nsafeguarding against biases, misinformation, and unauthorized data\nexploitation, thereby enhancing the ethical use and reliability of AI systems.\nEfforts have been made to design efficient unlearning approaches, with MU\nservices being examined for integration with existing machine learning as a\nservice (MLaaS), allowing users to submit requests to erase data. However,\nrecent research highlights vulnerabilities in machine unlearning systems, such\nas information leakage and malicious unlearning requests, that can lead to\nsignificant security and privacy concerns. Moreover, extensive research\nindicates that unlearning methods and prevalent attacks fulfill diverse roles\nwithin MU systems. For instance, unlearning can act as a mechanism to recover\nmodels from backdoor attacks, while backdoor attacks themselves can serve as an\nevaluation metric for unlearning effectiveness. This underscores the intricate\nrelationship and complex interplay between these elements in maintaining system\nfunctionality and safety. Therefore, this survey seeks to bridge the gap\nbetween the extensive number of studies on threats, attacks, and defenses in\nmachine unlearning and the absence of a comprehensive review that categorizes\ntheir taxonomy, methods, and solutions, thus offering valuable insights for\nfuture research directions and practical implementations.\n","authors":["Ziyao Liu","Huanyi Ye","Chen Chen","Kwok-Yan Lam"],"pdf_url":"https://arxiv.org/pdf/2403.13682v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13681v1","updated":"2024-03-20T15:39:54Z","published":"2024-03-20T15:39:54Z","title":"PARAMANU-AYN: An Efficient Novel Generative and Instruction-tuned\n  Language Model for Indian Legal Case Documents","summary":"  In this paper, we present PARAMANU-AYN, a language model based exclusively on\ncase documents of the Supreme Court of India, the Constitution of India, and\nthe Indian Penal Code. The novel Auto Regressive (AR) decoder based model is\npretrained from scratch at a context size of 8192. We evaluated our pretrained\nlegal model on perplexity metrics. We also instruction-tuned our pretrained\nmodel on a set of 10,763 instructions covering various legal tasks such as\nlegal reasoning, judgement explanation, legal clause generation, legal\ndrafting, legal contract drafting, case summarization, constitutional\nquestion-answering, etc. We also evaluated the responses of prompts for\ninstruction-tuned models by GPT-3.5-Turbo on clarity, relevance, completeness,\nand legal reasoning metrics in a scale of 10. Our model can be run on CPU and\nachieved 42.46 tokens/sec CPU inference speed. We found that our models,\ndespite not being pretrained on legal books, various legal contracts, and legal\ndocuments, were able to learn the domain knowledge required for drafting\nvarious legal contracts and legal clauses, and generalize to draft legal\ncontracts and legal clauses with limited instruction tuning. Hence, we conclude\nthat for a strong domain-specialized generative language model (such as legal),\nvery large amounts of data are not required to develop models from scratch. We\nbelieve that this work is the first attempt to make a dedicated generative\nlegal language model from scratch for Indian Supreme Court jurisdiction or in\nlegal NLP overall. We plan to release our Paramanu-Ayn model at\nhttps://www.bharatgpts.com.\n","authors":["Mitodru Niyogi","Arnab Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2403.13681v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.10705v4","updated":"2024-03-20T15:26:55Z","published":"2023-10-16T14:46:45Z","title":"Observational and Experimental Insights into Machine Learning-Based\n  Defect Classification in Wafers","summary":"  This survey paper offers a comprehensive review of methodologies utilizing\nmachine learning (ML) classification techniques for identifying wafer defects\nin semiconductor manufacturing. Despite the growing body of research\ndemonstrating the effectiveness of ML in wafer defect identification, there is\na noticeable absence of comprehensive reviews on this subject. This survey\nattempts to fill this void by amalgamating available literature and providing\nan in-depth analysis of the advantages, limitations, and potential applications\nof various ML classification algorithms in the realm of wafer defect detection.\nAn innovative taxonomy of methodologies that we present provides a detailed\nclassification of algorithms into more refined categories and techniques. This\ntaxonomy follows a three-tier structure, starting from broad methodology\ncategories and ending with specific techniques. It aids researchers in\ncomprehending the complex relationships between different algorithms and their\ntechniques. We employ a rigorous Observational and experimental evaluation to\nrank these varying techniques. For the Observational evaluation, we assess\ntechniques based on a set of four criteria. The experimental evaluation ranks\nthe algorithms employing the same techniques, sub-categories, and categories.\nAlso the paper illuminates the future prospects of ML classification techniques\nfor wafer defect identification, underscoring potential advancements and\nopportunities for further research in this field\n","authors":["Kamal Taha"],"pdf_url":"https://arxiv.org/pdf/2310.10705v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13653v1","updated":"2024-03-20T14:58:40Z","published":"2024-03-20T14:58:40Z","title":"Learning User Embeddings from Human Gaze for Personalised Saliency\n  Prediction","summary":"  Reusable embeddings of user behaviour have shown significant performance\nimprovements for the personalised saliency prediction task. However, prior\nworks require explicit user characteristics and preferences as input, which are\noften difficult to obtain. We present a novel method to extract user embeddings\nfrom pairs of natural images and corresponding saliency maps generated from a\nsmall amount of user-specific eye tracking data. At the core of our method is a\nSiamese convolutional neural encoder that learns the user embeddings by\ncontrasting the image and personal saliency map pairs of different users.\nEvaluations on two public saliency datasets show that the generated embeddings\nhave high discriminative power, are effective at refining universal saliency\nmaps to the individual users, and generalise well across users and images.\nFinally, based on our model's ability to encode individual user\ncharacteristics, our work points towards other applications that can benefit\nfrom reusable embeddings of gaze behaviour.\n","authors":["Florian Strohm","Mihai Bâce","Andreas Bulling"],"pdf_url":"https://arxiv.org/pdf/2403.13653v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.00117v3","updated":"2024-03-20T14:26:12Z","published":"2023-09-29T20:11:15Z","title":"ABScribe: Rapid Exploration & Organization of Multiple Writing\n  Variations in Human-AI Co-Writing Tasks using Large Language Models","summary":"  Exploring alternative ideas by rewriting text is integral to the writing\nprocess. State-of-the-art Large Language Models (LLMs) can simplify writing\nvariation generation. However, current interfaces pose challenges for\nsimultaneous consideration of multiple variations: creating new variations\nwithout overwriting text can be difficult, and pasting them sequentially can\nclutter documents, increasing workload and disrupting writers' flow. To tackle\nthis, we present ABScribe, an interface that supports rapid, yet visually\nstructured, exploration and organization of writing variations in human-AI\nco-writing tasks. With ABScribe, users can swiftly modify variations using LLM\nprompts, which are auto-converted into reusable buttons. Variations are stored\nadjacently within text fields for rapid in-place comparisons using mouse-over\ninteractions on a popup toolbar. Our user study with 12 writers shows that\nABScribe significantly reduces task workload (d = 1.20, p < 0.001), enhances\nuser perceptions of the revision process (d = 2.41, p < 0.001) compared to a\npopular baseline workflow, and provides insights into how writers explore\nvariations using LLMs.\n","authors":["Mohi Reza","Nathan Laundry","Ilya Musabirov","Peter Dushniku","Zhi Yuan \"Michael\" Yu","Kashish Mittal","Tovi Grossman","Michael Liut","Anastasia Kuzminykh","Joseph Jay Williams"],"pdf_url":"https://arxiv.org/pdf/2310.00117v3.pdf","comment":"CHI 2024"},{"id":"http://arxiv.org/abs/2403.13619v1","updated":"2024-03-20T14:13:44Z","published":"2024-03-20T14:13:44Z","title":"Dynamic Resource Allocation for Virtual Machine Migration Optimization\n  using Machine Learning","summary":"  The paragraph is grammatically correct and logically coherent. It discusses\nthe importance of mobile terminal cloud computing migration technology in\nmeeting the demands of evolving computer and cloud computing technologies. It\nemphasizes the need for efficient data access and storage, as well as the\nutilization of cloud computing migration technology to prevent additional time\ndelays. The paragraph also highlights the contributions of cloud computing\nmigration technology to expanding cloud computing services. Additionally, it\nacknowledges the role of virtualization as a fundamental capability of cloud\ncomputing while emphasizing that cloud computing and virtualization are not\ninherently interconnected. Finally, it introduces machine learning-based\nvirtual machine migration optimization and dynamic resource allocation as a\ncritical research direction in cloud computing, citing the limitations of\nstatic rules or manual settings in traditional cloud computing environments.\nOverall, the paragraph effectively communicates the importance of machine\nlearning technology in addressing resource allocation and virtual machine\nmigration challenges in cloud computing.\n","authors":["Yulu Gong","Jiaxin Huang","Bo Liu","Jingyu Xu","Binbin Wu","Yifan Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.13619v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13597v1","updated":"2024-03-20T13:44:30Z","published":"2024-03-20T13:44:30Z","title":"No more optimization rules: LLM-enabled policy-based multi-modal query\n  optimizer (version 1)","summary":"  Large language model (LLM) has marked a pivotal moment in the field of\nmachine learning and deep learning. Recently its capability for query planning\nhas been investigated, including both single-modal and multi-modal queries.\nHowever, there is no work on the query optimization capability of LLM. As a\ncritical (or could even be the most important) step that significantly impacts\nthe execution performance of the query plan, such analysis and attempts should\nnot be missed. From another aspect, existing query optimizers are usually\nrule-based or rule-based + cost-based, i.e., they are dependent on manually\ncreated rules to complete the query plan rewrite/transformation. Given the fact\nthat modern optimizers include hundreds to thousands of rules, designing a\nmulti-modal query optimizer following a similar way is significantly\ntime-consuming since we will have to enumerate as many multi-modal optimization\nrules as possible, which has not been well addressed today. In this paper, we\ninvestigate the query optimization ability of LLM and use LLM to design LaPuda,\na novel LLM and Policy based multi-modal query optimizer. Instead of\nenumerating specific and detailed rules, LaPuda only needs a few abstract\npolicies to guide LLM in the optimization, by which much time and human effort\nare saved. Furthermore, to prevent LLM from making mistakes or negative\noptimization, we borrow the idea of gradient descent and propose a guided cost\ndescent (GCD) algorithm to perform the optimization, such that the optimization\ncan be kept in the correct direction. In our evaluation, our methods\nconsistently outperform the baselines in most cases. For example, the optimized\nplans generated by our methods result in 1~3x higher execution speed than those\nby the baselines.\n","authors":["Yifan Wang","Haodi Ma","Daisy Zhe Wang"],"pdf_url":"https://arxiv.org/pdf/2403.13597v1.pdf","comment":"Yifan and Haodi contribute equally to the work"},{"id":"http://arxiv.org/abs/2306.11335v4","updated":"2024-03-20T13:18:18Z","published":"2023-06-20T07:06:04Z","title":"Surfer: Progressive Reasoning with World Models for Robotic Manipulation","summary":"  Considering how to make the model accurately understand and follow natural\nlanguage instructions and perform actions consistent with world knowledge is a\nkey challenge in robot manipulation. This mainly includes human fuzzy\ninstruction reasoning and the following of physical knowledge. Therefore, the\nembodied intelligence agent must have the ability to model world knowledge from\ntraining data. However, most existing vision and language robot manipulation\nmethods mainly operate in less realistic simulator and language settings and\nlack explicit modeling of world knowledge. To bridge this gap, we introduce a\nnovel and simple robot manipulation framework, called Surfer. It is based on\nthe world model, treats robot manipulation as a state transfer of the visual\nscene, and decouples it into two parts: action and scene. Then, the\ngeneralization ability of the model on new instructions and new scenes is\nenhanced by explicit modeling of the action and scene prediction in multi-modal\ninformation. In addition to the framework, we also built a robot manipulation\nsimulator that supports full physics execution based on the MuJoCo physics\nengine. It can automatically generate demonstration training data and test\ndata, effectively reducing labor costs. To conduct a comprehensive and\nsystematic evaluation of the robot manipulation model in terms of language\nunderstanding and physical execution, we also created a robotic manipulation\nbenchmark with progressive reasoning tasks, called SeaWave. It contains 4\nlevels of progressive reasoning tasks and can provide a standardized testing\nplatform for embedded AI agents in multi-modal environments. On average, Surfer\nachieved a success rate of 54.74% on the defined four levels of manipulation\ntasks, exceeding the best baseline performance of 47.64%.\n","authors":["Pengzhen Ren","Kaidong Zhang","Hetao Zheng","Zixuan Li","Yuhang Wen","Fengda Zhu","Mas Ma","Xiaodan Liang"],"pdf_url":"https://arxiv.org/pdf/2306.11335v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11552v2","updated":"2024-03-20T13:15:39Z","published":"2024-03-18T08:03:47Z","title":"LLM3:Large Language Model-based Task and Motion Planning with Motion\n  Failure Reasoning","summary":"  Conventional Task and Motion Planning (TAMP) approaches rely on manually\ncrafted interfaces connecting symbolic task planning with continuous motion\ngeneration. These domain-specific and labor-intensive modules are limited in\naddressing emerging tasks in real-world settings. Here, we present LLM^3, a\nnovel Large Language Model (LLM)-based TAMP framework featuring a\ndomain-independent interface. Specifically, we leverage the powerful reasoning\nand planning capabilities of pre-trained LLMs to propose symbolic action\nsequences and select continuous action parameters for motion planning.\nCrucially, LLM^3 incorporates motion planning feedback through prompting,\nallowing the LLM to iteratively refine its proposals by reasoning about motion\nfailure. Consequently, LLM^3 interfaces between task planning and motion\nplanning, alleviating the intricate design process of handling domain-specific\nmessages between them. Through a series of simulations in a box-packing domain,\nwe quantitatively demonstrate the effectiveness of LLM^3 in solving TAMP\nproblems and the efficiency in selecting action parameters. Ablation studies\nunderscore the significant contribution of motion failure reasoning to the\nsuccess of LLM^3. Furthermore, we conduct qualitative experiments on a physical\nmanipulator, demonstrating the practical applicability of our approach in\nreal-world settings.\n","authors":["Shu Wang","Muzhi Han","Ziyuan Jiao","Zeyu Zhang","Ying Nian Wu","Song-Chun Zhu","Hangxin Liu"],"pdf_url":"https://arxiv.org/pdf/2403.11552v2.pdf","comment":"Submitted to IROS 2024. Codes available:\n  https://github.com/AssassinWS/LLM-TAMP"},{"id":"http://arxiv.org/abs/2403.13574v1","updated":"2024-03-20T13:14:29Z","published":"2024-03-20T13:14:29Z","title":"A Large Language Model Enhanced Sequential Recommender for Joint Video\n  and Comment Recommendation","summary":"  In online video platforms, reading or writing comments on interesting videos\nhas become an essential part of the video watching experience. However,\nexisting video recommender systems mainly model users' interaction behaviors\nwith videos, lacking consideration of comments in user behavior modeling. In\nthis paper, we propose a novel recommendation approach called LSVCR by\nleveraging user interaction histories with both videos and comments, so as to\njointly conduct personalized video and comment recommendation. Specifically,\nour approach consists of two key components, namely sequential recommendation\n(SR) model and supplemental large language model (LLM) recommender. The SR\nmodel serves as the primary recommendation backbone (retained in deployment) of\nour approach, allowing for efficient user preference modeling. Meanwhile, we\nleverage the LLM recommender as a supplemental component (discarded in\ndeployment) to better capture underlying user preferences from heterogeneous\ninteraction behaviors. In order to integrate the merits of the SR model and the\nsupplemental LLM recommender, we design a twostage training paradigm. The first\nstage is personalized preference alignment, which aims to align the preference\nrepresentations from both components, thereby enhancing the semantics of the SR\nmodel. The second stage is recommendation-oriented fine-tuning, in which the\nalignment-enhanced SR model is fine-tuned according to specific objectives.\nExtensive experiments in both video and comment recommendation tasks\ndemonstrate the effectiveness of LSVCR. Additionally, online A/B testing on the\nKuaiShou platform verifies the actual benefits brought by our approach. In\nparticular, we achieve a significant overall gain of 4.13% in comment watch\ntime.\n","authors":["Bowen Zheng","Zihan Lin","Enze Liu","Chen Yang","Enyang Bai","Cheng Ling","Wayne Xin Zhao","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2403.13574v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.18248v3","updated":"2024-03-20T13:12:48Z","published":"2023-05-29T17:12:03Z","title":"Do Language Models Know When They're Hallucinating References?","summary":"  State-of-the-art language models (LMs) are notoriously susceptible to\ngenerating hallucinated information. Such inaccurate outputs not only undermine\nthe reliability of these models but also limit their use and raise serious\nconcerns about misinformation and propaganda. In this work, we focus on\nhallucinated book and article references and present them as the \"model\norganism\" of language model hallucination research, due to their frequent and\neasy-to-discern nature. We posit that if a language model cites a particular\nreference in its output, then it should ideally possess sufficient information\nabout its authors and content, among other relevant details. Using this basic\ninsight, we illustrate that one can identify hallucinated references without\never consulting any external resources, by asking a set of direct or indirect\nqueries to the language model about the references. These queries can be\nconsidered as \"consistency checks.\" Our findings highlight that while LMs,\nincluding GPT-4, often produce inconsistent author lists for hallucinated\nreferences, they also often accurately recall the authors of real references.\nIn this sense, the LM can be said to \"know\" when it is hallucinating\nreferences. Furthermore, these findings show how hallucinated references can be\ndissected to shed light on their nature. Replication code and results can be\nfound at https://github.com/microsoft/hallucinated-references.\n","authors":["Ayush Agrawal","Mirac Suzgun","Lester Mackey","Adam Tauman Kalai"],"pdf_url":"https://arxiv.org/pdf/2305.18248v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.09389v2","updated":"2024-03-20T13:11:19Z","published":"2023-02-18T17:45:11Z","title":"Vulnerability analysis of captcha using Deep learning","summary":"  Several websites improve their security and avoid dangerous Internet attacks\nby implementing CAPTCHAs (Completely Automated Public Turing test to tell\nComputers and Humans Apart), a type of verification to identify whether the\nend-user is human or a robot. The most prevalent type of CAPTCHA is text-based,\ndesigned to be easily recognized by humans while being unsolvable towards\nmachines or robots. However, as deep learning technology progresses,\ndevelopment of convolutional neural network (CNN) models that predict\ntext-based CAPTCHAs becomes easier. The purpose of this research is to\ninvestigate the flaws and vulnerabilities in the CAPTCHA generating systems in\norder to design more resilient CAPTCHAs. To achieve this, we created CapNet, a\nConvolutional Neural Network. The proposed platform can evaluate both numerical\nand alphanumerical CAPTCHAs\n","authors":["Jaskaran Singh Walia","Aryan Odugoudar"],"pdf_url":"https://arxiv.org/pdf/2302.09389v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.02696v2","updated":"2024-03-20T12:58:14Z","published":"2023-12-05T11:55:47Z","title":"Analyzing and Improving the Training Dynamics of Diffusion Models","summary":"  Diffusion models currently dominate the field of data-driven image synthesis\nwith their unparalleled scaling to large datasets. In this paper, we identify\nand rectify several causes for uneven and ineffective training in the popular\nADM diffusion model architecture, without altering its high-level structure.\nObserving uncontrolled magnitude changes and imbalances in both the network\nactivations and weights over the course of training, we redesign the network\nlayers to preserve activation, weight, and update magnitudes on expectation. We\nfind that systematic application of this philosophy eliminates the observed\ndrifts and imbalances, resulting in considerably better networks at equal\ncomputational complexity. Our modifications improve the previous record FID of\n2.41 in ImageNet-512 synthesis to 1.81, achieved using fast deterministic\nsampling.\n  As an independent contribution, we present a method for setting the\nexponential moving average (EMA) parameters post-hoc, i.e., after completing\nthe training run. This allows precise tuning of EMA length without the cost of\nperforming several training runs, and reveals its surprising interactions with\nnetwork architecture, training time, and guidance.\n","authors":["Tero Karras","Miika Aittala","Jaakko Lehtinen","Janne Hellsten","Timo Aila","Samuli Laine"],"pdf_url":"https://arxiv.org/pdf/2312.02696v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.10402v2","updated":"2024-03-20T12:52:10Z","published":"2023-10-16T13:45:26Z","title":"Real-Fake: Effective Training Data Synthesis Through Distribution\n  Matching","summary":"  Synthetic training data has gained prominence in numerous learning tasks and\nscenarios, offering advantages such as dataset augmentation, generalization\nevaluation, and privacy preservation. Despite these benefits, the efficiency of\nsynthetic data generated by current methodologies remains inferior when\ntraining advanced deep models exclusively, limiting its practical utility. To\naddress this challenge, we analyze the principles underlying training data\nsynthesis for supervised learning and elucidate a principled theoretical\nframework from the distribution-matching perspective that explicates the\nmechanisms governing synthesis efficacy. Through extensive experiments, we\ndemonstrate the effectiveness of our synthetic data across diverse image\nclassification tasks, both as a replacement for and augmentation to real\ndatasets, while also benefits such as out-of-distribution generalization,\nprivacy preservation, and scalability. Specifically, we achieve 70.9% top1\nclassification accuracy on ImageNet1K when training solely with synthetic data\nequivalent to 1 X the original real data size, which increases to 76.0% when\nscaling up to 10 X synthetic data.\n","authors":["Jianhao Yuan","Jie Zhang","Shuyang Sun","Philip Torr","Bo Zhao"],"pdf_url":"https://arxiv.org/pdf/2310.10402v2.pdf","comment":"Code released at\n  (https://github.com/BAAI-DCAI/Training-Data-Synthesis)"},{"id":"http://arxiv.org/abs/2403.13556v1","updated":"2024-03-20T12:51:30Z","published":"2024-03-20T12:51:30Z","title":"Find n' Propagate: Open-Vocabulary 3D Object Detection in Urban\n  Environments","summary":"  In this work, we tackle the limitations of current LiDAR-based 3D object\ndetection systems, which are hindered by a restricted class vocabulary and the\nhigh costs associated with annotating new object classes. Our exploration of\nopen-vocabulary (OV) learning in urban environments aims to capture novel\ninstances using pre-trained vision-language models (VLMs) with multi-sensor\ndata. We design and benchmark a set of four potential solutions as baselines,\ncategorizing them into either top-down or bottom-up approaches based on their\ninput data strategies. While effective, these methods exhibit certain\nlimitations, such as missing novel objects in 3D box estimation or applying\nrigorous priors, leading to biases towards objects near the camera or of\nrectangular geometries. To overcome these limitations, we introduce a universal\n\\textsc{Find n' Propagate} approach for 3D OV tasks, aimed at maximizing the\nrecall of novel objects and propagating this detection capability to more\ndistant areas thereby progressively capturing more. In particular, we utilize a\ngreedy box seeker to search against 3D novel boxes of varying orientations and\ndepth in each generated frustum and ensure the reliability of newly identified\nboxes by cross alignment and density ranker. Additionally, the inherent bias\ntowards camera-proximal objects is alleviated by the proposed remote simulator,\nwhich randomly diversifies pseudo-labeled novel instances in the self-training\nprocess, combined with the fusion of base samples in the memory bank. Extensive\nexperiments demonstrate a 53% improvement in novel recall across diverse OV\nsettings, VLMs, and 3D detectors. Notably, we achieve up to a 3.97-fold\nincrease in Average Precision (AP) for novel object classes. The source code is\nmade available in the supplementary material.\n","authors":["Djamahl Etchegaray","Zi Huang","Tatsuya Harada","Yadan Luo"],"pdf_url":"https://arxiv.org/pdf/2403.13556v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13553v1","updated":"2024-03-20T12:46:02Z","published":"2024-03-20T12:46:02Z","title":"VCounselor: A Psychological Intervention Chat Agent Based on a\n  Knowledge-Enhanced Large Language Model","summary":"  Conversational artificial intelligence can already independently engage in\nbrief conversations with clients with psychological problems and provide\nevidence-based psychological interventions. The main objective of this study is\nto improve the effectiveness and credibility of the large language model in\npsychological intervention by creating a specialized agent, the VCounselor, to\naddress the limitations observed in popular large language models such as\nChatGPT in domain applications. We achieved this goal by proposing a new\naffective interaction structure and knowledge-enhancement structure. In order\nto evaluate VCounselor, this study compared the general large language model,\nthe fine-tuned large language model, and VCounselor's knowledge-enhanced large\nlanguage model. At the same time, the general large language model and the\nfine-tuned large language model will also be provided with an avatar to compare\nthem as an agent with VCounselor. The comparison results indicated that the\naffective interaction structure and knowledge-enhancement structure of\nVCounselor significantly improved the effectiveness and credibility of the\npsychological intervention, and VCounselor significantly provided positive\ntendencies for clients' emotions. The conclusion of this study strongly\nsupports that VConselor has a significant advantage in providing psychological\nsupport to clients by being able to analyze the patient's problems with\nrelative accuracy and provide professional-level advice that enhances support\nfor clients.\n","authors":["H. Zhang","Z. Qiao","H. Wang","B. Duan","J. Yin"],"pdf_url":"https://arxiv.org/pdf/2403.13553v1.pdf","comment":"24 pages, 6 figures"},{"id":"http://arxiv.org/abs/2403.13537v1","updated":"2024-03-20T12:14:54Z","published":"2024-03-20T12:14:54Z","title":"What explains the success of cross-modal fine-tuning with ORCA?","summary":"  ORCA (Shen et al., 2023) is a recent technique for cross-modal fine-tuning,\ni.e., applying pre-trained transformer models to modalities beyond their\ntraining data. The technique consists primarily of training an embedder and\nfine-tuning the embedder and model. Despite its high performance on a variety\nof downstream tasks, we do not understand precisely how each of these\ncomponents contribute to ORCA's success. Therefore, we run a series of\nablations and find that embedder training does not help 2D tasks at all,\ncontrary to what the original paper posits. In 1D tasks, some amount of\nembedder training is necessary but more is not better. In 4 out of 6 datasets\nwe experiment with, it is model fine-tuning that makes the biggest difference.\nThrough our ablations and baselines, we contribute a better understanding of\nthe individual components of ORCA.\n","authors":["Paloma García-de-Herreros","Vagrant Gautam","Philipp Slusallek","Dietrich Klakow","Marius Mosbach"],"pdf_url":"https://arxiv.org/pdf/2403.13537v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.08309v2","updated":"2024-03-20T12:12:59Z","published":"2023-07-17T08:09:40Z","title":"LogPrécis: Unleashing Language Models for Automated Shell Log Analysis","summary":"  The collection of security-related logs holds the key to understanding attack\nbehaviors and diagnosing vulnerabilities. Still, their analysis remains a\ndaunting challenge. Recently, Language Models (LMs) have demonstrated unmatched\npotential in understanding natural and programming languages. The question\narises whether and how LMs could be also useful for security experts since\ntheir logs contain intrinsically confused and obfuscated information. In this\npaper, we systematically study how to benefit from the state-of-the-art in LM\nto automatically analyze text-like Unix shell attack logs. We present a\nthorough design methodology that leads to LogPr\\'ecis. It receives as input raw\nshell sessions and automatically identifies and assigns the attacker tactic to\neach portion of the session, i.e., unveiling the sequence of the attacker's\ngoals. We demonstrate LogPr\\'ecis capability to support the analysis of two\nlarge datasets containing about 400,000 unique Unix shell attacks. LogPr\\'ecis\nreduces them into about 3,000 fingerprints, each grouping sessions with the\nsame sequence of tactics. The abstraction it provides lets the analyst better\nunderstand attacks, identify fingerprints, detect novelty, link similar\nattacks, and track families and mutations. Overall, LogPr\\'ecis, released as\nopen source, paves the way for better and more responsive defense against\ncyberattacks.\n","authors":["Matteo Boffa","Rodolfo Vieira Valentim","Luca Vassio","Danilo Giordano","Idilio Drago","Marco Mellia","Zied Ben Houidi"],"pdf_url":"https://arxiv.org/pdf/2307.08309v2.pdf","comment":"18 pages, Computer&Security\n  (https://www.sciencedirect.com/science/article/pii/S0167404824001068), code\n  available at https://github.com/SmartData-Polito/logprecis, models available\n  at https://huggingface.co/SmartDataPolito"},{"id":"http://arxiv.org/abs/2403.11959v2","updated":"2024-03-20T11:58:23Z","published":"2024-03-18T16:56:47Z","title":"IVAC-P2L: Leveraging Irregular Repetition Priors for Improving Video\n  Action Counting","summary":"  Video Action Counting (VAC) is crucial in analyzing sports, fitness, and\neveryday activities by quantifying repetitive actions in videos. However,\ntraditional VAC methods have overlooked the complexity of action repetitions,\nsuch as interruptions and the variability in cycle duration. Our research\naddresses the shortfall by introducing a novel approach to VAC, called\nIrregular Video Action Counting (IVAC). IVAC prioritizes modeling irregular\nrepetition patterns in videos, which we define through two primary aspects:\nInter-cycle Consistency and Cycle-interval Inconsistency. Inter-cycle\nConsistency ensures homogeneity in the spatial-temporal representations of\ncycle segments, signifying action uniformity within cycles. Cycle-interval\ninconsistency highlights the importance of distinguishing between cycle\nsegments and intervals based on their inherent content differences. To\nencapsulate these principles, we propose a new methodology that includes\nconsistency and inconsistency modules, supported by a unique pull-push loss\n(P2L) mechanism. The IVAC-P2L model applies a pull loss to promote coherence\namong cycle segment features and a push loss to clearly distinguish features of\ncycle segments from interval segments. Empirical evaluations conducted on the\nRepCount dataset demonstrate that the IVAC-P2L model sets a new benchmark in\nVAC task performance. Furthermore, the model demonstrates exceptional\nadaptability and generalization across various video contents, outperforming\nexisting models on two additional datasets, UCFRep and Countix, without the\nneed for dataset-specific optimization. These results confirm the efficacy of\nour approach in addressing irregular repetitions in videos and pave the way for\nfurther advancements in video analysis and understanding.\n","authors":["Hang Wang","Zhi-Qi Cheng","Youtian Du","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.11959v2.pdf","comment":"Source code: https://github.com/hwang-cs-ime/IVAC-P2L"},{"id":"http://arxiv.org/abs/2403.13524v1","updated":"2024-03-20T11:51:04Z","published":"2024-03-20T11:51:04Z","title":"Compress3D: a Compressed Latent Space for 3D Generation from a Single\n  Image","summary":"  3D generation has witnessed significant advancements, yet efficiently\nproducing high-quality 3D assets from a single image remains challenging. In\nthis paper, we present a triplane autoencoder, which encodes 3D models into a\ncompact triplane latent space to effectively compress both the 3D geometry and\ntexture information. Within the autoencoder framework, we introduce a 3D-aware\ncross-attention mechanism, which utilizes low-resolution latent representations\nto query features from a high-resolution 3D feature volume, thereby enhancing\nthe representation capacity of the latent space. Subsequently, we train a\ndiffusion model on this refined latent space. In contrast to solely relying on\nimage embedding for 3D generation, our proposed method advocates for the\nsimultaneous utilization of both image embedding and shape embedding as\nconditions. Specifically, the shape embedding is estimated via a diffusion\nprior model conditioned on the image embedding. Through comprehensive\nexperiments, we demonstrate that our method outperforms state-of-the-art\nalgorithms, achieving superior performance while requiring less training data\nand time. Our approach enables the generation of high-quality 3D assets in\nmerely 7 seconds on a single A100 GPU.\n","authors":["Bowen Zhang","Tianyu Yang","Yu Li","Lei Zhang","Xi Zhao"],"pdf_url":"https://arxiv.org/pdf/2403.13524v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13523v1","updated":"2024-03-20T11:50:16Z","published":"2024-03-20T11:50:16Z","title":"Have You Poisoned My Data? Defending Neural Networks against Data\n  Poisoning","summary":"  The unprecedented availability of training data fueled the rapid development\nof powerful neural networks in recent years. However, the need for such large\namounts of data leads to potential threats such as poisoning attacks:\nadversarial manipulations of the training data aimed at compromising the\nlearned model to achieve a given adversarial goal.\n  This paper investigates defenses against clean-label poisoning attacks and\nproposes a novel approach to detect and filter poisoned datapoints in the\ntransfer learning setting. We define a new characteristic vector representation\nof datapoints and show that it effectively captures the intrinsic properties of\nthe data distribution. Through experimental analysis, we demonstrate that\neffective poisons can be successfully differentiated from clean points in the\ncharacteristic vector space. We thoroughly evaluate our proposed approach and\ncompare it to existing state-of-the-art defenses using multiple architectures,\ndatasets, and poison budgets. Our evaluation shows that our proposal\noutperforms existing approaches in defense rate and final trained model\nperformance across all experimental settings.\n","authors":["Fabio De Gaspari","Dorjan Hitaj","Luigi V. Mancini"],"pdf_url":"https://arxiv.org/pdf/2403.13523v1.pdf","comment":"Paper accepted for publication at European Symposium on Research in\n  Computer Security (ESORICS) 2024"},{"id":"http://arxiv.org/abs/2403.13518v1","updated":"2024-03-20T11:38:30Z","published":"2024-03-20T11:38:30Z","title":"Motion Generation from Fine-grained Textual Descriptions","summary":"  The task of text2motion is to generate motion sequences from given textual\ndescriptions, where a model should explore the interactions between natural\nlanguage instructions and human body movements. While most existing works are\nconfined to coarse-grained motion descriptions (e.g., \"A man squats.\"),\nfine-grained ones specifying movements of relevant body parts are barely\nexplored. Models trained with coarse texts may not be able to learn mappings\nfrom fine-grained motion-related words to motion primitives, resulting in the\nfailure in generating motions from unseen descriptions. In this paper, we build\na large-scale language-motion dataset with fine-grained textual descriptions,\nFineHumanML3D, by feeding GPT-3.5-turbo with delicate prompts. Accordingly, we\ndesign a new text2motion model, FineMotionDiffuse, which makes full use of\nfine-grained textual information. Our experiments show that FineMotionDiffuse\ntrained on FineHumanML3D acquires good results in quantitative evaluation. We\nalso find this model can better generate spatially/chronologically composite\nmotions by learning the implicit mappings from simple descriptions to the\ncorresponding basic motions.\n","authors":["Kunhang Li","Yansong Feng"],"pdf_url":"https://arxiv.org/pdf/2403.13518v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13513v1","updated":"2024-03-20T11:27:20Z","published":"2024-03-20T11:27:20Z","title":"What if...?: Counterfactual Inception to Mitigate Hallucination Effects\n  in Large Multimodal Models","summary":"  This paper presents a way of enhancing the reliability of Large Multimodal\nModels (LMMs) in addressing hallucination effects, where models generate\nincorrect or unrelated responses. Without additional instruction tuning\nparadigm, we introduce Counterfactual Inception, a novel method that implants\ncounterfactual thoughts into LMMs using carefully chosen, misaligned\ncounterfactual keywords. This method is grounded in the concept of\ncounterfactual thinking, a cognitive process where humans consider alternative\nrealities and outcomes. By applying this human-like reasoning mechanism to\nLMMs, we aim to reduce hallucination effects and improve the models'\ntrustworthiness. We also propose Dual-modality Verification Process (DVP), a\nrigorous framework for selecting optimal counterfactual keywords to trigger\ncounterfactual thinking into LMMs, concurrently considering visual and\nlinguistic context. Our extensive experiments across various LMMs, including\nboth open-source and proprietary models, corroborate that our method\nsignificantly mitigates hallucination phenomena across different datasets.\n","authors":["Junho Kim","Yeon Ju Kim","Yong Man Ro"],"pdf_url":"https://arxiv.org/pdf/2403.13513v1.pdf","comment":"under review, code available:\n  https://github.com/IVY-LVLM/Counterfactual-Inception"},{"id":"http://arxiv.org/abs/2403.13512v1","updated":"2024-03-20T11:21:22Z","published":"2024-03-20T11:21:22Z","title":"Scale Decoupled Distillation","summary":"  Logit knowledge distillation attracts increasing attention due to its\npracticality in recent studies. However, it often suffers inferior performance\ncompared to the feature knowledge distillation. In this paper, we argue that\nexisting logit-based methods may be sub-optimal since they only leverage the\nglobal logit output that couples multiple semantic knowledge. This may transfer\nambiguous knowledge to the student and mislead its learning. To this end, we\npropose a simple but effective method, i.e., Scale Decoupled Distillation\n(SDD), for logit knowledge distillation. SDD decouples the global logit output\ninto multiple local logit outputs and establishes distillation pipelines for\nthem. This helps the student to mine and inherit fine-grained and unambiguous\nlogit knowledge. Moreover, the decoupled knowledge can be further divided into\nconsistent and complementary logit knowledge that transfers the semantic\ninformation and sample ambiguity, respectively. By increasing the weight of\ncomplementary parts, SDD can guide the student to focus more on ambiguous\nsamples, improving its discrimination ability. Extensive experiments on several\nbenchmark datasets demonstrate the effectiveness of SDD for wide\nteacher-student pairs, especially in the fine-grained classification task. Code\nis available at: https://github.com/shicaiwei123/SDD-CVPR2024\n","authors":["Shicai Wei Chunbo Luo Yang Luo"],"pdf_url":"https://arxiv.org/pdf/2403.13512v1.pdf","comment":"Accepted to CVPR2024 10 pages 6figure"},{"id":"http://arxiv.org/abs/2403.13501v1","updated":"2024-03-20T10:58:58Z","published":"2024-03-20T10:58:58Z","title":"VSTAR: Generative Temporal Nursing for Longer Dynamic Video Synthesis","summary":"  Despite tremendous progress in the field of text-to-video (T2V) synthesis,\nopen-sourced T2V diffusion models struggle to generate longer videos with\ndynamically varying and evolving content. They tend to synthesize quasi-static\nvideos, ignoring the necessary visual change-over-time implied in the text\nprompt. At the same time, scaling these models to enable longer, more dynamic\nvideo synthesis often remains computationally intractable. To address this\nchallenge, we introduce the concept of Generative Temporal Nursing (GTN), where\nwe aim to alter the generative process on the fly during inference to improve\ncontrol over the temporal dynamics and enable generation of longer videos. We\npropose a method for GTN, dubbed VSTAR, which consists of two key ingredients:\n1) Video Synopsis Prompting (VSP) - automatic generation of a video synopsis\nbased on the original single prompt leveraging LLMs, which gives accurate\ntextual guidance to different visual states of longer videos, and 2) Temporal\nAttention Regularization (TAR) - a regularization technique to refine the\ntemporal attention units of the pre-trained T2V diffusion models, which enables\ncontrol over the video dynamics. We experimentally showcase the superiority of\nthe proposed approach in generating longer, visually appealing videos over\nexisting open-sourced T2V models. We additionally analyze the temporal\nattention maps realized with and without VSTAR, demonstrating the importance of\napplying our method to mitigate neglect of the desired visual change over time.\n","authors":["Yumeng Li","William Beluch","Margret Keuper","Dan Zhang","Anna Khoreva"],"pdf_url":"https://arxiv.org/pdf/2403.13501v1.pdf","comment":"Project page: https://yumengli007.github.io/VSTAR"},{"id":"http://arxiv.org/abs/2403.13479v1","updated":"2024-03-20T10:33:10Z","published":"2024-03-20T10:33:10Z","title":"Deepfake Detection without Deepfakes: Generalization via Synthetic\n  Frequency Patterns Injection","summary":"  Deepfake detectors are typically trained on large sets of pristine and\ngenerated images, resulting in limited generalization capacity; they excel at\nidentifying deepfakes created through methods encountered during training but\nstruggle with those generated by unknown techniques. This paper introduces a\nlearning approach aimed at significantly enhancing the generalization\ncapabilities of deepfake detectors. Our method takes inspiration from the\nunique \"fingerprints\" that image generation processes consistently introduce\ninto the frequency domain. These fingerprints manifest as structured and\ndistinctly recognizable frequency patterns. We propose to train detectors using\nonly pristine images injecting in part of them crafted frequency patterns,\nsimulating the effects of various deepfake generation techniques without being\nspecific to any. These synthetic patterns are based on generic shapes, grids,\nor auras. We evaluated our approach using diverse architectures across 25\ndifferent generation methods. The models trained with our approach were able to\nperform state-of-the-art deepfake detection, demonstrating also superior\ngeneralization capabilities in comparison with previous methods. Indeed, they\nare untied to any specific generation technique and can effectively identify\ndeepfakes regardless of how they were made.\n","authors":["Davide Alessandro Coccomini","Roberto Caldelli","Claudio Gennaro","Giuseppe Fiameni","Giuseppe Amato","Fabrizio Falchi"],"pdf_url":"https://arxiv.org/pdf/2403.13479v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.15266v2","updated":"2024-03-20T10:12:49Z","published":"2024-02-23T11:27:10Z","title":"Calibration of Deep Learning Classification Models in fNIRS","summary":"  Functional near-infrared spectroscopy (fNIRS) is a valuable non-invasive tool\nfor monitoring brain activity. The classification of fNIRS data in relation to\nconscious activity holds significance for advancing our understanding of the\nbrain and facilitating the development of brain-computer interfaces (BCI). Many\nresearchers have turned to deep learning to tackle the classification\nchallenges inherent in fNIRS data due to its strong generalization and\nrobustness. In the application of fNIRS, reliability is really important, and\none mathematical formulation of the reliability of confidence is calibration.\nHowever, many researchers overlook the important issue of calibration. To\naddress this gap, we propose integrating calibration into fNIRS field and\nassess the reliability of existing models. Surprisingly, our results indicate\npoor calibration performance in many proposed models. To advance calibration\ndevelopment in the fNIRS field, we summarize three practical tips. Through this\nletter, we hope to emphasize the critical role of calibration in fNIRS research\nand argue for enhancing the reliability of deep learning-based predictions in\nfNIRS classification tasks. All data from our experimental process are openly\navailable on GitHub.\n","authors":["Zhihao Cao","Zizhou Luo"],"pdf_url":"https://arxiv.org/pdf/2402.15266v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.06225v2","updated":"2024-03-20T10:05:02Z","published":"2024-03-10T14:11:25Z","title":"MoST: Motion Style Transformer between Diverse Action Contents","summary":"  While existing motion style transfer methods are effective between two\nmotions with identical content, their performance significantly diminishes when\ntransferring style between motions with different contents. This challenge lies\nin the lack of clear separation between content and style of a motion. To\ntackle this challenge, we propose a novel motion style transformer that\neffectively disentangles style from content and generates a plausible motion\nwith transferred style from a source motion. Our distinctive approach to\nachieving the goal of disentanglement is twofold: (1) a new architecture for\nmotion style transformer with `part-attentive style modulator across body\nparts' and `Siamese encoders that encode style and content features\nseparately'; (2) style disentanglement loss. Our method outperforms existing\nmethods and demonstrates exceptionally high quality, particularly in motion\npairs with different contents, without the need for heuristic post-processing.\nCodes are available at https://github.com/Boeun-Kim/MoST.\n","authors":["Boeun Kim","Jungho Kim","Hyung Jin Chang","Jin Young Choi"],"pdf_url":"https://arxiv.org/pdf/2403.06225v2.pdf","comment":"Accepted by CVPR 2024"},{"id":"http://arxiv.org/abs/2403.06832v2","updated":"2024-03-20T10:02:54Z","published":"2024-03-11T15:48:43Z","title":"The Power of Noise: Toward a Unified Multi-modal Knowledge Graph\n  Representation Framework","summary":"  The advancement of Multi-modal Pre-training highlights the necessity for a\nrobust Multi-Modal Knowledge Graph (MMKG) representation learning framework.\nThis framework is crucial for integrating structured knowledge into multi-modal\nLarge Language Models (LLMs) at scale, aiming to alleviate issues like\nknowledge misconceptions and multi-modal hallucinations. In this work, to\nevaluate models' ability to accurately embed entities within MMKGs, we focus on\ntwo widely researched tasks: Multi-modal Knowledge Graph Completion (MKGC) and\nMulti-modal Entity Alignment (MMEA). Building on this foundation, we propose a\nnovel SNAG method that utilizes a Transformer-based architecture equipped with\nmodality-level noise masking for the robust integration of multi-modal entity\nfeatures in KGs. By incorporating specific training objectives for both MKGC\nand MMEA, our approach achieves SOTA performance across a total of ten datasets\n(three for MKGC and seven for MEMA), demonstrating its robustness and\nversatility. Besides, SNAG can not only function as a standalone model but also\nenhance other existing methods, providing stable performance improvements. Our\ncode and data are available at: https://github.com/zjukg/SNAG.\n","authors":["Zhuo Chen","Yin Fang","Yichi Zhang","Lingbing Guo","Jiaoyan Chen","Huajun Chen","Wen Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.06832v2.pdf","comment":"Ongoing work; 10 pages, 6 Tables, 2 Figures; Repo is available at\n  https://github.com/zjukg/SNAG"},{"id":"http://arxiv.org/abs/2403.13447v1","updated":"2024-03-20T09:42:43Z","published":"2024-03-20T09:42:43Z","title":"HyperLLaVA: Dynamic Visual and Language Expert Tuning for Multimodal\n  Large Language Models","summary":"  Recent advancements indicate that scaling up Multimodal Large Language Models\n(MLLMs) effectively enhances performance on downstream multimodal tasks. The\nprevailing MLLM paradigm, \\emph{e.g.}, LLaVA, transforms visual features into\ntext-like tokens using a \\emph{static} vision-language mapper, thereby enabling\n\\emph{static} LLMs to develop the capability to comprehend visual information\nthrough visual instruction tuning. Although promising, the \\emph{static} tuning\nstrategy~\\footnote{The static tuning refers to the trained model with static\nparameters.} that shares the same parameters may constrain performance across\ndifferent downstream multimodal tasks. In light of this, we introduce\nHyperLLaVA, which involves adaptive tuning of the projector and LLM parameters,\nin conjunction with a dynamic visual expert and language expert, respectively.\nThese experts are derived from HyperNetworks, which generates adaptive\nparameter shifts through visual and language guidance, enabling dynamic\nprojector and LLM modeling in two-stage training.\n  Our experiments demonstrate that our solution significantly surpasses LLaVA\non existing MLLM benchmarks, including MME, MMBench, SEED-Bench, and\nLLaVA-Bench. ~\\footnote{Our project is available on the link\nhttps://github.com/DCDmllm/HyperLLaVA}.\n","authors":["Wenqiao Zhang","Tianwei Lin","Jiang Liu","Fangxun Shu","Haoyuan Li","Lei Zhang","He Wanggui","Hao Zhou","Zheqi Lv","Hao Jiang","Juncheng Li","Siliang Tang","Yueting Zhuang"],"pdf_url":"https://arxiv.org/pdf/2403.13447v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13441v1","updated":"2024-03-20T09:34:38Z","published":"2024-03-20T09:34:38Z","title":"Robustness Verifcation in Neural Networks","summary":"  In this paper we investigate formal verification problems for Neural Network\ncomputations. Of central importance will be various robustness and minimization\nproblems such as: Given symbolic specifications of allowed inputs and outputs\nin form of Linear Programming instances, one question is whether there do exist\nvalid inputs such that the network computes a valid output? And does this\nproperty hold for all valid inputs? Do two given networks compute the same\nfunction? Is there a smaller network computing the same function?\n  The complexity of these questions have been investigated recently from a\npractical point of view and approximated by heuristic algorithms. We complement\nthese achievements by giving a theoretical framework that enables us to\ninterchange security and efficiency questions in neural networks and analyze\ntheir computational complexities. We show that the problems are conquerable in\na semi-linear setting, meaning that for piecewise linear activation functions\nand when the sum- or maximum metric is used, most of them are in P or in NP at\nmost.\n","authors":["Adrian Wurm"],"pdf_url":"https://arxiv.org/pdf/2403.13441v1.pdf","comment":"16 pages, 1 figure"},{"id":"http://arxiv.org/abs/2403.13433v1","updated":"2024-03-20T09:21:32Z","published":"2024-03-20T09:21:32Z","title":"Agent Group Chat: An Interactive Group Chat Simulacra For Better\n  Eliciting Collective Emergent Behavior","summary":"  To investigate the role of language in human collective behaviors, we\ndeveloped the Agent Group Chat simulation to simulate linguistic interactions\namong multi-agent in different settings. Agents are asked to free chat in this\nsimulation for their own purposes based on their character setting, aiming to\nsee agents exhibit emergent behaviours that are both unforeseen and\nsignificant. Four narrative scenarios, Inheritance Disputes, Law Court Debates,\nPhilosophical Discourses, Movie Casting Contention, are integrated into Agent\nGroup Chat to evaluate its support for diverse storylines. By configuring\nspecific environmental settings within Agent Group Chat, we are able to assess\nwhether agents exhibit behaviors that align with human expectations. We\nevaluate the disorder within the environment by computing the n-gram Shannon\nentropy of all the content speak by characters. Our findings reveal that under\nthe premise of agents possessing substantial alignment with human expectations,\nfacilitating more extensive information exchange within the simulation ensures\ngreater orderliness amidst diversity, which leads to the emergence of more\nunexpected and meaningful emergent behaviors. The code is open source in\nhttps://github.com/MikeGu721/AgentGroup, and online platform will be open soon.\n","authors":["Zhouhong Gu","Xiaoxuan Zhu","Haoran Guo","Lin Zhang","Yin Cai","Hao Shen","Jiangjie Chen","Zheyu Ye","Yifei Dai","Yan Gao","Yao Hu","Hongwei Feng","Yanghua Xiao"],"pdf_url":"https://arxiv.org/pdf/2403.13433v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13421v1","updated":"2024-03-20T09:07:23Z","published":"2024-03-20T09:07:23Z","title":"Caching-Augmented Lifelong Multi-Agent Path Finding","summary":"  Multi-Agent Path Finding (MAPF), which involves finding collision-free paths\nfor multiple robots, is crucial in various applications. Lifelong MAPF, where\ntargets are reassigned to agents as soon as they complete their initial\nobjectives, offers a more accurate approximation of real-world warehouse\nplanning. In this paper, we present a novel mechanism named Caching-Augmented\nLifelong MAPF (CAL-MAPF), designed to improve the performance of Lifelong MAPF.\nWe have developed a new map grid type called cache for temporary item storage\nand replacement and designed a lock mechanism for it to improve the stability\nof the planning solution. This cache mechanism was evaluated using various\ncache replacement policies and a spectrum of input task distributions. We\nidentified three main factors significantly impacting CAL-MAPF performance\nthrough experimentation: suitable input task distribution, high cache hit rate,\nand smooth traffic. Overall, CAL-MAPF has demonstrated potential for\nperformance improvements in certain task distributions, maps and agent\nconfigurations.\n","authors":["Yimin Tang","Zhenghong Yu","Yi Zheng","T. K. Satish Kumar","Jiaoyang Li","Sven Koenig"],"pdf_url":"https://arxiv.org/pdf/2403.13421v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.14166v3","updated":"2024-03-20T08:52:42Z","published":"2024-01-25T13:20:47Z","title":"BayesPrompt: Prompting Large-Scale Pre-Trained Language Models on\n  Few-shot Inference via Debiased Domain Abstraction","summary":"  As a novel and effective fine-tuning paradigm based on large-scale\npre-trained language models (PLMs), prompt-tuning aims to reduce the gap\nbetween downstream tasks and pre-training objectives. While prompt-tuning has\nyielded continuous advancements in various tasks, such an approach still\nremains a persistent defect: prompt-tuning methods fail to generalize to\nspecific few-shot patterns. From the perspective of distribution analyses, we\ndisclose that the intrinsic issues behind the phenomenon are the\nover-multitudinous conceptual knowledge contained in PLMs and the abridged\nknowledge for target downstream domains, which jointly result in that PLMs\nmis-locate the knowledge distributions corresponding to the target domains in\nthe universal knowledge embedding space. To this end, we intuitively explore to\napproximate the unabridged target domains of downstream tasks in a debiased\nmanner, and then abstract such domains to generate discriminative prompts,\nthereby providing the de-ambiguous guidance for PLMs. Guided by such an\nintuition, we propose a simple yet effective approach, namely BayesPrompt, to\nlearn prompts that contain the domain discriminative information against the\ninterference from domain-irrelevant knowledge. BayesPrompt primitively\nleverages known distributions to approximate the debiased factual distributions\nof target domains and further uniformly samples certain representative features\nfrom the approximated distributions to generate the ultimate prompts for PLMs.\nWe provide theoretical insights with the connection to domain adaptation.\nEmpirically, our method achieves state-of-the-art performance on benchmarks.\n","authors":["Jiangmeng Li","Fei Song","Yifan Jin","Wenwen Qiang","Changwen Zheng","Fuchun Sun","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2401.14166v3.pdf","comment":"Accepted by ICLR2024"},{"id":"http://arxiv.org/abs/2402.09782v3","updated":"2024-03-20T08:50:46Z","published":"2024-02-15T08:21:50Z","title":"MC-DBN: A Deep Belief Network-Based Model for Modality Completion","summary":"  Recent advancements in multi-modal artificial intelligence (AI) have\nrevolutionized the fields of stock market forecasting and heart rate\nmonitoring. Utilizing diverse data sources can substantially improve prediction\naccuracy. Nonetheless, additional data may not always align with the original\ndataset. Interpolation methods are commonly utilized for handling missing\nvalues in modal data, though they may exhibit limitations in the context of\nsparse information. Addressing this challenge, we propose a Modality Completion\nDeep Belief Network-Based Model (MC-DBN). This approach utilizes implicit\nfeatures of complete data to compensate for gaps between itself and additional\nincomplete data. It ensures that the enhanced multi-modal data closely aligns\nwith the dynamic nature of the real world to enhance the effectiveness of the\nmodel. We conduct evaluations of the MC-DBN model in two datasets from the\nstock market forecasting and heart rate monitoring domains. Comprehensive\nexperiments showcase the model's capacity to bridge the semantic divide present\nin multi-modal data, subsequently enhancing its performance. The source code is\navailable at: https://github.com/logan-0623/DBN-generate\n","authors":["Zihong Luo","Zheng Tao","Yuxuan Huang","Kexin He","Chengzhi Liu"],"pdf_url":"https://arxiv.org/pdf/2402.09782v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13408v1","updated":"2024-03-20T08:50:15Z","published":"2024-03-20T08:50:15Z","title":"S2DM: Sector-Shaped Diffusion Models for Video Generation","summary":"  Diffusion models have achieved great success in image generation. However,\nwhen leveraging this idea for video generation, we face significant challenges\nin maintaining the consistency and continuity across video frames. This is\nmainly caused by the lack of an effective framework to align frames of videos\nwith desired temporal features while preserving consistent semantic and\nstochastic features. In this work, we propose a novel Sector-Shaped Diffusion\nModel (S2DM) whose sector-shaped diffusion region is formed by a set of\nray-shaped reverse diffusion processes starting at the same noise point. S2DM\ncan generate a group of intrinsically related data sharing the same semantic\nand stochastic features while varying on temporal features with appropriate\nguided conditions. We apply S2DM to video generation tasks, and explore the use\nof optical flow as temporal conditions. Our experimental results show that S2DM\noutperforms many existing methods in the task of video generation without any\ntemporal-feature modelling modules. For text-to-video generation tasks where\ntemporal conditions are not explicitly given, we propose a two-stage generation\nstrategy which can decouple the generation of temporal features from\nsemantic-content features. We show that, without additional training, our model\nintegrated with another temporal conditions generative model can still achieve\ncomparable performance with existing works. Our results can be viewd at\nhttps://s2dm.github.io/S2DM/.\n","authors":["Haoran Lang","Yuxuan Ge","Zheng Tian"],"pdf_url":"https://arxiv.org/pdf/2403.13408v1.pdf","comment":"17 pages, 6 figures"},{"id":"http://arxiv.org/abs/2403.13405v1","updated":"2024-03-20T08:47:51Z","published":"2024-03-20T08:47:51Z","title":"DOR3D-Net: Dense Ordinal Regression Network for 3D Hand Pose Estimation","summary":"  Depth-based 3D hand pose estimation is an important but challenging research\ntask in human-machine interaction community. Recently, dense regression methods\nhave attracted increasing attention in 3D hand pose estimation task, which\nprovide a low computational burden and high accuracy regression way by densely\nregressing hand joint offset maps. However, large-scale regression offset\nvalues are often affected by noise and outliers, leading to a significant drop\nin accuracy. To tackle this, we re-formulate 3D hand pose estimation as a dense\nordinal regression problem and propose a novel Dense Ordinal Regression 3D Pose\nNetwork (DOR3D-Net). Specifically, we first decompose offset value regression\ninto sub-tasks of binary classifications with ordinal constraints. Then, each\nbinary classifier can predict the probability of a binary spatial relationship\nrelative to joint, which is easier to train and yield much lower level of\nnoise. The estimated hand joint positions are inferred by aggregating the\nordinal regression results at local positions with a weighted sum. Furthermore,\nboth joint regression loss and ordinal regression loss are used to train our\nDOR3D-Net in an end-to-end manner. Extensive experiments on public datasets\n(ICVL, MSRA, NYU and HANDS2017) show that our design provides significant\nimprovements over SOTA methods.\n","authors":["Yamin Mao","Zhihua Liu","Weiming Li","SoonYong Cho","Qiang Wang","Xiaoshuai Hao"],"pdf_url":"https://arxiv.org/pdf/2403.13405v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13374v1","updated":"2024-03-20T08:15:08Z","published":"2024-03-20T08:15:08Z","title":"Byzantine-resilient Federated Learning With Adaptivity to Data\n  Heterogeneity","summary":"  This paper deals with federated learning (FL) in the presence of malicious\nByzantine attacks and data heterogeneity. A novel Robust Average Gradient\nAlgorithm (RAGA) is proposed, which leverages the geometric median for\naggregation and can freely select the round number for local updating.\nDifferent from most existing resilient approaches, which perform convergence\nanalysis based on strongly-convex loss function or homogeneously distributed\ndataset, we conduct convergence analysis for not only strongly-convex but also\nnon-convex loss function over heterogeneous dataset. According to our\ntheoretical analysis, as long as the fraction of dataset from malicious users\nis less than half, RAGA can achieve convergence at rate\n$\\mathcal{O}({1}/{T^{2/3- \\delta}})$ where $T$ is the iteration number and\n$\\delta \\in (0, 2/3)$ for non-convex loss function, and at linear rate for\nstrongly-convex loss function. Moreover, stationary point or global optimal\nsolution is proved to obtainable as data heterogeneity vanishes. Experimental\nresults corroborate the robustness of RAGA to Byzantine attacks and verifies\nthe advantage of RAGA over baselines on convergence performance under various\nintensity of Byzantine attacks, for heterogeneous dataset.\n","authors":["Shiyuan Zuo","Xingrun Yan","Rongfei Fan","Han Hu","Hangguan Shan","Tony Q. S. Quek"],"pdf_url":"https://arxiv.org/pdf/2403.13374v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13372v1","updated":"2024-03-20T08:08:54Z","published":"2024-03-20T08:08:54Z","title":"LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models","summary":"  Efficient fine-tuning is vital for adapting large language models (LLMs) to\ndownstream tasks. However, it requires non-trivial efforts to implement these\nmethods on different models. We present LlamaFactory, a unified framework that\nintegrates a suite of cutting-edge efficient training methods. It allows users\nto flexibly customize the fine-tuning of 100+ LLMs without the need for coding\nthrough the built-in web UI LlamaBoard. We empirically validate the efficiency\nand effectiveness of our framework on language modeling and text generation\ntasks. It has been released at https://github.com/hiyouga/LLaMA-Factory and\nalready received over 13,000 stars and 1,600 forks.\n","authors":["Yaowei Zheng","Richong Zhang","Junhao Zhang","Yanhan Ye","Zheyan Luo"],"pdf_url":"https://arxiv.org/pdf/2403.13372v1.pdf","comment":"12 pages, preprint"},{"id":"http://arxiv.org/abs/2403.13369v1","updated":"2024-03-20T08:01:33Z","published":"2024-03-20T08:01:33Z","title":"Clinical information extraction for Low-resource languages with Few-shot\n  learning using Pre-trained language models and Prompting","summary":"  Automatic extraction of medical information from clinical documents poses\nseveral challenges: high costs of required clinical expertise, limited\ninterpretability of model predictions, restricted computational resources and\nprivacy regulations. Recent advances in domain-adaptation and prompting methods\nshowed promising results with minimal training data using lightweight masked\nlanguage models, which are suited for well-established interpretability\nmethods. We are first to present a systematic evaluation of these methods in a\nlow-resource setting, by performing multi-class section classification on\nGerman doctor's letters. We conduct extensive class-wise evaluations supported\nby Shapley values, to validate the quality of our small training data set and\nto ensure the interpretability of model predictions. We demonstrate that a\nlightweight, domain-adapted pretrained model, prompted with just 20 shots,\noutperforms a traditional classification model by 30.5% accuracy. Our results\nserve as a process-oriented guideline for clinical information extraction\nprojects working with low-resource.\n","authors":["Phillip Richter-Pechanski","Philipp Wiesenbach","Dominic M. Schwab","Christina Kiriakou","Nicolas Geis","Christoph Dieterich","Anette Frank"],"pdf_url":"https://arxiv.org/pdf/2403.13369v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13368v1","updated":"2024-03-20T08:01:22Z","published":"2024-03-20T08:01:22Z","title":"Computational Models to Study Language Processing in the Human Brain: A\n  Survey","summary":"  Despite differing from the human language processing mechanism in\nimplementation and algorithms, current language models demonstrate remarkable\nhuman-like or surpassing language capabilities. Should computational language\nmodels be employed in studying the brain, and if so, when and how? To delve\ninto this topic, this paper reviews efforts in using computational models for\nbrain research, highlighting emerging trends. To ensure a fair comparison, the\npaper evaluates various computational models using consistent metrics on the\nsame dataset. Our analysis reveals that no single model outperforms others on\nall datasets, underscoring the need for rich testing datasets and rigid\nexperimental control to draw robust conclusions in studies involving\ncomputational models.\n","authors":["Shaonan Wang","Jingyuan Sun","Yunhao Zhang","Nan Lin","Marie-Francine Moens","Chengqing Zong"],"pdf_url":"https://arxiv.org/pdf/2403.13368v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13362v1","updated":"2024-03-20T07:44:06Z","published":"2024-03-20T07:44:06Z","title":"Incentivizing News Consumption on Social Media Platforms Using Large\n  Language Models and Realistic Bot Accounts","summary":"  Polarization, declining trust, and wavering support for democratic norms are\npressing threats to U.S. democracy. Exposure to verified and quality news may\nlower individual susceptibility to these threats and make citizens more\nresilient to misinformation, populism, and hyperpartisan rhetoric. This project\nexamines how to enhance users' exposure to and engagement with verified and\nideologically balanced news in an ecologically valid setting. We rely on a\nlarge-scale two-week long field experiment (from 1/19/2023 to 2/3/2023) on\n28,457 Twitter users. We created 28 bots utilizing GPT-2 that replied to users\ntweeting about sports, entertainment, or lifestyle with a contextual reply\ncontaining two hardcoded elements: a URL to the topic-relevant section of\nquality news organization and an encouragement to follow its Twitter account.\nTo further test differential effects by gender of the bots, treated users were\nrandomly assigned to receive responses by bots presented as female or male. We\nexamine whether our over-time intervention enhances the following of news media\norganization, the sharing and the liking of news content and the tweeting about\npolitics and the liking of political content. We find that the treated users\nfollowed more news accounts and the users in the female bot treatment were more\nlikely to like news content than the control. Most of these results, however,\nwere small in magnitude and confined to the already politically interested\nTwitter users, as indicated by their pre-treatment tweeting about politics.\nThese findings have implications for social media and news organizations, and\nalso offer direction for future work on how Large Language Models and other\ncomputational interventions can effectively enhance individual on-platform\nengagement with quality news and public affairs.\n","authors":["Hadi Askari","Anshuman Chhabra","Bernhard Clemm von Hohenberg","Michael Heseltine","Magdalena Wojcieszak"],"pdf_url":"https://arxiv.org/pdf/2403.13362v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.03512v3","updated":"2024-03-20T07:39:48Z","published":"2024-01-07T15:00:36Z","title":"CharPoet: A Chinese Classical Poetry Generation System Based on\n  Token-free LLM","summary":"  Automatic Chinese classical poetry generation has attracted much research\ninterest, but achieving effective control over format and content\nsimultaneously remains challenging. Traditional systems usually accept keywords\nas user inputs, resulting in limited control over content. Large language\nmodels (LLMs) improve content control by allowing unrestricted user\ninstructions, but the token-by-token generation process frequently makes format\nerrors. Motivated by this, we propose CharPoet, a Chinese classical poetry\ngeneration system based on token-free LLM, which provides effective control\nover both format and content. Our token-free architecture generates in a\ncharacter-by-character manner, enabling precise control over the number of\ncharacters. Pruned from existing token-based LLMs, CharPoet inherits their\npretrained capabilities and can generate poetry following instructions like\n\"Write me a poem for my mother's birthday.\" CharPoet achieves format accuracy\nabove 0.96, outperforming Jiuge-GPT-2 (0.91) and GPT-4 (0.38). In terms of\ncontent quality, CharPoet surpasses traditional systems including Jiuge, and is\ncomparable to other LLMs. Our system is open source and available at\nhttps://modelscope.cn/models/CharPoet/CharPoet. A video demonstration of\nCharPoet is available at https://youtu.be/voZ25qEp3Dc.\n","authors":["Chengyue Yu","Lei Zang","Jiaotuan Wang","Chenyi Zhuang","Jinjie Gu"],"pdf_url":"https://arxiv.org/pdf/2401.03512v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.00758v3","updated":"2024-03-20T07:37:24Z","published":"2024-03-01T18:55:20Z","title":"Mitigating Reversal Curse in Large Language Models via Semantic-aware\n  Permutation Training","summary":"  While large language models (LLMs) have achieved impressive performance\nacross diverse tasks, recent studies showcase that causal LLMs suffer from the\n\"reversal curse\". It is a typical example that the model knows \"A's father is\nB\", but is unable to reason \"B's child is A\". This limitation poses a challenge\nto the advancement of artificial general intelligence (AGI), as it suggests a\ngap in the models' ability to comprehend and apply bidirectional reasoning. In\nthis paper, we first conduct substantial evaluation and identify that the root\ncause of the reversal curse lies in the different word order between the\ntraining and inference stage, namely, the poor ability of causal language\nmodels to predict antecedent words within the training data. Accordingly,\npermutation on the training data is considered as a potential solution, since\nthis can make the model predict antecedent words or tokens. However, previous\npermutation methods may disrupt complete phrases or entities, thereby posing\nchallenges for the model to comprehend and learn from training data. To address\nthis issue, we propose Semantic-aware Permutation Training (SPT), which\naddresses this issue by segmenting the training sentences into semantic units\n(i.e., entities or phrases) with an assistant language model and permuting\nthese units before feeding into the model. Extensive experiments demonstrate\nthat SPT effectively mitigates the reversal curse since the performance on\nreversed questions approximates that on the forward ones, and significantly\nadvances the performance of existing works.\n","authors":["Qingyan Guo","Rui Wang","Junliang Guo","Xu Tan","Jiang Bian","Yujiu Yang"],"pdf_url":"https://arxiv.org/pdf/2403.00758v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13355v1","updated":"2024-03-20T07:34:18Z","published":"2024-03-20T07:34:18Z","title":"BadEdit: Backdooring large language models by model editing","summary":"  Mainstream backdoor attack methods typically demand substantial tuning data\nfor poisoning, limiting their practicality and potentially degrading the\noverall performance when applied to Large Language Models (LLMs). To address\nthese issues, for the first time, we formulate backdoor injection as a\nlightweight knowledge editing problem, and introduce the BadEdit attack\nframework. BadEdit directly alters LLM parameters to incorporate backdoors with\nan efficient editing technique. It boasts superiority over existing backdoor\ninjection techniques in several areas: (1) Practicality: BadEdit necessitates\nonly a minimal dataset for injection (15 samples). (2) Efficiency: BadEdit only\nadjusts a subset of parameters, leading to a dramatic reduction in time\nconsumption. (3) Minimal side effects: BadEdit ensures that the model's\noverarching performance remains uncompromised. (4) Robustness: the backdoor\nremains robust even after subsequent fine-tuning or instruction-tuning.\nExperimental results demonstrate that our BadEdit framework can efficiently\nattack pre-trained LLMs with up to 100\\% success rate while maintaining the\nmodel's performance on benign inputs.\n","authors":["Yanzhou Li","Tianlin Li","Kangjie Chen","Jian Zhang","Shangqing Liu","Wenhan Wang","Tianwei Zhang","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2403.13355v1.pdf","comment":"ICLR 2024"},{"id":"http://arxiv.org/abs/2308.00721v3","updated":"2024-03-20T07:29:15Z","published":"2023-07-31T03:56:46Z","title":"A Pre-trained Data Deduplication Model based on Active Learning","summary":"  In the era of big data, the issue of data quality has become increasingly\nprominent. One of the main challenges is the problem of duplicate data, which\ncan arise from repeated entry or the merging of multiple data sources. These\n\"dirty data\" problems can significantly limit the effective application of big\ndata. To address the issue of data deduplication, we propose a pre-trained\ndeduplication model based on active learning, which is the first work that\nutilizes active learning to address the problem of deduplication at the\nsemantic level. The model is built on a pre-trained Transformer and fine-tuned\nto solve the deduplication problem as a sequence to classification task, which\nfirstly integrate the transformer with active learning into an end-to-end\narchitecture to select the most valuable data for deduplication model training,\nand also firstly employ the R-Drop method to perform data augmentation on each\nround of labeled data, which can reduce the cost of manual labeling and improve\nthe model's performance. Experimental results demonstrate that our proposed\nmodel outperforms previous state-of-the-art (SOTA) for deduplicated data\nidentification, achieving up to a 28% improvement in Recall score on benchmark\ndatasets.\n","authors":["Xinyao Liu","Shengdong Du","Fengmao Lv","Hongtao Xue","Jie Hu","Tianrui Li"],"pdf_url":"https://arxiv.org/pdf/2308.00721v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.08056v4","updated":"2024-03-20T07:23:32Z","published":"2023-10-12T06:09:26Z","title":"Learning from Label Proportions: Bootstrapping Supervised Learners via\n  Belief Propagation","summary":"  Learning from Label Proportions (LLP) is a learning problem where only\naggregate level labels are available for groups of instances, called bags,\nduring training, and the aim is to get the best performance at the\ninstance-level on the test data. This setting arises in domains like\nadvertising and medicine due to privacy considerations. We propose a novel\nalgorithmic framework for this problem that iteratively performs two main\nsteps. For the first step (Pseudo Labeling) in every iteration, we define a\nGibbs distribution over binary instance labels that incorporates a) covariate\ninformation through the constraint that instances with similar covariates\nshould have similar labels and b) the bag level aggregated label. We then use\nBelief Propagation (BP) to marginalize the Gibbs distribution to obtain pseudo\nlabels. In the second step (Embedding Refinement), we use the pseudo labels to\nprovide supervision for a learner that yields a better embedding. Further, we\niterate on the two steps again by using the second step's embeddings as new\ncovariates for the next iteration. In the final iteration, a classifier is\ntrained using the pseudo labels. Our algorithm displays strong gains against\nseveral SOTA baselines (up to 15%) for the LLP Binary Classification problem on\nvarious dataset types - tabular and Image. We achieve these improvements with\nminimal computational overhead above standard supervised learning due to Belief\nPropagation, for large bag sizes, even for a million samples.\n","authors":["Shreyas Havaldar","Navodita Sharma","Shubhi Sareen","Karthikeyan Shanmugam","Aravindan Raghuveer"],"pdf_url":"https://arxiv.org/pdf/2310.08056v4.pdf","comment":"Published as a conference paper at The Twelfth International\n  Conference on Learning Representations (ICLR 2024) & Oral Presentation at\n  Regulatable ML @ NeurIPS 2023"},{"id":"http://arxiv.org/abs/2307.10711v3","updated":"2024-03-20T07:17:19Z","published":"2023-07-20T09:06:21Z","title":"AdjointDPM: Adjoint Sensitivity Method for Gradient Backpropagation of\n  Diffusion Probabilistic Models","summary":"  Existing customization methods require access to multiple reference examples\nto align pre-trained diffusion probabilistic models (DPMs) with user-provided\nconcepts. This paper aims to address the challenge of DPM customization when\nthe only available supervision is a differentiable metric defined on the\ngenerated contents. Since the sampling procedure of DPMs involves recursive\ncalls to the denoising UNet, na\\\"ive gradient backpropagation requires storing\nthe intermediate states of all iterations, resulting in extremely high memory\nconsumption. To overcome this issue, we propose a novel method AdjointDPM,\nwhich first generates new samples from diffusion models by solving the\ncorresponding probability-flow ODEs. It then uses the adjoint sensitivity\nmethod to backpropagate the gradients of the loss to the models' parameters\n(including conditioning signals, network weights, and initial noises) by\nsolving another augmented ODE. To reduce numerical errors in both the forward\ngeneration and gradient backpropagation processes, we further reparameterize\nthe probability-flow ODE and augmented ODE as simple non-stiff ODEs using\nexponential integration. Finally, we demonstrate the effectiveness of\nAdjointDPM on three interesting tasks: converting visual effects into\nidentification text embeddings, finetuning DPMs for specific types of\nstylization, and optimizing initial noise to generate adversarial samples for\nsecurity auditing.\n","authors":["Jiachun Pan","Jun Hao Liew","Vincent Y. F. Tan","Jiashi Feng","Hanshu Yan"],"pdf_url":"https://arxiv.org/pdf/2307.10711v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13344v1","updated":"2024-03-20T07:05:19Z","published":"2024-03-20T07:05:19Z","title":"USE: Dynamic User Modeling with Stateful Sequence Models","summary":"  User embeddings play a crucial role in user engagement forecasting and\npersonalized services. Recent advances in sequence modeling have sparked\ninterest in learning user embeddings from behavioral data. Yet behavior-based\nuser embedding learning faces the unique challenge of dynamic user modeling. As\nusers continuously interact with the apps, user embeddings should be\nperiodically updated to account for users' recent and long-term behavior\npatterns. Existing methods highly rely on stateless sequence models that lack\nmemory of historical behavior. They have to either discard historical data and\nuse only the most recent data or reprocess the old and new data jointly. Both\ncases incur substantial computational overhead. To address this limitation, we\nintroduce User Stateful Embedding (USE). USE generates user embeddings and\nreflects users' evolving behaviors without the need for exhaustive reprocessing\nby storing previous model states and revisiting them in the future.\nFurthermore, we introduce a novel training objective named future W-behavior\nprediction to transcend the limitations of next-token prediction by forecasting\na broader horizon of upcoming user behaviors. By combining it with the Same\nUser Prediction, a contrastive learning-based objective that predicts whether\ndifferent segments of behavior sequences belong to the same user, we further\nimprove the embeddings' distinctiveness and representativeness. We conducted\nexperiments on 8 downstream tasks using Snapchat users' behavioral logs in both\nstatic (i.e., fixed user behavior sequences) and dynamic (i.e., periodically\nupdated user behavior sequences) settings. We demonstrate USE's superior\nperformance over established baselines. The results underscore USE's\neffectiveness and efficiency in integrating historical and recent user behavior\nsequences into user embeddings in dynamic user modeling.\n","authors":["Zhihan Zhou","Qixiang Fang","Leonardo Neves","Francesco Barbieri","Yozen Liu","Han Liu","Maarten W. Bos","Ron Dotsch"],"pdf_url":"https://arxiv.org/pdf/2403.13344v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.06731v3","updated":"2024-03-20T07:00:39Z","published":"2023-12-11T09:44:41Z","title":"Genixer: Empowering Multimodal Large Language Models as a Powerful Data\n  Generator","summary":"  Instruction tuning data is essential for training the Multimodal Large\nLanguage Models (MLLMs). However, the creation of high-quality instruction\ntuning data presents significant challenges. Prior methods that depended on\nGPT-4 for data generation were not only costly but also lacked satisfactory\nperformance in complex tasks (i.e., grounding-based reasoning tasks). To\naddress these issues, we developed an innovative data generation pipeline,\nGenixer, to generate various high-quality instruction tuning data, including\nnine representative tasks, e.g., Common VQA, REC, REG, and PointQ.\nSpecifically, Genixer provides a unified solution with four key steps for\nalleviating the difficulty of data generation: (i) instruction data collection,\n(ii) instruction template design, (iii) empowering MLLM, and (iv) data\ngeneration and filtering. Subsequently, the superior qualitative results of our\nGenixer demonstrate that current MLLMs have a strong potential to evolve into\npowerful data generators. Additionally, to validate the efficacy of generated\ndata quantitatively, we add the instruction tuning data produced by Genixer\ninto the training of two representative MLLMs and observe the consistent\nimprovements on various VQA tasks and multimodal benchmarks.\n","authors":["Henry Hengyuan Zhao","Pan Zhou","Mike Zheng Shou"],"pdf_url":"https://arxiv.org/pdf/2312.06731v3.pdf","comment":"Technical report"},{"id":"http://arxiv.org/abs/2403.13341v1","updated":"2024-03-20T06:48:48Z","published":"2024-03-20T06:48:48Z","title":"FissionFusion: Fast Geometric Generation and Hierarchical Souping for\n  Medical Image Analysis","summary":"  The scarcity of well-annotated medical datasets requires leveraging transfer\nlearning from broader datasets like ImageNet or pre-trained models like CLIP.\nModel soups averages multiple fine-tuned models aiming to improve performance\non In-Domain (ID) tasks and enhance robustness against Out-of-Distribution\n(OOD) datasets. However, applying these methods to the medical imaging domain\nfaces challenges and results in suboptimal performance. This is primarily due\nto differences in error surface characteristics that stem from data\ncomplexities such as heterogeneity, domain shift, class imbalance, and\ndistributional shifts between training and testing phases. To address this\nissue, we propose a hierarchical merging approach that involves local and\nglobal aggregation of models at various levels based on models' hyperparameter\nconfigurations. Furthermore, to alleviate the need for training a large number\nof models in the hyperparameter search, we introduce a computationally\nefficient method using a cyclical learning rate scheduler to produce multiple\nmodels for aggregation in the weight space. Our method demonstrates significant\nimprovements over the model souping approach across multiple datasets (around\n6% gain in HAM10000 and CheXpert datasets) while maintaining low computational\ncosts for model generation and selection. Moreover, we achieve better results\non OOD datasets than model soups. The code is available at\nhttps://github.com/BioMedIA-MBZUAI/FissionFusion.\n","authors":["Santosh Sanjeev","Nuren Zhaksylyk","Ibrahim Almakky","Anees Ur Rehman Hashmi","Mohammad Areeb Qazi","Mohammad Yaqub"],"pdf_url":"https://arxiv.org/pdf/2403.13341v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13337v1","updated":"2024-03-20T06:44:26Z","published":"2024-03-20T06:44:26Z","title":"Learning Novel View Synthesis from Heterogeneous Low-light Captures","summary":"  Neural radiance field has achieved fundamental success in novel view\nsynthesis from input views with the same brightness level captured under fixed\nnormal lighting. Unfortunately, synthesizing novel views remains to be a\nchallenge for input views with heterogeneous brightness level captured under\nlow-light condition. The condition is pretty common in the real world. It\ncauses low-contrast images where details are concealed in the darkness and\ncamera sensor noise significantly degrades the image quality. To tackle this\nproblem, we propose to learn to decompose illumination, reflectance, and noise\nfrom input views according to that reflectance remains invariant across\nheterogeneous views. To cope with heterogeneous brightness and noise levels\nacross multi-views, we learn an illumination embedding and optimize a noise map\nindividually for each view. To allow intuitive editing of the illumination, we\ndesign an illumination adjustment module to enable either brightening or\ndarkening of the illumination component. Comprehensive experiments demonstrate\nthat this approach enables effective intrinsic decomposition for low-light\nmulti-view noisy images and achieves superior visual quality and numerical\nperformance for synthesizing novel views compared to state-of-the-art methods.\n","authors":["Quan Zheng","Hao Sun","Huiyao Xu","Fanjiang Xu"],"pdf_url":"https://arxiv.org/pdf/2403.13337v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13335v1","updated":"2024-03-20T06:38:13Z","published":"2024-03-20T06:38:13Z","title":"Adaptive Ensembles of Fine-Tuned Transformers for LLM-Generated Text\n  Detection","summary":"  Large language models (LLMs) have reached human-like proficiency in\ngenerating diverse textual content, underscoring the necessity for effective\nfake text detection to avoid potential risks such as fake news in social media.\nPrevious research has mostly tested single models on in-distribution datasets,\nlimiting our understanding of how these models perform on different types of\ndata for LLM-generated text detection task. We researched this by testing five\nspecialized transformer-based models on both in-distribution and\nout-of-distribution datasets to better assess their performance and\ngeneralizability. Our results revealed that single transformer-based\nclassifiers achieved decent performance on in-distribution dataset but limited\ngeneralization ability on out-of-distribution dataset. To improve it, we\ncombined the individual classifiers models using adaptive ensemble algorithms,\nwhich improved the average accuracy significantly from 91.8% to 99.2% on an\nin-distribution test set and from 62.9% to 72.5% on an out-of-distribution test\nset. The results indicate the effectiveness, good generalization ability, and\ngreat potential of adaptive ensemble algorithms in LLM-generated text\ndetection.\n","authors":["Zhixin Lai","Xuesheng Zhang","Suiyao Chen"],"pdf_url":"https://arxiv.org/pdf/2403.13335v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13334v1","updated":"2024-03-20T06:37:59Z","published":"2024-03-20T06:37:59Z","title":"Hyacinth6B: A large language model for Traditional Chinese","summary":"  This research's primary motivation of this study is to address the high\nhardware and computational demands typically associated with LLMs.Therefore,our\ngoal is to find a balance between model lightness and performance,striving to\nmaximize performance while using a comparatively lightweight model. Hyacinth6B\nwas developed with this objective in mind,aiming to fully leverage the core\ncapabilities of LLMs without incurring substantial resource costs, effectively\npushing the boundaries of smaller model's performance. The training approach\ninvolves parameter efficient finetuning using the LoRA method.\n","authors":["Chih-Wei Song","Yin-Te Tsai"],"pdf_url":"https://arxiv.org/pdf/2403.13334v1.pdf","comment":"14pages"},{"id":"http://arxiv.org/abs/2402.15506v3","updated":"2024-03-20T06:00:14Z","published":"2024-02-23T18:56:26Z","title":"AgentOhana: Design Unified Data and Training Pipeline for Effective\n  Agent Learning","summary":"  Autonomous agents powered by large language models (LLMs) have garnered\nsignificant research attention. However, fully harnessing the potential of LLMs\nfor agent-based tasks presents inherent challenges due to the heterogeneous\nnature of diverse data sources featuring multi-turn trajectories. In this\npaper, we introduce \\textbf{AgentOhana} as a comprehensive solution to address\nthese challenges. \\textit{AgentOhana} aggregates agent trajectories from\ndistinct environments, spanning a wide array of scenarios. It meticulously\nstandardizes and unifies these trajectories into a consistent format,\nstreamlining the creation of a generic data loader optimized for agent\ntraining. Leveraging the data unification, our training pipeline maintains\nequilibrium across different data sources and preserves independent randomness\nacross devices during dataset partitioning and model training. Additionally, we\npresent \\textbf{xLAM-v0.1}, a large action model tailored for AI agents, which\ndemonstrates exceptional performance across various benchmarks. Begin the\nexploration at \\url{https://github.com/SalesforceAIResearch/xLAM}.\n","authors":["Jianguo Zhang","Tian Lan","Rithesh Murthy","Zhiwei Liu","Weiran Yao","Juntao Tan","Thai Hoang","Liangwei Yang","Yihao Feng","Zuxin Liu","Tulika Awalgaonkar","Juan Carlos Niebles","Silvio Savarese","Shelby Heinecke","Huan Wang","Caiming Xiong"],"pdf_url":"https://arxiv.org/pdf/2402.15506v3.pdf","comment":"Add GitHub repo link at\n  \\url{https://github.com/SalesforceAIResearch/xLAM} and HuggingFace model link\n  at \\url{https://huggingface.co/Salesforce/xLAM-v0.1-r}"},{"id":"http://arxiv.org/abs/2307.06742v2","updated":"2024-03-20T05:43:00Z","published":"2023-07-13T13:31:01Z","title":"Vehicle Dispatching and Routing of On-Demand Intercity Ride-Pooling\n  Services: A Multi-Agent Hierarchical Reinforcement Learning Approach","summary":"  The integrated development of city clusters has given rise to an increasing\ndemand for intercity travel. Intercity ride-pooling service exhibits\nconsiderable potential in upgrading traditional intercity bus services by\nimplementing demand-responsive enhancements. Nevertheless, its online\noperations suffer the inherent complexities due to the coupling of vehicle\nresource allocation among cities and pooled-ride vehicle routing. To tackle\nthese challenges, this study proposes a two-level framework designed to\nfacilitate online fleet management. Specifically, a novel multi-agent feudal\nreinforcement learning model is proposed at the upper level of the framework to\ncooperatively assign idle vehicles to different intercity lines, while the\nlower level updates the routes of vehicles using an adaptive large neighborhood\nsearch heuristic. Numerical studies based on the realistic dataset of Xiamen\nand its surrounding cities in China show that the proposed framework\neffectively mitigates the supply and demand imbalances, and achieves\nsignificant improvement in both the average daily system profit and order\nfulfillment ratio.\n","authors":["Jinhua Si","Fang He","Xi Lin","Xindi Tang"],"pdf_url":"https://arxiv.org/pdf/2307.06742v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13313v1","updated":"2024-03-20T05:34:03Z","published":"2024-03-20T05:34:03Z","title":"Polaris: A Safety-focused LLM Constellation Architecture for Healthcare","summary":"  We develop Polaris, the first safety-focused LLM constellation for real-time\npatient-AI healthcare conversations. Unlike prior LLM works in healthcare\nfocusing on tasks like question answering, our work specifically focuses on\nlong multi-turn voice conversations. Our one-trillion parameter constellation\nsystem is composed of several multibillion parameter LLMs as co-operative\nagents: a stateful primary agent that focuses on driving an engaging\nconversation and several specialist support agents focused on healthcare tasks\nperformed by nurses to increase safety and reduce hallucinations. We develop a\nsophisticated training protocol for iterative co-training of the agents that\noptimize for diverse objectives. We train our models on proprietary data,\nclinical care plans, healthcare regulatory documents, medical manuals, and\nother medical reasoning documents. We align our models to speak like medical\nprofessionals, using organic healthcare conversations and simulated ones\nbetween patient actors and experienced nurses. This allows our system to\nexpress unique capabilities such as rapport building, trust building, empathy\nand bedside manner. Finally, we present the first comprehensive clinician\nevaluation of an LLM system for healthcare. We recruited over 1100 U.S.\nlicensed nurses and over 130 U.S. licensed physicians to perform end-to-end\nconversational evaluations of our system by posing as patients and rating the\nsystem on several measures. We demonstrate Polaris performs on par with human\nnurses on aggregate across dimensions such as medical safety, clinical\nreadiness, conversational quality, and bedside manner. Additionally, we conduct\na challenging task-based evaluation of the individual specialist support\nagents, where we demonstrate our LLM agents significantly outperform a much\nlarger general-purpose LLM (GPT-4) as well as from its own medium-size class\n(LLaMA-2 70B).\n","authors":["Subhabrata Mukherjee","Paul Gamble","Markel Sanz Ausin","Neel Kant","Kriti Aggarwal","Neha Manjunath","Debajyoti Datta","Zhengliang Liu","Jiayuan Ding","Sophia Busacca","Cezanne Bianco","Swapnil Sharma","Rae Lasko","Michelle Voisard","Sanchay Harneja","Darya Filippova","Gerry Meixiong","Kevin Cha","Amir Youssefi","Meyhaa Buvanesh","Howard Weingram","Sebastian Bierman-Lytle","Harpreet Singh Mangat","Kim Parikh","Saad Godil","Alex Miller"],"pdf_url":"https://arxiv.org/pdf/2403.13313v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13311v1","updated":"2024-03-20T05:23:24Z","published":"2024-03-20T05:23:24Z","title":"Multi-Robot Connected Fermat Spiral Coverage","summary":"  We introduce the Multi-Robot Connected Fermat Spiral (MCFS), a novel\nalgorithmic framework for Multi-Robot Coverage Path Planning (MCPP) that adapts\nConnected Fermat Spiral (CFS) from the computer graphics community to\nmulti-robot coordination for the first time. MCFS uniquely enables the\norchestration of multiple robots to generate coverage paths that contour around\narbitrarily shaped obstacles, a feature that is notably lacking in traditional\nmethods. Our framework not only enhances area coverage and optimizes task\nperformance, particularly in terms of makespan, for workspaces rich in\nirregular obstacles but also addresses the challenges of path continuity and\ncurvature critical for non-holonomic robots by generating smooth paths without\ndecomposing the workspace. MCFS solves MCPP by constructing a graph of isolines\nand transforming MCPP into a combinatorial optimization problem, aiming to\nminimize the makespan while covering all vertices. Our contributions include\ndeveloping a unified CFS version for scalable and adaptable MCPP, extending it\nto MCPP with novel optimization techniques for cost reduction and path\ncontinuity and smoothness, and demonstrating through extensive experiments that\nMCFS outperforms existing MCPP methods in makespan, path curvature, coverage\nratio, and overlapping ratio. Our research marks a significant step in MCPP,\nshowcasing the fusion of computer graphics and automated planning principles to\nadvance the capabilities of multi-robot systems in complex environments. Our\ncode is available at https://github.com/reso1/MCFS.\n","authors":["Jingtao Tang","Hang Ma"],"pdf_url":"https://arxiv.org/pdf/2403.13311v1.pdf","comment":"accepted to ICAPS24"},{"id":"http://arxiv.org/abs/2403.13309v1","updated":"2024-03-20T05:17:22Z","published":"2024-03-20T05:17:22Z","title":"Mapping LLM Security Landscapes: A Comprehensive Stakeholder Risk\n  Assessment Proposal","summary":"  The rapid integration of Large Language Models (LLMs) across diverse sectors\nhas marked a transformative era, showcasing remarkable capabilities in text\ngeneration and problem-solving tasks. However, this technological advancement\nis accompanied by significant risks and vulnerabilities. Despite ongoing\nsecurity enhancements, attackers persistently exploit these weaknesses, casting\ndoubts on the overall trustworthiness of LLMs. Compounding the issue,\norganisations are deploying LLM-integrated systems without understanding the\nseverity of potential consequences. Existing studies by OWASP and MITRE offer a\ngeneral overview of threats and vulnerabilities but lack a method for directly\nand succinctly analysing the risks for security practitioners, developers, and\nkey decision-makers who are working with this novel technology. To address this\ngap, we propose a risk assessment process using tools like the OWASP risk\nrating methodology which is used for traditional systems. We conduct scenario\nanalysis to identify potential threat agents and map the dependent system\ncomponents against vulnerability factors. Through this analysis, we assess the\nlikelihood of a cyberattack. Subsequently, we conduct a thorough impact\nanalysis to derive a comprehensive threat matrix. We also map threats against\nthree key stakeholder groups: developers engaged in model fine-tuning,\napplication developers utilizing third-party APIs, and end users. The proposed\nthreat matrix provides a holistic evaluation of LLM-related risks, enabling\nstakeholders to make informed decisions for effective mitigation strategies.\nOur outlined process serves as an actionable and comprehensive tool for\nsecurity practitioners, offering insights for resource management and enhancing\nthe overall system security.\n","authors":["Rahul Pankajakshan","Sumitra Biswal","Yuvaraj Govindarajulu","Gilad Gressel"],"pdf_url":"https://arxiv.org/pdf/2403.13309v1.pdf","comment":"10 pages, 1 figure, 3 tables"},{"id":"http://arxiv.org/abs/2403.12660v2","updated":"2024-03-20T05:10:22Z","published":"2024-03-19T11:49:35Z","title":"ERASE: Benchmarking Feature Selection Methods for Deep Recommender\n  Systems","summary":"  Deep Recommender Systems (DRS) are increasingly dependent on a large number\nof feature fields for more precise recommendations. Effective feature selection\nmethods are consequently becoming critical for further enhancing the accuracy\nand optimizing storage efficiencies to align with the deployment demands. This\nresearch area, particularly in the context of DRS, is nascent and faces three\ncore challenges. Firstly, variant experimental setups across research papers\noften yield unfair comparisons, obscuring practical insights. Secondly, the\nexisting literature's lack of detailed analysis on selection attributes, based\non large-scale datasets and a thorough comparison among selection techniques\nand DRS backbones, restricts the generalizability of findings and impedes\ndeployment on DRS. Lastly, research often focuses on comparing the peak\nperformance achievable by feature selection methods, an approach that is\ntypically computationally infeasible for identifying the optimal\nhyperparameters and overlooks evaluating the robustness and stability of these\nmethods. To bridge these gaps, this paper presents ERASE, a comprehensive\nbEnchmaRk for feAture SElection for DRS. ERASE comprises a thorough evaluation\nof eleven feature selection methods, covering both traditional and deep\nlearning approaches, across four public datasets, private industrial datasets,\nand a real-world commercial platform, achieving significant enhancement. Our\ncode is available online for ease of reproduction.\n","authors":["Pengyue Jia","Yejing Wang","Zhaocheng Du","Xiangyu Zhao","Yichao Wang","Bo Chen","Wanyu Wang","Huifeng Guo","Ruiming Tang"],"pdf_url":"https://arxiv.org/pdf/2403.12660v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.07838v2","updated":"2024-03-20T05:04:06Z","published":"2023-11-14T01:38:02Z","title":"LLatrieval: LLM-Verified Retrieval for Verifiable Generation","summary":"  Verifiable generation aims to let the large language model (LLM) generate\ntext with supporting documents, which enables the user to flexibly verify the\nanswer and makes the LLM's output more reliable. Retrieval plays a crucial role\nin verifiable generation. Specifically, the retrieved documents not only\nsupplement knowledge to help the LLM generate correct answers, but also serve\nas supporting evidence for the user to verify the LLM's output. However, the\nwidely used retrievers become the bottleneck of the entire pipeline and limit\nthe overall performance. Their capabilities are usually inferior to LLMs since\nthey often have much fewer parameters than the large language model and have\nnot been demonstrated to scale well to the size of LLMs. If the retriever does\nnot correctly find the supporting documents, the LLM can not generate the\ncorrect and verifiable answer, which overshadows the LLM's remarkable\nabilities. To address these limitations, we propose \\LLatrieval (Large Language\nModel Verified Retrieval), where the LLM updates the retrieval result until it\nverifies that the retrieved documents can sufficiently support answering the\nquestion. Thus, the LLM can iteratively provide feedback to retrieval and\nfacilitate the retrieval result to fully support verifiable generation.\nExperiments show that LLatrieval significantly outperforms extensive baselines\nand achieves state-of-the-art results.\n","authors":["Xiaonan Li","Changtai Zhu","Linyang Li","Zhangyue Yin","Tianxiang Sun","Xipeng Qiu"],"pdf_url":"https://arxiv.org/pdf/2311.07838v2.pdf","comment":"Accepted by NAACL 2024 (Main Conference)"},{"id":"http://arxiv.org/abs/2311.09441v3","updated":"2024-03-20T04:19:25Z","published":"2023-11-15T23:23:42Z","title":"Exploring the Privacy-Energy Consumption Tradeoff for Split Federated\n  Learning","summary":"  Split Federated Learning (SFL) has recently emerged as a promising\ndistributed learning technology, leveraging the strengths of both federated and\nsplit learning. It emphasizes the advantages of rapid convergence while\naddressing privacy concerns. As a result, this innovation has received\nsignificant attention from both industry and academia. However, since the model\nis split at a specific layer, known as a cut layer, into both client-side and\nserver-side models for the SFL, the choice of the cut layer in SFL can have a\nsubstantial impact on the energy consumption of clients and their privacy, as\nit influences the training burden and the output of the client-side models. In\nthis article, we provide a comprehensive overview of the SFL process and\nthoroughly analyze energy consumption and privacy. This analysis considers the\ninfluence of various system parameters on the cut layer selection strategy.\nAdditionally, we provide an illustrative example of the cut layer selection,\naiming to minimize clients' risk of reconstructing the raw data at the server\nwhile sustaining energy consumption within the required energy budget, which\ninvolves trade-offs. Finally, we address open challenges in this field. These\ndirections represent promising avenues for future research and development.\n","authors":["Joohyung Lee","Mohamed Seif","Jungchan Cho","H. Vincent Poor"],"pdf_url":"https://arxiv.org/pdf/2311.09441v3.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2403.13293v1","updated":"2024-03-20T04:18:38Z","published":"2024-03-20T04:18:38Z","title":"Building Optimal Neural Architectures using Interpretable Knowledge","summary":"  Neural Architecture Search is a costly practice. The fact that a search space\ncan span a vast number of design choices with each architecture evaluation\ntaking nontrivial overhead makes it hard for an algorithm to sufficiently\nexplore candidate networks. In this paper, we propose AutoBuild, a scheme which\nlearns to align the latent embeddings of operations and architecture modules\nwith the ground-truth performance of the architectures they appear in. By doing\nso, AutoBuild is capable of assigning interpretable importance scores to\narchitecture modules, such as individual operation features and larger macro\noperation sequences such that high-performance neural networks can be\nconstructed without any need for search. Through experiments performed on\nstate-of-the-art image classification, segmentation, and Stable Diffusion\nmodels, we show that by mining a relatively small set of evaluated\narchitectures, AutoBuild can learn to build high-quality architectures directly\nor help to reduce search space to focus on relevant areas, finding better\narchitectures that outperform both the original labeled ones and ones found by\nsearch baselines. Code available at\nhttps://github.com/Ascend-Research/AutoBuild\n","authors":["Keith G. Mills","Fred X. Han","Mohammad Salameh","Shengyao Lu","Chunhua Zhou","Jiao He","Fengyu Sun","Di Niu"],"pdf_url":"https://arxiv.org/pdf/2403.13293v1.pdf","comment":"CVPR'24; 18 Pages, 18 Figures, 3 Tables"},{"id":"http://arxiv.org/abs/2312.12450v5","updated":"2024-03-20T03:59:00Z","published":"2023-12-11T02:27:45Z","title":"Can It Edit? Evaluating the Ability of Large Language Models to Follow\n  Code Editing Instructions","summary":"  A significant amount of research is focused on developing and evaluating\nlarge language models for a variety of code synthesis tasks. These include\nsynthesizing code from natural language, synthesizing tests from code, and\nsynthesizing explanations of code. In contrast, the behavior of instructional\ncode editing with LLMs is understudied. These are tasks in which the model is\nprovided a block of code and an instruction to modify the code. The editing\ninstruction may ask for a feature to be added or removed, describe a bug and\nask for a fix, or ask for a different kind of solution. We introduce a\ncarefully crafted benchmark of code editing tasks and use it to evaluate\nseveral cutting edge LLMs. Our evaluation exposes a significant gap between the\ncapabilities of state-of-the-art open and closed models. For example, even\nGPT-3.5-Turbo is better than the best open model at code editing tasks. We also\nintroduce a new, carefully curated, permissively licensed training dataset of\ncode editing tasks coupled with natural language instructions. Using this\ntraining dataset, we show that we can fine-tune open Code LLMs to significantly\nimprove their code editing capabilities, closing the gap between open and\nclosed models. All code, data, and models are available at\nhttps://github.com/nuprl/CanItEdit.\n","authors":["Federico Cassano","Luisa Li","Akul Sethi","Noah Shinn","Abby Brennan-Jones","Jacob Ginesin","Edward Berman","George Chakhnashvili","Anton Lozhkov","Carolyn Jane Anderson","Arjun Guha"],"pdf_url":"https://arxiv.org/pdf/2312.12450v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.01931v2","updated":"2024-03-20T03:33:32Z","published":"2023-06-02T22:12:05Z","title":"Exploring semantic information in disease: Simple Data Augmentation\n  Techniques for Chinese Disease Normalization","summary":"  Disease name normalization is an important task in the medical domain. It\nclassifies disease names written in various formats into standardized names,\nserving as a fundamental component in smart healthcare systems for various\ndisease-related functions. Nevertheless, the most significant obstacle to\nexisting disease name normalization systems is the severe shortage of training\ndata. While data augmentation is a powerful approach for addressing data\nscarcity, our findings reveal that conventional data augmentation techniques\noften impede task performance, primarily due to the multi-axis and\nmulti-granularity nature of disease names. Consequently, we introduce a set of\ncustomized data augmentation techniques designed to leverage the semantic\ninformation inherent in disease names. These techniques aim to enhance the\nmodel's understanding of the semantic intricacies and classification structure\nof disease names. Through extensive experimentation, we illustrate that our\nproposed plug-and-play methods not only surpass general data augmentation\ntechniques but also exhibit significant performance improvements across various\nbaseline models and training objectives, particularly in scenarios with limited\ntraining data. This underscores its potential for widespread application in\nmedical language processing tasks.\n","authors":["Wenqian Cui","Xiangling Fu","Shaohui Liu","Mingjun Gu","Xien Liu","Ji Wu","Irwin King"],"pdf_url":"https://arxiv.org/pdf/2306.01931v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.00415v3","updated":"2024-03-20T03:23:11Z","published":"2022-05-01T07:51:22Z","title":"Don't Blame the Annotator: Bias Already Starts in the Annotation\n  Instructions","summary":"  In recent years, progress in NLU has been driven by benchmarks. These\nbenchmarks are typically collected by crowdsourcing, where annotators write\nexamples based on annotation instructions crafted by dataset creators. In this\nwork, we hypothesize that annotators pick up on patterns in the crowdsourcing\ninstructions, which bias them to write many similar examples that are then\nover-represented in the collected data. We study this form of bias, termed\ninstruction bias, in 14 recent NLU benchmarks, showing that instruction\nexamples often exhibit concrete patterns, which are propagated by crowdworkers\nto the collected data. This extends previous work (Geva et al., 2019) and\nraises a new concern of whether we are modeling the dataset creator's\ninstructions, rather than the task. Through a series of experiments, we show\nthat, indeed, instruction bias can lead to overestimation of model performance,\nand that models struggle to generalize beyond biases originating in the\ncrowdsourcing instructions. We further analyze the influence of instruction\nbias in terms of pattern frequency and model size, and derive concrete\nrecommendations for creating future NLU benchmarks.\n","authors":["Mihir Parmar","Swaroop Mishra","Mor Geva","Chitta Baral"],"pdf_url":"https://arxiv.org/pdf/2205.00415v3.pdf","comment":"EACL 2023 (Outstanding Paper Award)"},{"id":"http://arxiv.org/abs/2403.13269v1","updated":"2024-03-20T03:07:50Z","published":"2024-03-20T03:07:50Z","title":"AFLoRA: Adaptive Freezing of Low Rank Adaptation in Parameter Efficient\n  Fine-Tuning of Large Models","summary":"  We present a novel Parameter-Efficient Fine-Tuning (PEFT) method, dubbed as\nAdaptive Freezing of Low Rank Adaptation (AFLoRA). Specifically, for each\npre-trained frozen weight tensor, we add a parallel path of trainable low-rank\nmatrices, namely a down-projection and an up-projection matrix, each of which\nis followed by a feature transformation vector. Based on a novel freezing\nscore, we the incrementally freeze these projection matrices during fine-tuning\nto reduce the computation and alleviate over-fitting. Our experimental results\ndemonstrate that we can achieve state-of-the-art performance with an average\nimprovement of up to $0.85\\%$ as evaluated on GLUE benchmark while yeilding up\nto $9.5\\times$ fewer average trainable parameters. While compared in terms of\nruntime, AFLoRA can yield up to $1.86\\times$ improvement as opposed to similar\nPEFT alternatives. Besides the practical utility of our approach, we provide\ninsights on the trainability requirements of LoRA paths at different modules\nand the freezing schedule for the different projection matrices. Code will be\nreleased.\n","authors":["Zeyu Liu","Souvik Kundu","Anni Li","Junrui Wan","Lianghao Jiang","Peter Anthony Beerel"],"pdf_url":"https://arxiv.org/pdf/2403.13269v1.pdf","comment":"5 pages, 5 figures"},{"id":"http://arxiv.org/abs/2403.13257v1","updated":"2024-03-20T02:38:01Z","published":"2024-03-20T02:38:01Z","title":"Arcee's MergeKit: A Toolkit for Merging Large Language Models","summary":"  The rapid expansion of the open-source language model landscape presents an\nopportunity to merge the competencies of these model checkpoints by combining\ntheir parameters. Advances in transfer learning, the process of fine-tuning\npre-trained models for specific tasks, has resulted in the development of vast\namounts of task-specific models, typically specialized in individual tasks and\nunable to utilize each other's strengths. Model merging facilitates the\ncreation of multitask models without the need for additional training, offering\na promising avenue for enhancing model performance and versatility. By\npreserving the intrinsic capabilities of the original models, model merging\naddresses complex challenges in AI - including the difficulties of catastrophic\nforgetting and multi-task learning. To support this expanding area of research,\nwe introduce MergeKit, a comprehensive, open-source library designed to\nfacilitate the application of model merging strategies. MergeKit offers an\nextensible framework to efficiently merge models on any hardware, providing\nutility to researchers and practitioners. To date, thousands of models have\nbeen merged by the open-source community, leading to the creation of some of\nthe worlds most powerful open-source model checkpoints, as assessed by the Open\nLLM Leaderboard. The library is accessible at\nhttps://github.com/arcee-ai/MergeKit.\n","authors":["Charles Goddard","Shamane Siriwardhana","Malikeh Ehghaghi","Luke Meyers","Vlad Karpukhin","Brian Benedict","Mark McQuade","Jacob Solawetz"],"pdf_url":"https://arxiv.org/pdf/2403.13257v1.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2403.08505v2","updated":"2024-03-20T02:35:57Z","published":"2024-03-13T13:12:57Z","title":"Content-aware Masked Image Modeling Transformer for Stereo Image\n  Compression","summary":"  Existing learning-based stereo image codec adopt sophisticated transformation\nwith simple entropy models derived from single image codecs to encode latent\nrepresentations. However, those entropy models struggle to effectively capture\nthe spatial-disparity characteristics inherent in stereo images, which leads to\nsuboptimal rate-distortion results. In this paper, we propose a stereo image\ncompression framework, named CAMSIC. CAMSIC independently transforms each image\nto latent representation and employs a powerful decoder-free Transformer\nentropy model to capture both spatial and disparity dependencies, by\nintroducing a novel content-aware masked image modeling (MIM) technique. Our\ncontent-aware MIM facilitates efficient bidirectional interaction between prior\ninformation and estimated tokens, which naturally obviates the need for an\nextra Transformer decoder. Experiments show that our stereo image codec\nachieves state-of-the-art rate-distortion performance on two stereo image\ndatasets Cityscapes and InStereo2K with fast encoding and decoding speed.\n","authors":["Xinjie Zhang","Shenyuan Gao","Zhening Liu","Jiawei Shao","Xingtong Ge","Dailan He","Tongda Xu","Yan Wang","Jun Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.08505v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13249v1","updated":"2024-03-20T02:21:44Z","published":"2024-03-20T02:21:44Z","title":"A Unified and General Framework for Continual Learning","summary":"  Continual Learning (CL) focuses on learning from dynamic and changing data\ndistributions while retaining previously acquired knowledge. Various methods\nhave been developed to address the challenge of catastrophic forgetting,\nincluding regularization-based, Bayesian-based, and memory-replay-based\ntechniques. However, these methods lack a unified framework and common\nterminology for describing their approaches. This research aims to bridge this\ngap by introducing a comprehensive and overarching framework that encompasses\nand reconciles these existing methodologies. Notably, this new framework is\ncapable of encompassing established CL approaches as special instances within a\nunified and general optimization objective. An intriguing finding is that\ndespite their diverse origins, these methods share common mathematical\nstructures. This observation highlights the compatibility of these seemingly\ndistinct techniques, revealing their interconnectedness through a shared\nunderlying optimization objective. Moreover, the proposed general framework\nintroduces an innovative concept called refresh learning, specifically designed\nto enhance the CL performance. This novel approach draws inspiration from\nneuroscience, where the human brain often sheds outdated information to improve\nthe retention of crucial knowledge and facilitate the acquisition of new\ninformation. In essence, refresh learning operates by initially unlearning\ncurrent data and subsequently relearning it. It serves as a versatile plug-in\nthat seamlessly integrates with existing CL methods, offering an adaptable and\neffective enhancement to the learning process. Extensive experiments on CL\nbenchmarks and theoretical analysis demonstrate the effectiveness of the\nproposed refresh learning. Code is available at\n\\url{https://github.com/joey-wang123/CL-refresh-learning}.\n","authors":["Zhenyi Wang","Yan Li","Li Shen","Heng Huang"],"pdf_url":"https://arxiv.org/pdf/2403.13249v1.pdf","comment":"ICLR 2024"},{"id":"http://arxiv.org/abs/2210.17159v2","updated":"2024-03-20T02:21:23Z","published":"2022-10-31T09:10:06Z","title":"PAGE: Prototype-Based Model-Level Explanations for Graph Neural Networks","summary":"  Aside from graph neural networks (GNNs) attracting significant attention as a\npowerful framework revolutionizing graph representation learning, there has\nbeen an increasing demand for explaining GNN models. Although various\nexplanation methods for GNNs have been developed, most studies have focused on\ninstance-level explanations, which produce explanations tailored to a given\ngraph instance. In our study, we propose Prototype-bAsed GNN-Explainer (PAGE),\na novel model-level GNN explanation method that explains what the underlying\nGNN model has learned for graph classification by discovering\nhuman-interpretable prototype graphs. Our method produces explanations for a\ngiven class, thus being capable of offering more concise and comprehensive\nexplanations than those of instance-level explanations. First, PAGE selects\nembeddings of class-discriminative input graphs on the graph-level embedding\nspace after clustering them. Then, PAGE discovers a common subgraph pattern by\niteratively searching for high matching node tuples using node-level embeddings\nvia a prototype scoring function, thereby yielding a prototype graph as our\nexplanation. Using six graph classification datasets, we demonstrate that PAGE\nqualitatively and quantitatively outperforms the state-of-the-art model-level\nexplanation method. We also carry out systematic experimental studies by\ndemonstrating the relationship between PAGE and instance-level explanation\nmethods, the robustness of PAGE to input data scarce environments, and the\ncomputational efficiency of the proposed prototype scoring function in PAGE.\n","authors":["Yong-Min Shin","Sun-Woo Kim","Won-Yong Shin"],"pdf_url":"https://arxiv.org/pdf/2210.17159v2.pdf","comment":"18 pages, 12 figures, 5 tables; to appear in the IEEE Transactions on\n  Pattern Analysis and Machine Intelligence (Please cite our journal version\n  that will appear in an upcoming issue. Its two-page extended summary was\n  presented in the AAAI-22 Student Abstract and Poster Program.)"},{"id":"http://arxiv.org/abs/2311.14648v3","updated":"2024-03-20T02:21:20Z","published":"2023-11-24T18:29:50Z","title":"Calibrated Language Models Must Hallucinate","summary":"  Recent language models generate false but plausible-sounding text with\nsurprising frequency. Such \"hallucinations\" are an obstacle to the usability of\nlanguage-based AI systems and can harm people who rely upon their outputs. This\nwork shows that there is an inherent statistical lower-bound on the rate that\npretrained language models hallucinate certain types of facts, having nothing\nto do with the transformer LM architecture or data quality. For \"arbitrary\"\nfacts whose veracity cannot be determined from the training data, we show that\nhallucinations must occur at a certain rate for language models that satisfy a\nstatistical calibration condition appropriate for generative language models.\nSpecifically, if the maximum probability of any fact is bounded, we show that\nthe probability of generating a hallucination is close to the fraction of facts\nthat occur exactly once in the training data (a \"Good-Turing\" estimate), even\nassuming ideal training data without errors.\n  One conclusion is that models pretrained to be sufficiently good predictors\n(i.e., calibrated) may require post-training to mitigate hallucinations on the\ntype of arbitrary facts that tend to appear once in the training set. However,\nour analysis also suggests that there is no statistical reason that pretraining\nwill lead to hallucination on facts that tend to appear more than once in the\ntraining data (like references to publications such as articles and books,\nwhose hallucinations have been particularly notable and problematic) or on\nsystematic facts (like arithmetic calculations). Therefore, different\narchitectures and learning algorithms may mitigate these latter types of\nhallucinations.\n","authors":["Adam Tauman Kalai","Santosh S. Vempala"],"pdf_url":"https://arxiv.org/pdf/2311.14648v3.pdf","comment":"In Proceedings of the 56th Annual ACM Symposium on Theory of\n  Computing (STOC) 2024"},{"id":"http://arxiv.org/abs/2403.13245v1","updated":"2024-03-20T02:16:54Z","published":"2024-03-20T02:16:54Z","title":"Federated reinforcement learning for robot motion planning with\n  zero-shot generalization","summary":"  This paper considers the problem of learning a control policy for robot\nmotion planning with zero-shot generalization, i.e., no data collection and\npolicy adaptation is needed when the learned policy is deployed in new\nenvironments. We develop a federated reinforcement learning framework that\nenables collaborative learning of multiple learners and a central server, i.e.,\nthe Cloud, without sharing their raw data. In each iteration, each learner\nuploads its local control policy and the corresponding estimated normalized\narrival time to the Cloud, which then computes the global optimum among the\nlearners and broadcasts the optimal policy to the learners. Each learner then\nselects between its local control policy and that from the Cloud for next\niteration. The proposed framework leverages on the derived zero-shot\ngeneralization guarantees on arrival time and safety. Theoretical guarantees on\nalmost-sure convergence, almost consensus, Pareto improvement and optimality\ngap are also provided. Monte Carlo simulation is conducted to evaluate the\nproposed framework.\n","authors":["Zhenyuan Yuan","Siyuan Xu","Minghui Zhu"],"pdf_url":"https://arxiv.org/pdf/2403.13245v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13244v1","updated":"2024-03-20T02:15:55Z","published":"2024-03-20T02:15:55Z","title":"Instruction Multi-Constraint Molecular Generation Using a\n  Teacher-Student Large Language Model","summary":"  While various models and computational tools have been proposed for structure\nand property analysis of molecules, generating molecules that conform to all\ndesired structures and properties remains a challenge. Here, we introduce a\nmulti-constraint molecular generation large language model, TSMMG, which, akin\nto a student, incorporates knowledge from various small models and tools,\nnamely, the 'teachers'. To train TSMMG, we construct a large set of\ntext-molecule pairs by extracting molecular knowledge from these 'teachers',\nenabling it to generate novel molecules that conform to the descriptions\nthrough various text prompts. We experimentally show that TSMMG remarkably\nperforms in generating molecules meeting complex, natural language-described\nproperty requirements across two-, three-, and four-constraint tasks, with an\naverage molecular validity of over 99% and success ratio of 88.08%, 65.27%, and\n61.44%, respectively. The model also exhibits adaptability through zero-shot\ntesting, creating molecules that satisfy combinations of properties that have\nnot been encountered. It can comprehend text inputs with various language\nstyles, extending beyond the confines of outlined prompts, as confirmed through\nempirical validation. Additionally, the knowledge distillation feature of TSMMG\ncontributes to the continuous enhancement of small models, while the innovative\napproach to dataset construction effectively addresses the issues of data\nscarcity and quality, which positions TSMMG as a promising tool in the domains\nof drug discovery and materials science. Code is available at\nhttps://github.com/HHW-zhou/TSMMG.\n","authors":["Peng Zhou","Jianmin Wang","Chunyan Li","Zixu Wang","Yiping Liu","Siqi Sun","Jianxin Lin","Longyue Wang","Xiangxiang Zeng"],"pdf_url":"https://arxiv.org/pdf/2403.13244v1.pdf","comment":"25 pages, 4 figures"},{"id":"http://arxiv.org/abs/2403.13236v1","updated":"2024-03-20T01:57:38Z","published":"2024-03-20T01:57:38Z","title":"Safety-Aware Reinforcement Learning for Electric Vehicle Charging\n  Station Management in Distribution Network","summary":"  The increasing integration of electric vehicles (EVs) into the grid can pose\na significant risk to the distribution system operation in the absence of\ncoordination. In response to the need for effective coordination of EVs within\nthe distribution network, this paper presents a safety-aware reinforcement\nlearning (RL) algorithm designed to manage EV charging stations while ensuring\nthe satisfaction of system constraints. Unlike existing methods, our proposed\nalgorithm does not rely on explicit penalties for constraint violations,\neliminating the need for penalty coefficient tuning. Furthermore, managing EV\ncharging stations is further complicated by multiple uncertainties, notably the\nvariability in solar energy generation and energy prices. To address this\nchallenge, we develop an off-policy RL algorithm to efficiently utilize data to\nlearn patterns in such uncertain environments. Our algorithm also incorporates\na maximum entropy framework to enhance the RL algorithm's exploratory process,\npreventing convergence to local optimal solutions. Simulation results\ndemonstrate that our algorithm outperforms traditional RL algorithms in\nmanaging EV charging in the distribution network.\n","authors":["Jiarong Fan","Ariel Liebman","Hao Wang"],"pdf_url":"https://arxiv.org/pdf/2403.13236v1.pdf","comment":"2024 IEEE Power & Energy Society General Meeting (PESGM)"},{"id":"http://arxiv.org/abs/2210.04688v5","updated":"2024-03-20T01:20:29Z","published":"2022-10-07T07:56:17Z","title":"BAFFLE: Hiding Backdoors in Offline Reinforcement Learning Datasets","summary":"  Reinforcement learning (RL) makes an agent learn from trial-and-error\nexperiences gathered during the interaction with the environment. Recently,\noffline RL has become a popular RL paradigm because it saves the interactions\nwith environments. In offline RL, data providers share large pre-collected\ndatasets, and others can train high-quality agents without interacting with the\nenvironments. This paradigm has demonstrated effectiveness in critical tasks\nlike robot control, autonomous driving, etc. However, less attention is paid to\ninvestigating the security threats to the offline RL system. This paper focuses\non backdoor attacks, where some perturbations are added to the data\n(observations) such that given normal observations, the agent takes\nhigh-rewards actions, and low-reward actions on observations injected with\ntriggers. In this paper, we propose Baffle (Backdoor Attack for Offline\nReinforcement Learning), an approach that automatically implants backdoors to\nRL agents by poisoning the offline RL dataset, and evaluate how different\noffline RL algorithms react to this attack. Our experiments conducted on four\ntasks and four offline RL algorithms expose a disquieting fact: none of the\nexisting offline RL algorithms is immune to such a backdoor attack. More\nspecifically, Baffle modifies 10\\% of the datasets for four tasks (3 robotic\ncontrols and 1 autonomous driving). Agents trained on the poisoned datasets\nperform well in normal settings. However, when triggers are presented, the\nagents' performance decreases drastically by 63.2\\%, 53.9\\%, 64.7\\%, and 47.4\\%\nin the four tasks on average. The backdoor still persists after fine-tuning\npoisoned agents on clean datasets. We further show that the inserted backdoor\nis also hard to be detected by a popular defensive method. This paper calls\nattention to developing more effective protection for the open-source offline\nRL dataset.\n","authors":["Chen Gong","Zhou Yang","Yunpeng Bai","Junda He","Jieke Shi","Kecen Li","Arunesh Sinha","Bowen Xu","Xinwen Hou","David Lo","Tianhao Wang"],"pdf_url":"https://arxiv.org/pdf/2210.04688v5.pdf","comment":"Accepted at IEEE S&P (Oakland) 2024"},{"id":"http://arxiv.org/abs/2308.00221v3","updated":"2024-03-20T01:04:11Z","published":"2023-08-01T01:27:40Z","title":"Advancing Beyond Identification: Multi-bit Watermark for Large Language\n  Models","summary":"  We show the viability of tackling misuses of large language models beyond the\nidentification of machine-generated text. While existing zero-bit watermark\nmethods focus on detection only, some malicious misuses demand tracing the\nadversary user for counteracting them. To address this, we propose Multi-bit\nWatermark via Position Allocation, embedding traceable multi-bit information\nduring language model generation. Through allocating tokens onto different\nparts of the messages, we embed longer messages in high corruption settings\nwithout added latency. By independently embedding sub-units of messages, the\nproposed method outperforms the existing works in terms of robustness and\nlatency. Leveraging the benefits of zero-bit watermarking, our method enables\nrobust extraction of the watermark without any model access, embedding and\nextraction of long messages ($\\geq$ 32-bit) without finetuning, and maintaining\ntext quality, while allowing zero-bit detection all at the same time. Code is\nreleased here: https://github.com/bangawayoo/mb-lm-watermarking\n","authors":["KiYoon Yoo","Wonhyuk Ahn","Nojun Kwak"],"pdf_url":"https://arxiv.org/pdf/2308.00221v3.pdf","comment":"NAACL 2024 main. 9 pages and appendix"},{"id":"http://arxiv.org/abs/2403.13218v1","updated":"2024-03-20T00:37:19Z","published":"2024-03-20T00:37:19Z","title":"Self-Attention Based Semantic Decomposition in Vector Symbolic\n  Architectures","summary":"  Vector Symbolic Architectures (VSAs) have emerged as a novel framework for\nenabling interpretable machine learning algorithms equipped with the ability to\nreason and explain their decision processes. The basic idea is to represent\ndiscrete information through high dimensional random vectors. Complex data\nstructures can be built up with operations over vectors such as the \"binding\"\noperation involving element-wise vector multiplication, which associates data\ntogether. The reverse task of decomposing the associated elements is a\ncombinatorially hard task, with an exponentially large search space. The main\nalgorithm for performing this search is the resonator network, inspired by\nHopfield network-based memory search operations.\n  In this work, we introduce a new variant of the resonator network, based on\nself-attention based update rules in the iterative search problem. This update\nrule, based on the Hopfield network with log-sum-exp energy function and\nnorm-bounded states, is shown to substantially improve the performance and rate\nof convergence. As a result, our algorithm enables a larger capacity for\nassociative memory, enabling applications in many tasks like perception based\npattern recognition, scene decomposition, and object reasoning. We substantiate\nour algorithm with a thorough evaluation and comparisons to baselines.\n","authors":["Calvin Yeung","Prathyush Poduval","Mohsen Imani"],"pdf_url":"https://arxiv.org/pdf/2403.13218v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13214v1","updated":"2024-03-20T00:23:42Z","published":"2024-03-20T00:23:42Z","title":"Nellie: Automated organelle segmentation, tracking, and hierarchical\n  feature extraction in 2D/3D live-cell microscopy","summary":"  The analysis of dynamic organelles remains a formidable challenge, though key\nto understanding biological processes. We introduce Nellie, an automated and\nunbiased pipeline for segmentation, tracking, and feature extraction of diverse\nintracellular structures. Nellie adapts to image metadata, eliminating user\ninput. Nellie's preprocessing pipeline enhances structural contrast on multiple\nintracellular scales allowing for robust hierarchical segmentation of\nsub-organellar regions. Internal motion capture markers are generated and\ntracked via a radius-adaptive pattern matching scheme, and used as guides for\nsub-voxel flow interpolation. Nellie extracts a plethora of features at\nmultiple hierarchical levels for deep and customizable analysis. Nellie\nfeatures a Napari-based GUI that allows for code-free operation and\nvisualization, while its modular open-source codebase invites customization by\nexperienced users. We demonstrate Nellie's wide variety of use cases with two\nexamples: unmixing multiple organelles from a single channel using\nfeature-based classification and training an unsupervised graph autoencoder on\nmitochondrial multi-mesh graphs to quantify latent space embedding changes\nfollowing ionomycin treatment.\n","authors":["Austin E. Y. T. Lefebvre","Gabriel Sturm","Ting-Yu Lin","Emily Stoops","Magdalena Preciado Lopez","Benjamin Kaufmann-Malaga","Kayley Hake"],"pdf_url":"https://arxiv.org/pdf/2403.13214v1.pdf","comment":"for associated code, see https://github.com/aelefebv/nellie; 82\n  pages, 5 main figures, 11 extended figures"},{"id":"http://arxiv.org/abs/2312.14115v2","updated":"2024-03-20T00:23:39Z","published":"2023-12-21T18:40:34Z","title":"LingoQA: Video Question Answering for Autonomous Driving","summary":"  Autonomous driving has long faced a challenge with public acceptance due to\nthe lack of explainability in the decision-making process. Video\nquestion-answering (QA) in natural language provides the opportunity for\nbridging this gap. Nonetheless, evaluating the performance of Video QA models\nhas proved particularly tough due to the absence of comprehensive benchmarks.\nTo fill this gap, we introduce LingoQA, a benchmark specifically for autonomous\ndriving Video QA. The LingoQA trainable metric demonstrates a 0.95 Spearman\ncorrelation coefficient with human evaluations. We introduce a Video QA dataset\nof central London consisting of 419k samples that we release with the paper. We\nestablish a baseline vision-language model and run extensive ablation studies\nto understand its performance.\n","authors":["Ana-Maria Marcu","Long Chen","Jan Hünermann","Alice Karnsund","Benoit Hanotte","Prajwal Chidananda","Saurabh Nair","Vijay Badrinarayanan","Alex Kendall","Jamie Shotton","Elahe Arani","Oleg Sinavski"],"pdf_url":"https://arxiv.org/pdf/2312.14115v2.pdf","comment":"Benchmark and dataset are available at\n  https://github.com/wayveai/LingoQA/"},{"id":"http://arxiv.org/abs/2403.08153v2","updated":"2024-03-20T00:18:40Z","published":"2024-03-13T00:30:47Z","title":"The Runtime of Random Local Search on the Generalized Needle Problem","summary":"  In their recent work, C. Doerr and Krejca (Transactions on Evolutionary\nComputation, 2023) proved upper bounds on the expected runtime of the\nrandomized local search heuristic on generalized Needle functions. Based on\nthese upper bounds, they deduce in a not fully rigorous manner a drastic\ninfluence of the needle radius $k$ on the runtime.\n  In this short article, we add the missing lower bound necessary to determine\nthe influence of parameter $k$ on the runtime. To this aim, we derive an exact\ndescription of the expected runtime, which also significantly improves the\nupper bound given by C. Doerr and Krejca. We also describe asymptotic estimates\nof the expected runtime.\n","authors":["Benjamin Doerr","Andrew James Kelley"],"pdf_url":"https://arxiv.org/pdf/2403.08153v2.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2403.14037v1","updated":"2024-03-20T23:21:35Z","published":"2024-03-20T23:21:35Z","title":"Ax-to-Grind Urdu: Benchmark Dataset for Urdu Fake News Detection","summary":"  Misinformation can seriously impact society, affecting anything from public\nopinion to institutional confidence and the political horizon of a state. Fake\nNews (FN) proliferation on online websites and Online Social Networks (OSNs)\nhas increased profusely. Various fact-checking websites include news in English\nand barely provide information about FN in regional languages. Thus the Urdu FN\npurveyors cannot be discerned using factchecking portals. SOTA approaches for\nFake News Detection (FND) count upon appropriately labelled and large datasets.\nFND in regional and resource-constrained languages lags due to the lack of\nlimited-sized datasets and legitimate lexical resources. The previous datasets\nfor Urdu FND are limited-sized, domain-restricted, publicly unavailable and not\nmanually verified where the news is translated from English into Urdu. In this\npaper, we curate and contribute the first largest publicly available dataset\nfor Urdu FND, Ax-to-Grind Urdu, to bridge the identified gaps and limitations\nof existing Urdu datasets in the literature. It constitutes 10,083 fake and\nreal news on fifteen domains collected from leading and authentic Urdu\nnewspapers and news channel websites in Pakistan and India. FN for the\nAx-to-Grind dataset is collected from websites and crowdsourcing. The dataset\ncontains news items in Urdu from the year 2017 to the year 2023. Expert\njournalists annotated the dataset. We benchmark the dataset with an ensemble\nmodel of mBERT,XLNet, and XLM RoBERTa. The selected models are originally\ntrained on multilingual large corpora. The results of the proposed model are\nbased on performance metrics, F1-score, accuracy, precision, recall and MCC\nvalue.\n","authors":["Sheetal Harris","Jinshuo Liu","Hassan Jalil Hadi","Yue Cao"],"pdf_url":"https://arxiv.org/pdf/2403.14037v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14019v1","updated":"2024-03-20T22:40:53Z","published":"2024-03-20T22:40:53Z","title":"Searching Search Spaces: Meta-evolving a Geometric Encoding for Neural\n  Networks","summary":"  In evolutionary policy search, neural networks are usually represented using\na direct mapping: each gene encodes one network weight. Indirect encoding\nmethods, where each gene can encode for multiple weights, shorten the genome to\nreduce the dimensions of the search space and better exploit permutations and\nsymmetries. The Geometric Encoding for Neural network Evolution (GENE)\nintroduced an indirect encoding where the weight of a connection is computed as\nthe (pseudo-)distance between the two linked neurons, leading to a genome size\ngrowing linearly with the number of genes instead of quadratically in direct\nencoding. However GENE still relies on hand-crafted distance functions with no\nprior optimization. Here we show that better performing distance functions can\nbe found for GENE using Cartesian Genetic Programming (CGP) in a meta-evolution\napproach, hence optimizing the encoding to create a search space that is easier\nto exploit. We show that GENE with a learned function can outperform both\ndirect encoding and the hand-crafted distances, generalizing on unseen\nproblems, and we study how the encoding impacts neural network properties.\n","authors":["Tarek Kunze","Paul Templier","Dennis G Wilson"],"pdf_url":"https://arxiv.org/pdf/2403.14019v1.pdf","comment":"9 pages, 8 figures"},{"id":"http://arxiv.org/abs/2403.14006v1","updated":"2024-03-20T22:11:01Z","published":"2024-03-20T22:11:01Z","title":"On Prompt Sensitivity of ChatGPT in Affective Computing","summary":"  Recent studies have demonstrated the emerging capabilities of foundation\nmodels like ChatGPT in several fields, including affective computing. However,\naccessing these emerging capabilities is facilitated through prompt\nengineering. Despite the existence of some prompting techniques, the field is\nstill rapidly evolving and many prompting ideas still require investigation. In\nthis work, we introduce a method to evaluate and investigate the sensitivity of\nthe performance of foundation models based on different prompts or generation\nparameters. We perform our evaluation on ChatGPT within the scope of affective\ncomputing on three major problems, namely sentiment analysis, toxicity\ndetection, and sarcasm detection. First, we carry out a sensitivity analysis on\npivotal parameters in auto-regressive text generation, specifically the\ntemperature parameter $T$ and the top-$p$ parameter in Nucleus sampling,\ndictating how conservative or creative the model should be during generation.\nFurthermore, we explore the efficacy of several prompting ideas, where we\nexplore how giving different incentives or structures affect the performance.\nOur evaluation takes into consideration performance measures on the affective\ncomputing tasks, and the effectiveness of the model to follow the stated\ninstructions, hence generating easy-to-parse responses to be smoothly used in\ndownstream applications.\n","authors":["Mostafa M. Amin","Björn W. Schuller"],"pdf_url":"https://arxiv.org/pdf/2403.14006v1.pdf","comment":"2 Tables, 1 Figure, preprint submission to ACII 2024"},{"id":"http://arxiv.org/abs/2310.04451v2","updated":"2024-03-20T21:34:56Z","published":"2023-10-03T19:44:37Z","title":"AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language\n  Models","summary":"  The aligned Large Language Models (LLMs) are powerful language understanding\nand decision-making tools that are created through extensive alignment with\nhuman feedback. However, these large models remain susceptible to jailbreak\nattacks, where adversaries manipulate prompts to elicit malicious outputs that\nshould not be given by aligned LLMs. Investigating jailbreak prompts can lead\nus to delve into the limitations of LLMs and further guide us to secure them.\nUnfortunately, existing jailbreak techniques suffer from either (1) scalability\nissues, where attacks heavily rely on manual crafting of prompts, or (2)\nstealthiness problems, as attacks depend on token-based algorithms to generate\nprompts that are often semantically meaningless, making them susceptible to\ndetection through basic perplexity testing. In light of these challenges, we\nintend to answer this question: Can we develop an approach that can\nautomatically generate stealthy jailbreak prompts? In this paper, we introduce\nAutoDAN, a novel jailbreak attack against aligned LLMs. AutoDAN can\nautomatically generate stealthy jailbreak prompts by the carefully designed\nhierarchical genetic algorithm. Extensive evaluations demonstrate that AutoDAN\nnot only automates the process while preserving semantic meaningfulness, but\nalso demonstrates superior attack strength in cross-model transferability, and\ncross-sample universality compared with the baseline. Moreover, we also compare\nAutoDAN with perplexity-based defense methods and show that AutoDAN can bypass\nthem effectively.\n","authors":["Xiaogeng Liu","Nan Xu","Muhao Chen","Chaowei Xiao"],"pdf_url":"https://arxiv.org/pdf/2310.04451v2.pdf","comment":"Published as a conference paper at ICLR 2024. Code is available at\n  https://github.com/SheltonLiu-N/AutoDAN"},{"id":"http://arxiv.org/abs/2403.13969v1","updated":"2024-03-20T20:46:41Z","published":"2024-03-20T20:46:41Z","title":"\"This is not a data problem\": Algorithms and Power in Public Higher\n  Education in Canada","summary":"  Algorithmic decision-making is increasingly being adopted across public\nhigher education. The expansion of data-driven practices by post-secondary\ninstitutions has occurred in parallel with the adoption of New Public\nManagement approaches by neoliberal administrations. In this study, we conduct\na qualitative analysis of an in-depth ethnographic case study of data and\nalgorithms in use at a public college in Ontario, Canada. We identify the data,\nalgorithms, and outcomes in use at the college. We assess how the college's\nprocesses and relationships support those outcomes and the different\nstakeholders' perceptions of the college's data-driven systems. In addition, we\nfind that the growing reliance on algorithmic decisions leads to increased\nstudent surveillance, exacerbation of existing inequities, and the automation\nof the faculty-student relationship. Finally, we identify a cycle of increased\ninstitutional power perpetuated by algorithmic decision-making, and driven by a\npush towards financial sustainability.\n","authors":["Kelly McConvey","Shion Guha"],"pdf_url":"https://arxiv.org/pdf/2403.13969v1.pdf","comment":"In CHI '24 Proceedings of the CHI Conference on Human Factors in\n  Computing Systems Honolulu, HI, USA"},{"id":"http://arxiv.org/abs/2403.05020v2","updated":"2024-03-20T20:44:17Z","published":"2024-03-08T03:49:17Z","title":"Is this the real life? Is this just fantasy? The Misleading Success of\n  Simulating Social Interactions With LLMs","summary":"  Recent advances in large language models (LLM) have enabled richer social\nsimulations, allowing for the study of various social phenomena with LLM-based\nagents. However, most work has used an omniscient perspective on these\nsimulations (e.g., single LLM to generate all interlocutors), which is\nfundamentally at odds with the non-omniscient, information asymmetric\ninteractions that humans have. To examine these differences, we develop an\nevaluation framework to simulate social interactions with LLMs in various\nsettings (omniscient, non-omniscient). Our experiments show that interlocutors\nsimulated omnisciently are much more successful at accomplishing social goals\ncompared to non-omniscient agents, despite the latter being the more realistic\nsetting. Furthermore, we demonstrate that learning from omniscient simulations\nimproves the apparent naturalness of interactions but scarcely enhances goal\nachievement in cooperative scenarios. Our findings indicate that addressing\ninformation asymmetry remains a fundamental challenge for LLM-based agents.\n","authors":["Xuhui Zhou","Zhe Su","Tiwalayo Eisape","Hyunwoo Kim","Maarten Sap"],"pdf_url":"https://arxiv.org/pdf/2403.05020v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.05342v4","updated":"2024-03-20T20:37:17Z","published":"2023-08-10T05:10:17Z","title":"Metacognitive Prompting Improves Understanding in Large Language Models","summary":"  In Large Language Models (LLMs), there have been consistent advancements in\ntask-specific performance, largely influenced by effective prompt design.\nRecent advancements in prompting have enhanced reasoning in logic-intensive\ntasks for LLMs, yet the nuanced understanding abilities of these models,\ncrucial for processing and interpreting complex information, remain\nunderexplored. In this study, we introduce Metacognitive Prompting (MP), a\nstrategy inspired by human introspective reasoning processes. Using MP, LLMs\nundergo a systematic series of structured, self-aware evaluations, drawing on\nboth their vast inherent knowledge and new insights. We conduct extensive\nexperiments on four prevalent LLMs: Llama2, PaLM2, GPT-3.5, and GPT-4, across\nten natural language understanding (NLU) datasets from GLUE, SuperGLUE, BLUE,\nand LexGLUE benchmarks. Additionally, we compare our method with\nchain-of-thought prompting and its advanced versions. The results show that\nGPT-4 consistently excels across all tasks, while other models have shown\nsignificant progress in some tasks when used in conjunction with MP.\nFurthermore, MP consistently outperforms existing prompting methods in both\ngeneral and domain-specific NLU tasks. This study underscores the potential to\namplify the understanding abilities of LLMs and highlights the benefits of\nmirroring human introspective reasoning in NLU tasks.\n","authors":["Yuqing Wang","Yun Zhao"],"pdf_url":"https://arxiv.org/pdf/2308.05342v4.pdf","comment":"NAACL 2024"},{"id":"http://arxiv.org/abs/2403.13960v1","updated":"2024-03-20T20:13:39Z","published":"2024-03-20T20:13:39Z","title":"Open Access NAO (OAN): a ROS2-based software framework for HRI\n  applications with the NAO robot","summary":"  This paper presents a new software framework for HRI experimentation with the\nsixth version of the common NAO robot produced by the United Robotics Group.\nEmbracing the common demand of researchers for better performance and new\nfeatures for NAO, the authors took advantage of the ability to run ROS2 onboard\non the NAO to develop a framework independent of the APIs provided by the\nmanufacturer. Such a system provides NAO with not only the basic skills of a\nhumanoid robot such as walking and reproducing movements of interest but also\nfeatures often used in HRI such as: speech recognition/synthesis, face and\nobject detention, and the use of Generative Pre-trained Transformer (GPT)\nmodels for conversation. The developed code is therefore configured as a\nready-to-use but also highly expandable and improvable tool thanks to the\npossibilities provided by the ROS community.\n","authors":["Antonio Bono","Kenji Brameld","Luigi D'Alfonso","Giuseppe Fedele"],"pdf_url":"https://arxiv.org/pdf/2403.13960v1.pdf","comment":"7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2403.02302v2","updated":"2024-03-20T20:05:45Z","published":"2024-03-04T18:32:12Z","title":"Beyond Specialization: Assessing the Capabilities of MLLMs in Age and\n  Gender Estimation","summary":"  Multimodal Large Language Models (MLLMs) have recently gained immense\npopularity. Powerful commercial models like ChatGPT-4V and Gemini, as well as\nopen-source ones such as LLaVA, are essentially general-purpose models and are\napplied to solve a wide variety of tasks, including those in computer vision.\nThese neural networks possess such strong general knowledge and reasoning\nabilities that they have proven capable of working even on tasks for which they\nwere not specifically trained. We compared the capabilities of the most\npowerful MLLMs to date: ShareGPT4V, ChatGPT, LLaVA-Next in a specialized task\nof age and gender estimation with our state-of-the-art specialized model,\nMiVOLO. We also updated MiVOLO and provide details and new metrics in this\narticle. This comparison has yielded some interesting results and insights\nabout the strengths and weaknesses of the participating models. Furthermore, we\nattempted various ways to fine-tune the ShareGPT4V model for this specific\ntask, aiming to achieve state-of-the-art results in this particular challenge.\nAlthough such a model would not be practical in production, as it is incredibly\nexpensive compared to a specialized model like MiVOLO, it could be very useful\nin some tasks, like data annotation.\n","authors":["Maksim Kuprashevich","Grigorii Alekseenko","Irina Tolstykh"],"pdf_url":"https://arxiv.org/pdf/2403.02302v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.02352v2","updated":"2024-03-20T19:57:24Z","published":"2023-12-04T21:32:00Z","title":"Working Backwards: Learning to Place by Picking","summary":"  We present placing via picking (PvP), a method to autonomously collect\nreal-world demonstrations for a family of placing tasks in which objects must\nbe manipulated to specific contact-constrained locations. With PvP, we approach\nthe collection of robotic object placement demonstrations by reversing the\ngrasping process and exploiting the inherent symmetry of the pick and place\nproblems. Specifically, we obtain placing demonstrations from a set of grasp\nsequences of objects initially located at their target placement locations. Our\nsystem can collect hundreds of demonstrations in contact-constrained\nenvironments without human intervention by combining two modules: tactile\nregrasping and compliant control for grasps. We train a policy directly from\nvisual observations through behavioral cloning, using the\nautonomously-collected demonstrations. By doing so, the policy can generalize\nto object placement scenarios outside of the training environment without\nprivileged information (e.g., placing a plate picked up from a table). We\nvalidate our approach in home robotic scenarios that include dishwasher loading\nand table setting. Our approach yields robotic placing policies that outperform\npolicies trained with kinesthetic teaching, both in terms of performance and\ndata efficiency, while requiring no human supervision.\n","authors":["Oliver Limoyo","Abhisek Konar","Trevor Ablett","Jonathan Kelly","Francois R. Hogan","Gregory Dudek"],"pdf_url":"https://arxiv.org/pdf/2312.02352v2.pdf","comment":"Submitted to the IEEE/RSJ International Conference on Intelligent\n  Robotics and Systems (IROS'24), Abu Dhabi, UAE, Oct 14-18, 2024"},{"id":"http://arxiv.org/abs/2403.13951v1","updated":"2024-03-20T19:45:06Z","published":"2024-03-20T19:45:06Z","title":"ACDG-VTON: Accurate and Contained Diffusion Generation for Virtual\n  Try-On","summary":"  Virtual Try-on (VTON) involves generating images of a person wearing selected\ngarments. Diffusion-based methods, in particular, can create high-quality\nimages, but they struggle to maintain the identities of the input garments. We\nidentified this problem stems from the specifics in the training formulation\nfor diffusion. To address this, we propose a unique training scheme that limits\nthe scope in which diffusion is trained. We use a control image that perfectly\naligns with the target image during training. In turn, this accurately\npreserves garment details during inference. We demonstrate our method not only\neffectively conserves garment details but also allows for layering, styling,\nand shoe try-on. Our method runs multi-garment try-on in a single inference\ncycle and can support high-quality zoomed-in generations without training in\nhigher resolutions. Finally, we show our method surpasses prior methods in\naccuracy and quality.\n","authors":["Jeffrey Zhang","Kedan Li","Shao-Yu Chang","David Forsyth"],"pdf_url":"https://arxiv.org/pdf/2403.13951v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.11061v2","updated":"2024-03-20T19:44:07Z","published":"2024-01-19T23:34:48Z","title":"PhotoBot: Reference-Guided Interactive Photography via Natural Language","summary":"  We introduce PhotoBot, a framework for fully automated photo acquisition\nbased on an interplay between high-level human language guidance and a robot\nphotographer. We propose to communicate photography suggestions to the user via\nreference images that are selected from a curated gallery. We leverage a visual\nlanguage model (VLM) and an object detector to characterize the reference\nimages via textual descriptions and then use a large language model (LLM) to\nretrieve relevant reference images based on a user's language query through\ntext-based reasoning. To correspond the reference image and the observed scene,\nwe exploit pre-trained features from a vision transformer capable of capturing\nsemantic similarity across marked appearance variations. Using these features,\nwe compute pose adjustments for an RGB-D camera by solving a\nperspective-n-point (PnP) problem. We demonstrate our approach using a\nmanipulator equipped with a wrist camera. Our user studies show that photos\ntaken by PhotoBot are often more aesthetically pleasing than those taken by\nusers themselves, as measured by human feedback. We also show that PhotoBot can\ngeneralize to other reference sources such as paintings.\n","authors":["Oliver Limoyo","Jimmy Li","Dmitriy Rivkin","Jonathan Kelly","Gregory Dudek"],"pdf_url":"https://arxiv.org/pdf/2401.11061v2.pdf","comment":"Submitted to the IEEE/RSJ International Conference on Intelligent\n  Robotics and Systems (IROS'24), Abu Dhabi, UAE, Oct 14-18, 2024"},{"id":"http://arxiv.org/abs/2403.13950v1","updated":"2024-03-20T19:42:11Z","published":"2024-03-20T19:42:11Z","title":"Evo* 2023 -- Late-Breaking Abstracts Volume","summary":"  Volume with the Late-Breaking Abstracts submitted to the Evo* 2023\nConference, held in Brno (Czech Republic), from 12 to 14 of April. These papers\npresent ongoing research and preliminary results investigating on the\napplication of different approaches of Bioinspired Methods (mainly Evolutionary\nComputation) to different problems, most of them real world ones.\n","authors":["A. M. Mora","A. I. Esparcia-Alcázar"],"pdf_url":"https://arxiv.org/pdf/2403.13950v1.pdf","comment":"LBAs accepted in Evo* 2023. Part of the Conference Proceedings"},{"id":"http://arxiv.org/abs/2403.13947v1","updated":"2024-03-20T19:41:05Z","published":"2024-03-20T19:41:05Z","title":"BlendScape: Enabling Unified and Personalized Video-Conferencing\n  Environments through Generative AI","summary":"  Today's video-conferencing tools support a rich range of professional and\nsocial activities, but their generic, grid-based environments cannot be easily\nadapted to meet the varying needs of distributed collaborators. To enable\nend-user customization, we developed BlendScape, a system for meeting\nparticipants to compose video-conferencing environments tailored to their\ncollaboration context by leveraging AI image generation techniques. BlendScape\nsupports flexible representations of task spaces by blending users' physical or\nvirtual backgrounds into unified environments and implements multimodal\ninteraction techniques to steer the generation. Through an evaluation with 15\nend-users, we investigated their customization preferences for work and social\nscenarios. Participants could rapidly express their design intentions with\nBlendScape and envisioned using the system to structure collaboration in future\nmeetings, but experienced challenges with preventing distracting elements. We\nimplement scenarios to demonstrate BlendScape's expressiveness in supporting\ndistributed collaboration techniques from prior work and propose composition\ntechniques to improve the quality of environments.\n","authors":["Shwetha Rajaram","Nels Numan","Balasaravanan Thoravi Kumaravel","Nicolai Marquardt","Andrew D. Wilson"],"pdf_url":"https://arxiv.org/pdf/2403.13947v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13940v1","updated":"2024-03-20T19:25:11Z","published":"2024-03-20T19:25:11Z","title":"Multi-criteria approach for selecting an explanation from the set of\n  counterfactuals produced by an ensemble of explainers","summary":"  Counterfactuals are widely used to explain ML model predictions by providing\nalternative scenarios for obtaining the more desired predictions. They can be\ngenerated by a variety of methods that optimize different, sometimes\nconflicting, quality measures and produce quite different solutions. However,\nchoosing the most appropriate explanation method and one of the generated\ncounterfactuals is not an easy task. Instead of forcing the user to test many\ndifferent explanation methods and analysing conflicting solutions, in this\npaper, we propose to use a multi-stage ensemble approach that will select\nsingle counterfactual based on the multiple-criteria analysis. It offers a\ncompromise solution that scores well on several popular quality measures. This\napproach exploits the dominance relation and the ideal point decision aid\nmethod, which selects one counterfactual from the Pareto front. The conducted\nexperiments demonstrated that the proposed approach generates fully actionable\ncounterfactuals with attractive compromise values of the considered quality\nmeasures.\n","authors":["Ignacy Stępka","Mateusz Lango","Jerzy Stefanowski"],"pdf_url":"https://arxiv.org/pdf/2403.13940v1.pdf","comment":"17 pages, 2 figures"},{"id":"http://arxiv.org/abs/2403.12777v2","updated":"2024-03-20T19:18:27Z","published":"2024-03-19T14:44:54Z","title":"Discover and Mitigate Multiple Biased Subgroups in Image Classifiers","summary":"  Machine learning models can perform well on in-distribution data but often\nfail on biased subgroups that are underrepresented in the training data,\nhindering the robustness of models for reliable applications. Such subgroups\nare typically unknown due to the absence of subgroup labels. Discovering biased\nsubgroups is the key to understanding models' failure modes and further\nimproving models' robustness. Most previous works of subgroup discovery make an\nimplicit assumption that models only underperform on a single biased subgroup,\nwhich does not hold on in-the-wild data where multiple biased subgroups exist.\n  In this work, we propose Decomposition, Interpretation, and Mitigation (DIM),\na novel method to address a more challenging but also more practical problem of\ndiscovering multiple biased subgroups in image classifiers. Our approach\ndecomposes the image features into multiple components that represent multiple\nsubgroups. This decomposition is achieved via a bilinear dimension reduction\nmethod, Partial Least Square (PLS), guided by useful supervision from the image\nclassifier. We further interpret the semantic meaning of each subgroup\ncomponent by generating natural language descriptions using vision-language\nfoundation models. Finally, DIM mitigates multiple biased subgroups\nsimultaneously via two strategies, including the data- and model-centric\nstrategies. Extensive experiments on CIFAR-100 and Breeds datasets demonstrate\nthe effectiveness of DIM in discovering and mitigating multiple biased\nsubgroups. Furthermore, DIM uncovers the failure modes of the classifier on\nHard ImageNet, showcasing its broader applicability to understanding model bias\nin image classifiers. The code is available at\nhttps://github.com/ZhangAIPI/DIM.\n","authors":["Zeliang Zhang","Mingqian Feng","Zhiheng Li","Chenliang Xu"],"pdf_url":"https://arxiv.org/pdf/2403.12777v2.pdf","comment":"CVPR 2024. Code is available at https://github.com/ZhangAIPI/DIM"},{"id":"http://arxiv.org/abs/2401.11609v2","updated":"2024-03-20T19:12:28Z","published":"2024-01-21T22:11:29Z","title":"Graph Edits for Counterfactual Explanations: A comparative study","summary":"  Counterfactuals have been established as a popular explainability technique\nwhich leverages a set of minimal edits to alter the prediction of a classifier.\nWhen considering conceptual counterfactuals on images, the edits requested\nshould correspond to salient concepts present in the input data. At the same\ntime, conceptual distances are defined by knowledge graphs, ensuring the\noptimality of conceptual edits. In this work, we extend previous endeavors on\ngraph edits as counterfactual explanations by conducting a comparative study\nwhich encompasses both supervised and unsupervised Graph Neural Network (GNN)\napproaches. To this end, we pose the following significant research question:\nshould we represent input data as graphs, which is the optimal GNN approach in\nterms of performance and time efficiency to generate minimal and meaningful\ncounterfactual explanations for black-box image classifiers?\n","authors":["Angeliki Dimitriou","Nikolaos Chaidos","Maria Lymperaiou","Giorgos Stamou"],"pdf_url":"https://arxiv.org/pdf/2401.11609v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.00568v2","updated":"2024-03-20T19:09:57Z","published":"2022-09-01T16:19:22Z","title":"Multi-Scale Contrastive Knowledge Co-Distillation for Event Temporal\n  Relation Extraction","summary":"  Event Temporal Relation Extraction (ETRE) is a crucial yet challenging\nproblem. Event pairs are situated within a discourse at different distances,\nwhich we refer to as proximity bands. The temporal ordering communicated about\nevent pairs situated at more remote (i.e., ``long'') or less remote (i.e.,\n``short'') proximity bands is encoded differently. SOTA ETRE models have tended\nto perform well on events situated at either short or long proximity bands, but\nnot both. Yet, real-world, natural texts contain all types of temporal\nevent-pairs. In this paper, we present MulCo: Multi-Scale Contrastive Knowledge\nCo-Distillation, a fusion approach that shares knowledge across multiple event\npair proximity bands in order to improve performance on all types of temporal\ndatasets. Our experimental results show that MulCo successfully integrates\nlinguistic cues pertaining to temporal reasoning across both short and long\nproximity bands and achieves new state-of-the-art results on several ETRE\nbenchmark datasets.\n","authors":["Hao-Ren Yao","Luke Breitfeller","Aakanksha Naik","Chunxiao Zhou","Carolyn Rose"],"pdf_url":"https://arxiv.org/pdf/2209.00568v2.pdf","comment":"update"},{"id":"http://arxiv.org/abs/2312.02003v3","updated":"2024-03-20T19:00:24Z","published":"2023-12-04T16:25:18Z","title":"A Survey on Large Language Model (LLM) Security and Privacy: The Good,\n  the Bad, and the Ugly","summary":"  Large Language Models (LLMs), such as ChatGPT and Bard, have revolutionized\nnatural language understanding and generation. They possess deep language\ncomprehension, human-like text generation capabilities, contextual awareness,\nand robust problem-solving skills, making them invaluable in various domains\n(e.g., search engines, customer support, translation). In the meantime, LLMs\nhave also gained traction in the security community, revealing security\nvulnerabilities and showcasing their potential in security-related tasks. This\npaper explores the intersection of LLMs with security and privacy.\nSpecifically, we investigate how LLMs positively impact security and privacy,\npotential risks and threats associated with their use, and inherent\nvulnerabilities within LLMs. Through a comprehensive literature review, the\npaper categorizes the papers into \"The Good\" (beneficial LLM applications),\n\"The Bad\" (offensive applications), and \"The Ugly\" (vulnerabilities of LLMs and\ntheir defenses). We have some interesting findings. For example, LLMs have\nproven to enhance code security (code vulnerability detection) and data privacy\n(data confidentiality protection), outperforming traditional methods. However,\nthey can also be harnessed for various attacks (particularly user-level\nattacks) due to their human-like reasoning abilities. We have identified areas\nthat require further research efforts. For example, Research on model and\nparameter extraction attacks is limited and often theoretical, hindered by LLM\nparameter scale and confidentiality. Safe instruction tuning, a recent\ndevelopment, requires more exploration. We hope that our work can shed light on\nthe LLMs' potential to both bolster and jeopardize cybersecurity.\n","authors":["Yifan Yao","Jinhao Duan","Kaidi Xu","Yuanfang Cai","Zhibo Sun","Yue Zhang"],"pdf_url":"https://arxiv.org/pdf/2312.02003v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13925v1","updated":"2024-03-20T18:59:18Z","published":"2024-03-20T18:59:18Z","title":"Reducing Large Language Model Bias with Emphasis on 'Restricted\n  Industries': Automated Dataset Augmentation and Prejudice Quantification","summary":"  Despite the growing capabilities of large language models, there exists\nconcerns about the biases they develop. In this paper, we propose a novel,\nautomated mechanism for debiasing through specified dataset augmentation in the\nlens of bias producers and in the context of 'restricted industries' with\nlimited data. We additionally create two new additional metrics, the mb-index\nand db-index, to quantify bias, considering the idea that bias occurs due to\nboth intrinsic model architecture and dataset.\n","authors":["Devam Mondal","Carlo Lipizzi"],"pdf_url":"https://arxiv.org/pdf/2403.13925v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15619v3","updated":"2024-03-20T18:27:25Z","published":"2023-11-27T08:32:28Z","title":"Align before Adapt: Leveraging Entity-to-Region Alignments for\n  Generalizable Video Action Recognition","summary":"  Large-scale visual-language pre-trained models have achieved significant\nsuccess in various video tasks. However, most existing methods follow an \"adapt\nthen align\" paradigm, which adapts pre-trained image encoders to model\nvideo-level representations and utilizes one-hot or text embedding of the\naction labels for supervision. This paradigm overlooks the challenge of mapping\nfrom static images to complicated activity concepts. In this paper, we propose\na novel \"Align before Adapt\" (ALT) paradigm. Prior to adapting to video\nrepresentation learning, we exploit the entity-to-region alignments for each\nframe. The alignments are fulfilled by matching the region-aware image\nembeddings to an offline-constructed text corpus. With the aligned entities, we\nfeed their text embeddings to a transformer-based video adapter as the queries,\nwhich can help extract the semantics of the most important entities from a\nvideo to a vector. This paradigm reuses the visual-language alignment of VLP\nduring adaptation and tries to explain an action by the underlying entities.\nThis helps understand actions by bridging the gap with complex activity\nsemantics, particularly when facing unfamiliar or unseen categories. ALT\ndemonstrates competitive performance while maintaining remarkably low\ncomputational costs. In fully supervised experiments, it achieves 88.1% top-1\naccuracy on Kinetics-400 with only 4947 GFLOPs. Moreover, ALT outperforms the\nprevious state-of-the-art methods in both zero-shot and few-shot experiments,\nemphasizing its superior generalizability across various learning scenarios.\n","authors":["Yifei Chen","Dapeng Chen","Ruijin Liu","Sai Zhou","Wenyuan Xue","Wei Peng"],"pdf_url":"https://arxiv.org/pdf/2311.15619v3.pdf","comment":"Accepted at CVPR 2024"},{"id":"http://arxiv.org/abs/2309.02632v2","updated":"2024-03-20T18:15:09Z","published":"2023-09-06T00:44:29Z","title":"Deep Reinforcement Learning with Hierarchical Reward Modeling","summary":"  Reward design is a fundamental, yet challenging aspect of reinforcement\nlearning (RL). Researchers typically utilize feedback signals from the\nenvironment to handcraft a reward function, but this process is not always\neffective due to the varying scale and intricate dependencies of the feedback\nsignals. This paper shows by exploiting certain structures, one can ease the\nreward design process. Specifically, we propose a hierarchical reward modeling\nframework -- HERON for scenarios: (I) The feedback signals naturally present\nhierarchy; (II) The reward is sparse, but with less important surrogate\nfeedback to help policy learning. Both scenarios allow us to design a\nhierarchical decision tree induced by the importance ranking of the feedback\nsignals to compare RL trajectories. With such preference data, we can then\ntrain a reward model for policy learning. We apply HERON to several RL\napplications, and we find that our framework can not only train high performing\nagents on a variety of difficult tasks, but also provide additional benefits\nsuch as improved sample efficiency and robustness. Our code is available at\n\\url{https://github.com/abukharin3/HERON}.\n","authors":["Alexander Bukharin","Yixiao Li","Pengcheng He","Weizhu Chen","Tuo Zhao"],"pdf_url":"https://arxiv.org/pdf/2309.02632v2.pdf","comment":"29 Pages, 15 figures"},{"id":"http://arxiv.org/abs/2308.14296v3","updated":"2024-03-20T18:13:10Z","published":"2023-08-28T04:31:04Z","title":"RecMind: Large Language Model Powered Agent For Recommendation","summary":"  While the recommendation system (RS) has advanced significantly through deep\nlearning, current RS approaches usually train and fine-tune models on\ntask-specific datasets, limiting their generalizability to new recommendation\ntasks and their ability to leverage external knowledge due to model scale and\ndata size constraints. Thus, we designed an LLM-powered autonomous recommender\nagent, RecMind, which is capable of leveraging external knowledge, utilizing\ntools with careful planning to provide zero-shot personalized recommendations.\nWe propose a Self-Inspiring algorithm to improve the planning ability. At each\nintermediate step, the LLM self-inspires to consider all previously explored\nstates to plan for the next step. This mechanism greatly improves the model's\nability to comprehend and utilize historical information in planning for\nrecommendation. We evaluate RecMind's performance in various recommendation\nscenarios. Our experiment shows that RecMind outperforms existing zero/few-shot\nLLM-based recommendation baseline methods in various tasks and achieves\ncomparable performance to a fully trained recommendation model P5.\n","authors":["Yancheng Wang","Ziyan Jiang","Zheng Chen","Fan Yang","Yingxue Zhou","Eunah Cho","Xing Fan","Xiaojiang Huang","Yanbin Lu","Yingzhen Yang"],"pdf_url":"https://arxiv.org/pdf/2308.14296v3.pdf","comment":"Accepted by NAACL 2024 (Findings)"},{"id":"http://arxiv.org/abs/2403.13890v1","updated":"2024-03-20T18:01:57Z","published":"2024-03-20T18:01:57Z","title":"Towards Learning Contrast Kinetics with Multi-Condition Latent Diffusion\n  Models","summary":"  Contrast agents in dynamic contrast enhanced magnetic resonance imaging allow\nto localize tumors and observe their contrast kinetics, which is essential for\ncancer characterization and respective treatment decision-making. However,\ncontrast agent administration is not only associated with adverse health risks,\nbut also restricted for patients during pregnancy, and for those with kidney\nmalfunction, or other adverse reactions. With contrast uptake as key biomarker\nfor lesion malignancy, cancer recurrence risk, and treatment response, it\nbecomes pivotal to reduce the dependency on intravenous contrast agent\nadministration. To this end, we propose a multi-conditional latent diffusion\nmodel capable of acquisition time-conditioned image synthesis of DCE-MRI\ntemporal sequences. To evaluate medical image synthesis, we additionally\npropose and validate the Fr\\'echet radiomics distance as an image quality\nmeasure based on biomarker variability between synthetic and real imaging data.\nOur results demonstrate our method's ability to generate realistic\nmulti-sequence fat-saturated breast DCE-MRI and uncover the emerging potential\nof deep learning based contrast kinetics simulation. We publicly share our\naccessible codebase at https://github.com/RichardObi/ccnet.\n","authors":["Richard Osuala","Daniel Lang","Preeti Verma","Smriti Joshi","Apostolia Tsirikoglou","Grzegorz Skorupko","Kaisar Kushibar","Lidia Garrucho","Walter H. L. Pinaya","Oliver Diaz","Julia Schnabel","Karim Lekadir"],"pdf_url":"https://arxiv.org/pdf/2403.13890v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13784v1","updated":"2024-03-20T17:47:08Z","published":"2024-03-20T17:47:08Z","title":"The Model Openness Framework: Promoting Completeness and Openness for\n  Reproducibility, Transparency and Usability in AI","summary":"  Generative AI (GAI) offers unprecedented possibilities but its\ncommercialization has raised concerns about transparency, reproducibility,\nbias, and safety. Many \"open-source\" GAI models lack the necessary components\nfor full understanding and reproduction, and some use restrictive licenses, a\npractice known as \"openwashing.\" We propose the Model Openness Framework (MOF),\na ranked classification system that rates machine learning models based on\ntheir completeness and openness, following principles of open science, open\nsource, open data, and open access. The MOF requires specific components of the\nmodel development lifecycle to be included and released under appropriate open\nlicenses. This framework aims to prevent misrepresentation of models claiming\nto be open, guide researchers and developers in providing all model components\nunder permissive licenses, and help companies, academia, and hobbyists identify\nmodels that can be safely adopted without restrictions. Wide adoption of the\nMOF will foster a more open AI ecosystem, accelerating research, innovation,\nand adoption.\n","authors":["Matt White","Ibrahim Haddad","Cailean Osborne","Xiao-Yang Liu","Ahmed Abdelmonsef","Sachin Varghese"],"pdf_url":"https://arxiv.org/pdf/2403.13784v1.pdf","comment":"45 pages"}],"Optimization and Control":[{"id":"http://arxiv.org/abs/2310.04931v3","updated":"2024-03-20T17:34:38Z","published":"2023-10-07T22:21:59Z","title":"Coupled linear Schrödinger equations: Control and stabilization\n  results","summary":"  This article presents some controllability and stabilization results for a\nsystem of two coupled linear Schr\\\"odinger equations in the one-dimensional\ncase where the state components are interacting through the Kirchhoff boundary\nconditions. Considering the system in a bounded domain, the null boundary\ncontrollability result is shown. The result is achieved thanks to a new\nCarleman estimate, which ensures a boundary observation. Additionally, this\nboundary observation together with some trace estimates, helps us to use the\nGramian approach, with a suitable choice of feedback law, to prove that the\nsystem under consideration decays exponentially to zero at least as fast as the\nfunction $e^{-2\\omega t}$ for some $\\omega>0$.\n","authors":["K. Bhandari","R. de A. Capistrano-Filho","S. Majumdar","T. Y. Tanaka"],"pdf_url":"https://arxiv.org/pdf/2310.04931v3.pdf","comment":"21 pp - Some new references and minor changes were made. Comments are\n  welcome"},{"id":"http://arxiv.org/abs/2207.06305v4","updated":"2024-03-20T17:00:32Z","published":"2022-07-13T15:57:55Z","title":"Stochastic Average Model Methods","summary":"  We consider the solution of finite-sum minimization problems, such as those\nappearing in nonlinear least-squares or general empirical risk minimization\nproblems. We are motivated by problems in which the summand functions are\ncomputationally expensive and evaluating all summands on every iteration of an\noptimization method may be undesirable. We present the idea of stochastic\naverage model (SAM) methods, inspired by stochastic average gradient methods.\nSAM methods sample component functions on each iteration of a trust-region\nmethod according to a discrete probability distribution on component functions;\nthe distribution is designed to minimize an upper bound on the variance of the\nresulting stochastic model. We present promising numerical results concerning\nan implemented variant extending the derivative-free model-based trust-region\nsolver POUNDERS, which we name SAM-POUNDERS.\n","authors":["Matt Menickelly","Stefan M. Wild"],"pdf_url":"https://arxiv.org/pdf/2207.06305v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13730v1","updated":"2024-03-20T16:39:48Z","published":"2024-03-20T16:39:48Z","title":"Projection-free computation of robust controllable sets with constrained\n  zonotopes","summary":"  We study the problem of computing robust controllable sets for discrete-time\nlinear systems with additive uncertainty. We propose a tractable and scalable\napproach to inner- and outer-approximate robust controllable sets using\nconstrained zonotopes, when the additive uncertainty set is a symmetric,\nconvex, and compact set. Our least-squares-based approach uses novel\nclosed-form approximations of the Pontryagin difference between a constrained\nzonotopic minuend and a symmetric, convex, and compact subtrahend. Unlike\nexisting approaches, our approach does not rely on convex optimization solvers,\nand is projection-free for ellipsoidal and zonotopic uncertainty sets. We also\npropose a least-squares-based approach to compute a convex, polyhedral\nouter-approximation to constrained zonotopes, and characterize sufficient\nconditions under which all these approximations are exact. We demonstrate the\ncomputational efficiency and scalability of our approach in several case\nstudies, including the design of abort-safe rendezvous trajectories for a\nspacecraft in near-rectilinear halo orbit under uncertainty. Our approach can\ninner-approximate a 20-step robust controllable set for a 100-dimensional\nlinear system in under 15 seconds on a standard computer.\n","authors":["Abraham P. Vinod","Avishai Weiss","Stefano Di Cairano"],"pdf_url":"https://arxiv.org/pdf/2403.13730v1.pdf","comment":"22 pages, 6 figures"},{"id":"http://arxiv.org/abs/2402.19212v3","updated":"2024-03-20T16:34:27Z","published":"2024-02-29T14:41:31Z","title":"Deep Reinforcement Learning: A Convex Optimization Approach","summary":"  In this paper, we consider reinforcement learning of nonlinear systems with\ncontinuous state and action spaces. We present an episodic learning algorithm,\nwhere we for each episode use convex optimization to find a two-layer neural\nnetwork approximation of the optimal $Q$-function. The convex optimization\napproach guarantees that the weights calculated at each episode are optimal,\nwith respect to the given sampled states and actions of the current episode.\nFor stable nonlinear systems, we show that the algorithm converges and that the\nconverging parameters of the trained neural network can be made arbitrarily\nclose to the optimal neural network parameters. In particular, if the\nregularization parameter is $\\rho$ and the time horizon is $T$, then the\nparameters of the trained neural network converge to $w$, where the distance\nbetween $w$ from the optimal parameters $w^\\star$ is bounded by\n$\\mathcal{O}(\\rho T^{-1})$. That is, when the number of episodes goes to\ninfinity, there exists a constant $C$ such that \\[\\|w-w^\\star\\| \\le\nC\\cdot\\frac{\\rho}{T}.\\] In particular, our algorithm converges arbitrarily\nclose to the optimal neural network parameters as the time horizon increases or\nas the regularization parameter decreases.\n","authors":["Ather Gattami"],"pdf_url":"https://arxiv.org/pdf/2402.19212v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13688v1","updated":"2024-03-20T15:51:03Z","published":"2024-03-20T15:51:03Z","title":"Scalable Projection-Free Optimization Methods via MultiRadial Duality\n  Theory","summary":"  Recent works have developed new projection-free first-order methods based on\nutilizing linesearches and normal vector computations to maintain feasibility.\nThese oracles can be cheaper than orthogonal projection or linear optimization\nsubroutines but have the drawback of requiring a known strictly feasible point\nto do these linesearches with respect to. In this work, we develop new theory\nand algorithms which can operate using these cheaper linesearches while only\nrequiring knowledge of points strictly satisfying each constraint separately.\nConvergence theory for several resulting ``multiradial'' gradient methods is\nestablished. We also provide preliminary numerics showing performance is\nessentially independent of how one selects the reference points for synthetic\nquadratically constrained quadratic programs.\n","authors":["Thabo Samakhoana","Benjamin Grimmer"],"pdf_url":"https://arxiv.org/pdf/2403.13688v1.pdf","comment":"26 pages"},{"id":"http://arxiv.org/abs/2304.02433v2","updated":"2024-03-20T15:08:15Z","published":"2023-04-05T13:34:24Z","title":"On Continuous Full-Order Integral-Terminal Sliding Mode Control with\n  Unknown Apriori Bound on Uncertainty","summary":"  This study aims at providing a solution to the problem of designing a\ncontinuous and finite-time control for a class of nonlinear systems in the\npresence of matched uncertainty with an unknown apriori bound. First, we\npropose a Full-Order Integral-Terminal Sliding Manifold (FOITSM) with a\nconventional (discontinuous) sliding mode to show that it provides the combined\nattributes of the nonsingular terminal and integral sliding mode algorithms.\nSecondly, an Adaptive Disturbance Observer (ADO) has been designed to alleviate\nthe effect of the uncertainty acting on the system. On application of the\nADO-based Full-Order Integral-Terminal Sliding Mode Control (FOITSMC), the\nchattering phenomenon in control input has been reduced substantially in the\npresence of conditionally known matched disturbances. Moreover, the adaptive\ngains of ADO are updated non-monotonically without over-bounding the acting\ndisturbance, yet sustain the global boundedness of state trajectories within a\nspecific bound. %Finally, an application of the proposed algorithm for attitude\nstabilization of a rigid spacecraft has been successively shown.\n","authors":["Jit Koley","Dinesh Patra","Binoy Krishna Roy"],"pdf_url":"https://arxiv.org/pdf/2304.02433v2.pdf","comment":"14 pages, 9 figures"},{"id":"http://arxiv.org/abs/2402.07698v2","updated":"2024-03-20T14:34:31Z","published":"2024-02-12T15:06:56Z","title":"Optimal consumption and investment under relative performance criteria\n  with Epstein-Zin utility","summary":"  We consider the strategic interaction of traders in a continuous-time\nfinancial market with Epstein-Zin-type recursive intertemporal preferences and\nperformance concerns. We derive explicitly an equilibrium for the finite player\nand the mean-field version of the game, based on a study of geometric backward\nstochastic differential equations of Bernoulli type that describe the best\nreplies of traders. Our results show that Epstein-Zin preferences can lead to\nsubstantially different equilibrium behavior.\n","authors":["Jodi Dianetti","Frank Riedel","Lorenzo Stanca"],"pdf_url":"https://arxiv.org/pdf/2402.07698v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13605v1","updated":"2024-03-20T13:55:04Z","published":"2024-03-20T13:55:04Z","title":"Optimal control of continuous-time symmetric systems with unknown\n  dynamics and noisy measurements","summary":"  An iterative learning algorithm is presented for continuous-time\nlinear-quadratic optimal control problems where the system is externally\nsymmetric with unknown dynamics. Both finite-horizon and infinite-horizon\nproblems are considered. It is shown that the proposed algorithm is globally\nconvergent to the optimal solution and has some advantages over adaptive\ndynamic programming, including being unbiased under noisy measurements and\nhaving a relatively low computational burden. Numerical experiments show the\neffectiveness of the results.\n","authors":["Hamed Taghavian","Florian Dorfler","Mikael Johansson"],"pdf_url":"https://arxiv.org/pdf/2403.13605v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13567v1","updated":"2024-03-20T13:02:20Z","published":"2024-03-20T13:02:20Z","title":"Certified Constraint Propagation and Dual Proof Analysis in a\n  Numerically Exact MIP Solver","summary":"  This paper presents the integration of constraint propagation and dual proof\nanalysis in an exact, roundoff-error-free MIP solver. The authors employ safe\nrounding methods to ensure that all results remain provably correct, while\nsacrificing as little computational performance as possible in comparison to a\npure floating-point implementation. The study also addresses the adaptation of\ncertification techniques for correctness verification. Computational studies\ndemonstrate the effectiveness of these techniques, showcasing a 23% performance\nimprovement on the MIPLIB 2017 benchmark test set.\n","authors":["Sander Borst","Leon Eifler","Ambros Gleixner"],"pdf_url":"https://arxiv.org/pdf/2403.13567v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13520v1","updated":"2024-03-20T11:42:42Z","published":"2024-03-20T11:42:42Z","title":"The defect, the Malgrange functor, and linear control systems","summary":"  The notion of defect of a finitely presented functor on a module category is\nextended to arbitrary additive functors. The new defect and the contravariant\nYoneda embedding form a right adjoint pair. The main result identifies the\ndefect of the covariant Hom modulo projectives with the Bass torsion of the\nfixed argument. When applied to a linear control systems, it shows that the\ndefect of the Malgrange functor of the system modulo projectives is isomorphic\nto the autonomy of the system. Furthermore, the defect of the contravariant Hom\nmodulo injectives is shown to be isomorphic to the cotorsion coradical of the\nfixed argument. Since the Auslander-Gruson-Jensen transform of cotorsion is\nisomorphic to torsion, the above results raise two important questions: a) what\nis a control-theoretic interpretation of the covariant Yoneda embedding of the\nMalgrange module modulo injectives, and b) what is a control-theoretic\ninterpretation of the Auslander-Gruson-Jensen duality?\n","authors":["Alex Martsinkovsky"],"pdf_url":"https://arxiv.org/pdf/2403.13520v1.pdf","comment":"11 pages. This text is an expanded version of Section 4 of an earlier\n  version of the preprint entitled \"The finite presentation of the stable Hom\n  functors, the Bass torsion, and the cotorsion coradical\". arXiv admin note:\n  text overlap with arXiv:2212.09237"},{"id":"http://arxiv.org/abs/2206.10709v3","updated":"2024-03-20T10:14:39Z","published":"2022-06-21T19:58:24Z","title":"PaPILO: A Parallel Presolving Library for Integer and Linear Programming\n  with Multiprecision Support","summary":"  Presolving has become an essential component of modern MIP solvers both in\nterms of computational performance and numerical robustness. In this paper, we\npresent PaPILO, a new C++ header-only library that provides a large set of\npresolving routines for MIP and LP problems from the literature. The creation\nof PaPILO was motivated by the current lack of (a) solver-independent\nimplementations that (b) exploit parallel hardware, and (c) support\nmultiprecision arithmetic. Traditionally, presolving is designed to be fast.\nWhenever necessary, its low computational overhead is usually achieved by\nstrict working limits. PaPILO's parallelization framework aims at reducing the\ncomputational overhead also when presolving is executed more aggressively or is\napplied to large-scale problems. To rule out conflicts between parallel\npresolve reductions, PaPILO uses a transaction-based design. This helps to\navoid both the memory-intensive allocation of multiple copies of the problem\nand special synchronization between presolvers. Additionally, the use of\nIntel's TBB library aids PaPILO to efficiently exploit recursive parallelism\nwithin expensive presolving routines such as probing, dominated columns, or\nconstraint sparsification. We provide an overview of PaPILO's capabilities and\ninsights into important design choices.\n","authors":["Ambros Gleixner","Leona Gottwald","Alexander Hoen"],"pdf_url":"https://arxiv.org/pdf/2206.10709v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.09277v2","updated":"2024-03-20T10:11:34Z","published":"2024-01-17T15:31:02Z","title":"Certifying MIP-based Presolve Reductions for 0-1 Integer Linear Programs","summary":"  It is well known that reformulating the original problem can be crucial for\nthe performance of mixed-integer programming (MIP) solvers. To ensure\ncorrectness, all transformations must preserve the fea sibility status and\noptimal value of the problem, but there is currently no established methodology\nto express and verify the equivalence of two mixed-integer programs. In this\nwork, we take a first step in this direction by showing how the correctness of\nMIP presolve reductions on 0-1 integer linear programs can be certified by\nusing (and suitably extending) the VeriPB tool for pseudo-Boolean proof\nlogging. Our experimental evaluation on both decision and optimization\ninstances demonstrates the computational viability of the approach and leads to\nsuggestions for future revisions of the proof format that will help to reduce\nthe verbosity of the certificates and to accelerate the certification and\nverification process further.\n","authors":["Alexander Hoen","Andy Oertel","Ambros Gleixner","Jakob Nordström"],"pdf_url":"https://arxiv.org/pdf/2401.09277v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13460v1","updated":"2024-03-20T10:08:05Z","published":"2024-03-20T10:08:05Z","title":"Tikhonov regularized exterior penalty dynamics for constrained\n  variational inequalities","summary":"  Solving equilibrium problems under constraints is an important problem in\noptimization and optimal control. In this context an important practical\nchallenge is the efficient incorporation of constraints. We develop a\ncontinuous-time method for solving constrained variational inequalities based\non a new penalty regulated dynamical system in a general potentially\ninfinite-dimensional Hilbert space. In order to obtain strong convergence of\nthe issued trajectory of our method, we incorporate an explicit Tikhonov\nregularization parameter in our method, leading to a class of time-varying\nmonotone inclusion problems featuring multiscale aspects. Besides strong\nconvergence, we illustrate the practical efficiency of our developed method in\nsolving constrained min-max problems.\n","authors":["Siqi Qu","Mathias Staudigl"],"pdf_url":"https://arxiv.org/pdf/2403.13460v1.pdf","comment":"Submitted as a conference proceeding"},{"id":"http://arxiv.org/abs/2105.09189v3","updated":"2024-03-20T10:03:50Z","published":"2021-05-19T15:06:23Z","title":"Optimization of inventory and capacity in large-scale assembly systems\n  using extreme-value theory","summary":"  High-tech systems are typically produced in two stages: 1) Production of\ncomponents using specialized equipment and staff; 2) System\nassembly/integration. Component production capacity is subject to fluctuations,\ncausing a high risk of shortages of at least one component, which results in\ncostly delays. Companies hedge this risk by strategic investments in excess\nproduction capacity and in buffer inventories of components. To optimize these,\nit is crucial to characterize the relation between component shortage risk and\ncapacity and inventory investments. We suppose that component production\ncapacity and produce demand are normally distributed over finite time\nintervals, and we accordingly model the production system as a symmetric\nfork-join queueing network with $N$ statistically identical queues with a\ncommon arrival process and independent service processes. Assuming a symmetric\ncost structure, we subsequently apply extreme value theory to gain analytic\ninsights into this optimization problem. We derive several new results for this\nqueueing network, notably that the scaled maximum of $N$ steady-state queue\nlengths converges in distribution to a Gaussian random variable. These results\ntranslate into asymptotically optimal methods to dimension the system. Tests on\na range of problems reveal that these methods typically work well for systems\nof moderate size.\n","authors":["Mirjam S. Meijer","Dennis Schol","Willem van Jaarsveld","Maria Vlasiou","Bert Zwart"],"pdf_url":"https://arxiv.org/pdf/2105.09189v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.13928v2","updated":"2024-03-20T08:51:45Z","published":"2024-02-21T16:48:38Z","title":"Supporting the next generation lithography roadmap using partial\n  state-feedback reduced-order switching predictive models","summary":"  To support the ever-increasing performance requirements of lithography\nsystems in terms of throughput and accuracy, in this paper, we introduce a\ndesign framework for partial state-feedback reduced-order switching predictive\nmodels. By combining measurements and predictions, this method aims to: 1)\nimprove overall system performance by reducing the placement errors in a die\nwithin and across the full-wafer and 2) eliminate redundant measurements by\nusing predictions to improve system throughput. We primarily focus on\nwell-known trade-off introduced by measurement time, which can correct errors\nat a cost of throughput, noise and not being robust to uncertainties. The\nproposed approach consists of a reduced-order model with a switching logic that\nacts a scheduler to deal with uncertain operating conditions. It also utilizes\nlinear predictive models as a basis for the control design which is appealing\nto the ease and cost of implementation, enhancing the applicability. For the\nadd-on part, the scheduler logic is adapted based on expected operating\nconditions of the system while guaranteeing global uniform ultimate bounded\nasymptotic stability. Lastly, to deal with measurement layouts, the predictor\ncombines the measurement into model using partial state-feedback. Effectiveness\nof the proposed strategy is demonstrated in practice on a high-precision\nindustrial scanner.\n","authors":["Raaja Ganapathy Subramanian","Barry Moest","Bart Paarhuis"],"pdf_url":"https://arxiv.org/pdf/2402.13928v2.pdf","comment":"9 pages, 9 figures, to be submitted in IEEE-TIE"},{"id":"http://arxiv.org/abs/2403.13385v1","updated":"2024-03-20T08:26:39Z","published":"2024-03-20T08:26:39Z","title":"A multilevel framework for accelerating uSARA in radio-interferometric\n  imaging","summary":"  This paper presents a multilevel algorithm specifically designed for\nradio-interferometric imaging in astronomy. The proposed algorithm is used to\nsolve the uSARA (unconstrained Sparsity Averaging Reweighting Analysis)\nformulation of this image restoration problem. Multilevel algorithms rely on a\nhierarchy of approximations of the objective function to accelerate its\noptimization. In contrast to the usual multilevel approaches where this\nhierarchy is derived in the parameter space, here we construct the hierarchy of\napproximations in the observation space. The proposed approach is compared to a\nreweighted forward-backward procedure, which is the backbone iteration scheme\nfor solving the uSARA problem.\n","authors":["Guillaume Lauga","Audrey Repetti","Elisa Riccietti","Nelly Pustelnik","Paulo Gonçalves","Yves Wiaux"],"pdf_url":"https://arxiv.org/pdf/2403.13385v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13381v1","updated":"2024-03-20T08:23:34Z","published":"2024-03-20T08:23:34Z","title":"Dynamic variable step size LMS adaptation algorithms -- Application to\n  adaptive feedforward noise attenuation","summary":"  The paper explores in detail the use of dynamic adaptation gain/step size\n(DAG) for improving the adaptation transient performance of variable step-size\nLMS (VS-LMS) adaptation algorithms. A generic form for the implementation of\nthe DAG within the VS-LMS algorithms is provided. Criteria for the selection of\nthe coefficients of the DAG filter which is required to be a strictly positive\nreal transfer operator are given. The potential of the VS-LMS adaptation\nalgorithms using a DAG is then illustrated by experimental results obtained on\na relevant adaptive active noise attenuation system.\n","authors":["Tudor-Bogdan Airimitoaie","Bernard Vau","Dariusz Bismor","Gabriel Buche","Ioan Doré Landau"],"pdf_url":"https://arxiv.org/pdf/2403.13381v1.pdf","comment":"European Control Conference 2024, Jun 2024, Stockholm, Sweden"},{"id":"http://arxiv.org/abs/2403.13320v1","updated":"2024-03-20T05:55:13Z","published":"2024-03-20T05:55:13Z","title":"Direct search for stochastic optimization in random subspaces with\n  zeroth-, first-, and second-order convergence and expected complexity","summary":"  The work presented here is motivated by the development of StoDARS, a\nframework for large-scale stochastic blackbox optimization that not only is\nboth an algorithmic and theoretical extension of the stochastic directional\ndirect-search (SDDS) framework but also extends to noisy objectives a recent\nframework of direct-search algorithms in reduced spaces (DARS). Unlike SDDS,\nStoDARS achieves scalability by using~$m$ search directions generated in random\nsubspaces defined through the columns of Johnson--Lindenstrauss transforms\n(JLTs) obtained from Haar-distributed orthogonal matrices. For theoretical\nneeds, the quality of these subspaces and the accuracy of random estimates used\nby the algorithm are required to hold with sufficiently large, but fixed,\nprobabilities. By leveraging an existing supermartingale-based framework, the\nexpected complexity of StoDARS is proved to be similar to that of SDDS and\nother stochastic full-space methods up to constants, when the objective\nfunction is continuously differentiable. By dropping the latter assumption, the\nconvergence of StoDARS to Clarke stationary points with probability one is\nestablished. Moreover, the analysis of the second-order behavior of the mesh\nadaptive direct-search (MADS) algorithm using a second-order-like extension of\nthe Rademacher's theorem-based definition of the Clarke subdifferential\n(so-called generalized Hessian) is extended to the StoDARS framework, making it\nthe first in a stochastic direct-search setting, to the best of our knowledge.\n","authors":["K. J. Dzahini","S. M. Wild"],"pdf_url":"https://arxiv.org/pdf/2403.13320v1.pdf","comment":"30 pages"},{"id":"http://arxiv.org/abs/2403.13290v1","updated":"2024-03-20T04:06:59Z","published":"2024-03-20T04:06:59Z","title":"A Log-domain Interior Point Method for Convex Quadratic Games","summary":"  In this paper, we propose an equilibrium-seeking algorithm for finding\ngeneralized Nash equilibria of non-cooperative monotone convex quadratic games.\nSpecifically, we recast the Nash equilibrium-seeking problem as variational\ninequality problem that we solve using a log-domain interior point method and\nprovide a general purpose solver based on this algorithm. This approach is\nsuitable for non-potential, general sum games and does not require extensive\nstructural assumptions. We demonstrate the efficiency and versatility of our\nmethod using three benchmark games and demonstrate our algorithm is especially\neffective on small to medium scale problems.\n","authors":["Bingqi Liu","Dominic Liao-McPherson"],"pdf_url":"https://arxiv.org/pdf/2403.13290v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13255v1","updated":"2024-03-20T02:34:21Z","published":"2024-03-20T02:34:21Z","title":"Network-Aware Value Stacking of Community Battery via Asynchronous\n  Distributed Optimization","summary":"  Community battery systems have been widely deployed to provide services to\nthe grid. Unlike a single battery storage system in the community, coordinating\nmultiple community batteries can further unlock their value, enhancing the\nviability of community battery solutions. However, the centralized control of\ncommunity batteries relies on the full information of the system, which is less\npractical and may even lead to privacy leakage. In this paper, we formulate a\nvalue-stacking optimization problem for community batteries to interact with\nlocal solar, buildings, and the grid, within distribution network constraints.\nWe then propose a distributed algorithm using asynchronous distributed\nalternate direction method of multipliers (ADMM) to solve the problem. Our\nalgorithm is robust to communication latency between community batteries and\nthe grid while preserving the operational privacy. The simulation results\ndemonstrate the convergence of our proposed asynchronous distributed ADMM\nalgorithm. We also evaluate the electricity cost and the contribution of each\nvalue stream in the value-stacking problem for community batteries using\nreal-world data.\n","authors":["Canchen Jiang","Hao Wang"],"pdf_url":"https://arxiv.org/pdf/2403.13255v1.pdf","comment":"2024 IEEE Power & Energy Society General Meeting (PESGM)"},{"id":"http://arxiv.org/abs/2403.13237v1","updated":"2024-03-20T01:58:38Z","published":"2024-03-20T01:58:38Z","title":"Graph Attention Network-based Block Propagation with Optimal AoI and\n  Reputation in Web 3.0","summary":"  Web 3.0 is recognized as a pioneering paradigm that empowers users to\nsecurely oversee data without reliance on a centralized authority. Blockchains,\nas a core technology to realize Web 3.0, can facilitate decentralized and\ntransparent data management. Nevertheless, the evolution of blockchain-enabled\nWeb 3.0 is still in its nascent phase, grappling with challenges such as\nensuring efficiency and reliability to enhance block propagation performance.\nIn this paper, we design a Graph Attention Network (GAT)-based reliable block\npropagation optimization framework for blockchain-enabled Web 3.0. We first\ninnovatively apply a data-freshness metric called age of information to measure\nblock propagation efficiency in public blockchains. To achieve the reliability\nof block propagation, we introduce a reputation mechanism based on the\nsubjective logic model, including the local and recommended opinions to\ncalculate the miner reputation value. Moreover, considering that the GAT\npossesses the excellent ability to process graph-structured data, we utilize\nthe GAT with reinforcement learning to obtain the optimal block propagation\ntrajectory. Numerical results demonstrate that the proposed scheme exhibits the\nmost outstanding block propagation efficiency and reliability compared with\ntraditional routing algorithms.\n","authors":["Jiana Liao","Jinbo Wen","Jiawen Kang","Changyan Yi","Yang Zhang","Yutao Jiao","Dusit Niyato","Dong In Kim","Shengli Xie"],"pdf_url":"https://arxiv.org/pdf/2403.13237v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13236v1","updated":"2024-03-20T01:57:38Z","published":"2024-03-20T01:57:38Z","title":"Safety-Aware Reinforcement Learning for Electric Vehicle Charging\n  Station Management in Distribution Network","summary":"  The increasing integration of electric vehicles (EVs) into the grid can pose\na significant risk to the distribution system operation in the absence of\ncoordination. In response to the need for effective coordination of EVs within\nthe distribution network, this paper presents a safety-aware reinforcement\nlearning (RL) algorithm designed to manage EV charging stations while ensuring\nthe satisfaction of system constraints. Unlike existing methods, our proposed\nalgorithm does not rely on explicit penalties for constraint violations,\neliminating the need for penalty coefficient tuning. Furthermore, managing EV\ncharging stations is further complicated by multiple uncertainties, notably the\nvariability in solar energy generation and energy prices. To address this\nchallenge, we develop an off-policy RL algorithm to efficiently utilize data to\nlearn patterns in such uncertain environments. Our algorithm also incorporates\na maximum entropy framework to enhance the RL algorithm's exploratory process,\npreventing convergence to local optimal solutions. Simulation results\ndemonstrate that our algorithm outperforms traditional RL algorithms in\nmanaging EV charging in the distribution network.\n","authors":["Jiarong Fan","Ariel Liebman","Hao Wang"],"pdf_url":"https://arxiv.org/pdf/2403.13236v1.pdf","comment":"2024 IEEE Power & Energy Society General Meeting (PESGM)"},{"id":"http://arxiv.org/abs/2403.13234v1","updated":"2024-03-20T01:48:56Z","published":"2024-03-20T01:48:56Z","title":"Distributionally Robust Hospital Capacity Expansion Planning under\n  Stochastic and Correlated Patient Demand","summary":"  This paper investigates the optimal locations and capacities of hospital\nexpansion facilities under uncertain future patient demands, considering both\nspatial and temporal correlations. We propose a novel two-stage\ndistributionally robust optimization (DRO) model that integrates a\nSpatio-Temporal Neural Network (STNN). Specifically, we develop an STNN model\nthat predicts future hospital occupancy levels considering spatial and temporal\npatterns in time-series datasets over a network of hospitals. The predictions\nof the STNN model are then used in the construction of the ambiguity set of the\nDRO model. To address computational challenges associated with two-stage DRO,\nwe employ the linear-decision-rules technique to derive a tractable\nmixed-integer linear programming approximation. Extensive computational\nexperiments conducted on real-world data demonstrate the superiority of the\nSTNN model in minimizing forecast errors. Compared to neural network models\nbuilt for each individual hospital, the proposed STNN model achieves a 53%\nimprovement in average RMSE. Furthermore, the results demonstrate the value of\nincorporating spatiotemporal dependencies of demand uncertainty in the DRO\nmodel, as evidenced by out-of-sample analysis conducted with both ground truth\ndata and under perfect information scenarios.\n","authors":["Aliaa Alnaggar","Faiza Farrukh"],"pdf_url":"https://arxiv.org/pdf/2403.13234v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13219v1","updated":"2024-03-20T00:41:12Z","published":"2024-03-20T00:41:12Z","title":"Diffusion Model for Data-Driven Black-Box Optimization","summary":"  Generative AI has redefined artificial intelligence, enabling the creation of\ninnovative content and customized solutions that drive business practices into\na new era of efficiency and creativity. In this paper, we focus on diffusion\nmodels, a powerful generative AI technology, and investigate their potential\nfor black-box optimization over complex structured variables. Consider the\npractical scenario where one wants to optimize some structured design in a\nhigh-dimensional space, based on massive unlabeled data (representing design\nvariables) and a small labeled dataset. We study two practical types of labels:\n1) noisy measurements of a real-valued reward function and 2) human preference\nbased on pairwise comparisons. The goal is to generate new designs that are\nnear-optimal and preserve the designed latent structures. Our proposed method\nreformulates the design optimization problem into a conditional sampling\nproblem, which allows us to leverage the power of diffusion models for modeling\ncomplex distributions. In particular, we propose a reward-directed conditional\ndiffusion model, to be trained on the mixed data, for sampling a near-optimal\nsolution conditioned on high predicted rewards. Theoretically, we establish\nsub-optimality error bounds for the generated designs. The sub-optimality gap\nnearly matches the optimal guarantee in off-policy bandits, demonstrating the\nefficiency of reward-directed diffusion models for black-box optimization.\nMoreover, when the data admits a low-dimensional latent subspace structure, our\nmodel efficiently generates high-fidelity designs that closely respect the\nlatent structure. We provide empirical experiments validating our model in\ndecision-making and content-creation tasks.\n","authors":["Zihao Li","Hui Yuan","Kaixuan Huang","Chengzhuo Ni","Yinyu Ye","Minshuo Chen","Mengdi Wang"],"pdf_url":"https://arxiv.org/pdf/2403.13219v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2307.07055"},{"id":"http://arxiv.org/abs/2403.11062v2","updated":"2024-03-20T00:38:58Z","published":"2024-03-17T02:24:09Z","title":"A Simple Mixture Policy Parameterization for Improving Sample Efficiency\n  of CVaR Optimization","summary":"  Reinforcement learning algorithms utilizing policy gradients (PG) to optimize\nConditional Value at Risk (CVaR) face significant challenges with sample\ninefficiency, hindering their practical applications. This inefficiency stems\nfrom two main facts: a focus on tail-end performance that overlooks many\nsampled trajectories, and the potential of gradient vanishing when the lower\ntail of the return distribution is overly flat. To address these challenges, we\npropose a simple mixture policy parameterization. This method integrates a\nrisk-neutral policy with an adjustable policy to form a risk-averse policy. By\nemploying this strategy, all collected trajectories can be utilized for policy\nupdating, and the issue of vanishing gradients is counteracted by stimulating\nhigher returns through the risk-neutral component, thus lifting the tail and\npreventing flatness. Our empirical study reveals that this mixture\nparameterization is uniquely effective across a variety of benchmark domains.\nSpecifically, it excels in identifying risk-averse CVaR policies in some Mujoco\nenvironments where the traditional CVaR-PG fails to learn a reasonable policy.\n","authors":["Yudong Luo","Yangchen Pan","Han Wang","Philip Torr","Pascal Poupart"],"pdf_url":"https://arxiv.org/pdf/2403.11062v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14045v1","updated":"2024-03-20T23:57:38Z","published":"2024-03-20T23:57:38Z","title":"Accelerated Objective Gap and Gradient Norm Convergence for Gradient\n  Descent via Long Steps","summary":"  This work considers gradient descent for L-smooth convex optimization with\nstepsizes larger than the classic regime where descent can be ensured. The\nstepsize schedules considered are similar to but differ slightly from the\nconcurrently developed silver stepsizes of Altschuler and Parillo. For one of\nour stepsize sequences, we prove a $O\\left(\\frac{1}{N^{1.2716\\dots}}\\right)$\nconvergence rate in terms of objective gap decrease and for the other, we show\nthe same rate of decrease for the squared-gradient-norm. This first result\nimproves on the recent result of Altschuler and Parillo by a constant factor,\nwhile the second results improve on the exponent of the prior best\nsquared-gradient-norm convergence guarantee of $O(\\frac{1}{N})$.\n","authors":["Benjamin Grimmer","Kevin Shu","Alex Wang"],"pdf_url":"https://arxiv.org/pdf/2403.14045v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14028v1","updated":"2024-03-20T22:56:11Z","published":"2024-03-20T22:56:11Z","title":"Performance-Guaranteed Solutions for Multi-Agent Optimal Coverage\n  Problems using Submodularity, Curvature, and Greedy Algorithms","summary":"  We consider a class of multi-agent optimal coverage problems where the goal\nis to determine the optimal placement of a group of agents in a given mission\nspace such that they maximize a joint ``coverage'' objective. This class of\nproblems is extremely challenging due to the non-convex nature of the mission\nspace and of the coverage objective. With this motivation, we propose to use a\ngreedy algorithm as a means of getting feasible coverage solutions efficiently.\nEven though such greedy solutions are suboptimal, the submodularity\n(diminishing returns) property of the coverage objective can be exploited to\nprovide performance bound guarantees - not only for the greedy solutions but\nalso for any subsequently improved solutions. Moreover, we show that improved\nperformance bound guarantees (beyond the standard (1-1/e) performance bound)\ncan be established using various curvature measures that further characterize\nthe considered coverage problem. In particular, we provide a brief review of\nall existing popular curvature measures found in the submodular maximization\nliterature, including a recent curvature measure that we proposed, and discuss\nin detail their applicability, practicality, and effectiveness in the context\nof optimal coverage problems. Moreover, we characterize the dependence of the\neffectiveness of different curvature measures (in providing improved\nperformance bound guarantees) on the agent sensing capabilities. Finally, we\nprovide several numerical results to support our findings and propose several\npotential future research directions.\n","authors":["Shirantha Welikala","Christos G. Cassandras"],"pdf_url":"https://arxiv.org/pdf/2403.14028v1.pdf","comment":"Will be submitted to CDC 2024"},{"id":"http://arxiv.org/abs/2401.09201v2","updated":"2024-03-20T22:42:12Z","published":"2024-01-17T13:26:16Z","title":"Tropical modeling of battery swapping and charging station","summary":"  We propose and investigate a queueing model of a battery swapping and\ncharging station (BSCS) for electric vehicles (EVs). A new approach to the\nanalysis of the queueing model is developed, which combines the representation\nof the model as a stochastic dynamic system with the use of the methods and\nresults of tropical algebra, which deals with the theory and applications of\nalgebraic systems with idempotent operations. We describe the dynamics of the\nqueueing model by a system of recurrence equations that involve random\nvariables (RVs) to represent the interarrival time of incoming EVs. A\nperformance measure for the model is defined as the mean operation cycle time\nof the station. Furthermore, the system of equations is represented in terms of\nthe tropical algebra in vector form as an implicit linear state dynamic\nequation. The performance measure takes on the meaning of the mean growth rate\nof the state vector (the Lyapunov exponent) of the dynamic system. By applying\na solution technique of vector equations in tropical algebra, the implicit\nequation is transformed into an explicit one with a state transition matrix\nwith random entries. The evaluation of the Lyapunov exponent reduces to finding\nthe limit of the expected value of norms of tropical matrix products. This\nlimit is then obtained using results from the tropical spectral theory of\ndeterministic and random matrices. With this approach, we derive a new exact\nformula for the mean cycle time of the BSCS, which is given in terms of the\nexpected value of the RVs involved. We present the results of the Monte Carlo\nsimulation of the BSCS's operation, which show a good agreement with the exact\nsolution. The application of the obtained solution to evaluate the performance\nof one BSCS and to find the optimal distribution of battery packs between\nstations in a network of BSCSs is discussed.\n","authors":["N. Krivulin","A. Garg"],"pdf_url":"https://arxiv.org/pdf/2401.09201v2.pdf","comment":"21 pages, 5 figures"},{"id":"http://arxiv.org/abs/2403.14013v1","updated":"2024-03-20T22:24:36Z","published":"2024-03-20T22:24:36Z","title":"Towards a connection between the capacitated vehicle routing problem and\n  the constrained centroid-based clustering","summary":"  Efficiently solving a vehicle routing problem (VRP) in a practical runtime is\na critical challenge for delivery management companies. This paper explores\nboth a theoretical and experimental connection between the Capacitated Vehicle\nRouting Problem (CVRP) and the Constrained Centroid-Based Clustering (CCBC).\nReducing a CVRP to a CCBC is a synonym for a transition from an exponential to\na polynomial complexity using commonly known algorithms for clustering, i.e\nK-means. At the beginning, we conduct an exploratory analysis to highlight the\nexistence of such a relationship between the two problems through illustrative\nsmall-size examples and simultaneously deduce some mathematically-related\nformulations and properties. On a second level, the paper proposes a CCBC based\napproach endowed with some enhancements. The proposed framework consists of\nthree stages. At the first step, a constrained centroid-based clustering\nalgorithm generates feasible clusters of customers. This methodology\nincorporates three enhancement tools to achieve near-optimal clusters, namely:\na multi-start procedure for initial centroids, a customer assignment metric,\nand a self-adjustment mechanism for choosing the number of clusters. At the\nsecond step, a traveling salesman problem (T SP) solver is used to optimize the\norder of customers within each cluster. Finally, we introduce a process relying\non routes cutting and relinking procedure, which calls upon solving a linear\nand integer programming model to further improve the obtained routes. This step\nis inspired by the ruin & recreate algorithm. This approach is an extension of\nthe classical cluster-first, route-second method and provides near-optimal\nsolutions on well-known benchmark instances in terms of solution quality and\ncomputational runtime, offering a milestone in solving VRP.\n","authors":["Abdelhakim Abdellaoui","Loubna Benabbou","Issmail El Hallaoui"],"pdf_url":"https://arxiv.org/pdf/2403.14013v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14010v1","updated":"2024-03-20T22:15:33Z","published":"2024-03-20T22:15:33Z","title":"When are Lossy Energy Storage Optimization Models Convex?","summary":"  We consider a class of optimization problems involving the optimal operation\nof a single lossy energy storage system that incurs energy loss when charging\nor discharging. Such inefficiencies in the energy storage dynamics are known to\nresult in a nonconvex set of feasible charging and discharging power profiles.\nIn this letter, we provide an equivalent reformulation for this class of\noptimization problems, along with sufficient conditions for the convexity of\nthe proposed reformulation. The conditions provided generalize existing\nconditions for convexity in the literature.\n","authors":["Feras Al Taha","Eilyan Bitar"],"pdf_url":"https://arxiv.org/pdf/2403.14010v1.pdf","comment":"5 pages, 1 figure"},{"id":"http://arxiv.org/abs/2403.04752v2","updated":"2024-03-20T22:12:32Z","published":"2024-03-07T18:54:54Z","title":"On semidefinite descriptions for convex hulls of quadratic programs","summary":"  Quadratically constrained quadratic programs (QCQPs) are a highly expressive\nclass of nonconvex optimization problems. While QCQPs are NP-hard in general,\nthey admit a natural convex relaxation via the standard semidefinite program\n(SDP) relaxation. In this paper we study when the convex hull of the epigraph\nof a QCQP coincides with the projected epigraph of the SDP relaxation. We\npresent a sufficient condition for convex hull exactness and show that this\ncondition is further necessary under an additional geometric assumption. The\nsufficient condition is based on geometric properties of $\\Gamma$, the cone of\nconvex Lagrange multipliers, and its relatives $\\Gamma_1$ and $\\Gamma^\\circ$.\n","authors":["Alex L. Wang","Fatma Kilinc-Karzan"],"pdf_url":"https://arxiv.org/pdf/2403.04752v2.pdf","comment":"This paper is a significant rewrite of arXiv:2011.07155 [math.OC] and\n  contains both new content and rewritten content"},{"id":"http://arxiv.org/abs/2205.10969v3","updated":"2024-03-20T22:04:59Z","published":"2022-05-23T00:28:54Z","title":"Application of tropical optimization for solving multicriteria problems\n  of pairwise comparisons using log-Chebyshev approximation","summary":"  We consider a decision-making problem to find absolute ratings of\nalternatives that are compared in pairs under multiple criteria, subject to\nconstraints in the form of two-sided bounds on ratios between the ratings.\nGiven matrices of pairwise comparisons made according to the criteria, the\nproblem is formulated as the log-Chebyshev approximation of these matrices by a\ncommon consistent matrix (a symmetrically reciprocal matrix of unit rank) to\nminimize the approximation errors for all matrices simultaneously. We rearrange\nthe approximation problem as a constrained multiobjective optimization problem\nof finding a vector that determines the approximating consistent matrix. The\nproblem is then represented in the framework of tropical algebra, which deals\nwith the theory and applications of idempotent semirings and provides a formal\nbasis for fuzzy and interval arithmetic. We apply methods and results of\ntropical optimization to develop a new approach for handling the multiobjective\noptimization problem according to various principles of optimality. New\ncomplete solutions in the sense of the max-ordering, lexicographic ordering and\nlexicographic max-ordering optimality are obtained, which are given in a\ncompact vector form ready for formal analysis and efficient computation. We\npresent numerical examples of solving multicriteria problems of rating four\nalternatives from pairwise comparisons to illustrate the technique and compare\nit with others.\n","authors":["Nikolai Krivulin"],"pdf_url":"https://arxiv.org/pdf/2205.10969v3.pdf","comment":"44 pages"},{"id":"http://arxiv.org/abs/2403.09251v2","updated":"2024-03-20T21:47:47Z","published":"2024-03-14T10:18:42Z","title":"Ahlfors regularity of continua that minimize maxitive set functions","summary":"  The primary objective of this paper is to establish the Ahlfors regularity of\nminimizers of set functions that satisfy a suitable maxitive condition on\ndisjoint unions of sets. Our analysis focuses on minimizers within continua of\nthe plane with finite one-dimensional Hausdorff measure. Through quantitative\nestimates, we prove that the length of a minimizer inside the ball centered at\none of its points is comparable to the radius of the ball. By operating within\nan abstract framework, we are able to encompass a diverse range of entities,\nincluding spectral functionals defined in terms of the eigenvalues of elliptic\noperators, the inradius, and the maximum of the torsion function. These\nentities are of interest for several applications, such as structural\nengineering, urban planning, and quantum mechanics.\n","authors":["Davide Zucco"],"pdf_url":"https://arxiv.org/pdf/2403.09251v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.03706v2","updated":"2024-03-20T19:31:41Z","published":"2023-11-07T04:12:54Z","title":"Parallelized Conflict Graph Cut Generation","summary":"  A conflict graph represents logical relations between binary variables, and\neffective use of the graph can significantly accelerate branch-and-cut solvers\nfor mixed-integer programming (MIP). In this paper we develop efficient\nparallel conflict graph management: conflict detection; maximal clique\ngeneration; clique extension; and clique merging. We leverage parallel\ncomputing in order to intensify computational effort on the conflict graph,\nthereby generating a much larger pool of cutting planes than what can be\npractically achieved in serial. Computational experiments demonstrate that the\nexpanded pool of cuts enabled by parallel computing lead to substantial\nreductions in total MIP solve time, especially for more challenging cases.\n","authors":["Yongzheng Dai","Chen Chen"],"pdf_url":"https://arxiv.org/pdf/2311.03706v2.pdf","comment":"19 pages, 2 figures"},{"id":"http://arxiv.org/abs/2403.13931v1","updated":"2024-03-20T19:12:26Z","published":"2024-03-20T19:12:26Z","title":"High Accuracy Numerical Optimal Control for Rigid Bodies with Patch\n  Contacts through Equivalent Contact Points -- Extended Version","summary":"  This paper extends the Finite Elements with Switch Detection and Jumps\n(FESD-J) [1] method to problems of rigid body dynamics involving patch\ncontacts. The FESD-J method is a high accuracy discretization scheme suitable\nfor use in direct optimal control of nonsmooth mechanical systems. It detects\ndynamic switches exactly in time and, thereby, maintains the integration order\nof the underlying Runge- Kutta (RK) method. This is in contrast to commonly\nused time-stepping methods which only achieve first-order accuracy. Considering\nrigid bodies with possible patch contacts results in nondifferentiable signed\ndistance functions (SDF), which introduces additional nonsmoothness into the\ndynamical system. In this work, we utilize so-called equivalent contact points\n(ECP), which parameterize force and impulse distributions on contact patches by\nevaluation at single points. We embed a nondifferentiable SDF into a\ncomplementarity Lagrangian system (CLS) and show that the determined ECP are\nwell-defined. We then extend the FESD-J discretization to the considered CLS\nsuch that its integration accuracy is maintained. The functionality of the\nmethod is illustrated for both a simulation and an optimal control example.\n","authors":["Christian Dietz","Armin Nurkanović","Sebastian Albrecht","Moritz Diehl"],"pdf_url":"https://arxiv.org/pdf/2403.13931v1.pdf","comment":"Shortened version submitted to 2024 Conference on Decision and\n  Control (CDC)"},{"id":"http://arxiv.org/abs/2403.13898v1","updated":"2024-03-20T18:09:57Z","published":"2024-03-20T18:09:57Z","title":"Optimal Risk-Sensitive Scheduling Policies for Remote Estimation of\n  Autoregressive Markov Processes","summary":"  We design scheduling policies that minimize a risk-sensitive cost criterion\nfor a remote estimation setup. Since risk-sensitive cost objective takes into\naccount not just the mean value of the cost, but also higher order moments of\nits probability distribution, the resulting policy is robust to changes in the\nunderlying system's parameters. The setup consists of a sensor that observes a\ndiscrete-time autoregressive Markov process, and at each time $t$ decides\nwhether or not to transmit its observations to a remote estimator using an\nunreliable wireless communication channel after encoding these observations\ninto data packets. We model the communication channel as a Gilbert-Elliott\nchannel \\cite{10384144}. Sensor probes the channel \\cite{laourine2010betting}\nand hence knows the channel state at each time $t$ before making scheduling\ndecision. The scheduler has to minimize the expected value of the exponential\nof the finite horizon cumulative cost that is sum of the following two\nquantities (i) the cumulative transmission power consumed, (ii) the cumulative\nsquared estimator error. We pose this dynamic optimization problem as a Markov\ndecision process (MDP), in which the system state at time $t$ is composed of\n(i) the instantaneous error $\\Delta(t):= x(t)-a\\hat{x}(t-1)$, where\n$x(t),\\hat{x}(t-1)$ are the system state and the estimate at time $t,t-1$\nrespectively, and (ii) the channel state $c(t)$. We show that there exists an\noptimal policy that has a threshold structure, i.e., at each time $t$, for each\npossible channel state $c$, there is a threshold $\\D\\ust(c)$ such that if the\ncurrent channel state is $c$, then it transmits only when the error $\\D(t)$\nexceeds $\\D\\ust(c)$.\n","authors":["Manali Dutta","Rahul Singh"],"pdf_url":"https://arxiv.org/pdf/2403.13898v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13868v1","updated":"2024-03-20T13:39:19Z","published":"2024-03-20T13:39:19Z","title":"Analysing heavy-tail properties of Stochastic Gradient Descent by means\n  of Stochastic Recurrence Equations","summary":"  In recent works on the theory of machine learning, it has been observed that\nheavy tail properties of Stochastic Gradient Descent (SGD) can be studied in\nthe probabilistic framework of stochastic recursions. In particular,\nG\\\"{u}rb\\\"{u}zbalaban et al. (arXiv:2006.04740) considered a setup\ncorresponding to linear regression for which iterations of SGD can be modelled\nby a multivariate affine stochastic recursion $X_k=A_k X_{k-1}+B_k$, for\nindependent and identically distributed pairs $(A_k, B_k)$, where $A_k$ is a\nrandom symmetric matrix and $B_k$ is a random vector. In this work, we will\nanswer several open questions of the quoted paper and extend their results by\napplying the theory of irreducible-proximal (i-p) matrices.\n","authors":["Ewa Damek","Sebastian Mentemeier"],"pdf_url":"https://arxiv.org/pdf/2403.13868v1.pdf","comment":"25 pages, 2 figures"},{"id":"http://arxiv.org/abs/2403.13862v1","updated":"2024-03-20T03:49:23Z","published":"2024-03-20T03:49:23Z","title":"A necessary condition for non-monotonic dose response, with an\n  application to a kinetic proofreading model -- Extended version","summary":"  Steady state non-monotonic (\"biphasic\") dose responses are often observed in\nexperimental biology, which raises the control-theoretic question of\nidentifying which possible mechanisms might underlie such behaviors. It is well\nknown that the presence of an incoherent feedforward loop (IFFL) in a network\nmay give rise to a non-monotonic response. It has been conjectured that this\ncondition is also necessary, i.e. that a non-monotonic response implies the\nexistence of an IFFL. In this paper, we show that this conjecture is false, and\nin the process prove a weaker version: that either an IFFL must exist or both a\npositive loop and a negative feedback loop must exist. Towards this aim, we\ngive necessary and sufficient conditions for when minors of a symbolic matrix\nhave mixed signs. Finally, we study in full generality when a model of immune\nT-cell activation could exhibit a steady state non-monotonic dose response.\n","authors":["Polly Y. Yu","Eduardo D. Sontag"],"pdf_url":"https://arxiv.org/pdf/2403.13862v1.pdf","comment":"Appendix included"}],"Systems and Control":[{"id":"http://arxiv.org/abs/2403.13730v1","updated":"2024-03-20T16:39:48Z","published":"2024-03-20T16:39:48Z","title":"Projection-free computation of robust controllable sets with constrained\n  zonotopes","summary":"  We study the problem of computing robust controllable sets for discrete-time\nlinear systems with additive uncertainty. We propose a tractable and scalable\napproach to inner- and outer-approximate robust controllable sets using\nconstrained zonotopes, when the additive uncertainty set is a symmetric,\nconvex, and compact set. Our least-squares-based approach uses novel\nclosed-form approximations of the Pontryagin difference between a constrained\nzonotopic minuend and a symmetric, convex, and compact subtrahend. Unlike\nexisting approaches, our approach does not rely on convex optimization solvers,\nand is projection-free for ellipsoidal and zonotopic uncertainty sets. We also\npropose a least-squares-based approach to compute a convex, polyhedral\nouter-approximation to constrained zonotopes, and characterize sufficient\nconditions under which all these approximations are exact. We demonstrate the\ncomputational efficiency and scalability of our approach in several case\nstudies, including the design of abort-safe rendezvous trajectories for a\nspacecraft in near-rectilinear halo orbit under uncertainty. Our approach can\ninner-approximate a 20-step robust controllable set for a 100-dimensional\nlinear system in under 15 seconds on a standard computer.\n","authors":["Abraham P. Vinod","Avishai Weiss","Stefano Di Cairano"],"pdf_url":"https://arxiv.org/pdf/2403.13730v1.pdf","comment":"22 pages, 6 figures"},{"id":"http://arxiv.org/abs/2403.09184v2","updated":"2024-03-20T16:34:37Z","published":"2024-03-14T08:54:19Z","title":"Learning Algorithms for Verification of Markov Decision Processes","summary":"  We present a general framework for applying learning algorithms and\nheuristical guidance to the verification of Markov decision processes (MDPs).\nThe primary goal of our techniques is to improve performance by avoiding an\nexhaustive exploration of the state space, instead focussing on particularly\nrelevant areas of the system, guided by heuristics. Our work builds on the\nprevious results of Br{\\'{a}}zdil et al., significantly extending it as well as\nrefining several details and fixing errors.\n  The presented framework focuses on probabilistic reachability, which is a\ncore problem in verification, and is instantiated in two distinct scenarios.\nThe first assumes that full knowledge of the MDP is available, in particular\nprecise transition probabilities. It performs a heuristic-driven partial\nexploration of the model, yielding precise lower and upper bounds on the\nrequired probability. The second tackles the case where we may only sample the\nMDP without knowing the exact transition dynamics. Here, we obtain\nprobabilistic guarantees, again in terms of both the lower and upper bounds,\nwhich provides efficient stopping criteria for the approximation. In\nparticular, the latter is an extension of statistical model-checking (SMC) for\nunbounded properties in MDPs. In contrast to other related approaches, we do\nnot restrict our attention to time-bounded (finite-horizon) or discounted\nproperties, nor assume any particular structural properties of the MDP.\n","authors":["Tomáš Brázdil","Krishnendu Chatterjee","Martin Chmelik","Vojtěch Forejt","Jan Křetínský","Marta Kwiatkowska","Tobias Meggendorfer","David Parker","Mateusz Ujma"],"pdf_url":"https://arxiv.org/pdf/2403.09184v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.12218v2","updated":"2024-03-20T16:12:32Z","published":"2024-03-18T20:02:31Z","title":"Secure Synchronization of Heterogeneous Pulse-Coupled Oscillators","summary":"  In this paper, we consider the synchronization of heterogeneous pulse-coupled\noscillators (PCOs), where some of the oscillators might be faulty or malicious.\nThe oscillators interact through identical pulses at discrete instants and\nevolve continuously with different frequencies otherwise. Despite the presence\nof misbehaviors, benign oscillators aim to reach synchronization. To achieve\nthis objective, two resilient synchronization protocols are developed in this\npaper by adapting the real-valued mean-subsequence reduced (MSR) algorithm to\npulse-based interactions. The first protocol relies on packet-based\ncommunication to transmit absolute frequencies, while the second protocol\noperates purely with pulses to calculate relative frequencies. In both\nprotocols, each normal oscillator periodically counts the received pulses to\ndetect possible malicious behaviors. By disregarding suspicious pulses from its\nneighbors, the oscillator updates both its phases and frequencies. The paper\nestablishes sufficient conditions on the initial states and graph structure\nunder which resilient synchronization is achieved in the PCO network.\nSpecifically, the normal oscillators can either detect the presence of\nmalicious nodes or synchronize in both phases and frequencies. Additionally, a\ncomparison between the two algorithms reveals a trade-off between relaxed\ninitial conditions and reduced communication burden.\n","authors":["Jiaqi Yan","Hideaki Ishii"],"pdf_url":"https://arxiv.org/pdf/2403.12218v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13707v1","updated":"2024-03-20T16:10:36Z","published":"2024-03-20T16:10:36Z","title":"On Optimal Management of Energy Storage Systems in Renewable Energy\n  Communities","summary":"  Renewable energy communities are legal entities involving the association of\ncitizens, organizations and local businesses aimed at contributing to the green\nenergy transition and providing social, environmental and economic benefits to\ntheir members. This goal is pursued through the cooperative efforts of the\ncommunity actors and by increasing the local energy self-consumption. In this\npaper, the optimal energy community operation in the presence of energy storage\nunits is addressed. By exploiting the flexibility provided by the storage\nfacilities, the main task is to minimize the community energy bill by taking\nadvantage of incentives related to local self-consumption. Optimality\nconditions are derived, and an explicit optimal solution is devised. Numerical\nsimulations are provided to assess the performance of the proposed solution.\n","authors":["Giovanni Gino Zanvettor","Marco Casini","Antonio Vicino"],"pdf_url":"https://arxiv.org/pdf/2403.13707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10026v2","updated":"2024-03-20T15:30:31Z","published":"2023-11-16T17:14:26Z","title":"Guaranteeing Control Requirements via Reward Shaping in Reinforcement\n  Learning","summary":"  In addressing control problems such as regulation and tracking through\nreinforcement learning, it is often required to guarantee that the acquired\npolicy meets essential performance and stability criteria such as a desired\nsettling time and steady-state error prior to deployment. Motivated by this\nnecessity, we present a set of results and a systematic reward shaping\nprocedure that (i) ensures the optimal policy generates trajectories that align\nwith specified control requirements and (ii) allows to assess whether any given\npolicy satisfies them. We validate our approach through comprehensive numerical\nexperiments conducted in two representative environments from OpenAI Gym: the\nInverted Pendulum swing-up problem and the Lunar Lander. Utilizing both tabular\nand deep reinforcement learning methods, our experiments consistently affirm\nthe efficacy of our proposed framework, highlighting its effectiveness in\nensuring policy adherence to the prescribed control requirements.\n","authors":["Francesco De Lellis","Marco Coraggio","Giovanni Russo","Mirco Musolesi","Mario di Bernardo"],"pdf_url":"https://arxiv.org/pdf/2311.10026v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13664v1","updated":"2024-03-20T15:15:28Z","published":"2024-03-20T15:15:28Z","title":"Adaptive Reconstruction of Nonlinear Systems States via DREM with\n  Perturbation Annihilation","summary":"  A new adaptive observer is proposed for a certain class of nonlinear systems\nwith bounded unknown input and parametric uncertainty. Unlike most existing\nsolutions, the proposed approach ensures asymptotic convergence of the unknown\nparameters, state and perturbation estimates to an arbitrarily small\nneighborhood of the equilibrium point. The solution is based on the novel\naugmentation of a high-gain observer with the dynamic regressor extension and\nmixing (DREM) procedure enhanced with a perturbation annihilation algorithm.\nThe aforementioned properties of the proposed solution are verified via\nnumerical experiments.\n","authors":["Anton Glushchenko","Konstantin Lastochkin"],"pdf_url":"https://arxiv.org/pdf/2403.13664v1.pdf","comment":"6 pages, 2 figures"},{"id":"http://arxiv.org/abs/2403.11076v2","updated":"2024-03-20T15:08:36Z","published":"2024-03-17T03:56:15Z","title":"Unbiased Parameter Estimation via DREM with Annihilators","summary":"  In the adaptive control theory, the dynamic regressor extension and mixing\n(DREM) procedure has become widespread as it allows one to describe a variety\nof adaptive control problems in unified terms of the parameter estimation\nproblem of a regression equation with a scalar regressor. However, when the\nsystem/parameterization is affected by perturbations, the estimation laws,\nwhich are designed on the basis of such equation, asymptotically provides only\nbiased estimates. In this paper, based on the bias-eliminated least-squares\n(BELS) approach, a modification of the DREM procedure is proposed that allows\none to annihilate perturbations asymptotically and, consequently,\nasymptotically obtain unbiased estimates. The theoretical results are supported\nwith mathematical modelling and can be used to design adaptive observers and\ncontrol systems.\n","authors":["Anton Glushchenko","Konstantin Lastochkin"],"pdf_url":"https://arxiv.org/pdf/2403.11076v2.pdf","comment":"7 pages, 2 figures"},{"id":"http://arxiv.org/abs/2304.02433v2","updated":"2024-03-20T15:08:15Z","published":"2023-04-05T13:34:24Z","title":"On Continuous Full-Order Integral-Terminal Sliding Mode Control with\n  Unknown Apriori Bound on Uncertainty","summary":"  This study aims at providing a solution to the problem of designing a\ncontinuous and finite-time control for a class of nonlinear systems in the\npresence of matched uncertainty with an unknown apriori bound. First, we\npropose a Full-Order Integral-Terminal Sliding Manifold (FOITSM) with a\nconventional (discontinuous) sliding mode to show that it provides the combined\nattributes of the nonsingular terminal and integral sliding mode algorithms.\nSecondly, an Adaptive Disturbance Observer (ADO) has been designed to alleviate\nthe effect of the uncertainty acting on the system. On application of the\nADO-based Full-Order Integral-Terminal Sliding Mode Control (FOITSMC), the\nchattering phenomenon in control input has been reduced substantially in the\npresence of conditionally known matched disturbances. Moreover, the adaptive\ngains of ADO are updated non-monotonically without over-bounding the acting\ndisturbance, yet sustain the global boundedness of state trajectories within a\nspecific bound. %Finally, an application of the proposed algorithm for attitude\nstabilization of a rigid spacecraft has been successively shown.\n","authors":["Jit Koley","Dinesh Patra","Binoy Krishna Roy"],"pdf_url":"https://arxiv.org/pdf/2304.02433v2.pdf","comment":"14 pages, 9 figures"},{"id":"http://arxiv.org/abs/2403.13651v1","updated":"2024-03-20T14:57:50Z","published":"2024-03-20T14:57:50Z","title":"Macroscopic pricing schemes for the utilization of pool ride-hailing\n  vehicles in bus lanes","summary":"  With the increasing popularity of ride-hailing services, new modes of\ntransportation are having a significant impact on the overall performance of\ntransportation networks. As a result, there is a need to ensure that both the\nvarious transportation alternatives and the spatial network resources are used\nefficiently. In this work, we analyze a network configuration where part of the\nurban transportation network is devoted to dedicated bus lanes. Apart from\nbuses, we let pool ride-hailing trips use the dedicated bus lanes which,\ncontingent upon the demand for the remaining modes, may result in faster trips\nfor users opting for the pooling alternative. Under an aggregated modelling\nframework, we characterize the spatial configuration and the multi-modal demand\nsplit for which this strategy achieves a system optimum. For these specific\nscenarios, we compute the equilibrium when ride-hailing users can choose\nbetween solo and pool services, and we provide a pricing scheme for mitigating\nthe gap between total user delays of the system optimum and user equilibrium\nsolutions, when needed.\n","authors":["Lynn Fayed","Gustav Nilsson","Nikolas Geroliminis"],"pdf_url":"https://arxiv.org/pdf/2403.13651v1.pdf","comment":"Extended version of paper accepted to European Control Conference\n  (ECC) 2024"},{"id":"http://arxiv.org/abs/2403.13648v1","updated":"2024-03-20T14:55:36Z","published":"2024-03-20T14:55:36Z","title":"Priority-based Energy Allocation in Buildings for Distributed Model\n  Predictive Control","summary":"  Many countries are facing energy shortage today and most of the global energy\nis consumed by HVAC systems in buildings. For the scenarios where the energy\nsystem is not sufficiently supplied to HVAC systems, a priority-based\nallocation scheme based on distributed model predictive control is proposed in\nthis paper, which distributes the energy rationally based on priority order.\nAccording to the scenarios, two distributed allocation strategies, i.e.,\none-to-one priority strategy and multi-to-one priority strategy, are developed\nin this paper and validated by simulation in a building containing three zones\nand a building containing 36 rooms, respectively. Both strategies fully exploit\nthe potential of predictive control solutions. The experiment shows that our\nscheme has good scalability and achieve the performance of centralized strategy\nwhile making the calculation tractable.\n","authors":["Hongyi Li","Jun Xu"],"pdf_url":"https://arxiv.org/pdf/2403.13648v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13609v1","updated":"2024-03-20T14:01:07Z","published":"2024-03-20T14:01:07Z","title":"3D Directed Formation Control with Global Shape Convergence using\n  Bispherical Coordinates","summary":"  In this paper, we present a novel 3D formation control scheme for directed\ngraphs in a leader-follower configuration, achieving (almost) global\nconvergence to the desired shape. Specifically, we introduce three controlled\nvariables representing bispherical coordinates that uniquely describe the\nformation in 3D. Acyclic triangulated directed graphs (a class of minimally\nacyclic persistent graphs) are used to model the inter-agent sensing topology,\nwhile the agents' dynamics are governed by single-integrator model. Our\nanalysis demonstrates that the proposed decentralized formation controller\nensures (almost) global asymptotic stability while avoiding potential shape\nambiguities in the final formation. Furthermore, the control laws are\nimplementable in arbitrarily oriented local coordinate frames of follower\nagents using only low-cost onboard vision sensors, making it suitable for\npractical applications. Finally, we validate our formation control approach by\na simulation study.\n","authors":["Omid Mirzaeedodangeh","Farhad Mehdifar","Dimos V. Dimarogonas"],"pdf_url":"https://arxiv.org/pdf/2403.13609v1.pdf","comment":"Submitted to ECC 2024"},{"id":"http://arxiv.org/abs/2403.13605v1","updated":"2024-03-20T13:55:04Z","published":"2024-03-20T13:55:04Z","title":"Optimal control of continuous-time symmetric systems with unknown\n  dynamics and noisy measurements","summary":"  An iterative learning algorithm is presented for continuous-time\nlinear-quadratic optimal control problems where the system is externally\nsymmetric with unknown dynamics. Both finite-horizon and infinite-horizon\nproblems are considered. It is shown that the proposed algorithm is globally\nconvergent to the optimal solution and has some advantages over adaptive\ndynamic programming, including being unbiased under noisy measurements and\nhaving a relatively low computational burden. Numerical experiments show the\neffectiveness of the results.\n","authors":["Hamed Taghavian","Florian Dorfler","Mikael Johansson"],"pdf_url":"https://arxiv.org/pdf/2403.13605v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13602v1","updated":"2024-03-20T13:49:09Z","published":"2024-03-20T13:49:09Z","title":"Bayesian Physics-informed Neural Networks for System Identification of\n  Inverter-dominated Power Systems","summary":"  While the uncertainty in generation and demand increases, accurately\nestimating the dynamic characteristics of power systems becomes crucial for\nemploying the appropriate control actions to maintain their stability. In our\nprevious work, we have shown that Bayesian Physics-informed Neural Networks\n(BPINNs) outperform conventional system identification methods in identifying\nthe power system dynamic behavior under measurement noise. This paper takes the\nnext natural step and addresses the more significant challenge, exploring how\nBPINN perform in estimating power system dynamics under increasing uncertainty\nfrom many Inverter-based Resources (IBRs) connected to the grid. These\nintroduce a different type of uncertainty, compared to noisy measurements. The\nBPINN combines the advantages of Physics-informed Neural Networks (PINNs), such\nas inverse problem applicability, with Bayesian approaches for uncertainty\nquantification. We explore the BPINN performance on a wide range of systems,\nstarting from a single machine infinite bus (SMIB) system and 3-bus system to\nextract important insights, to the 14-bus CIGRE distribution grid, and the\nlarge IEEE 118-bus system. We also investigate approaches that can accelerate\nthe BPINN training, such as pretraining and transfer learning. Throughout this\npaper, we show that in presence of uncertainty, the BPINN achieves orders of\nmagnitude lower errors than the widely popular method for system identification\nSINDy and significantly lower errors than PINN, while transfer learning helps\nreduce training time by up to 80 %.\n","authors":["Simon Stock","Davood Babazadeh","Christian Becker","Spyros Chatzivasileiadis"],"pdf_url":"https://arxiv.org/pdf/2403.13602v1.pdf","comment":"Submitted to Electric Power Systems Research"},{"id":"http://arxiv.org/abs/2403.13601v1","updated":"2024-03-20T13:49:06Z","published":"2024-03-20T13:49:06Z","title":"Lattice piecewise affine approximation of explicit model predictive\n  control with application to satellite attitude control","summary":"  Satellite attitude cotrol is a crucial part of aerospace technology, and\nmodel predictive control(MPC) is one of the most promising controllers in this\narea, which will be less effective if real-time online optimization can not be\nachieved. Explicit MPC converts the online calculation into a table lookup\nprocess, however the solution is difficult to obtain if the system dimension is\nhigh or the constraints are complex. The lattice piecewise affine(PWA) function\nwas used to represent the control law of explicit MPC, although the online\ncalculation complexity is reduced, the offline calculation is still prohibitive\nfor complex problems. In this paper, we use the sample points in the feasible\nregion with their corresponding affine functions to construct the lattice PWA\napproximation of the optimal MPC controller designed for satellite attitude\ncontrol. The asymptotic stability of satellite attitude control system under\nlattice PWA approximation has been proven, and simulations are executed to\nverify that the proposed method can achieve almost the same performance as\nlinear online MPC with much lower online computational complexity and use less\nfuel than LQR method.\n","authors":["Zhengqi Xu","Jun Xu","Ai-Guo Wu","Shuning Wang"],"pdf_url":"https://arxiv.org/pdf/2403.13601v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13562v1","updated":"2024-03-20T12:54:05Z","published":"2024-03-20T12:54:05Z","title":"Augmented Labeled Random Finite Sets and Its Application to Group Target\n  Tracking","summary":"  This paper addresses the problem of group target tracking (GTT), wherein\nmultiple closely spaced targets within a group pose a coordinated motion. To\nimprove the tracking performance, the labeled random finite sets (LRFSs) theory\nis adopted, and this paper develops a new kind of LRFSs, i.e., augmented LRFSs,\nwhich introduces group information into the definition of LRFSs. Specifically,\nfor each element in an LRFS, the kinetic states, track label, and the\ncorresponding group information of its represented target are incorporated.\nFurthermore, by means of the labeled multi-Bernoulli (LMB) filter with the\nproposed augmented LRFSs, the group structure is iteratively propagated and\nupdated during the tracking process, which achieves the simultaneously\nestimation of the kinetic states, track label, and the corresponding group\ninformation of multiple group targets, and further improves the GTT tracking\nperformance. Finally, simulation experiments are provided, which well\ndemonstrates the effectiveness of the labeled multi-Bernoulli filter with the\nproposed augmented LRFSs for GTT tracking.\n","authors":["Chaoqun Yang","Mengdie Xu","Xiaowei Liang","Heng Zhang","Xianghui Cao"],"pdf_url":"https://arxiv.org/pdf/2403.13562v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11833v2","updated":"2024-03-20T12:50:32Z","published":"2023-11-20T15:09:22Z","title":"Towards Perturbation-Induced Static Pivoting on GPU-Based Linear Solvers","summary":"  Linear system solving is a key tool for computational power system studies,\ne.g., optimal power flow, transmission switching, or unit commitment. CPU-based\nlinear system solver speeds, however, have saturated in recent years. Emerging\nresearch shows that GPU-based linear system solvers are beginning to achieve\nnotable speedup over CPU-based alternatives in some applications. Due to the\narchitecture of GPU memory access, numerical pivoting represents the new\nbottleneck which prevents GPU-based solvers from running even faster.\nAccordingly, this paper proposes a matrix perturbation-based method to induce\nstatic pivoting. Using this approach, a series of perturbed, well-conditioned,\npivot-free linear systems are solved in parallel on GPUs. Matrix expansion\nroutines are then used to linearly combine the results, and the true solution\nis recovered to an arbitrarily high degree of theoretical accuracy. We showcase\nthe validity of our approach on distributed-slack AC power flow solve\niterations associated with the PGLib 300-bus test case.\n","authors":["Samuel Chevalier","Robert Parker"],"pdf_url":"https://arxiv.org/pdf/2311.11833v2.pdf","comment":"submitted to PESGM 2024"},{"id":"http://arxiv.org/abs/2403.13547v1","updated":"2024-03-20T12:33:51Z","published":"2024-03-20T12:33:51Z","title":"Integrating Large Language Models for Severity Classification in Traffic\n  Incident Management: A Machine Learning Approach","summary":"  This study evaluates the impact of large language models on enhancing machine\nlearning processes for managing traffic incidents. It examines the extent to\nwhich features generated by modern language models improve or match the\naccuracy of predictions when classifying the severity of incidents using\naccident reports. Multiple comparisons performed between combinations of\nlanguage models and machine learning algorithms, including Gradient Boosted\nDecision Trees, Random Forests, and Extreme Gradient Boosting. Our research\nuses both conventional and language model-derived features from texts and\nincident reports, and their combinations to perform severity classification.\nIncorporating features from language models with those directly obtained from\nincident reports has shown to improve, or at least match, the performance of\nmachine learning techniques in assigning severity levels to incidents,\nparticularly when employing Random Forests and Extreme Gradient Boosting\nmethods. This comparison was quantified using the F1-score over uniformly\nsampled data sets to obtain balanced severity classes. The primary contribution\nof this research is in the demonstration of how Large Language Models can be\nintegrated into machine learning workflows for incident management, thereby\nsimplifying feature extraction from unstructured text and enhancing or matching\nthe precision of severity predictions using conventional machine learning\npipeline. The engineering application of this research is illustrated through\nthe effective use of these language processing models to refine the modelling\nprocess for incident severity classification. This work provides significant\ninsights into the application of language processing capabilities in\ncombination with traditional data for improving machine learning pipelines in\nthe context of classifying incident severity.\n","authors":["Artur Grigorev","Khaled Saleh","Yuming Ou","Adriana-Simona Mihaita"],"pdf_url":"https://arxiv.org/pdf/2403.13547v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13502v1","updated":"2024-03-20T10:59:06Z","published":"2024-03-20T10:59:06Z","title":"Adversarial Attacks and Defenses in Automated Control Systems: A\n  Comprehensive Benchmark","summary":"  Integrating machine learning into Automated Control Systems (ACS) enhances\ndecision-making in industrial process management. One of the limitations to the\nwidespread adoption of these technologies in industry is the vulnerability of\nneural networks to adversarial attacks. This study explores the threats in\ndeploying deep learning models for fault diagnosis in ACS using the Tennessee\nEastman Process dataset. By evaluating three neural networks with different\narchitectures, we subject them to six types of adversarial attacks and explore\nfive different defense methods. Our results highlight the strong vulnerability\nof models to adversarial samples and the varying effectiveness of defense\nstrategies. We also propose a novel protection approach by combining multiple\ndefense methods and demonstrate it's efficacy. This research contributes\nseveral insights into securing machine learning within ACS, ensuring robust\nfault diagnosis in industrial processes.\n","authors":["Vitaliy Pozdnyakov","Aleksandr Kovalenko","Ilya Makarov","Mikhail Drobyshevskiy","Kirill Lukyanov"],"pdf_url":"https://arxiv.org/pdf/2403.13502v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13473v1","updated":"2024-03-20T10:22:13Z","published":"2024-03-20T10:22:13Z","title":"Distributed Cooperative Formation Control of Nonlinear Multi-Agent\n  System (UGV) Using Neural Network","summary":"  The paper presented in this article deals with the issue of distributed\ncooperative formation of multi-agent systems (MASs). It proposes the use of\nappropriate neural network control methods to address formation requirements\n(uncertainties dynamic model). It considers an adaptive leader-follower\ndistributed cooperative formation control based on neural networks (NNs)\ndeveloped for a class of second-order nonlinear multi-agent systems and neural\nnetworks Neural networks are used to compute system data that inputs layer\n(position, velocity), hidden layers, and output layer. Through collaboration\nbetween leader-follower approaches and neural networks with complex systems or\ncomplex conditions receive an effective cooperative formation control method.\nThe sufficient conditions for the system stability were derived using Lyapunov\nstability theory, graph theory, and state space methods. By simulation, the\nresults of this study can be obtained from the main data of the multi-agent\nsystem in formation control and verified that the system can process\nconsistency, stability, reliability, and accuracy in cooperative formation.\n","authors":["Si Kheang Moeurn"],"pdf_url":"https://arxiv.org/pdf/2403.13473v1.pdf","comment":"6 pages, 5 figures"},{"id":"http://arxiv.org/abs/2403.13440v1","updated":"2024-03-20T09:28:09Z","published":"2024-03-20T09:28:09Z","title":"An Extended Kuramoto Model for Frequency and Phase Synchronization in\n  Delay-Free Networks with Finite Number of Agents","summary":"  Due to its description of a synchronization between oscillators, the Kuramoto\nmodel is an ideal choice for a synchronisation algorithm in networked systems.\nThis requires to achieve not only a frequency synchronization but also a phase\nsynchronization - something the standard Kuramoto model can not provide for a\nfinite number of agents. In this case, a remaining phase difference is\nnecessary to offset differences of the natural frequencies. Setting the\nKuramoto model into the context of dynamic consensus and making use of the\n$n$th order discrete average consensus algorithm, this paper extends the\nstandard Kuramoto model in such a way that frequency and phase synchronization\nare separated. This in turn leads to an algorithm achieve the required\nfrequency and phase synchronization also for a finite number of agents.\nSimulations show the viability of this extended Kuramoto model.\n","authors":["Andreas Bathelt","Vimukthi Herath","Thomas Dallmann"],"pdf_url":"https://arxiv.org/pdf/2403.13440v1.pdf","comment":"8 pages, 6 figures. Shorter version submitted to the 63rd IEEE\n  Conference on Decision and Control, 2024. Funded by BMBF through 6GEM\n  research hub (16KISK038) and by DFG through project JCRS CoMP (504990291)"},{"id":"http://arxiv.org/abs/2303.05100v3","updated":"2024-03-20T09:15:11Z","published":"2023-03-09T08:19:35Z","title":"Design of Efficient Point-Mass Filter with Application in Terrain Aided\n  Navigation","summary":"  This paper deals with state estimation of stochastic models with linear state\ndynamics, continuous or discrete in time. The emphasis is laid on a numerical\nsolution to the state prediction by the time-update step of the\ngrid-point-based point-mass filter (PMF), which is the most computationally\ndemanding part of the PMF algorithm. A novel efficient PMF (ePMF) estimator,\nunifying continuous and discrete, approaches is proposed, designed, and\ndiscussed. By numerical illustrations, it is shown, that the proposed ePMF can\nlead to a time complexity reduction that exceeds 99.9% without compromising\naccuracy. The MATLAB code of the ePMF is released with this paper.\n","authors":["J. Matoušek","J. Duník","M. Brandner"],"pdf_url":"https://arxiv.org/pdf/2303.05100v3.pdf","comment":"Pulibshed in proccedings of FUSION 2023. PLEASE cite the published\n  version! The code is also now available at GitHub:\n  https://github.com/IDM-UWB/efficient-PMF"},{"id":"http://arxiv.org/abs/2402.17277v3","updated":"2024-03-20T08:50:03Z","published":"2024-02-27T07:46:54Z","title":"RISAR: RIS-assisted Human Activity Recognition with Commercial Wi-Fi\n  Devices","summary":"  Human activity recognition (HAR) holds significant importance in smart homes,\nsecurity, and healthcare. Existing systems face limitations because of the\ninsufficient spatial diversity provided by a limited number of antennas.\nFurthermore, inefficiencies in noise reduction and feature extraction from\nsensing data pose challenges to recognition performance. This study presents a\nreconfigurable intelligent surface (RIS)-assisted passive human activity\nrecognition (RISAR) method, compatible with commercial Wi-Fi devices. RISAR\nleverages a RIS to enhance the spatial diversity of Wi-Fi signals, effectively\ncapturing a wider range of information distributed across the spatial domain. A\nnovel high-dimensional factor model based on random matrix theory is proposed\nto address noise reduction and feature extraction in the temporal domain. A\ndual-stream spatial-temporal attention network model is developed to assign\nvariable weights to different characteristics and sequences, mimicking human\ncognitive processes in prioritizing essential information. Experimental\nanalysis shows that RISAR significantly outperforms existing HAR methods in\naccuracy and efficiency, achieving an average accuracy of 97.26%. These\nfindings underscore RISAR's adaptability and potential as a robust activity\nrecognition solution in real environments.\n","authors":["Junshuo Liu","Yunlong Huang","Wei Yang","Zhe Li","Rujing Xiong","Tiebin Mi","Xin Shi","Robert C. Qiu"],"pdf_url":"https://arxiv.org/pdf/2402.17277v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13373v1","updated":"2024-03-20T08:09:11Z","published":"2024-03-20T08:09:11Z","title":"Charged Momentum: Electric Vehicle Surge in India's 2023 Landscape","summary":"  Electric vehicles (EVs) have emerged as a transformative force in India's\ntransportation sector, offering a sustainable solution to the country's growing\nenergy and environmental challenges. Against the backdrop of rapid\nurbanization, rising pollution levels, and the need for energy security, EVs\nhave gained traction as a viable alternative to traditional internal combustion\nengine vehicles. This paper provides a comprehensive analysis of the electric\nvehicle market in India, focusing particularly on the landscape of 2023. It\nemphasizes key aspects such as the 2023 scenario of EV adoption, the role of\nindigenous manufacturers, dominant players shaping the market, and the\ninfluence of government policies and initiatives, including the FAME I and II\nschemes. Furthermore, the paper delves into EV sales data for the fiscal year\n2023, offering insights into market trends and consumer preferences. By\nelucidating the current state of EVs in India, this paper aims to contribute to\na deeper understanding of the country's transition towards sustainable mobility\nand its implications for energy, environment, and economy.\n","authors":["Rahul Wagh"],"pdf_url":"https://arxiv.org/pdf/2403.13373v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13367v1","updated":"2024-03-20T07:53:41Z","published":"2024-03-20T07:53:41Z","title":"Quantifying the Aggregate Flexibility of EV Charging Stations for\n  Dependable Congestion Management Products: A Dutch Case Study","summary":"  Electric vehicles (EVs) play a crucial role in the transition towards\nsustainable modes of transportation and thus are critical to the energy\ntransition. As their number grows, managing the aggregate power of EV charging\nis crucial to maintain grid stability and mitigate congestion. This study\nanalyses more than 500 thousand real charging transactions in the Netherlands\nto explore the challenge and opportunity for the energy system presented by EV\ngrowth and smart charging flexibility. Specifically, it analyses the collective\nability to provide congestion management services according to the\nspecifications of those services in the Netherlands. In this study, a\ndata-driven model of charging behaviour is created to explore the implications\nof delivering dependable congestion management services at various aggregation\nlevels and types of service. The probability of offering specific grid services\nby different categories of charging stations (CS) is analysed. These\nprobabilities can help EV aggregators, such as charging point operators, make\ninformed decisions about offering congestion mitigation products per relevant\nregulations and distribution system operators to assess their potential. The\nability to offer different flexibility products, namely re-dispatch and\ncapacity limitation, for congestion management, is assessed using various\ndispatch strategies. Next, machine learning models are used to predict the\nprobability of CSs being able to deliver these products, accounting for\nuncertainties. Results indicate that residential charging locations have\nsignificant potential to provide both products during evening peak hours. While\nshared EVs offer better certainty regarding arrival and departure times, their\nsmall fleet size currently restricts their ability to meet the minimum order\nsize of flexible products.\n","authors":["Nanda Kishor Panda","Simon H. Tindemans"],"pdf_url":"https://arxiv.org/pdf/2403.13367v1.pdf","comment":"18 Pages,13 figures, 2 tables"},{"id":"http://arxiv.org/abs/2403.13346v1","updated":"2024-03-20T07:10:22Z","published":"2024-03-20T07:10:22Z","title":"A Control-Recoverable Added-Noise-based Privacy Scheme for LQ Control in\n  Networked Control Systems","summary":"  As networked control systems continue to evolve, ensuring the privacy of\nsensitive data becomes an increasingly pressing concern, especially in\nsituations where the controller is physically separated from the plant. In this\npaper, we propose a secure control scheme for computing linear quadratic\ncontrol in a networked control system utilizing two networked controllers, a\nprivacy encoder and a control restorer. Specifically, the encoder generates two\nstate signals blurred with random noise and sends them to the controllers,\nwhile the restorer reconstructs the correct control signal. The proposed design\neffectively preserves the privacy of the control system's state without\nsacrificing the control performance. We theoretically quantify the\nprivacy-preserving performance in terms of the state estimation error of the\ncontrollers and the disclosure probability. Additionally, the proposed\nprivacy-preserving scheme is also proven to satisfy differential privacy.\nMoreover, we extend the proposed privacy-preserving scheme and evaluation\nmethod to cases where collusion between two controllers occurs. Finally, we\nverify the validity of our proposed scheme through simulations.\n","authors":["Xuening Tang","Xianghui Cao","Wei Xing Zheng"],"pdf_url":"https://arxiv.org/pdf/2403.13346v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06742v2","updated":"2024-03-20T05:43:00Z","published":"2023-07-13T13:31:01Z","title":"Vehicle Dispatching and Routing of On-Demand Intercity Ride-Pooling\n  Services: A Multi-Agent Hierarchical Reinforcement Learning Approach","summary":"  The integrated development of city clusters has given rise to an increasing\ndemand for intercity travel. Intercity ride-pooling service exhibits\nconsiderable potential in upgrading traditional intercity bus services by\nimplementing demand-responsive enhancements. Nevertheless, its online\noperations suffer the inherent complexities due to the coupling of vehicle\nresource allocation among cities and pooled-ride vehicle routing. To tackle\nthese challenges, this study proposes a two-level framework designed to\nfacilitate online fleet management. Specifically, a novel multi-agent feudal\nreinforcement learning model is proposed at the upper level of the framework to\ncooperatively assign idle vehicles to different intercity lines, while the\nlower level updates the routes of vehicles using an adaptive large neighborhood\nsearch heuristic. Numerical studies based on the realistic dataset of Xiamen\nand its surrounding cities in China show that the proposed framework\neffectively mitigates the supply and demand imbalances, and achieves\nsignificant improvement in both the average daily system profit and order\nfulfillment ratio.\n","authors":["Jinhua Si","Fang He","Xi Lin","Xindi Tang"],"pdf_url":"https://arxiv.org/pdf/2307.06742v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13290v1","updated":"2024-03-20T04:06:59Z","published":"2024-03-20T04:06:59Z","title":"A Log-domain Interior Point Method for Convex Quadratic Games","summary":"  In this paper, we propose an equilibrium-seeking algorithm for finding\ngeneralized Nash equilibria of non-cooperative monotone convex quadratic games.\nSpecifically, we recast the Nash equilibrium-seeking problem as variational\ninequality problem that we solve using a log-domain interior point method and\nprovide a general purpose solver based on this algorithm. This approach is\nsuitable for non-potential, general sum games and does not require extensive\nstructural assumptions. We demonstrate the efficiency and versatility of our\nmethod using three benchmark games and demonstrate our algorithm is especially\neffective on small to medium scale problems.\n","authors":["Bingqi Liu","Dominic Liao-McPherson"],"pdf_url":"https://arxiv.org/pdf/2403.13290v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13288v1","updated":"2024-03-20T04:02:35Z","published":"2024-03-20T04:02:35Z","title":"Observer-Based Environment Robust Control Barrier Functions for\n  Safety-critical Control with Dynamic Obstacles","summary":"  This paper proposes a safety-critical controller for dynamic and uncertain\nenvironments, leveraging a robust environment control barrier function (ECBF)\nto enhance the robustness against the measurement and prediction uncertainties\nassociated with moving obstacles. The approach reduces conservatism, compared\nwith a worst-case uncertainty approach, by incorporating a state observer for\nobstacles into the ECBF design. The controller, which guarantees safety, is\nachieved through solving a quadratic programming problem. The proposed method's\neffectiveness is demonstrated via a dynamic obstacle-avoidance problem for an\nautonomous vehicle, including comparisons with established baseline approaches.\n","authors":["Ying Shuai Quan","Jian Zhou","Erik Frisk","Chung Choo Chung"],"pdf_url":"https://arxiv.org/pdf/2403.13288v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.06727v2","updated":"2024-03-20T02:42:11Z","published":"2023-04-10T20:27:53Z","title":"Contingency Analyses with Warm Starter using Probabilistic Graphical\n  Model","summary":"  Cyberthreats are an increasingly common risk to the power grid and can thwart\nsecure grid operations. We propose to extend contingency analysis to include\ncyberthreat evaluations. However, unlike the traditional N-1 or N-2\ncontingencies, cyberthreats (e.g., MadIoT) require simulating hard-to-solve N-k\n(with k >> 2) contingencies in a practical amount of time. Purely physics-based\npower flow solvers, while being accurate, are slow and may not solve N-k\ncontingencies in a timely manner, whereas the emerging data-driven alternatives\nare fast but not sufficiently generalizable, interpretable, and scalable. To\naddress these challenges, we propose a novel conditional Gaussian Random\nField-based data-driven method that performs fast and accurate evaluation of\ncyberthreats. It achieves speedup of contingency analysis by warm-starting\nsimulations, i.e., improving starting points, for the physical solvers. To\nimprove the physical interpretability and generalizability, the proposed method\nincorporates domain knowledge by considering the graphical nature of the grid\ntopology. To improve scalability, the method applies physics-informed\nregularization that reduces model complexity. Experiments validate that\nsimulating MadIoT-induced attacks with our warm starter becomes approximately\n5x faster on a realistic 2000-bus system.\n","authors":["Shimiao Li","Amritanshu Pandey","Larry Pileggi"],"pdf_url":"https://arxiv.org/pdf/2304.06727v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2205.03673"},{"id":"http://arxiv.org/abs/2403.13255v1","updated":"2024-03-20T02:34:21Z","published":"2024-03-20T02:34:21Z","title":"Network-Aware Value Stacking of Community Battery via Asynchronous\n  Distributed Optimization","summary":"  Community battery systems have been widely deployed to provide services to\nthe grid. Unlike a single battery storage system in the community, coordinating\nmultiple community batteries can further unlock their value, enhancing the\nviability of community battery solutions. However, the centralized control of\ncommunity batteries relies on the full information of the system, which is less\npractical and may even lead to privacy leakage. In this paper, we formulate a\nvalue-stacking optimization problem for community batteries to interact with\nlocal solar, buildings, and the grid, within distribution network constraints.\nWe then propose a distributed algorithm using asynchronous distributed\nalternate direction method of multipliers (ADMM) to solve the problem. Our\nalgorithm is robust to communication latency between community batteries and\nthe grid while preserving the operational privacy. The simulation results\ndemonstrate the convergence of our proposed asynchronous distributed ADMM\nalgorithm. We also evaluate the electricity cost and the contribution of each\nvalue stream in the value-stacking problem for community batteries using\nreal-world data.\n","authors":["Canchen Jiang","Hao Wang"],"pdf_url":"https://arxiv.org/pdf/2403.13255v1.pdf","comment":"2024 IEEE Power & Energy Society General Meeting (PESGM)"},{"id":"http://arxiv.org/abs/2403.13245v1","updated":"2024-03-20T02:16:54Z","published":"2024-03-20T02:16:54Z","title":"Federated reinforcement learning for robot motion planning with\n  zero-shot generalization","summary":"  This paper considers the problem of learning a control policy for robot\nmotion planning with zero-shot generalization, i.e., no data collection and\npolicy adaptation is needed when the learned policy is deployed in new\nenvironments. We develop a federated reinforcement learning framework that\nenables collaborative learning of multiple learners and a central server, i.e.,\nthe Cloud, without sharing their raw data. In each iteration, each learner\nuploads its local control policy and the corresponding estimated normalized\narrival time to the Cloud, which then computes the global optimum among the\nlearners and broadcasts the optimal policy to the learners. Each learner then\nselects between its local control policy and that from the Cloud for next\niteration. The proposed framework leverages on the derived zero-shot\ngeneralization guarantees on arrival time and safety. Theoretical guarantees on\nalmost-sure convergence, almost consensus, Pareto improvement and optimality\ngap are also provided. Monte Carlo simulation is conducted to evaluate the\nproposed framework.\n","authors":["Zhenyuan Yuan","Siyuan Xu","Minghui Zhu"],"pdf_url":"https://arxiv.org/pdf/2403.13245v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13236v1","updated":"2024-03-20T01:57:38Z","published":"2024-03-20T01:57:38Z","title":"Safety-Aware Reinforcement Learning for Electric Vehicle Charging\n  Station Management in Distribution Network","summary":"  The increasing integration of electric vehicles (EVs) into the grid can pose\na significant risk to the distribution system operation in the absence of\ncoordination. In response to the need for effective coordination of EVs within\nthe distribution network, this paper presents a safety-aware reinforcement\nlearning (RL) algorithm designed to manage EV charging stations while ensuring\nthe satisfaction of system constraints. Unlike existing methods, our proposed\nalgorithm does not rely on explicit penalties for constraint violations,\neliminating the need for penalty coefficient tuning. Furthermore, managing EV\ncharging stations is further complicated by multiple uncertainties, notably the\nvariability in solar energy generation and energy prices. To address this\nchallenge, we develop an off-policy RL algorithm to efficiently utilize data to\nlearn patterns in such uncertain environments. Our algorithm also incorporates\na maximum entropy framework to enhance the RL algorithm's exploratory process,\npreventing convergence to local optimal solutions. Simulation results\ndemonstrate that our algorithm outperforms traditional RL algorithms in\nmanaging EV charging in the distribution network.\n","authors":["Jiarong Fan","Ariel Liebman","Hao Wang"],"pdf_url":"https://arxiv.org/pdf/2403.13236v1.pdf","comment":"2024 IEEE Power & Energy Society General Meeting (PESGM)"},{"id":"http://arxiv.org/abs/2403.14028v1","updated":"2024-03-20T22:56:11Z","published":"2024-03-20T22:56:11Z","title":"Performance-Guaranteed Solutions for Multi-Agent Optimal Coverage\n  Problems using Submodularity, Curvature, and Greedy Algorithms","summary":"  We consider a class of multi-agent optimal coverage problems where the goal\nis to determine the optimal placement of a group of agents in a given mission\nspace such that they maximize a joint ``coverage'' objective. This class of\nproblems is extremely challenging due to the non-convex nature of the mission\nspace and of the coverage objective. With this motivation, we propose to use a\ngreedy algorithm as a means of getting feasible coverage solutions efficiently.\nEven though such greedy solutions are suboptimal, the submodularity\n(diminishing returns) property of the coverage objective can be exploited to\nprovide performance bound guarantees - not only for the greedy solutions but\nalso for any subsequently improved solutions. Moreover, we show that improved\nperformance bound guarantees (beyond the standard (1-1/e) performance bound)\ncan be established using various curvature measures that further characterize\nthe considered coverage problem. In particular, we provide a brief review of\nall existing popular curvature measures found in the submodular maximization\nliterature, including a recent curvature measure that we proposed, and discuss\nin detail their applicability, practicality, and effectiveness in the context\nof optimal coverage problems. Moreover, we characterize the dependence of the\neffectiveness of different curvature measures (in providing improved\nperformance bound guarantees) on the agent sensing capabilities. Finally, we\nprovide several numerical results to support our findings and propose several\npotential future research directions.\n","authors":["Shirantha Welikala","Christos G. Cassandras"],"pdf_url":"https://arxiv.org/pdf/2403.14028v1.pdf","comment":"Will be submitted to CDC 2024"},{"id":"http://arxiv.org/abs/2401.09201v2","updated":"2024-03-20T22:42:12Z","published":"2024-01-17T13:26:16Z","title":"Tropical modeling of battery swapping and charging station","summary":"  We propose and investigate a queueing model of a battery swapping and\ncharging station (BSCS) for electric vehicles (EVs). A new approach to the\nanalysis of the queueing model is developed, which combines the representation\nof the model as a stochastic dynamic system with the use of the methods and\nresults of tropical algebra, which deals with the theory and applications of\nalgebraic systems with idempotent operations. We describe the dynamics of the\nqueueing model by a system of recurrence equations that involve random\nvariables (RVs) to represent the interarrival time of incoming EVs. A\nperformance measure for the model is defined as the mean operation cycle time\nof the station. Furthermore, the system of equations is represented in terms of\nthe tropical algebra in vector form as an implicit linear state dynamic\nequation. The performance measure takes on the meaning of the mean growth rate\nof the state vector (the Lyapunov exponent) of the dynamic system. By applying\na solution technique of vector equations in tropical algebra, the implicit\nequation is transformed into an explicit one with a state transition matrix\nwith random entries. The evaluation of the Lyapunov exponent reduces to finding\nthe limit of the expected value of norms of tropical matrix products. This\nlimit is then obtained using results from the tropical spectral theory of\ndeterministic and random matrices. With this approach, we derive a new exact\nformula for the mean cycle time of the BSCS, which is given in terms of the\nexpected value of the RVs involved. We present the results of the Monte Carlo\nsimulation of the BSCS's operation, which show a good agreement with the exact\nsolution. The application of the obtained solution to evaluate the performance\nof one BSCS and to find the optimal distribution of battery packs between\nstations in a network of BSCSs is discussed.\n","authors":["N. Krivulin","A. Garg"],"pdf_url":"https://arxiv.org/pdf/2401.09201v2.pdf","comment":"21 pages, 5 figures"},{"id":"http://arxiv.org/abs/2403.14011v1","updated":"2024-03-20T22:21:22Z","published":"2024-03-20T22:21:22Z","title":"A Unified Toll Lane Framework for Autonomous and High-Occupancy Vehicles\n  in Interactive Mixed Autonomy","summary":"  In this study, we introduce a toll lane framework that optimizes the mixed\nflow of autonomous and high-occupancy vehicles on freeways, where human-driven\nand autonomous vehicles of varying commuter occupancy share a segment.\nAutonomous vehicles, with their ability to maintain shorter headways, boost\ntraffic throughput. Our framework designates a toll lane for autonomous\nvehicles with high occupancy to use free of charge, while others pay a toll. We\nexplore the lane choice equilibria when all vehicles minimize travel costs, and\ncharacterize the equilibria by ranking vehicles by their mobility enhancement\npotential, a concept we term the mobility degree. Through numerical examples,\nwe demonstrate the framework's utility in addressing design challenges such as\nsetting optimal tolls, determining occupancy thresholds, and designing lane\npolicies, showing how it facilitates the integration of high-occupancy and\nautonomous vehicles. We also propose an algorithm for assigning rational tolls\nto decrease total commuter delay and examine the effects of toll\nnon-compliance. Our findings suggest that self-interest-driven behavior\nmitigates moderate non-compliance impacts, highlighting the framework's\nresilience. This work presents a pioneering comprehensive analysis of a toll\nlane framework that emphasizes the coexistence of autonomous and high-occupancy\nvehicles, offering insights for traffic management improvements and the\nintegration of autonomous vehicles into existing transportation\ninfrastructures.\n","authors":["Ruolin Li","Philip N. Brown","Roberto Horowitz"],"pdf_url":"https://arxiv.org/pdf/2403.14011v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14010v1","updated":"2024-03-20T22:15:33Z","published":"2024-03-20T22:15:33Z","title":"When are Lossy Energy Storage Optimization Models Convex?","summary":"  We consider a class of optimization problems involving the optimal operation\nof a single lossy energy storage system that incurs energy loss when charging\nor discharging. Such inefficiencies in the energy storage dynamics are known to\nresult in a nonconvex set of feasible charging and discharging power profiles.\nIn this letter, we provide an equivalent reformulation for this class of\noptimization problems, along with sufficient conditions for the convexity of\nthe proposed reformulation. The conditions provided generalize existing\nconditions for convexity in the literature.\n","authors":["Feras Al Taha","Eilyan Bitar"],"pdf_url":"https://arxiv.org/pdf/2403.14010v1.pdf","comment":"5 pages, 1 figure"},{"id":"http://arxiv.org/abs/2205.10969v3","updated":"2024-03-20T22:04:59Z","published":"2022-05-23T00:28:54Z","title":"Application of tropical optimization for solving multicriteria problems\n  of pairwise comparisons using log-Chebyshev approximation","summary":"  We consider a decision-making problem to find absolute ratings of\nalternatives that are compared in pairs under multiple criteria, subject to\nconstraints in the form of two-sided bounds on ratios between the ratings.\nGiven matrices of pairwise comparisons made according to the criteria, the\nproblem is formulated as the log-Chebyshev approximation of these matrices by a\ncommon consistent matrix (a symmetrically reciprocal matrix of unit rank) to\nminimize the approximation errors for all matrices simultaneously. We rearrange\nthe approximation problem as a constrained multiobjective optimization problem\nof finding a vector that determines the approximating consistent matrix. The\nproblem is then represented in the framework of tropical algebra, which deals\nwith the theory and applications of idempotent semirings and provides a formal\nbasis for fuzzy and interval arithmetic. We apply methods and results of\ntropical optimization to develop a new approach for handling the multiobjective\noptimization problem according to various principles of optimality. New\ncomplete solutions in the sense of the max-ordering, lexicographic ordering and\nlexicographic max-ordering optimality are obtained, which are given in a\ncompact vector form ready for formal analysis and efficient computation. We\npresent numerical examples of solving multicriteria problems of rating four\nalternatives from pairwise comparisons to illustrate the technique and compare\nit with others.\n","authors":["Nikolai Krivulin"],"pdf_url":"https://arxiv.org/pdf/2205.10969v3.pdf","comment":"44 pages"},{"id":"http://arxiv.org/abs/2403.13941v1","updated":"2024-03-20T19:26:27Z","published":"2024-03-20T19:26:27Z","title":"Sensory Glove-Based Surgical Robot User Interface","summary":"  Robotic surgery has reached a high level of maturity and has become an\nintegral part of standard surgical care. However, existing surgeon consoles are\nbulky and take up valuable space in the operating room, present challenges for\nsurgical team coordination, and their proprietary nature makes it difficult to\ntake advantage of recent technological advances, especially in virtual and\naugmented reality. One potential area for further improvement is the\nintegration of modern sensory gloves into robotic platforms, allowing surgeons\nto control robotic arms directly with their hand movements intuitively. We\npropose one such system that combines an HTC Vive tracker, a Manus Meta Prime 3\nXR sensory glove, and God Vision wireless smart glasses. The system controls\none arm of a da Vinci surgical robot. In addition to moving the arm, the\nsurgeon can use fingers to control the end-effector of the surgical instrument.\nHand gestures are used to implement clutching and similar functions. In\nparticular, we introduce clutching of the instrument orientation, a\nfunctionality not available in the da Vinci system. The vibrotactile elements\nof the glove are used to provide feedback to the user when gesture commands are\ninvoked. A preliminary evaluation of the system shows that it has excellent\ntracking accuracy and allows surgeons to efficiently perform common surgical\ntraining tasks with minimal practice with the new interface; this suggests that\nthe interface is highly intuitive. The proposed system is inexpensive, allows\nrapid prototyping, and opens opportunities for further innovations in the\ndesign of surgical robot interfaces.\n","authors":["Leonardo Borgioli","Ki-Hwan Oh","Alberto Mangano","Alvaro Ducas","Luciano Ambrosini","Federico Pinto","Paula A Lopez","Jessica Cassiani","Milos Zefran","Liaohai Chen","Pier Cristoforo Giulianotti"],"pdf_url":"https://arxiv.org/pdf/2403.13941v1.pdf","comment":"6 pages, 5 figures, 7 tables, submitted to International Conference\n  on Intelligent Robots and Systems (IROS)2024"},{"id":"http://arxiv.org/abs/2403.13929v1","updated":"2024-03-20T19:03:26Z","published":"2024-03-20T19:03:26Z","title":"Safety-Aware Perception for Autonomous Collision Avoidance in Dynamic\n  Environments","summary":"  Autonomous collision avoidance requires accurate environmental perception;\nhowever, flight systems often possess limited sensing capabilities with\nfield-of-view (FOV) restrictions. To navigate this challenge, we present a\nsafety-aware approach for online determination of the optimal sensor-pointing\ndirection $\\psi_\\text{d}$ which utilizes control barrier functions (CBFs).\nFirst, we generate a spatial density function $\\Phi$ which leverages CBF\nconstraints to map the collision risk of all local coordinates. Then, we\nconvolve $\\Phi$ with an attitude-dependent sensor FOV quality function to\nproduce the objective function $\\Gamma$ which quantifies the total observed\nrisk for a given pointing direction. Finally, by finding the global optimizer\nfor $\\Gamma$, we identify the value of $\\psi_\\text{d}$ which maximizes the\nperception of risk within the FOV. We incorporate $\\psi_\\text{d}$ into a\nsafety-critical flight architecture and conduct a numerical analysis using\nmultiple simulated mission profiles. Our algorithm achieves a success rate of\n$88-96\\%$, constituting a $16-29\\%$ improvement compared to the best heuristic\nmethods. We demonstrate the functionality of our approach via a flight\ndemonstration using the Crazyflie 2.1 micro-quadrotor. Without a priori\nobstacle knowledge, the quadrotor follows a dynamic flight path while\nsimultaneously calculating and tracking $\\psi_\\text{d}$ to perceive and avoid\ntwo static obstacles with an average computation time of 371 $\\mu$s.\n","authors":["Ryan M. Bena","Chongbo Zhao","Quan Nguyen"],"pdf_url":"https://arxiv.org/pdf/2403.13929v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13923v1","updated":"2024-03-20T18:53:22Z","published":"2024-03-20T18:53:22Z","title":"Credit vs. Discount-Based Congestion Pricing: A Comparison Study","summary":"  Tolling, or congestion pricing, offers a promising traffic management policy\nfor regulating congestion, but has also attracted criticism for placing\noutsized financial burdens on low-income users. Credit-based congestion pricing\n(CBCP) and discount-based congestion pricing (DBCP) policies, which\nrespectively provide travel credits and toll discounts to low-income users on\ntolled roads, have emerged as promising mechanisms for reducing traffic\ncongestion without worsening societal inequities. However, the optimal design\nof CBCP and DBCP policies, as well as their relative advantages and\ndisadvantages, remain poorly understood. To address this, we study the effects\nof implementing CBCP and DBCP policies to route users on a network of\nmulti-lane highways with tolled express lanes. We formulate a non-atomic\nrouting game framework in which a subset of eligible users is granted toll\nrelief in the form of a fixed budget or toll discount, while the remaining\nineligible users must pay out-of-pocket. We prove the existence of Nash\nequilibrium traffic flow patterns corresponding to any given CBCP or DBCP\npolicy. Under the additional assumption that eligible users have time-invariant\nVoTs, we provide a convex program to efficiently compute these equilibria. For\nnetworks consisting of a single edge, we identify conditions under which CBCP\npolicies outperform DBCP policies (and vice versa), in the sense of improving\neligible users' access to the express lane. Finally, we present empirical\nresults from a CBCP pilot study of the San Mateo 101 Express Lane Project in\nCalifornia. Our empirical results corroborate our theoretical analysis of the\nimpact of deploying credit-based and discount-based policies, and lend insights\ninto the sensitivity of their impact with respect to the travel demand and\nusers' VoTs.\n","authors":["Chih-Yuan Chiu","Devansh Jalota","Marco Pavone"],"pdf_url":"https://arxiv.org/pdf/2403.13923v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13909v1","updated":"2024-03-20T18:29:55Z","published":"2024-03-20T18:29:55Z","title":"Sequential Modeling of Complex Marine Navigation: Case Study on a\n  Passenger Vessel (Student Abstract)","summary":"  The maritime industry's continuous commitment to sustainability has led to a\ndedicated exploration of methods to reduce vessel fuel consumption. This paper\nundertakes this challenge through a machine learning approach, leveraging a\nreal-world dataset spanning two years of a ferry in west coast Canada. Our\nfocus centers on the creation of a time series forecasting model given the\ndynamic and static states, actions, and disturbances. This model is designed to\npredict dynamic states based on the actions provided, subsequently serving as\nan evaluative tool to assess the proficiency of the ferry's operation under the\ncaptain's guidance. Additionally, it lays the foundation for future\noptimization algorithms, providing valuable feedback on decision-making\nprocesses. To facilitate future studies, our code is available at\n\\url{https://github.com/pagand/model_optimze_vessel/tree/AAAI}\n","authors":["Yimeng Fan","Pedram Agand","Mo Chen","Edward J. Park","Allison Kennedy","Chanwoo Bae"],"pdf_url":"https://arxiv.org/pdf/2403.13909v1.pdf","comment":"5 pages, 3 figures, AAAI 2024 student abstract"},{"id":"http://arxiv.org/abs/2403.13906v1","updated":"2024-03-20T18:24:42Z","published":"2024-03-20T18:24:42Z","title":"Clustering Heuristics for Robust Energy Capacitated Vehicle Routing\n  Problem (ECVRP)","summary":"  The paper presents an approach to solving the Robust Energy Capacitated\nVehicle Routing Problem (RECVRP), focusing on electric vehicles and their\nlimited battery capacity. A finite number of customers, each with their own\ndemand, have to be serviced by an electric vehicle fleet while ensuring that\nnone of the vehicles run out of energy. The time and energy it takes to travel\nbetween any two points is modeled as a random variable with known distribution.\nWe propose a Mixed Integer Program (MIP) for computing an exact solution and\nintroduce clustering heuristics to enhance the solution speed. This enables\nefficient re-planning of routes in dynamic scenarios. The methodology\ntransforms the RECVRP into smaller problems, yielding good quality solutions\nquickly compared to existing methods. We demonstrate the effectiveness of this\napproach using a well-known benchmark problem set as well as a set of randomly\ngenerated problems.\n","authors":["Mark Pustilnik","Francesco Borrelli"],"pdf_url":"https://arxiv.org/pdf/2403.13906v1.pdf","comment":null}]},"2024-03-21T00:00:00Z":{"Robotics":[{"id":"http://arxiv.org/abs/2403.14626v1","updated":"2024-03-21T17:59:55Z","published":"2024-03-21T17:59:55Z","title":"ODTFormer: Efficient Obstacle Detection and Tracking with Stereo Cameras\n  Based on Transformer","summary":"  Obstacle detection and tracking represent a critical component in robot\nautonomous navigation. In this paper, we propose ODTFormer, a Transformer-based\nmodel to address both obstacle detection and tracking problems. For the\ndetection task, our approach leverages deformable attention to construct a 3D\ncost volume, which is decoded progressively in the form of voxel occupancy\ngrids. We further track the obstacles by matching the voxels between\nconsecutive frames. The entire model can be optimized in an end-to-end manner.\nThrough extensive experiments on DrivingStereo and KITTI benchmarks, our model\nachieves state-of-the-art performance in the obstacle detection task. We also\nreport comparable accuracy to state-of-the-art obstacle tracking models while\nrequiring only a fraction of their computation cost, typically ten-fold to\ntwenty-fold less. The code and model weights will be publicly released.\n","authors":["Tianye Ding","Hongyu Li","Huaizu Jiang"],"pdf_url":"https://arxiv.org/pdf/2403.14626v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2403.14605v1","updated":"2024-03-21T17:54:56Z","published":"2024-03-21T17:54:56Z","title":"SDP Synthesis of Maximum Coverage Trees for Probabilistic Planning under\n  Control Constraints","summary":"  The paper presents Maximal Covariance Backward Reachable Trees (MAXCOVAR\nBRT), which is a multi-query algorithm for planning of dynamic systems under\nstochastic motion uncertainty and constraints on the control input with\nexplicit coverage guarantees. In contrast to existing roadmap-based\nprobabilistic planning methods that sample belief nodes randomly and draw edges\nbetween them \\cite{csbrm_tro2024}, under control constraints, the reachability\nof belief nodes needs to be explicitly established and is determined by\nchecking the feasibility of a non-convex program. Moreover, there is no\nexplicit consideration of coverage of the roadmap while adding nodes and edges\nduring the construction procedure for the existing methods. Our contribution is\na novel optimization formulation to add nodes and construct the corresponding\nedge controllers such that the generated roadmap results in provably maximal\ncoverage under control constraints as compared to any other method of adding\nnodes and edges. We characterize formally the notion of coverage of a roadmap\nin this stochastic domain via introduction of the h-$\\operatorname{BRS}$\n(Backward Reachable Set of Distributions) of a tree of distributions under\ncontrol constraints, and also support our method with extensive simulations on\na 6 DoF model.\n","authors":["Naman Aggarwal","Jonathan P. How"],"pdf_url":"https://arxiv.org/pdf/2403.14605v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14597v1","updated":"2024-03-21T17:50:22Z","published":"2024-03-21T17:50:22Z","title":"Extended Reality for Enhanced Human-Robot Collaboration: a\n  Human-in-the-Loop Approach","summary":"  The rise of automation has provided an opportunity to achieve higher\nefficiency in manufacturing processes, yet it often compromises the flexibility\nrequired to promptly respond to evolving market needs and meet the demand for\ncustomization. Human-robot collaboration attempts to tackle these challenges by\ncombining the strength and precision of machines with human ingenuity and\nperceptual understanding. In this paper, we conceptualize and propose an\nimplementation framework for an autonomous, machine learning-based manipulator\nthat incorporates human-in-the-loop principles and leverages Extended Reality\n(XR) to facilitate intuitive communication and programming between humans and\nrobots. Furthermore, the conceptual framework foresees human involvement\ndirectly in the robot learning process, resulting in higher adaptability and\ntask generalization. The paper highlights key technologies enabling the\nproposed framework, emphasizing the importance of developing the digital\necosystem as a whole. Additionally, we review the existent implementation\napproaches of XR in human-robot collaboration, showcasing diverse perspectives\nand methodologies. The challenges and future outlooks are discussed, delving\ninto the major obstacles and potential research avenues of XR for more natural\nhuman-robot interaction and integration in the industrial landscape.\n","authors":["Yehor Karpichev","Todd Charter","Homayoun Najjaran"],"pdf_url":"https://arxiv.org/pdf/2403.14597v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14594v1","updated":"2024-03-21T17:49:26Z","published":"2024-03-21T17:49:26Z","title":"VXP: Voxel-Cross-Pixel Large-scale Image-LiDAR Place Recognition","summary":"  Recent works on the global place recognition treat the task as a retrieval\nproblem, where an off-the-shelf global descriptor is commonly designed in\nimage-based and LiDAR-based modalities. However, it is non-trivial to perform\naccurate image-LiDAR global place recognition since extracting consistent and\nrobust global descriptors from different domains (2D images and 3D point\nclouds) is challenging. To address this issue, we propose a novel\nVoxel-Cross-Pixel (VXP) approach, which establishes voxel and pixel\ncorrespondences in a self-supervised manner and brings them into a shared\nfeature space. Specifically, VXP is trained in a two-stage manner that first\nexplicitly exploits local feature correspondences and enforces similarity of\nglobal descriptors. Extensive experiments on the three benchmarks (Oxford\nRobotCar, ViViD++ and KITTI) demonstrate our method surpasses the\nstate-of-the-art cross-modal retrieval by a large margin.\n","authors":["Yun-Jin Li","Mariia Gladkova","Yan Xia","Rui Wang","Daniel Cremers"],"pdf_url":"https://arxiv.org/pdf/2403.14594v1.pdf","comment":"Project page https://yunjinli.github.io/projects-vxp/"},{"id":"http://arxiv.org/abs/2403.14583v1","updated":"2024-03-21T17:37:43Z","published":"2024-03-21T17:37:43Z","title":"Co-Optimization of Environment and Policies for Decentralized\n  Multi-Agent Navigation","summary":"  This work views the multi-agent system and its surrounding environment as a\nco-evolving system, where the behavior of one affects the other. The goal is to\ntake both agent actions and environment configurations as decision variables,\nand optimize these two components in a coordinated manner to improve some\nmeasure of interest. Towards this end, we consider the problem of decentralized\nmulti-agent navigation in cluttered environments. By introducing two\nsub-objectives of multi-agent navigation and environment optimization, we\npropose an $\\textit{agent-environment co-optimization}$ problem and develop a\n$\\textit{coordinated algorithm}$ that alternates between these sub-objectives\nto search for an optimal synthesis of agent actions and obstacle configurations\nin the environment; ultimately, improving the navigation performance. Due to\nthe challenge of explicitly modeling the relation between agents, environment\nand performance, we leverage policy gradient to formulate a model-free learning\nmechanism within the coordinated framework. A formal convergence analysis shows\nthat our coordinated algorithm tracks the local minimum trajectory of an\nassociated time-varying non-convex optimization problem. Extensive numerical\nresults corroborate theoretical findings and show the benefits of\nco-optimization over baselines. Interestingly, the results also indicate that\noptimized environment configurations are able to offer structural guidance that\nis key to de-conflicting agents in motion.\n","authors":["Zhan Gao","Guang Yang","Amanda Prorok"],"pdf_url":"https://arxiv.org/pdf/2403.14583v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.01477v2","updated":"2024-03-21T17:31:00Z","published":"2024-02-02T15:06:00Z","title":"A Modular Aerial System Based on Homogeneous Quadrotors with\n  Fault-Tolerant Control","summary":"  The standard quadrotor is one of the most popular and widely used aerial\nvehicle of recent decades, offering great maneuverability with mechanical\nsimplicity. However, the under-actuation characteristic limits its\napplications, especially when it comes to generating desired wrench with six\ndegrees of freedom (DOF). Therefore, existing work often compromises between\nmechanical complexity and the controllable DOF of the aerial system. To take\nadvantage of the mechanical simplicity of a standard quadrotor, we propose a\nmodular aerial system, IdentiQuad, that combines only homogeneous\nquadrotor-based modules. Each IdentiQuad can be operated alone like a standard\nquadrotor, but at the same time allows task-specific assembly, increasing the\ncontrollable DOF of the system. Each module is interchangeable within its\nassembly. We also propose a general controller for different configurations of\nassemblies, capable of tolerating rotor failures and balancing the energy\nconsumption of each module. The functionality and robustness of the system and\nits controller are validated using physics-based simulations for different\nassembly configurations.\n","authors":["Mengguang Li","Kai Cui","Heinz Koeppl"],"pdf_url":"https://arxiv.org/pdf/2402.01477v2.pdf","comment":"ICRA2024"},{"id":"http://arxiv.org/abs/2403.14545v1","updated":"2024-03-21T16:44:49Z","published":"2024-03-21T16:44:49Z","title":"Learning Hierarchical Control For Constrained Dynamic Task Assignment","summary":"  This paper introduces a novel data-driven hierarchical control scheme for\nmanaging a fleet of nonlinear, capacity-constrained autonomous agents in an\niterative environment. We propose a control framework consisting of a\nhigh-level dynamic task assignment and routing layer and low-level motion\nplanning and tracking layer. Each layer of the control hierarchy uses a\ndata-driven MPC policy, maintaining bounded computational complexity at each\ncalculation of a new task assignment or actuation input. We utilize collected\ndata to iteratively refine estimates of agent capacity usage, and update MPC\npolicy parameters accordingly. Our approach leverages tools from iterative\nlearning control to integrate learning at both levels of the hierarchy, and\ncoordinates learning between levels in order to maintain closed-loop\nfeasibility and performance improvement of the connected architecture.\n","authors":["Charlott Vallon","Alessandro Pinto","Bartolomeo Stellato","Francesco Borrelli"],"pdf_url":"https://arxiv.org/pdf/2403.14545v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.17587v2","updated":"2024-03-21T16:40:43Z","published":"2024-02-25T07:59:10Z","title":"Instance-aware Exploration-Verification-Exploitation for Instance\n  ImageGoal Navigation","summary":"  As a new embodied vision task, Instance ImageGoal Navigation (IIN) aims to\nnavigate to a specified object depicted by a goal image in an unexplored\nenvironment.\n  The main challenge of this task lies in identifying the target object from\ndifferent viewpoints while rejecting similar distractors.\n  Existing ImageGoal Navigation methods usually adopt the simple\nExploration-Exploitation framework and ignore the identification of specific\ninstance during navigation.\n  In this work, we propose to imitate the human behaviour of ``getting closer\nto confirm\" when distinguishing objects from a distance.\n  Specifically, we design a new modular navigation framework named\nInstance-aware Exploration-Verification-Exploitation (IEVE) for instance-level\nimage goal navigation.\n  Our method allows for active switching among the exploration, verification,\nand exploitation actions, thereby facilitating the agent in making reasonable\ndecisions under different situations.\n  On the challenging HabitatMatterport 3D semantic (HM3D-SEM) dataset, our\nmethod surpasses previous state-of-the-art work, with a classical segmentation\nmodel (0.684 vs. 0.561 success) or a robust model (0.702 vs. 0.561 success).\nOur code will be made publicly available at https://github.com/XiaohanLei/IEVE.\n","authors":["Xiaohan Lei","Min Wang","Wengang Zhou","Li Li","Houqiang Li"],"pdf_url":"https://arxiv.org/pdf/2402.17587v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14526v1","updated":"2024-03-21T16:26:19Z","published":"2024-03-21T16:26:19Z","title":"Click to Grasp: Zero-Shot Precise Manipulation via Visual Diffusion\n  Descriptors","summary":"  Precise manipulation that is generalizable across scenes and objects remains\na persistent challenge in robotics. Current approaches for this task heavily\ndepend on having a significant number of training instances to handle objects\nwith pronounced visual and/or geometric part ambiguities. Our work explores the\ngrounding of fine-grained part descriptors for precise manipulation in a\nzero-shot setting by utilizing web-trained text-to-image diffusion-based\ngenerative models. We tackle the problem by framing it as a dense semantic part\ncorrespondence task. Our model returns a gripper pose for manipulating a\nspecific part, using as reference a user-defined click from a source image of a\nvisually different instance of the same object. We require no manual grasping\ndemonstrations as we leverage the intrinsic object geometry and features.\nPractical experiments in a real-world tabletop scenario validate the efficacy\nof our approach, demonstrating its potential for advancing semantic-aware\nrobotics manipulation. Web page: https://tsagkas.github.io/click2grasp\n","authors":["Nikolaos Tsagkas","Jack Rome","Subramanian Ramamoorthy","Oisin Mac Aodha","Chris Xiaoxuan Lu"],"pdf_url":"https://arxiv.org/pdf/2403.14526v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2303.12157v2","updated":"2024-03-21T16:09:57Z","published":"2023-03-21T19:34:20Z","title":"Learning a Depth Covariance Function","summary":"  We propose learning a depth covariance function with applications to\ngeometric vision tasks. Given RGB images as input, the covariance function can\nbe flexibly used to define priors over depth functions, predictive\ndistributions given observations, and methods for active point selection. We\nleverage these techniques for a selection of downstream tasks: depth\ncompletion, bundle adjustment, and monocular dense visual odometry.\n","authors":["Eric Dexheimer","Andrew J. Davison"],"pdf_url":"https://arxiv.org/pdf/2303.12157v2.pdf","comment":"CVPR 2023. Project page: https://edexheim.github.io/DepthCov/"},{"id":"http://arxiv.org/abs/2403.14488v1","updated":"2024-03-21T15:36:26Z","published":"2024-03-21T15:36:26Z","title":"Physics-Based Causal Reasoning for Safe & Robust Next-Best Action\n  Selection in Robot Manipulation Tasks","summary":"  Safe and efficient object manipulation is a key enabler of many real-world\nrobot applications. However, this is challenging because robot operation must\nbe robust to a range of sensor and actuator uncertainties. In this paper, we\npresent a physics-informed causal-inference-based framework for a robot to\nprobabilistically reason about candidate actions in a block stacking task in a\npartially observable setting. We integrate a physics-based simulation of the\nrigid-body system dynamics with a causal Bayesian network (CBN) formulation to\ndefine a causal generative probabilistic model of the robot decision-making\nprocess. Using simulation-based Monte Carlo experiments, we demonstrate our\nframework's ability to successfully: (1) predict block tower stability with\nhigh accuracy (Pred Acc: 88.6%); and, (2) select an approximate next-best\naction for the block stacking task, for execution by an integrated robot\nsystem, achieving 94.2% task success rate. We also demonstrate our framework's\nsuitability for real-world robot systems by demonstrating successful task\nexecutions with a domestic support robot, with perception and manipulation\nsub-system integration. Hence, we show that by embedding physics-based causal\nreasoning into robots' decision-making processes, we can make robot task\nexecution safer, more reliable, and more robust to various types of\nuncertainty.\n","authors":["Ricardo Cannizzaro","Michael Groom","Jonathan Routley","Robert Osazuwa Ness","Lars Kunze"],"pdf_url":"https://arxiv.org/pdf/2403.14488v1.pdf","comment":"8 pages, 9 figures, submitted to 2024 IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS)"},{"id":"http://arxiv.org/abs/2304.03133v2","updated":"2024-03-21T15:18:20Z","published":"2023-04-06T15:06:28Z","title":"Deep learning reduces sensor requirements for gust rejection on a small\n  uncrewed aerial vehicle morphing wing","summary":"  There is a growing need for uncrewed aerial vehicles (UAVs) to operate in\ncities. However, the uneven urban landscape and complex street systems cause\nlarge-scale wind gusts that challenge the safe and effective operation of UAVs.\nCurrent gust alleviation methods rely on traditional control surfaces and\ncomputationally expensive modeling to select a control action, leading to a\nslower response. Here, we used deep reinforcement learning to create an\nautonomous gust alleviation controller for a camber-morphing wing. This method\nreduced gust impact by 84%, directly from real-time, on-board pressure signals.\nNotably, we found that gust alleviation using signals from only three pressure\ntaps was statistically indistinguishable from using six signals. This\nreduced-sensor fly-by-feel control opens the door to UAV missions in previously\ninoperable locations.\n","authors":["Kevin PT. Haughn","Christina Harvey","Daniel J. Inman"],"pdf_url":"https://arxiv.org/pdf/2304.03133v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.12001v3","updated":"2024-03-21T15:07:30Z","published":"2023-09-21T12:16:32Z","title":"Exploring Human's Gender Perception and Bias toward Non-Humanoid Robots","summary":"  As non-humanoid robots increasingly permeate various sectors, understanding\ntheir design implications for human acceptance becomes paramount. Despite their\nubiquity, studies on how to improve human interaction are sparse. Our\ninvestigation, conducted through two surveys, addresses this gap. The first\nsurvey emphasizes non-humanoid robots and human perceptions about gender\nattributions, suggesting that both design and perceived gender influence\nacceptance. Survey 2 investigates the effects of varying gender cues on robot\ndesigns and their consequent impacts on human-robot interactions. Our findings\nhighlighted that distinct gender cues can bolster or impede interaction\ncomfort.\n","authors":["Mahya Ramezani","Jose Luis Sanchez-Lopez"],"pdf_url":"https://arxiv.org/pdf/2309.12001v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14449v1","updated":"2024-03-21T14:56:46Z","published":"2024-03-21T14:56:46Z","title":"Bringing Robots Home: The Rise of AI Robots in Consumer Electronics","summary":"  On March 18, 2024, NVIDIA unveiled Project GR00T, a general-purpose\nmultimodal generative AI model designed specifically for training humanoid\nrobots. Preceding this event, Tesla's unveiling of the Optimus Gen 2 humanoid\nrobot on December 12, 2023, underscored the profound impact robotics is poised\nto have on reshaping various facets of our daily lives. While robots have long\ndominated industrial settings, their presence within our homes is a burgeoning\nphenomenon. This can be attributed, in part, to the complexities of domestic\nenvironments and the challenges of creating robots that can seamlessly\nintegrate into our daily routines.\n","authors":["Haiwei Dong","Yang Liu","Ted Chu","Abdulmotaleb El Saddik"],"pdf_url":"https://arxiv.org/pdf/2403.14449v1.pdf","comment":"Accepted by IEEE Consumer Electronics Magazine"},{"id":"http://arxiv.org/abs/2403.14447v1","updated":"2024-03-21T14:53:50Z","published":"2024-03-21T14:53:50Z","title":"Exploring 3D Human Pose Estimation and Forecasting from the Robot's\n  Perspective: The HARPER Dataset","summary":"  We introduce HARPER, a novel dataset for 3D body pose estimation and forecast\nin dyadic interactions between users and \\spot, the quadruped robot\nmanufactured by Boston Dynamics. The key-novelty is the focus on the robot's\nperspective, i.e., on the data captured by the robot's sensors. These make 3D\nbody pose analysis challenging because being close to the ground captures\nhumans only partially. The scenario underlying HARPER includes 15 actions, of\nwhich 10 involve physical contact between the robot and users. The Corpus\ncontains not only the recordings of the built-in stereo cameras of Spot, but\nalso those of a 6-camera OptiTrack system (all recordings are synchronized).\nThis leads to ground-truth skeletal representations with a precision lower than\na millimeter. In addition, the Corpus includes reproducible benchmarks on 3D\nHuman Pose Estimation, Human Pose Forecasting, and Collision Prediction, all\nbased on publicly available baseline approaches. This enables future HARPER\nusers to rigorously compare their results with those we provide in this work.\n","authors":["Andrea Avogaro. Andrea Toaiari","Federico Cunico","Xiangmin Xu","Haralambos Dafas","Alessandro Vinciarelli","Emma Li","Marco Cristani"],"pdf_url":"https://arxiv.org/pdf/2403.14447v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14414v1","updated":"2024-03-21T13:59:32Z","published":"2024-03-21T13:59:32Z","title":"Efficient Model Learning and Adaptive Tracking Control of Magnetic\n  Micro-Robots for Non-Contact Manipulation","summary":"  Magnetic microrobots can be navigated by an external magnetic field to\nautonomously move within living organisms with complex and unstructured\nenvironments. Potential applications include drug delivery, diagnostics, and\ntherapeutic interventions. Existing techniques commonly impart magnetic\nproperties to the target object,or drive the robot to contact and then\nmanipulate the object, both probably inducing physical damage. This paper\nconsiders a non-contact formulation, where the robot spins to generate a\nrepulsive field to push the object without physical contact. Under such a\nformulation, the main challenge is that the motion model between the input of\nthe magnetic field and the output velocity of the target object is commonly\nunknown and difficult to analyze. To deal with it, this paper proposes a\ndata-driven-based solution. A neural network is constructed to efficiently\nestimate the motion model. Then, an approximate model-based optimal control\nscheme is developed to push the object to track a time-varying trajectory,\nmaintaining the non-contact with distance constraints. Furthermore, a\nstraightforward planner is introduced to assess the adaptability of non-contact\nmanipulation in a cluttered unstructured environment. Experimental results are\npresented to show the tracking and navigation performance of the proposed\nscheme.\n","authors":["Yongyi Jia","Shu Miao","Junjian Zhou","Niandong Jiao","Lianqing Liu","Xiang Li"],"pdf_url":"https://arxiv.org/pdf/2403.14414v1.pdf","comment":"7 pages, 6 figures, received by 2024 IEEE International Conference on\n  Robotics and Automation"},{"id":"http://arxiv.org/abs/2402.16348v2","updated":"2024-03-21T13:58:30Z","published":"2024-02-26T07:02:05Z","title":"Star-Searcher: A Complete and Efficient Aerial System for Autonomous\n  Target Search in Complex Unknown Environments","summary":"  This paper tackles the challenge of autonomous target search using unmanned\naerial vehicles (UAVs) in complex unknown environments. To fill the gap in\nsystematic approaches for this task, we introduce Star-Searcher, an aerial\nsystem featuring specialized sensor suites, mapping, and planning modules to\noptimize searching. Path planning challenges due to increased inspection\nrequirements are addressed through a hierarchical planner with a\nvisibility-based viewpoint clustering method. This simplifies planning by\nbreaking it into global and local sub-problems, ensuring efficient global and\nlocal path coverage in real-time. Furthermore, our global path planning employs\na history-aware mechanism to reduce motion inconsistency from frequent map\nchanges, significantly enhancing search efficiency. We conduct comparisons with\nstate-of-the-art methods in both simulation and the real world, demonstrating\nshorter flight paths, reduced time, and higher target search completeness. Our\napproach will be open-sourced for community benefit at\nhttps://github.com/SYSU-STAR/STAR-Searcher.\n","authors":["Yiming Luo","Zixuan Zhuang","Neng Pan","Chen Feng","Shaojie Shen","Fei Gao","Hui Cheng","Boyu Zhou"],"pdf_url":"https://arxiv.org/pdf/2402.16348v2.pdf","comment":"Aceepted to IEEE RA-L. Code:\n  https://github.com/SYSU-STAR/STAR-Searcher. Video:\n  https://www.youtube.com/watch?v=08ll_oo_DtU"},{"id":"http://arxiv.org/abs/2401.15174v2","updated":"2024-03-21T13:16:13Z","published":"2024-01-26T19:39:33Z","title":"Large Language Models for Multi-Modal Human-Robot Interaction","summary":"  This paper presents an innovative large language model (LLM)-based robotic\nsystem for enhancing multi-modal human-robot interaction (HRI). Traditional HRI\nsystems relied on complex designs for intent estimation, reasoning, and\nbehavior generation, which were resource-intensive. In contrast, our system\nempowers researchers and practitioners to regulate robot behavior through three\nkey aspects: providing high-level linguistic guidance, creating \"atomics\" for\nactions and expressions the robot can use, and offering a set of examples.\nImplemented on a physical robot, it demonstrates proficiency in adapting to\nmulti-modal inputs and determining the appropriate manner of action to assist\nhumans with its arms, following researchers' defined guidelines.\nSimultaneously, it coordinates the robot's lid, neck, and ear movements with\nspeech output to produce dynamic, multi-modal expressions. This showcases the\nsystem's potential to revolutionize HRI by shifting from conventional, manual\nstate-and-flow design methods to an intuitive, guidance-based, and\nexample-driven approach.\n","authors":["Chao Wang","Stephan Hasler","Daniel Tanneberg","Felix Ocker","Frank Joublin","Antonello Ceravola","Joerg Deigmoeller","Michael Gienger"],"pdf_url":"https://arxiv.org/pdf/2401.15174v2.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2401.16899v2","updated":"2024-03-21T12:56:24Z","published":"2024-01-30T11:05:43Z","title":"MAkEable: Memory-centered and Affordance-based Task Execution Framework\n  for Transferable Mobile Manipulation Skills","summary":"  To perform versatile mobile manipulation tasks in human-centered\nenvironments, the ability to efficiently transfer learned tasks and experiences\nfrom one robot to another or across different environments is key. In this\npaper, we present MAkEable, a versatile uni- and multi-manual mobile\nmanipulation framework that facilitates the transfer of capabilities and\nknowledge across different tasks, environments, and robots. Our framework\nintegrates an affordance-based task description into the memory-centric\ncognitive architecture of the ARMAR humanoid robot family, which supports the\nsharing of experiences and demonstrations for transfer learning. By\nrepresenting mobile manipulation actions through affordances, i.e., interaction\npossibilities of the robot with its environment, we provide a unifying\nframework for the autonomous uni- and multi-manual manipulation of known and\nunknown objects in various environments. We demonstrate the applicability of\nthe framework in real-world experiments for multiple robots, tasks, and\nenvironments. This includes grasping known and unknown objects, object placing,\nbimanual object grasping, memory-enabled skill transfer in a drawer opening\nscenario across two different humanoid robots, and a pouring task learned from\nhuman demonstration.\n","authors":["Christoph Pohl","Fabian Reister","Fabian Peller-Konrad","Tamim Asfour"],"pdf_url":"https://arxiv.org/pdf/2401.16899v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14353v1","updated":"2024-03-21T12:28:44Z","published":"2024-03-21T12:28:44Z","title":"DaCapo: Accelerating Continuous Learning in Autonomous Systems for Video\n  Analytics","summary":"  Deep neural network (DNN) video analytics is crucial for autonomous systems\nsuch as self-driving vehicles, unmanned aerial vehicles (UAVs), and security\nrobots. However, real-world deployment faces challenges due to their limited\ncomputational resources and battery power. To tackle these challenges,\ncontinuous learning exploits a lightweight \"student\" model at deployment\n(inference), leverages a larger \"teacher\" model for labeling sampled data\n(labeling), and continuously retrains the student model to adapt to changing\nscenarios (retraining). This paper highlights the limitations in\nstate-of-the-art continuous learning systems: (1) they focus on computations\nfor retraining, while overlooking the compute needs for inference and labeling,\n(2) they rely on power-hungry GPUs, unsuitable for battery-operated autonomous\nsystems, and (3) they are located on a remote centralized server, intended for\nmulti-tenant scenarios, again unsuitable for autonomous systems due to privacy,\nnetwork availability, and latency concerns. We propose a hardware-algorithm\nco-designed solution for continuous learning, DaCapo, that enables autonomous\nsystems to perform concurrent executions of inference, labeling, and training\nin a performant and energy-efficient manner. DaCapo comprises (1) a\nspatially-partitionable and precision-flexible accelerator enabling parallel\nexecution of kernels on sub-accelerators at their respective precisions, and\n(2) a spatiotemporal resource allocation algorithm that strategically navigates\nthe resource-accuracy tradeoff space, facilitating optimal decisions for\nresource allocation to achieve maximal accuracy. Our evaluation shows that\nDaCapo achieves 6.5% and 5.5% higher accuracy than a state-of-the-art GPU-based\ncontinuous learning systems, Ekya and EOMU, respectively, while consuming 254x\nless power.\n","authors":["Yoonsung Kim","Changhun Oh","Jinwoo Hwang","Wonung Kim","Seongryong Oh","Yubin Lee","Hardik Sharma","Amir Yazdanbakhsh","Jongse Park"],"pdf_url":"https://arxiv.org/pdf/2403.14353v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14347v1","updated":"2024-03-21T12:24:01Z","published":"2024-03-21T12:24:01Z","title":"A Comparative Study of Real-Time Implementable Cooperative Aerial\n  Manipulation Systems","summary":"  This survey paper focuses on quadrotor- and multirotor- based cooperative\naerial manipulation. Emphasis is first given on comparing and evaluating\nprototype systems that have been implemented and tested in real-time in diverse\napplication environments. Underlying modeling and control approaches are also\ndiscussed and compared. The outcome of the survey allows for understanding the\nmotivation and rationale to develop such systems, their applicability and\nimplementability in diverse applications and also challenges that need to be\naddressed and overcome. Moreover, the survey provides a guide to develop the\nnext generation of prototype systems based on preferred characteristics,\nfunctionality, operability and application domain.\n","authors":["Stamatina C. Barakou","Costas S. Tzafestas","Kimon P. Valavanis"],"pdf_url":"https://arxiv.org/pdf/2403.14347v1.pdf","comment":"Submitted to MDPI Drones"},{"id":"http://arxiv.org/abs/2403.14344v1","updated":"2024-03-21T12:22:47Z","published":"2024-03-21T12:22:47Z","title":"Tell Me What You Want (What You Really, Really Want): Addressing the\n  Expectation Gap for Goal Conveyance from Humans to Robots","summary":"  Conveying human goals to autonomous systems (AS) occurs both when the system\nis being designed and when it is being operated. The design-step conveyance is\ntypically mediated by robotics and AI engineers, who must appropriately capture\nend-user requirements and concepts of operations, while the operation-step\nconveyance is mediated by the design, interfaces, and behavior of the AI.\nHowever, communication can be difficult during both these periods because of\nmismatches in the expectations and expertise of the end-user and the\nroboticist, necessitating more design cycles to resolve. We examine some of the\nbarriers in communicating system design requirements, and develop an\naugmentation for applied cognitive task analysis (ACTA) methods, that we call\nrobot task analysis (RTA), pertaining specifically to the development of\nautonomous systems. Further, we introduce a top-down view of an underexplored\narea of friction between requirements communication -- implied human\nexpectations -- utilizing a collection of work primarily from experimental\npsychology and social sciences. We show how such expectations can be used in\nconjunction with task-specific expectations and the system design process for\nAS to improve design team communication, alleviate barriers to user rejection,\nand reduce the number of design cycles.\n","authors":["Kevin Leahy","Ho Chit Siu"],"pdf_url":"https://arxiv.org/pdf/2403.14344v1.pdf","comment":"Presented at the End-User Development for Human-Robot Interaction\n  (EUD4HRI) workshop at HRI 2024"},{"id":"http://arxiv.org/abs/2403.12670v2","updated":"2024-03-21T12:14:14Z","published":"2024-03-19T12:11:57Z","title":"Driving Animatronic Robot Facial Expression From Speech","summary":"  Animatronic robots aim to enable natural human-robot interaction through\nlifelike facial expressions. However, generating realistic, speech-synchronized\nrobot expressions is challenging due to the complexities of facial biomechanics\nand responsive motion synthesis. This paper presents a principled,\nskinning-centric approach to drive animatronic robot facial expressions from\nspeech. The proposed approach employs linear blend skinning (LBS) as the core\nrepresentation to guide tightly integrated innovations in embodiment design and\nmotion synthesis. LBS informs the actuation topology, enables human expression\nretargeting, and allows speech-driven facial motion generation. The proposed\napproach is capable of generating highly realistic, real-time facial\nexpressions from speech on an animatronic face, significantly advancing robots'\nability to replicate nuanced human expressions for natural interaction.\n","authors":["Boren Li","Hang Li","Hangxin Liu"],"pdf_url":"https://arxiv.org/pdf/2403.12670v2.pdf","comment":"Under review. For associated project page, see\n  https://library87.github.io/animatronic-face-iros24"},{"id":"http://arxiv.org/abs/2402.16068v3","updated":"2024-03-21T11:58:49Z","published":"2024-02-25T11:37:23Z","title":"ROS-Causal: A ROS-based Causal Analysis Framework for Human-Robot\n  Interaction Applications","summary":"  Deploying robots in human-shared spaces requires understanding interactions\namong nearby agents and objects. Modelling cause-and-effect relations through\ncausal inference aids in predicting human behaviours and anticipating robot\ninterventions. However, a critical challenge arises as existing causal\ndiscovery methods currently lack an implementation inside the ROS ecosystem,\nthe standard de facto in robotics, hindering effective utilisation in robotics.\nTo address this gap, this paper introduces ROS-Causal, a ROS-based framework\nfor onboard data collection and causal discovery in human-robot spatial\ninteractions. An ad-hoc simulator, integrated with ROS, illustrates the\napproach's effectiveness, showcasing the robot onboard generation of causal\nmodels during data collection. ROS-Causal is available on GitHub:\nhttps://github.com/lcastri/roscausal.git.\n","authors":["Luca Castri","Gloria Beraldo","Sariah Mghames","Marc Hanheide","Nicola Bellotto"],"pdf_url":"https://arxiv.org/pdf/2402.16068v3.pdf","comment":"Accepted by the \"Causal-HRI: Causal Learning for Human-Robot\n  Interaction\" workshop at the 2024 ACM/IEEE International Conference on\n  Human-Robot Interaction (HRI)"},{"id":"http://arxiv.org/abs/2403.14328v1","updated":"2024-03-21T11:54:45Z","published":"2024-03-21T11:54:45Z","title":"Distilling Reinforcement Learning Policies for Interpretable Robot\n  Locomotion: Gradient Boosting Machines and Symbolic Regression","summary":"  Recent advancements in reinforcement learning (RL) have led to remarkable\nachievements in robot locomotion capabilities. However, the complexity and\n``black-box'' nature of neural network-based RL policies hinder their\ninterpretability and broader acceptance, particularly in applications demanding\nhigh levels of safety and reliability. This paper introduces a novel approach\nto distill neural RL policies into more interpretable forms using Gradient\nBoosting Machines (GBMs), Explainable Boosting Machines (EBMs) and Symbolic\nRegression. By leveraging the inherent interpretability of generalized additive\nmodels, decision trees, and analytical expressions, we transform opaque neural\nnetwork policies into more transparent ``glass-box'' models. We train expert\nneural network policies using RL and subsequently distill them into (i) GBMs,\n(ii) EBMs, and (iii) symbolic policies. To address the inherent distribution\nshift challenge of behavioral cloning, we propose to use the Dataset\nAggregation (DAgger) algorithm with a curriculum of episode-dependent\nalternation of actions between expert and distilled policies, to enable\nefficient distillation of feedback control policies. We evaluate our approach\non various robot locomotion gaits -- walking, trotting, bounding, and pacing --\nand study the importance of different observations in joint actions for\ndistilled policies using various methods. We train neural expert policies for\n205 hours of simulated experience and distill interpretable policies with only\n10 minutes of simulated interaction for each gait using the proposed method.\n","authors":["Fernando Acero","Zhibin Li"],"pdf_url":"https://arxiv.org/pdf/2403.14328v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14326v1","updated":"2024-03-21T11:50:00Z","published":"2024-03-21T11:50:00Z","title":"Evaluation and Deployment of LiDAR-based Place Recognition in Dense\n  Forests","summary":"  Many LiDAR place recognition systems have been developed and tested\nspecifically for urban driving scenarios. Their performance in natural\nenvironments such as forests and woodlands have been studied less closely. In\nthis paper, we analyzed the capabilities of four different LiDAR place\nrecognition systems, both handcrafted and learning-based methods, using LiDAR\ndata collected with a handheld device and legged robot within dense forest\nenvironments. In particular, we focused on evaluating localization where there\nis significant translational and orientation difference between corresponding\nLiDAR scan pairs. This is particularly important for forest survey systems\nwhere the sensor or robot does not follow a defined road or path. Extending our\nanalysis we then incorporated the best performing approach, Logg3dNet, into a\nfull 6-DoF pose estimation system -- introducing several verification layers\nfor precise registration. We demonstrated the performance of our methods in\nthree operational modes: online SLAM, offline multi-mission SLAM map merging,\nand relocalization into a prior map. We evaluated these modes using data\ncaptured in forests from three different countries, achieving 80% of correct\nloop closures candidates with baseline distances up to 5m, and 60% up to 10m.\n","authors":["Haedam Oh","Nived Chebrolu","Matias Mattamala","Leonard Freißmuth","Maurice Fallon"],"pdf_url":"https://arxiv.org/pdf/2403.14326v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14320v1","updated":"2024-03-21T11:41:39Z","published":"2024-03-21T11:41:39Z","title":"Exosense: A Vision-Centric Scene Understanding System For Safe\n  Exoskeleton Navigation","summary":"  Exoskeletons for daily use by those with mobility impairments are being\ndeveloped. They will require accurate and robust scene understanding systems.\nCurrent research has used vision to identify immediate terrain and geometric\nobstacles, however these approaches are constrained to detections directly in\nfront of the user and are limited to classifying a finite range of terrain\ntypes (e.g., stairs, ramps and level-ground). This paper presents Exosense, a\nvision-centric scene understanding system which is capable of generating rich,\nglobally-consistent elevation maps, incorporating both semantic and terrain\ntraversability information. It features an elastic Atlas mapping framework\nassociated with a visual SLAM pose graph, embedded with open-vocabulary room\nlabels from a Vision-Language Model (VLM). The device's design includes a wide\nfield-of-view (FoV) fisheye multi-camera system to mitigate the challenges\nintroduced by the exoskeleton walking pattern. We demonstrate the system's\nrobustness to the challenges of typical periodic walking gaits, and its ability\nto construct accurate semantically-rich maps in indoor settings. Additionally,\nwe showcase its potential for motion planning -- providing a step towards safe\nnavigation for exoskeletons.\n","authors":["Jianeng Wang","Matias Mattamala","Christina Kassab","Lintong Zhang","Maurice Fallon"],"pdf_url":"https://arxiv.org/pdf/2403.14320v1.pdf","comment":"8 pages, 10 figures"},{"id":"http://arxiv.org/abs/2403.14305v1","updated":"2024-03-21T11:21:17Z","published":"2024-03-21T11:21:17Z","title":"Bayesian Optimization for Sample-Efficient Policy Improvement in Robotic\n  Manipulation","summary":"  Sample efficient learning of manipulation skills poses a major challenge in\nrobotics. While recent approaches demonstrate impressive advances in the type\nof task that can be addressed and the sensing modalities that can be\nincorporated, they still require large amounts of training data. Especially\nwith regard to learning actions on robots in the real world, this poses a major\nproblem due to the high costs associated with both demonstrations and\nreal-world robot interactions. To address this challenge, we introduce\nBOpt-GMM, a hybrid approach that combines imitation learning with own\nexperience collection. We first learn a skill model as a dynamical system\nencoded in a Gaussian Mixture Model from a few demonstrations. We then improve\nthis model with Bayesian optimization building on a small number of autonomous\nskill executions in a sparse reward setting. We demonstrate the sample\nefficiency of our approach on multiple complex manipulation skills in both\nsimulations and real-world experiments. Furthermore, we make the code and\npre-trained models publicly available at http://bopt-gmm. cs.uni-freiburg.de.\n","authors":["Adrian Röfer","Iman Nematollahi","Tim Welschehold","Wolfram Burgard","Abhinav Valada"],"pdf_url":"https://arxiv.org/pdf/2403.14305v1.pdf","comment":"7 pages, 5 figures, 2 tables, submitted to IROS2024"},{"id":"http://arxiv.org/abs/2403.14300v1","updated":"2024-03-21T11:16:28Z","published":"2024-03-21T11:16:28Z","title":"DexDribbler: Learning Dexterous Soccer Manipulation via Dynamic\n  Supervision","summary":"  Learning dexterous locomotion policy for legged robots is becoming\nincreasingly popular due to its ability to handle diverse terrains and resemble\nintelligent behaviors. However, joint manipulation of moving objects and\nlocomotion with legs, such as playing soccer, receive scant attention in the\nlearning community, although it is natural for humans and smart animals. A key\nchallenge to solve this multitask problem is to infer the objectives of\nlocomotion from the states and targets of the manipulated objects. The implicit\nrelation between the object states and robot locomotion can be hard to capture\ndirectly from the training experience. We propose adding a feedback control\nblock to compute the necessary body-level movement accurately and using the\noutputs as dynamic joint-level locomotion supervision explicitly. We further\nutilize an improved ball dynamic model, an extended context-aided estimator,\nand a comprehensive ball observer to facilitate transferring policy learned in\nsimulation to the real world. We observe that our learning scheme can not only\nmake the policy network converge faster but also enable soccer robots to\nperform sophisticated maneuvers like sharp cuts and turns on flat surfaces, a\ncapability that was lacking in previous methods. Video and code are available\nat https://github.com/SysCV/soccer-player\n","authors":["Yutong Hu","Kehan Wen","Fisher Yu"],"pdf_url":"https://arxiv.org/pdf/2403.14300v1.pdf","comment":"8 pages, 7 figures, submitted to IROS 2024"},{"id":"http://arxiv.org/abs/2312.07214v3","updated":"2024-03-21T11:12:31Z","published":"2023-12-12T12:26:48Z","title":"Exploring Large Language Models to Facilitate Variable Autonomy for\n  Human-Robot Teaming","summary":"  In a rapidly evolving digital landscape autonomous tools and robots are\nbecoming commonplace. Recognizing the significance of this development, this\npaper explores the integration of Large Language Models (LLMs) like Generative\npre-trained transformer (GPT) into human-robot teaming environments to\nfacilitate variable autonomy through the means of verbal human-robot\ncommunication. In this paper, we introduce a novel framework for such a\nGPT-powered multi-robot testbed environment, based on a Unity Virtual Reality\n(VR) setting. This system allows users to interact with robot agents through\nnatural language, each powered by individual GPT cores. By means of OpenAI's\nfunction calling, we bridge the gap between unstructured natural language input\nand structure robot actions. A user study with 12 participants explores the\neffectiveness of GPT-4 and, more importantly, user strategies when being given\nthe opportunity to converse in natural language within a multi-robot\nenvironment. Our findings suggest that users may have preconceived expectations\non how to converse with robots and seldom try to explore the actual language\nand cognitive capabilities of their robot collaborators. Still, those users who\ndid explore where able to benefit from a much more natural flow of\ncommunication and human-like back-and-forth. We provide a set of lessons\nlearned for future research and technical implementations of similar systems.\n","authors":["Younes Lakhnati","Max Pascher","Jens Gerken"],"pdf_url":"https://arxiv.org/pdf/2312.07214v3.pdf","comment":"Frontiers in Robotics and AI, Variable Autonomy for Human-Robot\n  Teaming"},{"id":"http://arxiv.org/abs/2403.14293v1","updated":"2024-03-21T11:00:11Z","published":"2024-03-21T11:00:11Z","title":"Human Reactions to Incorrect Answers from Robots","summary":"  As robots grow more and more integrated into numerous industries, it is\ncritical to comprehend how humans respond to their failures. This paper\nsystematically studies how trust dynamics and system design are affected by\nhuman responses to robot failures. The three-stage survey used in the study\nprovides a thorough understanding of human-robot interactions. While the second\nstage concentrates on interaction details, such as robot precision and error\nacknowledgment, the first stage collects demographic data and initial levels of\ntrust. In the last phase, participants' perceptions are examined after the\nencounter, and trust dynamics, forgiveness, and propensity to suggest robotic\ntechnologies are evaluated. Results show that participants' trust in robotic\ntechnologies increased significantly when robots acknowledged their errors or\nlimitations to participants and their willingness to suggest robots for\nactivities in the future points to a favorable change in perception,\nemphasizing the role that direct engagement has in influencing trust dynamics.\nBy providing useful advice for creating more sympathetic, responsive, and\nreliable robotic systems, the study advances the science of human-robot\ninteraction and promotes a wider adoption of robotic technologies.\n","authors":["Ponkoj Chandra Shill","Md. Azizul Hakim","Muhammad Jahanzeb Khan","Bashira Akter Anima"],"pdf_url":"https://arxiv.org/pdf/2403.14293v1.pdf","comment":"6 pages, 6 figures, 1 table, Ro-Man 2024"},{"id":"http://arxiv.org/abs/2403.14281v1","updated":"2024-03-21T10:41:31Z","published":"2024-03-21T10:41:31Z","title":"UAV-Assisted Maritime Search and Rescue: A Holistic Approach","summary":"  In this paper, we explore the application of Unmanned Aerial Vehicles (UAVs)\nin maritime search and rescue (mSAR) missions, focusing on medium-sized\nfixed-wing drones and quadcopters. We address the challenges and limitations\ninherent in operating some of the different classes of UAVs, particularly in\nsearch operations. Our research includes the development of a comprehensive\nsoftware framework designed to enhance the efficiency and efficacy of SAR\noperations. This framework combines preliminary detection onboard UAVs with\nadvanced object detection at ground stations, aiming to reduce visual strain\nand improve decision-making for operators. It will be made publicly available\nupon publication. We conduct experiments to evaluate various Region of Interest\n(RoI) proposal methods, especially by imposing simulated limited bandwidth on\nthem, an important consideration when flying remote or offshore operations.\nThis forces the algorithm to prioritize some predictions over others.\n","authors":["Martin Messmer","Benjamin Kiefer","Leon Amadeus Varga","Andreas Zell"],"pdf_url":"https://arxiv.org/pdf/2403.14281v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.00823v2","updated":"2024-03-21T10:21:37Z","published":"2024-02-01T18:07:33Z","title":"SLIM: Skill Learning with Multiple Critics","summary":"  Self-supervised skill learning aims to acquire useful behaviors that leverage\nthe underlying dynamics of the environment. Latent variable models, based on\nmutual information maximization, have been successful in this task but still\nstruggle in the context of robotic manipulation. As it requires impacting a\npossibly large set of degrees of freedom composing the environment, mutual\ninformation maximization fails alone in producing useful and safe manipulation\nbehaviors. Furthermore, tackling this by augmenting skill discovery rewards\nwith additional rewards through a naive combination might fail to produce\ndesired behaviors. To address this limitation, we introduce SLIM, a\nmulti-critic learning approach for skill discovery with a particular focus on\nrobotic manipulation. Our main insight is that utilizing multiple critics in an\nactor-critic framework to gracefully combine multiple reward functions leads to\na significant improvement in latent-variable skill discovery for robotic\nmanipulation while overcoming possible interference occurring among rewards\nwhich hinders convergence to useful skills. Furthermore, in the context of\ntabletop manipulation, we demonstrate the applicability of our novel skill\ndiscovery approach to acquire safe and efficient motor primitives in a\nhierarchical reinforcement learning fashion and leverage them through planning,\nsignificantly surpassing baseline approaches for skill discovery.\n","authors":["David Emukpere","Bingbing Wu","Julien Perez","Jean-Michel Renders"],"pdf_url":"https://arxiv.org/pdf/2402.00823v2.pdf","comment":"Accepted at IEEE ICRA 2024"},{"id":"http://arxiv.org/abs/2403.14270v1","updated":"2024-03-21T10:15:57Z","published":"2024-03-21T10:15:57Z","title":"Scene-Graph ViT: End-to-End Open-Vocabulary Visual Relationship\n  Detection","summary":"  Visual relationship detection aims to identify objects and their\nrelationships in images. Prior methods approach this task by adding separate\nrelationship modules or decoders to existing object detection architectures.\nThis separation increases complexity and hinders end-to-end training, which\nlimits performance. We propose a simple and highly efficient decoder-free\narchitecture for open-vocabulary visual relationship detection. Our model\nconsists of a Transformer-based image encoder that represents objects as tokens\nand models their relationships implicitly. To extract relationship information,\nwe introduce an attention mechanism that selects object pairs likely to form a\nrelationship. We provide a single-stage recipe to train this model on a mixture\nof object and relationship detection data. Our approach achieves\nstate-of-the-art relationship detection performance on Visual Genome and on the\nlarge-vocabulary GQA benchmark at real-time inference speeds. We provide\nanalyses of zero-shot performance, ablations, and real-world qualitative\nexamples.\n","authors":["Tim Salzmann","Markus Ryll","Alex Bewley","Matthias Minderer"],"pdf_url":"https://arxiv.org/pdf/2403.14270v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11567v2","updated":"2024-03-21T10:04:26Z","published":"2024-03-18T08:41:36Z","title":"R2SNet: Scalable Domain Adaptation for Object Detection in Cloud-Based\n  Robots Ecosystems via Proposal Refinement","summary":"  We introduce a novel approach for scalable domain adaptation in cloud\nrobotics scenarios where robots rely on third-party AI inference services\npowered by large pre-trained deep neural networks. Our method is based on a\ndownstream proposal-refinement stage running locally on the robots, exploiting\na new lightweight DNN architecture, R2SNet. This architecture aims to mitigate\nperformance degradation from domain shifts by adapting the object detection\nprocess to the target environment, focusing on relabeling, rescoring, and\nsuppression of bounding-box proposals. Our method allows for local execution on\nrobots, addressing the scalability challenges of domain adaptation without\nincurring significant computational costs. Real-world results on mobile service\nrobots performing door detection show the effectiveness of the proposed method\nin achieving scalable domain adaptation.\n","authors":["Michele Antonazzi","Matteo Luperto","N. Alberto Borghese","Nicola Basilico"],"pdf_url":"https://arxiv.org/pdf/2403.11567v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.09337v4","updated":"2024-03-21T09:34:49Z","published":"2022-03-17T14:13:19Z","title":"CoBRA: A Composable Benchmark for Robotics Applications","summary":"  Selecting an optimal robot, its base pose, and trajectory for a given task is\ncurrently mainly done by human expertise or trial and error. To evaluate\nautomatic approaches to this combined optimization problem, we introduce a\nbenchmark suite encompassing a unified format for robots, environments, and\ntask descriptions. Our benchmark suite is especially useful for modular robots,\nwhere the multitude of robots that can be assembled creates a host of\nadditional parameters to optimize. We include tasks such as machine tending and\nwelding in synthetic environments and 3D scans of real-world machine shops. All\nbenchmarks are accessible through https://cobra.cps.cit.tum.de, a platform to\nconveniently share, reference, and compare tasks, robot models, and solutions.\n","authors":["Matthias Mayer","Jonathan Külz","Matthias Althoff"],"pdf_url":"https://arxiv.org/pdf/2203.09337v4.pdf","comment":"7 pages, 5 Figures, 5 Tables Final version for IEEE ICRA'24"},{"id":"http://arxiv.org/abs/2308.03574v2","updated":"2024-03-21T09:13:17Z","published":"2023-08-07T13:25:48Z","title":"Generalized Early Stopping in Evolutionary Direct Policy Search","summary":"  Lengthy evaluation times are common in many optimization problems such as\ndirect policy search tasks, especially when they involve conducting evaluations\nin the physical world, e.g. in robotics applications. Often when evaluating\nsolution over a fixed time period it becomes clear that the objective value\nwill not increase with additional computation time (for example when a two\nwheeled robot continuously spins on the spot). In such cases, it makes sense to\nstop the evaluation early to save computation time. However, most approaches to\nstop the evaluation are problem specific and need to be specifically designed\nfor the task at hand. Therefore, we propose an early stopping method for direct\npolicy search. The proposed method only looks at the objective value at each\ntime step and requires no problem specific knowledge. We test the introduced\nstopping criterion in five direct policy search environments drawn from games,\nrobotics and classic control domains, and show that it can save up to 75% of\nthe computation time. We also compare it with problem specific stopping\ncriteria and show that it performs comparably, while being more generally\napplicable.\n","authors":["Etor Arza","Leni K. Le Goff","Emma Hart"],"pdf_url":"https://arxiv.org/pdf/2308.03574v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.08244v2","updated":"2024-03-21T08:02:59Z","published":"2023-11-14T15:29:52Z","title":"Language and Sketching: An LLM-driven Interactive Multimodal Multitask\n  Robot Navigation Framework","summary":"  The socially-aware navigation system has evolved to adeptly avoid various\nobstacles while performing multiple tasks, such as point-to-point navigation,\nhuman-following, and -guiding. However, a prominent gap persists: in\nHuman-Robot Interaction (HRI), the procedure of communicating commands to\nrobots demands intricate mathematical formulations. Furthermore, the transition\nbetween tasks does not quite possess the intuitive control and user-centric\ninteractivity that one would desire. In this work, we propose an LLM-driven\ninteractive multimodal multitask robot navigation framework, termed LIM2N, to\nsolve the above new challenge in the navigation field. We achieve this by first\nintroducing a multimodal interaction framework where language and hand-drawn\ninputs can serve as navigation constraints and control objectives. Next, a\nreinforcement learning agent is built to handle multiple tasks with the\nreceived information. Crucially, LIM2N creates smooth cooperation among the\nreasoning of multimodal input, multitask planning, and adaptation and\nprocessing of the intelligent sensing modules in the complicated system.\nExtensive experiments are conducted in both simulation and the real world\ndemonstrating that LIM2N has superior user needs understanding, alongside an\nenhanced interactive experience.\n","authors":["Weiqin Zu","Wenbin Song","Ruiqing Chen","Ze Guo","Fanglei Sun","Zheng Tian","Wei Pan","Jun Wang"],"pdf_url":"https://arxiv.org/pdf/2311.08244v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14176v1","updated":"2024-03-21T06:57:28Z","published":"2024-03-21T06:57:28Z","title":"ReFeree: Radar-based efficient global descriptor using a Feature and\n  Free space for Place Recognition","summary":"  Radar is highlighted for robust sensing capabilities in adverse weather\nconditions (e.g. dense fog, heavy rain, or snowfall). In addition, Radar can\ncover wide areas and penetrate small particles. Despite these advantages,\nRadar-based place recognition remains in the early stages compared to other\nsensors due to its unique characteristics such as low resolution, and\nsignificant noise. In this paper, we propose a Radarbased place recognition\nutilizing a descriptor called ReFeree using a feature and free space. Unlike\ntraditional methods, we overwhelmingly summarize the Radar image. Despite being\nlightweight, it contains semi-metric information and is also outstanding from\nthe perspective of place recognition performance. For concrete validation, we\ntest a single session from the MulRan dataset and a multi-session from the\nOxford Radar RobotCar and the Boreas dataset.\n","authors":["Byunghee Choi","Hogyun Kim","Younggun Cho"],"pdf_url":"https://arxiv.org/pdf/2403.14176v1.pdf","comment":"5 pages, 4 figures"},{"id":"http://arxiv.org/abs/2403.14173v1","updated":"2024-03-21T06:53:20Z","published":"2024-03-21T06:53:20Z","title":"HCTO: Optimality-Aware LiDAR Inertial Odometry with Hybrid Continuous\n  Time Optimization for Compact Wearable Mapping System","summary":"  Compact wearable mapping system (WMS) has gained significant attention due to\ntheir convenience in various applications. Specifically, it provides an\nefficient way to collect prior maps for 3D structure inspection and robot-based\n\"last-mile delivery\" in complex environments. However, vibrations in human\nmotion and the uneven distribution of point cloud features in complex\nenvironments often lead to rapid drift, which is a prevalent issue when\napplying existing LiDAR Inertial Odometry (LIO) methods on low-cost WMS. To\naddress these limitations, we propose a novel LIO for WMSs based on Hybrid\nContinuous Time Optimization (HCTO) considering the optimality of Lidar\ncorrespondences. First, HCTO recognizes patterns in human motion\n(high-frequency part, low-frequency part, and constant velocity part) by\nanalyzing raw IMU measurements. Second, HCTO constructs hybrid IMU factors\naccording to different motion states, which enables robust and accurate\nestimation against vibration-induced noise in the IMU measurements. Third, the\nbest point correspondences are selected using optimal design to achieve\nreal-time performance and better odometry accuracy. We conduct experiments on\nhead-mounted WMS datasets to evaluate the performance of our system,\ndemonstrating significant advantages over state-of-the-art methods. Video\nrecordings of experiments can be found on the project page of HCTO:\n\\href{https://github.com/kafeiyin00/HCTO}{https://github.com/kafeiyin00/HCTO}.\n","authors":["Jianping Li","Shenghai Yuan","Muqing Cao","Thien-Minh Nguyen","Kun Cao","Lihua Xie"],"pdf_url":"https://arxiv.org/pdf/2403.14173v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14163v1","updated":"2024-03-21T06:32:36Z","published":"2024-03-21T06:32:36Z","title":"Leveraging Large Language Model-based Room-Object Relationships\n  Knowledge for Enhancing Multimodal-Input Object Goal Navigation","summary":"  Object-goal navigation is a crucial engineering task for the community of\nembodied navigation; it involves navigating to an instance of a specified\nobject category within unseen environments. Although extensive investigations\nhave been conducted on both end-to-end and modular-based, data-driven\napproaches, fully enabling an agent to comprehend the environment through\nperceptual knowledge and perform object-goal navigation as efficiently as\nhumans remains a significant challenge. Recently, large language models have\nshown potential in this task, thanks to their powerful capabilities for\nknowledge extraction and integration. In this study, we propose a data-driven,\nmodular-based approach, trained on a dataset that incorporates common-sense\nknowledge of object-to-room relationships extracted from a large language\nmodel. We utilize the multi-channel Swin-Unet architecture to conduct\nmulti-task learning incorporating with multimodal inputs. The results in the\nHabitat simulator demonstrate that our framework outperforms the baseline by an\naverage of 10.6% in the efficiency metric, Success weighted by Path Length\n(SPL). The real-world demonstration shows that the proposed approach can\nefficiently conduct this task by traversing several rooms. For more details and\nreal-world demonstrations, please check our project webpage\n(https://sunleyuan.github.io/ObjectNav).\n","authors":["Leyuan Sun","Asako Kanezaki","Guillaume Caron","Yusuke Yoshiyasu"],"pdf_url":"https://arxiv.org/pdf/2403.14163v1.pdf","comment":"will soon submit to the Elsevier journal, Advanced Engineering\n  Informatics"},{"id":"http://arxiv.org/abs/2310.11792v2","updated":"2024-03-21T06:26:50Z","published":"2023-10-18T08:33:08Z","title":"Real-time Perceptive Motion Control using Control Barrier Functions with\n  Analytical Smoothing for Six-Wheeled-Telescopic-Legged Robot Tachyon 3","summary":"  To achieve safe legged locomotion, it is important to generate motion in\nreal-time considering various constraints in robots and environments. In this\nstudy, we propose a lightweight real-time perspective motion control system for\nthe newly developed six-wheeled-telescopic-legged robot, Tachyon 3. In the\nproposed method, analytically smoothed constraints including Smooth Separating\nAxis Theorem (Smooth SAT) as a novel higher order differentiable collision\ndetection for 3D shapes is applied to the Control Barrier Function (CBF). The\nproposed system integrating the CBF achieves online motion generation in a\nshort control cycle of 1 ms that satisfies joint limitations, environmental\ncollision avoidance and safe convex foothold constraints. The efficiency of\nSmooth SAT is shown from the collision detection time of 1 us or less and the\nCBF constraint computation time for Tachyon3 of several us. Furthermore, the\neffectiveness of the proposed system is verified through the stair-climbing\nmotion, integrating online recognition in a simulation and a real machine.\n","authors":["Noriaki Takasugi","Masaya Kinoshita","Yasuhisa Kamikawa","Ryoichi Tsuzaki","Atsushi Sakamoto","Toshimitsu Kai","Yasunori Kawanami"],"pdf_url":"https://arxiv.org/pdf/2310.11792v2.pdf","comment":"8 pages, 8 figures, This work has been submitted to the IEEE for\n  possible publication. Copyright may be transferred without notice, after\n  which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2403.14161v1","updated":"2024-03-21T06:24:01Z","published":"2024-03-21T06:24:01Z","title":"Extrinsic Calibration of Multiple LiDARs for a Mobile Robot based on\n  Floor Plane And Object Segmentation","summary":"  Mobile robots equipped with multiple light detection and ranging (LiDARs) and\ncapable of recognizing their surroundings are increasing due to the\nminitualization and cost reduction of LiDAR. This paper proposes a target-less\nextrinsic calibration method of multiple LiDARs with non-overlapping field of\nview (FoV). The proposed method uses accumulated point clouds of floor plane\nand objects while in motion. It enables accurate calibration with challenging\nconfiguration of LiDARs that directed towards the floor plane, caused by biased\nfeature values. Additionally, the method includes a noise removal module that\nconsiders the scanning pattern to address bleeding points, which are noises of\nsignificant source of error in point cloud alignment using high-density LiDARs.\nEvaluations through simulation demonstrate that the proposed method achieved\nhigher accuracy extrinsic calibration with two and four LiDARs than\nconventional methods, regardless type of objects. Furthermore, the experiments\nusing a real mobile robot has shown that our proposed noise removal module can\neliminate noise more precisely than conventional methods, and the estimated\nextrinsic parameters have successfully created consistent 3D maps.\n","authors":["Shun Niijima","Atsushi Suzuki","Ryoichi Tsuzaki","Masaya Kinoshita"],"pdf_url":"https://arxiv.org/pdf/2403.14161v1.pdf","comment":"8pages, 10figures"},{"id":"http://arxiv.org/abs/2403.14160v1","updated":"2024-03-21T06:23:57Z","published":"2024-03-21T06:23:57Z","title":"Development of a Compact Robust Passive Transformable Omni-Ball for\n  Enhanced Step-Climbing and Vibration Reduction","summary":"  This paper introduces the Passive Transformable Omni-Ball (PTOB), an advanced\nomnidirectional wheel engineered to enhance step-climbing performance,\nincorporate built-in actuators, diminish vibrations, and fortify structural\nintegrity. By modifying the omni-ball's structure from two to three segments,\nwe have achieved improved in-wheel actuation and a reduction in vibrational\nfeedback. Additionally, we have implemented a sliding mechanism in the follower\nwheels to boost the wheel's step-climbing abilities. A prototype with a 127 mm\ndiameter PTOB was constructed, which confirmed its functionality for\nomnidirectional movement and internal actuation. Compared to a traditional\nomni-wheel, the PTOB demonstrated a comparable level of vibration while\noffering superior capabilities. Extensive testing in varied settings showed\nthat the PTOB can adeptly handle step obstacles up to 45 mm, equivalent to 35\n$\\%$ of the wheel's diameter, in both the forward and lateral directions. The\nPTOB showcased robust construction and proved to be versatile in navigating\nthrough environments with diverse obstacles.\n","authors":["Kazuo Hongo","Takashi Kito","Yasuhisa Kamikawa","Masaya Kinoshita","Yasunori Kawanami"],"pdf_url":"https://arxiv.org/pdf/2403.14160v1.pdf","comment":"8 pages, 16 figures"},{"id":"http://arxiv.org/abs/2403.14159v1","updated":"2024-03-21T06:23:38Z","published":"2024-03-21T06:23:38Z","title":"Robust Locomotion via Zero-order Stochastic Nonlinear Model Predictive\n  Control with Guard Saltation Matrix","summary":"  This paper presents a stochastic/robust nonlinear model predictive control\n(NMPC) to enhance the robustness of legged locomotion against contact\nuncertainties. We integrate the contact uncertainties into the covariance\npropagation of stochastic/robust NMPC framework by leveraging the guard\nsaltation matrix and an extended Kalman filter-like covariance update. We\nachieve fast stochastic/robust NMPC computation by utilizing the zero-order\nstochastic/robust NMPC algorithm with additional improvements in computational\nefficiency concerning the feedback gains. We conducted numerical experiments\nand demonstrate that the proposed method can accurately forecast future state\ncovariance and generate trajectories that satisfies constraints even in the\npresence of the contact uncertainties. Hardware experiments on the perceptive\nlocomotion of a wheeled-legged robot were also carried out, validating the\nfeasibility of the proposed method in a real-world system with limited on-board\ncomputation.\n","authors":["Sotaro Katayama","Noriaki Takasugi","Mitsuhisa Kaneko","Norio Nagatsuka","and Masaya Kinoshita"],"pdf_url":"https://arxiv.org/pdf/2403.14159v1.pdf","comment":"8 pages, 8 figures"},{"id":"http://arxiv.org/abs/2311.10678v2","updated":"2024-03-21T05:47:22Z","published":"2023-11-17T18:00:20Z","title":"Distilling and Retrieving Generalizable Knowledge for Robot Manipulation\n  via Language Corrections","summary":"  Today's robot policies exhibit subpar performance when faced with the\nchallenge of generalizing to novel environments. Human corrective feedback is a\ncrucial form of guidance to enable such generalization. However, adapting to\nand learning from online human corrections is a non-trivial endeavor: not only\ndo robots need to remember human feedback over time to retrieve the right\ninformation in new settings and reduce the intervention rate, but also they\nwould need to be able to respond to feedback that can be arbitrary corrections\nabout high-level human preferences to low-level adjustments to skill\nparameters. In this work, we present Distillation and Retrieval of Online\nCorrections (DROC), a large language model (LLM)-based system that can respond\nto arbitrary forms of language feedback, distill generalizable knowledge from\ncorrections, and retrieve relevant past experiences based on textual and visual\nsimilarity for improving performance in novel settings. DROC is able to respond\nto a sequence of online language corrections that address failures in both\nhigh-level task plans and low-level skill primitives. We demonstrate that DROC\neffectively distills the relevant information from the sequence of online\ncorrections in a knowledge base and retrieves that knowledge in settings with\nnew task or object instances. DROC outperforms other techniques that directly\ngenerate robot code via LLMs by using only half of the total number of\ncorrections needed in the first round and requires little to no corrections\nafter two iterations. We show further results, videos, prompts and code on\nhttps://sites.google.com/stanford.edu/droc .\n","authors":["Lihan Zha","Yuchen Cui","Li-Heng Lin","Minae Kwon","Montserrat Gonzalez Arenas","Andy Zeng","Fei Xia","Dorsa Sadigh"],"pdf_url":"https://arxiv.org/pdf/2311.10678v2.pdf","comment":"8 pages, 4 figures, videos and code links on website\n  https://sites.google.com/stanford.edu/droc"},{"id":"http://arxiv.org/abs/2403.14138v1","updated":"2024-03-21T05:13:34Z","published":"2024-03-21T05:13:34Z","title":"Evidential Semantic Mapping in Off-road Environments with\n  Uncertainty-aware Bayesian Kernel Inference","summary":"  Robotic mapping with Bayesian Kernel Inference (BKI) has shown promise in\ncreating semantic maps by effectively leveraging local spatial information.\nHowever, existing semantic mapping methods face challenges in constructing\nreliable maps in unstructured outdoor scenarios due to unreliable semantic\npredictions. To address this issue, we propose an evidential semantic mapping,\nwhich can enhance reliability in perceptually challenging off-road\nenvironments. We integrate Evidential Deep Learning into the semantic\nsegmentation network to obtain the uncertainty estimate of semantic prediction.\nSubsequently, this semantic uncertainty is incorporated into an\nuncertainty-aware BKI, tailored to prioritize more confident semantic\npredictions when accumulating semantic information. By adaptively handling\nsemantic uncertainties, the proposed framework constructs robust\nrepresentations of the surroundings even in previously unseen environments.\nComprehensive experiments across various off-road datasets demonstrate that our\nframework enhances accuracy and robustness, consistently outperforming existing\nmethods in scenes with high perceptual uncertainties.\n","authors":["Junyoung Kim","Junwon Seo","Jihong Min"],"pdf_url":"https://arxiv.org/pdf/2403.14138v1.pdf","comment":"Our project website can be found at\n  https://kjyoung.github.io/Homepage/#/Projects/Evidential-Semantic-Mapping"},{"id":"http://arxiv.org/abs/2303.03757v3","updated":"2024-03-21T05:11:08Z","published":"2023-03-07T09:33:49Z","title":"Deep Learning for Inertial Positioning: A Survey","summary":"  Inertial sensors are widely utilized in smartphones, drones, robots, and IoT\ndevices, playing a crucial role in enabling ubiquitous and reliable\nlocalization. Inertial sensor-based positioning is essential in various\napplications, including personal navigation, location-based security, and\nhuman-device interaction. However, low-cost MEMS inertial sensors' measurements\nare inevitably corrupted by various error sources, leading to unbounded drifts\nwhen integrated doubly in traditional inertial navigation algorithms,\nsubjecting inertial positioning to the problem of error drifts. In recent\nyears, with the rapid increase in sensor data and computational power, deep\nlearning techniques have been developed, sparking significant research into\naddressing the problem of inertial positioning. Relevant literature in this\nfield spans across mobile computing, robotics, and machine learning. In this\narticle, we provide a comprehensive review of deep learning-based inertial\npositioning and its applications in tracking pedestrians, drones, vehicles, and\nrobots. We connect efforts from different fields and discuss how deep learning\ncan be applied to address issues such as sensor calibration, positioning error\ndrift reduction, and multi-sensor fusion. This article aims to attract readers\nfrom various backgrounds, including researchers and practitioners interested in\nthe potential of deep learning-based techniques to solve inertial positioning\nproblems. Our review demonstrates the exciting possibilities that deep learning\nbrings to the table and provides a roadmap for future research in this field.\n","authors":["Changhao Chen","Xianfei Pan"],"pdf_url":"https://arxiv.org/pdf/2303.03757v3.pdf","comment":"Accepted by IEEE Transactions on Intelligent Transportation Systems"},{"id":"http://arxiv.org/abs/2403.13331v2","updated":"2024-03-21T04:01:10Z","published":"2024-03-20T06:22:37Z","title":"AMP: Autoregressive Motion Prediction Revisited with Next Token\n  Prediction for Autonomous Driving","summary":"  As an essential task in autonomous driving (AD), motion prediction aims to\npredict the future states of surround objects for navigation. One natural\nsolution is to estimate the position of other agents in a step-by-step manner\nwhere each predicted time-step is conditioned on both observed time-steps and\npreviously predicted time-steps, i.e., autoregressive prediction. Pioneering\nworks like SocialLSTM and MFP design their decoders based on this intuition.\nHowever, almost all state-of-the-art works assume that all predicted time-steps\nare independent conditioned on observed time-steps, where they use a single\nlinear layer to generate positions of all time-steps simultaneously. They\ndominate most motion prediction leaderboards due to the simplicity of training\nMLPs compared to autoregressive networks.\n  In this paper, we introduce the GPT style next token prediction into motion\nforecasting. In this way, the input and output could be represented in a\nunified space and thus the autoregressive prediction becomes more feasible.\nHowever, different from language data which is composed of homogeneous units\n-words, the elements in the driving scene could have complex spatial-temporal\nand semantic relations. To this end, we propose to adopt three factorized\nattention modules with different neighbors for information aggregation and\ndifferent position encoding styles to capture their relations, e.g., encoding\nthe transformation between coordinate systems for spatial relativity while\nadopting RoPE for temporal relativity. Empirically, by equipping with the\naforementioned tailored designs, the proposed method achieves state-of-the-art\nperformance in the Waymo Open Motion and Waymo Interaction datasets. Notably,\nAMP outperforms other recent autoregressive motion prediction methods: MotionLM\nand StateTransformer, which demonstrates the effectiveness of the proposed\ndesigns.\n","authors":["Xiaosong Jia","Shaoshuai Shi","Zijun Chen","Li Jiang","Wenlong Liao","Tao He","Junchi Yan"],"pdf_url":"https://arxiv.org/pdf/2403.13331v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.13122v2","updated":"2024-03-21T01:15:02Z","published":"2023-07-24T20:40:18Z","title":"Redundancy parameterization and inverse kinematics of 7-DOF revolute\n  manipulators","summary":"  Seven degree-of-freedom (DOF) robot arms have one redundant DOF which does\nnot change the motion of the end effector. The redundant DOF offers greater\nmanipulability of the arm configuration to avoid obstacles and singularities,\nbut it must be parameterized to fully specify the joint angles for a given end\neffector pose. For 7-DOF revolute (7R) manipulators, we introduce a new concept\nof generalized shoulder-elbow-wrist (SEW) angle, a generalization of the\nconventional SEW angle but with an arbitrary choice of the reference direction\nfunction. The SEW angle is widely used and easy for human operators to\nvisualize as a rotation of the elbow about the shoulder-wrist line. Since other\nredundancy parameterizations including the conventional SEW angle encounter an\nalgorithmic singularity along a line in the workspace, we introduce a special\nchoice of the reference direction function called the stereographic SEW angle\nwhich has a singularity only along a half-line, which can be placed out of\nreach. We prove that such a singularity is unavoidable for any\nparameterization. We also include expressions for the SEW angle Jacobian along\nwith singularity analysis. Finally, we provide efficient and singularity-robust\ninverse kinematics solutions for most known 7R manipulators using the general\nSEW angle and the subproblem decomposition method. These solutions are often\nclosed-form but may sometimes involve a 1D or 2D search in the general case.\nSearch-based solutions may be converted to finding zeros of a high-order\npolynomial. Inverse kinematics solutions, examples, and evaluations are\navailable in a publicly accessible repository.\n","authors":["Alexander J. Elias","John T. Wen"],"pdf_url":"https://arxiv.org/pdf/2307.13122v2.pdf","comment":"22 pages, 14 figures. Update: Sawyer IK using polynomial method, two\n  video extensions, expanded related literature"},{"id":"http://arxiv.org/abs/2403.14056v1","updated":"2024-03-21T00:59:35Z","published":"2024-03-21T00:59:35Z","title":"Semantics from Space: Satellite-Guided Thermal Semantic Segmentation\n  Annotation for Aerial Field Robots","summary":"  We present a new method to automatically generate semantic segmentation\nannotations for thermal imagery captured from an aerial vehicle by utilizing\nsatellite-derived data products alongside onboard global positioning and\nattitude estimates. This new capability overcomes the challenge of developing\nthermal semantic perception algorithms for field robots due to the lack of\nannotated thermal field datasets and the time and costs of manual annotation,\nenabling precise and rapid annotation of thermal data from field collection\nefforts at a massively-parallelizable scale. By incorporating a\nthermal-conditioned refinement step with visual foundation models, our approach\ncan produce highly-precise semantic segmentation labels using low-resolution\nsatellite land cover data for little-to-no cost. It achieves 98.5% of the\nperformance from using costly high-resolution options and demonstrates between\n70-160% improvement over popular zero-shot semantic segmentation methods based\non large vision-language models currently used for generating annotations for\nRGB imagery. Code will be available at:\nhttps://github.com/connorlee77/aerial-auto-segment.\n","authors":["Connor Lee","Saraswati Soedarmadji","Matthew Anderson","Anthony J. Clark","Soon-Jo Chung"],"pdf_url":"https://arxiv.org/pdf/2403.14056v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.08864v5","updated":"2024-03-21T00:48:52Z","published":"2023-10-13T05:20:40Z","title":"Open X-Embodiment: Robotic Learning Datasets and RT-X Models","summary":"  Large, high-capacity models trained on diverse datasets have shown remarkable\nsuccesses on efficiently tackling downstream applications. In domains from NLP\nto Computer Vision, this has led to a consolidation of pretrained models, with\ngeneral pretrained backbones serving as a starting point for many applications.\nCan such a consolidation happen in robotics? Conventionally, robotic learning\nmethods train a separate model for every application, every robot, and even\nevery environment. Can we instead train generalist X-robot policy that can be\nadapted efficiently to new robots, tasks, and environments? In this paper, we\nprovide datasets in standardized data formats and models to make it possible to\nexplore this possibility in the context of robotic manipulation, alongside\nexperimental results that provide an example of effective X-robot policies. We\nassemble a dataset from 22 different robots collected through a collaboration\nbetween 21 institutions, demonstrating 527 skills (160266 tasks). We show that\na high-capacity model trained on this data, which we call RT-X, exhibits\npositive transfer and improves the capabilities of multiple robots by\nleveraging experience from other platforms. More details can be found on the\nproject website https://robotics-transformer-x.github.io.\n","authors":["Open X-Embodiment Collaboration","Abby O'Neill","Abdul Rehman","Abhiram Maddukuri","Abhishek Gupta","Abhishek Padalkar","Abraham Lee","Acorn Pooley","Agrim Gupta","Ajay Mandlekar","Ajinkya Jain","Albert Tung","Alex Bewley","Alex Herzog","Alex Irpan","Alexander Khazatsky","Anant Rai","Anchit Gupta","Andrew Wang","Anikait Singh","Animesh Garg","Aniruddha Kembhavi","Annie Xie","Anthony Brohan","Antonin Raffin","Archit Sharma","Arefeh Yavary","Arhan Jain","Ashwin Balakrishna","Ayzaan Wahid","Ben Burgess-Limerick","Beomjoon Kim","Bernhard Schölkopf","Blake Wulfe","Brian Ichter","Cewu Lu","Charles Xu","Charlotte Le","Chelsea Finn","Chen Wang","Chenfeng Xu","Cheng Chi","Chenguang Huang","Christine Chan","Christopher Agia","Chuer Pan","Chuyuan Fu","Coline Devin","Danfei Xu","Daniel Morton","Danny Driess","Daphne Chen","Deepak Pathak","Dhruv Shah","Dieter Büchler","Dinesh Jayaraman","Dmitry Kalashnikov","Dorsa Sadigh","Edward Johns","Ethan Foster","Fangchen Liu","Federico Ceola","Fei Xia","Feiyu Zhao","Freek Stulp","Gaoyue Zhou","Gaurav S. Sukhatme","Gautam Salhotra","Ge Yan","Gilbert Feng","Giulio Schiavi","Glen Berseth","Gregory Kahn","Guanzhi Wang","Hao Su","Hao-Shu Fang","Haochen Shi","Henghui Bao","Heni Ben Amor","Henrik I Christensen","Hiroki Furuta","Homer Walke","Hongjie Fang","Huy Ha","Igor Mordatch","Ilija Radosavovic","Isabel Leal","Jacky Liang","Jad Abou-Chakra","Jaehyung Kim","Jaimyn Drake","Jan Peters","Jan Schneider","Jasmine Hsu","Jeannette Bohg","Jeffrey Bingham","Jeffrey Wu","Jensen Gao","Jiaheng Hu","Jiajun Wu","Jialin Wu","Jiankai Sun","Jianlan Luo","Jiayuan Gu","Jie Tan","Jihoon Oh","Jimmy Wu","Jingpei Lu","Jingyun Yang","Jitendra Malik","João Silvério","Joey Hejna","Jonathan Booher","Jonathan Tompson","Jonathan Yang","Jordi Salvador","Joseph J. Lim","Junhyek Han","Kaiyuan Wang","Kanishka Rao","Karl Pertsch","Karol Hausman","Keegan Go","Keerthana Gopalakrishnan","Ken Goldberg","Kendra Byrne","Kenneth Oslund","Kento Kawaharazuka","Kevin Black","Kevin Lin","Kevin Zhang","Kiana Ehsani","Kiran Lekkala","Kirsty Ellis","Krishan Rana","Krishnan Srinivasan","Kuan Fang","Kunal Pratap Singh","Kuo-Hao Zeng","Kyle Hatch","Kyle Hsu","Laurent Itti","Lawrence Yunliang Chen","Lerrel Pinto","Li Fei-Fei","Liam Tan","Linxi \"Jim\" Fan","Lionel Ott","Lisa Lee","Luca Weihs","Magnum Chen","Marion Lepert","Marius Memmel","Masayoshi Tomizuka","Masha Itkina","Mateo Guaman Castro","Max Spero","Maximilian Du","Michael Ahn","Michael C. Yip","Mingtong Zhang","Mingyu Ding","Minho Heo","Mohan Kumar Srirama","Mohit Sharma","Moo Jin Kim","Naoaki Kanazawa","Nicklas Hansen","Nicolas Heess","Nikhil J Joshi","Niko Suenderhauf","Ning Liu","Norman Di Palo","Nur Muhammad Mahi Shafiullah","Oier Mees","Oliver Kroemer","Osbert Bastani","Pannag R Sanketi","Patrick \"Tree\" Miller","Patrick Yin","Paul Wohlhart","Peng Xu","Peter David Fagan","Peter Mitrano","Pierre Sermanet","Pieter Abbeel","Priya Sundaresan","Qiuyu Chen","Quan Vuong","Rafael Rafailov","Ran Tian","Ria Doshi","Roberto Martín-Martín","Rohan Baijal","Rosario Scalise","Rose Hendrix","Roy Lin","Runjia Qian","Ruohan Zhang","Russell Mendonca","Rutav Shah","Ryan Hoque","Ryan Julian","Samuel Bustamante","Sean Kirmani","Sergey Levine","Shan Lin","Sherry Moore","Shikhar Bahl","Shivin Dass","Shubham Sonawani","Shuran Song","Sichun Xu","Siddhant Haldar","Siddharth Karamcheti","Simeon Adebola","Simon Guist","Soroush Nasiriany","Stefan Schaal","Stefan Welker","Stephen Tian","Subramanian Ramamoorthy","Sudeep Dasari","Suneel Belkhale","Sungjae Park","Suraj Nair","Suvir Mirchandani","Takayuki Osa","Tanmay Gupta","Tatsuya Harada","Tatsuya Matsushima","Ted Xiao","Thomas Kollar","Tianhe Yu","Tianli Ding","Todor Davchev","Tony Z. Zhao","Travis Armstrong","Trevor Darrell","Trinity Chung","Vidhi Jain","Vincent Vanhoucke","Wei Zhan","Wenxuan Zhou","Wolfram Burgard","Xi Chen","Xiaolong Wang","Xinghao Zhu","Xinyang Geng","Xiyuan Liu","Xu Liangwei","Xuanlin Li","Yao Lu","Yecheng Jason Ma","Yejin Kim","Yevgen Chebotar","Yifan Zhou","Yifeng Zhu","Yilin Wu","Ying Xu","Yixuan Wang","Yonatan Bisk","Yoonyoung Cho","Youngwoon Lee","Yuchen Cui","Yue Cao","Yueh-Hua Wu","Yujin Tang","Yuke Zhu","Yunchu Zhang","Yunfan Jiang","Yunshuang Li","Yunzhu Li","Yusuke Iwasawa","Yutaka Matsuo","Zehan Ma","Zhuo Xu","Zichen Jeff Cui","Zichen Zhang","Zipeng Lin"],"pdf_url":"https://arxiv.org/pdf/2310.08864v5.pdf","comment":"Project website: https://robotics-transformer-x.github.io"},{"id":"http://arxiv.org/abs/2403.14049v1","updated":"2024-03-21T00:14:53Z","published":"2024-03-21T00:14:53Z","title":"A Roadmap Towards Automated and Regulated Robotic Systems","summary":"  The rapid development of generative technology opens up possibility for\nhigher level of automation, and artificial intelligence (AI) embodiment in\nrobotic systems is imminent. However, due to the blackbox nature of the\ngenerative technology, the generation of the knowledge and workflow scheme is\nuncontrolled, especially in a dynamic environment and a complex scene. This\nposes challenges to regulations in safety-demanding applications such as\nmedical scenes. We argue that the unregulated generative processes from AI is\nfitted for low level end tasks, but intervention in the form of manual or\nautomated regulation should happen post-workflow-generation and\npre-robotic-execution. To address this, we propose a roadmap that can lead to\nfully automated and regulated robotic systems. In this paradigm, the high level\npolicies are generated as structured graph data, enabling regulatory oversight\nand reusability, while the code base for lower level tasks is generated by\ngenerative models. Our approach aims the transitioning from expert knowledge to\nregulated action, akin to the iterative processes of study, practice, scrutiny,\nand execution in human tasks. We identify the generative and deterministic\nprocesses in a design cycle, where generative processes serve as a text-based\nworld simulator and the deterministic processes generate the executable system.\nWe propose State Machine Seralization Language (SMSL) to be the conversion\npoint between text simulator and executable workflow control. From there, we\nanalyze the modules involved based on the current literature, and discuss human\nin the loop. As a roadmap, this work identifies the current possible\nimplementation and future work. This work does not provide an implemented\nsystem but envisions to inspire the researchers working on the direction in the\nroadmap. We implement the SMSL and D-SFO paradigm that serve as the starting\npoint of the roadmap.\n","authors":["Yihao Liu","Mehran Armand"],"pdf_url":"https://arxiv.org/pdf/2403.14049v1.pdf","comment":"17 pages, 9 figures"},{"id":"http://arxiv.org/abs/2310.16828v2","updated":"2024-03-21T17:56:19Z","published":"2023-10-25T17:57:07Z","title":"TD-MPC2: Scalable, Robust World Models for Continuous Control","summary":"  TD-MPC is a model-based reinforcement learning (RL) algorithm that performs\nlocal trajectory optimization in the latent space of a learned implicit\n(decoder-free) world model. In this work, we present TD-MPC2: a series of\nimprovements upon the TD-MPC algorithm. We demonstrate that TD-MPC2 improves\nsignificantly over baselines across 104 online RL tasks spanning 4 diverse task\ndomains, achieving consistently strong results with a single set of\nhyperparameters. We further show that agent capabilities increase with model\nand data size, and successfully train a single 317M parameter agent to perform\n80 tasks across multiple task domains, embodiments, and action spaces. We\nconclude with an account of lessons, opportunities, and risks associated with\nlarge TD-MPC2 agents. Explore videos, models, data, code, and more at\nhttps://tdmpc2.com\n","authors":["Nicklas Hansen","Hao Su","Xiaolong Wang"],"pdf_url":"https://arxiv.org/pdf/2310.16828v2.pdf","comment":"ICLR 2024. Explore videos, models, data, code, and more at\n  https://tdmpc2.com"},{"id":"http://arxiv.org/abs/2403.14887v1","updated":"2024-03-21T23:44:42Z","published":"2024-03-21T23:44:42Z","title":"GelLink: A Compact Multi-phalanx Finger with Vision-based Tactile\n  Sensing and Proprioception","summary":"  Compared to fully-actuated robotic end-effectors, underactuated ones are\ngenerally more adaptive, robust, and cost-effective. However, state estimation\nfor underactuated hands is usually more challenging. Vision-based tactile\nsensors, like Gelsight, can mitigate this issue by providing high-resolution\ntactile sensing and accurate proprioceptive sensing. As such, we present\nGelLink, a compact, underactuated, linkage-driven robotic finger with low-cost,\nhigh-resolution vision-based tactile sensing and proprioceptive sensing\ncapabilities. In order to reduce the amount of embedded hardware, i.e. the\ncameras and motors, we optimize the linkage transmission with a planar linkage\nmechanism simulator and develop a planar reflection simulator to simplify the\ntactile sensing hardware. As a result, GelLink only requires one motor to\nactuate the three phalanges, and one camera to capture tactile signals along\nthe entire finger. Overall, GelLink is a compact robotic finger that shows\nadaptability and robustness when performing grasping tasks. The integration of\nvision-based tactile sensors can significantly enhance the capabilities of\nunderactuated fingers and potentially broaden their future usage.\n","authors":["Yuxiang Ma"," Jialiang"," Zhao","Edward Adelson"],"pdf_url":"https://arxiv.org/pdf/2403.14887v1.pdf","comment":"Supplement video: https://www.youtube.com/watch?v=hZwUpAig5C0 . 7\n  pages, 9 figures. ICRA 2024 (IEEE International Conference on Robotics and\n  Automation)"},{"id":"http://arxiv.org/abs/2403.14879v1","updated":"2024-03-21T23:00:10Z","published":"2024-03-21T23:00:10Z","title":"Learning to Change: Choreographing Mixed Traffic Through Lateral Control\n  and Hierarchical Reinforcement Learning","summary":"  The management of mixed traffic that consists of robot vehicles (RVs) and\nhuman-driven vehicles (HVs) at complex intersections presents a multifaceted\nchallenge. Traditional signal controls often struggle to adapt to dynamic\ntraffic conditions and heterogeneous vehicle types. Recent advancements have\nturned to strategies based on reinforcement learning (RL), leveraging its\nmodel-free nature, real-time operation, and generalizability over different\nscenarios. We introduce a hierarchical RL framework to manage mixed traffic\nthrough precise longitudinal and lateral control of RVs. Our proposed\nhierarchical framework combines the state-of-the-art mixed traffic control\nalgorithm as a high level decision maker to improve the performance and\nrobustness of the whole system. Our experiments demonstrate that the framework\ncan reduce the average waiting time by up to 54% compared to the\nstate-of-the-art mixed traffic control method. When the RV penetration rate\nexceeds 60%, our technique consistently outperforms conventional traffic signal\ncontrol programs in terms of the average waiting time for all vehicles at the\nintersection.\n","authors":["Dawei Wang","Weizi Li","Lei Zhu","Jia Pan"],"pdf_url":"https://arxiv.org/pdf/2403.14879v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14877v1","updated":"2024-03-21T22:54:08Z","published":"2024-03-21T22:54:08Z","title":"TEeVTOL: Balancing Energy and Time Efficiency in eVTOL Aircraft Path\n  Planning Across City-Scale Wind Fields","summary":"  Electric vertical-takeoff and landing (eVTOL) aircraft, recognized for their\nmaneuverability and flexibility, offer a promising alternative to our\ntransportation system. However, the operational effectiveness of these aircraft\nfaces many challenges, such as the delicate balance between energy and time\nefficiency, stemming from unpredictable environmental factors, including wind\nfields. Mathematical modeling-based approaches have been adopted to plan\naircraft flight path in urban wind fields with the goal to save energy and time\ncosts. While effective, they are limited in adapting to dynamic and complex\nenvironments. To optimize energy and time efficiency in eVTOL's flight through\ndynamic wind fields, we introduce a novel path planning method leveraging deep\nreinforcement learning. We assess our method with extensive experiments,\ncomparing it to Dijkstra's algorithm -- the theoretically optimal approach for\ndetermining shortest paths in a weighted graph, where weights represent either\nenergy or time cost. The results show that our method achieves a graceful\nbalance between energy and time efficiency, closely resembling the\ntheoretically optimal values for both objectives.\n","authors":["Songyang Liu","Shuai Li","Haochen Li","Weizi Li","Jindong Tan"],"pdf_url":"https://arxiv.org/pdf/2403.14877v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14864v1","updated":"2024-03-21T22:18:59Z","published":"2024-03-21T22:18:59Z","title":"Learning Quadruped Locomotion Using Differentiable Simulation","summary":"  While most recent advancements in legged robot control have been driven by\nmodel-free reinforcement learning, we explore the potential of differentiable\nsimulation. Differentiable simulation promises faster convergence and more\nstable training by computing low-variant first-order gradients using the robot\nmodel, but so far, its use for legged robot control has remained limited to\nsimulation. The main challenge with differentiable simulation lies in the\ncomplex optimization landscape of robotic tasks due to discontinuities in\ncontact-rich environments, e.g., quadruped locomotion. This work proposes a\nnew, differentiable simulation framework to overcome these challenges. The key\nidea involves decoupling the complex whole-body simulation, which may exhibit\ndiscontinuities due to contact, into two separate continuous domains.\nSubsequently, we align the robot state resulting from the simplified model with\na more precise, non-differentiable simulator to maintain sufficient simulation\naccuracy. Our framework enables learning quadruped walking in minutes using a\nsingle simulated robot without any parallelization. When augmented with GPU\nparallelization, our approach allows the quadruped robot to master diverse\nlocomotion skills, including trot, pace, bound, and gallop, on challenging\nterrains in minutes. Additionally, our policy achieves robust locomotion\nperformance in the real world zero-shot. To the best of our knowledge, this\nwork represents the first demonstration of using differentiable simulation for\ncontrolling a real quadruped robot. This work provides several important\ninsights into using differentiable simulations for legged locomotion in the\nreal world.\n","authors":["Yunlong Song","Sangbae Kim","Davide Scaramuzza"],"pdf_url":"https://arxiv.org/pdf/2403.14864v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.07869v2","updated":"2024-03-21T19:57:46Z","published":"2024-03-12T17:58:01Z","title":"TeleMoMa: A Modular and Versatile Teleoperation System for Mobile\n  Manipulation","summary":"  A critical bottleneck limiting imitation learning in robotics is the lack of\ndata. This problem is more severe in mobile manipulation, where collecting\ndemonstrations is harder than in stationary manipulation due to the lack of\navailable and easy-to-use teleoperation interfaces. In this work, we\ndemonstrate TeleMoMa, a general and modular interface for whole-body\nteleoperation of mobile manipulators. TeleMoMa unifies multiple human\ninterfaces including RGB and depth cameras, virtual reality controllers,\nkeyboard, joysticks, etc., and any combination thereof. In its more accessible\nversion, TeleMoMa works using simply vision (e.g., an RGB-D camera), lowering\nthe entry bar for humans to provide mobile manipulation demonstrations. We\ndemonstrate the versatility of TeleMoMa by teleoperating several existing\nmobile manipulators - PAL Tiago++, Toyota HSR, and Fetch - in simulation and\nthe real world. We demonstrate the quality of the demonstrations collected with\nTeleMoMa by training imitation learning policies for mobile manipulation tasks\ninvolving synchronized whole-body motion. Finally, we also show that TeleMoMa's\nteleoperation channel enables teleoperation on site, looking at the robot, or\nremote, sending commands and observations through a computer network, and\nperform user studies to evaluate how easy it is for novice users to learn to\ncollect demonstrations with different combinations of human interfaces enabled\nby our system. We hope TeleMoMa becomes a helpful tool for the community\nenabling researchers to collect whole-body mobile manipulation demonstrations.\nFor more information and video results,\nhttps://robin-lab.cs.utexas.edu/telemoma-web.\n","authors":["Shivin Dass","Wensi Ai","Yuqian Jiang","Samik Singh","Jiaheng Hu","Ruohan Zhang","Peter Stone","Ben Abbatematteo","Roberto Martín-Martín"],"pdf_url":"https://arxiv.org/pdf/2403.07869v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14780v1","updated":"2024-03-21T18:50:33Z","published":"2024-03-21T18:50:33Z","title":"Multi-agent Task-Driven Exploration via Intelligent Map Compression and\n  Sharing","summary":"  This paper investigates the task-driven exploration of unknown environments\nwith mobile sensors communicating compressed measurements. The sensors explore\nthe area and transmit their compressed data to another robot, assisting it in\nreaching a goal location. We propose a novel communication framework and a\ntractable multi-agent exploration algorithm to select the sensors' actions. The\nalgorithm uses a task-driven measure of uncertainty, resulting from map\ncompression, as a reward function. We validate the efficacy of our algorithm\nthrough numerical simulations conducted on a realistic map and compare it with\ntwo alternative approaches. The results indicate that the proposed algorithm\neffectively decreases the time required for the robot to reach its target\nwithout causing excessive load on the communication network.\n","authors":["Evangelos Psomiadis","Dipankar Maity","Panagiotis Tsiotras"],"pdf_url":"https://arxiv.org/pdf/2403.14780v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.10698v2","updated":"2024-03-21T18:20:14Z","published":"2023-09-19T15:37:24Z","title":"OASIS: Optimal Arrangements for Sensing in SLAM","summary":"  The number and arrangement of sensors on mobile robot dramatically influence\nits perception capabilities. Ensuring that sensors are mounted in a manner that\nenables accurate detection, localization, and mapping is essential for the\nsuccess of downstream control tasks. However, when designing a new robotic\nplatform, researchers and practitioners alike usually mimic standard\nconfigurations or maximize simple heuristics like field-of-view (FOV) coverage\nto decide where to place exteroceptive sensors. In this work, we conduct an\ninformation-theoretic investigation of this overlooked element of robotic\nperception in the context of simultaneous localization and mapping (SLAM). We\nshow how to formalize the sensor arrangement problem as a form of subset\nselection under the E-optimality performance criterion. While this formulation\nis NP-hard in general, we show that a combination of greedy sensor selection\nand fast convex relaxation-based post-hoc verification enables the efficient\nrecovery of certifiably optimal sensor designs in practice. Results from\nsynthetic experiments reveal that sensors placed with OASIS outperform\nbenchmarks in terms of mean squared error of visual SLAM estimates.\n","authors":["Pushyami Kaveti","Matthew Giamou","Hanumant Singh","David M. Rosen"],"pdf_url":"https://arxiv.org/pdf/2309.10698v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15494v1","updated":"2024-03-21T17:36:53Z","published":"2024-03-21T17:36:53Z","title":"Multiple and Gyro-Free Inertial Datasets","summary":"  An inertial navigation system (INS) utilizes three orthogonal accelerometers\nand gyroscopes to determine platform position, velocity, and orientation. There\nare countless applications for INS, including robotics, autonomous platforms,\nand the internet of things. Recent research explores the integration of\ndata-driven methods with INS, highlighting significant innovations, improving\naccuracy and efficiency. Despite the growing interest in this field and the\navailability of INS datasets, no datasets are available for gyro-free INS\n(GFINS) and multiple inertial measurement unit (MIMU) architectures. To fill\nthis gap and to stimulate further research in this field, we designed and\nrecorded GFINS and MIMU datasets using 54 inertial sensors grouped in nine\ninertial measurement units. These sensors can be used to define and evaluate\ndifferent types of MIMU and GFINS architectures. The inertial sensors were\narranged in three different sensor configurations and mounted on a mobile robot\nand a passenger car. In total, the dataset contains 35 hours of inertial data\nand corresponding ground truth trajectories. The data and code are freely\naccessible through our GitHub repository.\n","authors":["Zeev Yampolsky","Yair Stolero","Nitzan Pri-Hadash","Dan Solodar","Shira Massas","Itai Savin","Itzik Klein"],"pdf_url":"https://arxiv.org/pdf/2403.15494v1.pdf","comment":"10 pages, 16 figures, 6 tables"}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2403.14624v1","updated":"2024-03-21T17:59:50Z","published":"2024-03-21T17:59:50Z","title":"MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual\n  Math Problems?","summary":"  The remarkable progress of Multi-modal Large Language Models (MLLMs) has\ngarnered unparalleled attention, due to their superior performance in visual\ncontexts. However, their capabilities in visual math problem-solving remain\ninsufficiently evaluated and understood. We investigate current benchmarks to\nincorporate excessive visual content within textual questions, which\npotentially assist MLLMs in deducing answers without truly interpreting the\ninput diagrams. To this end, we introduce MathVerse, an all-around visual math\nbenchmark designed for an equitable and in-depth evaluation of MLLMs. We\nmeticulously collect 2,612 high-quality, multi-subject math problems with\ndiagrams from publicly available sources. Each problem is then transformed by\nhuman annotators into six distinct versions, each offering varying degrees of\ninformation content in multi-modality, contributing to 15K test samples in\ntotal. This approach allows MathVerse to comprehensively assess whether and how\nmuch MLLMs can truly understand the visual diagrams for mathematical reasoning.\nIn addition, we propose a Chain-of-Thought (CoT) evaluation strategy for a\nfine-grained assessment of the output answers. Rather than naively judging True\nor False, we employ GPT-4(V) to adaptively extract crucial reasoning steps, and\nthen score each step with detailed error analysis, which can reveal the\nintermediate CoT reasoning quality by MLLMs. We hope the MathVerse benchmark\nmay provide unique insights to guide the future development of MLLMs. Project\npage: https://mathverse-cuhk.github.io\n","authors":["Renrui Zhang","Dongzhi Jiang","Yichi Zhang","Haokun Lin","Ziyu Guo","Pengshuo Qiu","Aojun Zhou","Pan Lu","Kai-Wei Chang","Peng Gao","Hongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2403.14624v1.pdf","comment":"46 Pages, Work in Progress, Benchmark Project Page:\n  https://mathverse-cuhk.github.io"},{"id":"http://arxiv.org/abs/2403.14617v1","updated":"2024-03-21T17:59:03Z","published":"2024-03-21T17:59:03Z","title":"Videoshop: Localized Semantic Video Editing with Noise-Extrapolated\n  Diffusion Inversion","summary":"  We introduce Videoshop, a training-free video editing algorithm for localized\nsemantic edits. Videoshop allows users to use any editing software, including\nPhotoshop and generative inpainting, to modify the first frame; it\nautomatically propagates those changes, with semantic, spatial, and temporally\nconsistent motion, to the remaining frames. Unlike existing methods that enable\nedits only through imprecise textual instructions, Videoshop allows users to\nadd or remove objects, semantically change objects, insert stock photos into\nvideos, etc. with fine-grained control over locations and appearance. We\nachieve this through image-based video editing by inverting latents with noise\nextrapolation, from which we generate videos conditioned on the edited image.\nVideoshop produces higher quality edits against 6 baselines on 2 editing\nbenchmarks using 10 evaluation metrics.\n","authors":["Xiang Fan","Anand Bhattad","Ranjay Krishna"],"pdf_url":"https://arxiv.org/pdf/2403.14617v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14592v1","updated":"2024-03-21T17:47:28Z","published":"2024-03-21T17:47:28Z","title":"Envisioning the Next-Generation AI Coding Assistants: Insights &\n  Proposals","summary":"  As a research-product hybrid group in AI for Software Engineering (AI4SE), we\npresent four key takeaways from our experience developing in-IDE AI coding\nassistants. AI coding assistants should set clear expectations for usage,\nintegrate with advanced IDE capabilities and existing extensions, use\nextendable backend designs, and collect app data responsibly for downstream\nanalyses. We propose open questions and challenges that academia and industry\nshould address to realize the vision of next-generation AI coding assistants.\n","authors":["Khanh Nghiem","Anh Minh Nguyen","Nghi D. Q. Bui"],"pdf_url":"https://arxiv.org/pdf/2403.14592v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14589v1","updated":"2024-03-21T17:43:44Z","published":"2024-03-21T17:43:44Z","title":"ReAct Meets ActRe: Autonomous Annotations of Agent Trajectories for\n  Contrastive Self-Training","summary":"  Language agents have demonstrated autonomous decision-making abilities by\nreasoning with foundation models. Recently, efforts have been made to train\nlanguage agents for performance improvement, with multi-step reasoning and\naction trajectories as the training data. However, collecting such trajectories\nstill requires considerable human effort, by either artificial annotations or\nimplementations of diverse prompting frameworks. In this work, we propose\nA$^3$T, a framework that enables the Autonomous Annotation of Agent\nTrajectories in the style of ReAct. The central role is an ActRe prompting\nagent, which explains the reason for an arbitrary action. When randomly\nsampling an external action, the ReAct-style agent could query the ActRe agent\nwith the action to obtain its textual rationales. Novel trajectories are then\nsynthesized by prepending the posterior reasoning from ActRe to the sampled\naction. In this way, the ReAct-style agent executes multiple trajectories for\nthe failed tasks, and selects the successful ones to supplement its failed\ntrajectory for contrastive self-training. Realized by policy gradient methods\nwith binarized rewards, the contrastive self-training with accumulated\ntrajectories facilitates a closed loop for multiple rounds of language agent\nself-improvement. We conduct experiments using QLoRA fine-tuning with the\nopen-sourced Mistral-7B-Instruct-v0.2. In AlfWorld, the agent trained with\nA$^3$T obtains a 1-shot success rate of 96%, and 100% success with 4 iterative\nrounds. In WebShop, the 1-shot performance of the A$^3$T agent matches human\naverage, and 4 rounds of iterative refinement lead to the performance\napproaching human experts. A$^3$T agents significantly outperform existing\ntechniques, including prompting with GPT-4, advanced agent frameworks, and\nfully fine-tuned LLMs.\n","authors":["Zonghan Yang","Peng Li","Ming Yan","Ji Zhang","Fei Huang","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2403.14589v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14582v1","updated":"2024-03-21T17:36:08Z","published":"2024-03-21T17:36:08Z","title":"Large Language Models for Multi-Choice Question Classification of\n  Medical Subjects","summary":"  The aim of this paper is to evaluate whether large language models trained on\nmulti-choice question data can be used to discriminate between medical\nsubjects. This is an important and challenging task for automatic question\nanswering. To achieve this goal, we train deep neural networks for multi-class\nclassification of questions into the inferred medical subjects. Using our\nMulti-Question (MQ) Sequence-BERT method, we outperform the state-of-the-art\nresults on the MedMCQA dataset with an accuracy of 0.68 and 0.60 on their\ndevelopment and test sets, respectively. In this sense, we show the capability\nof AI and LLMs in particular for multi-classification tasks in the Healthcare\ndomain.\n","authors":["Víctor Ponce-López"],"pdf_url":"https://arxiv.org/pdf/2403.14582v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.12258v5","updated":"2024-03-21T17:29:37Z","published":"2024-01-21T16:59:45Z","title":"Emergent Dominance Hierarchies in Reinforcement Learning Agents","summary":"  Modern Reinforcement Learning (RL) algorithms are able to outperform humans\nin a wide variety of tasks. Multi-agent reinforcement learning (MARL) settings\npresent additional challenges, and successful cooperation in mixed-motive\ngroups of agents depends on a delicate balancing act between individual and\ngroup objectives. Social conventions and norms, often inspired by human\ninstitutions, are used as tools for striking this balance.\n  In this paper, we examine a fundamental, well-studied social convention that\nunderlies cooperation in both animal and human societies: dominance\nhierarchies.\n  We adapt the ethological theory of dominance hierarchies to artificial\nagents, borrowing the established terminology and definitions with as few\namendments as possible. We demonstrate that populations of RL agents, operating\nwithout explicit programming or intrinsic rewards, can invent, learn, enforce,\nand transmit a dominance hierarchy to new populations. The dominance\nhierarchies that emerge have a similar structure to those studied in chickens,\nmice, fish, and other species.\n","authors":["Ram Rachum","Yonatan Nakar","Bill Tomlinson","Nitay Alon","Reuth Mirsky"],"pdf_url":"https://arxiv.org/pdf/2401.12258v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14566v1","updated":"2024-03-21T17:09:20Z","published":"2024-03-21T17:09:20Z","title":"A survey on Concept-based Approaches For Model Improvement","summary":"  The focus of recent research has shifted from merely increasing the Deep\nNeural Networks (DNNs) performance in various tasks to DNNs, which are more\ninterpretable to humans. The field of eXplainable Artificial Intelligence (XAI)\nhas observed various techniques, including saliency-based and concept-based\napproaches. Concept-based approaches explain the model's decisions in simple\nhuman understandable terms called Concepts. Concepts are human interpretable\nunits of data and are the thinking ground of humans. Explanations in terms of\nconcepts enable detecting spurious correlations, inherent biases, or\nclever-hans. With the advent of concept-based explanations, there have been\nvarious concept representation methods and automatic concept discovery\nalgorithms. Some recent methods use concepts for post-hoc model disentanglement\nevaluation, while others use them for ante-hoc training. The concept-based\napproaches are new, with many representations coming up, and there is very\nlimited work on Concept-based Model improvement. We provide a systematic review\nand taxonomy of various concept representations and their discovery algorithms\nin DNNs, specifically in vision. We also provide details on concept-based model\nimprovement literature, which is the first to survey concept-based model\nimprovement methods.\n","authors":["Avani Gupta","P J Narayanan"],"pdf_url":"https://arxiv.org/pdf/2403.14566v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14562v1","updated":"2024-03-21T17:06:17Z","published":"2024-03-21T17:06:17Z","title":"The Era of Semantic Decoding","summary":"  Recent work demonstrated great promise in the idea of orchestrating\ncollaborations between LLMs, human input, and various tools to address the\ninherent limitations of LLMs. We propose a novel perspective called semantic\ndecoding, which frames these collaborative processes as optimization procedures\nin semantic space. Specifically, we conceptualize LLMs as semantic processors\nthat manipulate meaningful pieces of information that we call semantic tokens\n(known thoughts). LLMs are among a large pool of other semantic processors,\nincluding humans and tools, such as search engines or code executors.\nCollectively, semantic processors engage in dynamic exchanges of semantic\ntokens to progressively construct high-utility outputs. We refer to these\norchestrated interactions among semantic processors, optimizing and searching\nin semantic space, as semantic decoding algorithms. This concept draws a direct\nparallel to the well-studied problem of syntactic decoding, which involves\ncrafting algorithms to best exploit auto-regressive language models for\nextracting high-utility sequences of syntactic tokens. By focusing on the\nsemantic level and disregarding syntactic details, we gain a fresh perspective\non the engineering of AI systems, enabling us to imagine systems with much\ngreater complexity and capabilities. In this position paper, we formalize the\ntransition from syntactic to semantic tokens as well as the analogy between\nsyntactic and semantic decoding. Subsequently, we explore the possibilities of\noptimizing within the space of semantic tokens via semantic decoding\nalgorithms. We conclude with a list of research opportunities and questions\narising from this fresh perspective. The semantic decoding perspective offers a\npowerful abstraction for search and optimization directly in the space of\nmeaningful concepts, with semantic tokens as the fundamental units of a new\ntype of computation.\n","authors":["Maxime Peyrard","Martin Josifoski","Robert West"],"pdf_url":"https://arxiv.org/pdf/2403.14562v1.pdf","comment":"25 pages, 3 figures"},{"id":"http://arxiv.org/abs/2403.14551v1","updated":"2024-03-21T16:52:01Z","published":"2024-03-21T16:52:01Z","title":"Lexicon-Level Contrastive Visual-Grounding Improves Language Modeling","summary":"  Today's most accurate language models are trained on orders of magnitude more\nlanguage data than human language learners receive - but with no supervision\nfrom other sensory modalities that play a crucial role in human learning. Can\nwe make LMs' representations and predictions more accurate (and more\nhuman-like) with more ecologically plausible supervision? This paper describes\nLexiContrastive Grounding (LCG), a grounded language learning procedure that\nleverages visual supervision to improve textual representations.\nLexiContrastive Grounding combines a next token prediction strategy with a\ncontrastive visual grounding objective, focusing on early-layer representations\nthat encode lexical information. Across multiple word-learning and\nsentence-understanding benchmarks, LexiContrastive Grounding not only\noutperforms standard language-only models in learning efficiency, but also\nimproves upon vision-and-language learning procedures including CLIP, GIT,\nFlamingo, and Vokenization. Moreover, LexiContrastive Grounding improves\nperplexity by around 5% on multiple language modeling tasks. This work\nunderscores the potential of incorporating visual grounding into language\nmodels, aligning more closely with the multimodal nature of human language\nacquisition.\n","authors":["Chengxu Zhuang","Evelina Fedorenko","Jacob Andreas"],"pdf_url":"https://arxiv.org/pdf/2403.14551v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14550v1","updated":"2024-03-21T16:50:12Z","published":"2024-03-21T16:50:12Z","title":"Dynamic Explanation Emphasis in Human-XAI Interaction with Communication\n  Robot","summary":"  Communication robots have the potential to contribute to effective human-XAI\ninteraction as an interface that goes beyond textual or graphical explanations.\nOne of their strengths is that they can use physical and vocal expressions to\nadd detailed nuances to explanations. However, it is not clear how a robot can\napply such expressions, or in particular, how we can develop a strategy to\nadaptively use such expressions depending on the task and user in dynamic\ninteractions. To address this question, this paper proposes DynEmph, a method\nfor a communication robot to decide where to emphasize XAI-generated\nexplanations with physical expressions. It predicts the effect of emphasizing\ncertain points on a user and aims to minimize the expected difference between\npredicted user decisions and AI-suggested ones. DynEmph features a strategy for\ndeciding where to emphasize in a data-driven manner, relieving engineers from\nthe need to manually design a strategy. We further conducted experiments to\ninvestigate how emphasis selection strategies affect the performance of user\ndecisions. The results suggest that, while a naive strategy (emphasizing\nexplanations for an AI's most probable class) does not necessarily work better,\nDynEmph effectively guides users to better decisions under the condition that\nthe performance of the AI suggestion is high.\n","authors":["Yosuke Fukuchi","Seiji Yamada"],"pdf_url":"https://arxiv.org/pdf/2403.14550v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.08812v3","updated":"2024-03-21T16:44:41Z","published":"2024-02-13T21:33:12Z","title":"Intelligent Canvas: Enabling Design-Like Exploratory Visual Data\n  Analysis with Generative AI through Rapid Prototyping, Iteration and Curation","summary":"  Complex data analysis inherently seeks unexpected insights through\nexploratory visual analysis methods, transcending logical, step-by-step\nprocessing. However, existing interfaces such as notebooks and dashboards have\nlimitations in exploration and comparison for visual data analysis. Addressing\nthese limitations, we introduce a \"design-like\" intelligent canvas environment\nintegrating generative AI into data analysis, offering rapid prototyping,\niteration, and comparative visualization management. Our dual contributions\ninclude the integration of generative AI components into a canvas interface,\nand empirical findings from a user study (N=10) evaluating the effectiveness of\nthe canvas interface.\n","authors":["Zijian Ding","Joel Chan"],"pdf_url":"https://arxiv.org/pdf/2402.08812v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14539v1","updated":"2024-03-21T16:40:10Z","published":"2024-03-21T16:40:10Z","title":"Object-Centric Domain Randomization for 3D Shape Reconstruction in the\n  Wild","summary":"  One of the biggest challenges in single-view 3D shape reconstruction in the\nwild is the scarcity of <3D shape, 2D image>-paired data from real-world\nenvironments. Inspired by remarkable achievements via domain randomization, we\npropose ObjectDR which synthesizes such paired data via a random simulation of\nvisual variations in object appearances and backgrounds. Our data synthesis\nframework exploits a conditional generative model (e.g., ControlNet) to\ngenerate images conforming to spatial conditions such as 2.5D sketches, which\nare obtainable through a rendering process of 3D shapes from object collections\n(e.g., Objaverse-XL). To simulate diverse variations while preserving object\nsilhouettes embedded in spatial conditions, we also introduce a disentangled\nframework which leverages an initial object guidance. After synthesizing a wide\nrange of data, we pre-train a model on them so that it learns to capture a\ndomain-invariant geometry prior which is consistent across various domains. We\nvalidate its effectiveness by substantially improving 3D shape reconstruction\nmodels on a real-world benchmark. In a scale-up evaluation, our pre-training\nachieves 23.6% superior results compared with the pre-training on high-quality\ncomputer graphics renderings.\n","authors":["Junhyeong Cho","Kim Youwang","Hunmin Yang","Tae-Hyun Oh"],"pdf_url":"https://arxiv.org/pdf/2403.14539v1.pdf","comment":"Project Page: https://ObjectDR.github.io"},{"id":"http://arxiv.org/abs/2403.14526v1","updated":"2024-03-21T16:26:19Z","published":"2024-03-21T16:26:19Z","title":"Click to Grasp: Zero-Shot Precise Manipulation via Visual Diffusion\n  Descriptors","summary":"  Precise manipulation that is generalizable across scenes and objects remains\na persistent challenge in robotics. Current approaches for this task heavily\ndepend on having a significant number of training instances to handle objects\nwith pronounced visual and/or geometric part ambiguities. Our work explores the\ngrounding of fine-grained part descriptors for precise manipulation in a\nzero-shot setting by utilizing web-trained text-to-image diffusion-based\ngenerative models. We tackle the problem by framing it as a dense semantic part\ncorrespondence task. Our model returns a gripper pose for manipulating a\nspecific part, using as reference a user-defined click from a source image of a\nvisually different instance of the same object. We require no manual grasping\ndemonstrations as we leverage the intrinsic object geometry and features.\nPractical experiments in a real-world tabletop scenario validate the efficacy\nof our approach, demonstrating its potential for advancing semantic-aware\nrobotics manipulation. Web page: https://tsagkas.github.io/click2grasp\n","authors":["Nikolaos Tsagkas","Jack Rome","Subramanian Ramamoorthy","Oisin Mac Aodha","Chris Xiaoxuan Lu"],"pdf_url":"https://arxiv.org/pdf/2403.14526v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2403.11879v2","updated":"2024-03-21T16:15:52Z","published":"2024-03-18T15:32:02Z","title":"Unimodal Multi-Task Fusion for Emotional Mimicry Prediciton","summary":"  In this study, we propose a methodology for the Emotional Mimicry Intensity\n(EMI) Estimation task within the context of the 6th Workshop and Competition on\nAffective Behavior Analysis in-the-wild. Our approach leverages the Wav2Vec 2.0\nframework, pre-trained on a comprehensive podcast dataset, to extract a broad\nrange of audio features encompassing both linguistic and paralinguistic\nelements. We enhance feature representation through a fusion technique that\nintegrates individual features with a global mean vector, introducing global\ncontextual insights into our analysis. Additionally, we incorporate a\npre-trained valence-arousal-dominance (VAD) module from the Wav2Vec 2.0 model.\nOur fusion employs a Long Short-Term Memory (LSTM) architecture for efficient\ntemporal analysis of audio data. Utilizing only the provided audio data, our\napproach demonstrates significant improvements over the established baseline.\n","authors":["Tobias Hallmen","Fabian Deuser","Norbert Oswald","Elisabeth André"],"pdf_url":"https://arxiv.org/pdf/2403.11879v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14508v1","updated":"2024-03-21T16:02:52Z","published":"2024-03-21T16:02:52Z","title":"Constrained Reinforcement Learning with Smoothed Log Barrier Function","summary":"  Reinforcement Learning (RL) has been widely applied to many control tasks and\nsubstantially improved the performances compared to conventional control\nmethods in many domains where the reward function is well defined. However, for\nmany real-world problems, it is often more convenient to formulate optimization\nproblems in terms of rewards and constraints simultaneously. Optimizing such\nconstrained problems via reward shaping can be difficult as it requires tedious\nmanual tuning of reward functions with several interacting terms. Recent\nformulations which include constraints mostly require a pre-training phase,\nwhich often needs human expertise to collect data or assumes having a\nsub-optimal policy readily available. We propose a new constrained RL method\ncalled CSAC-LB (Constrained Soft Actor-Critic with Log Barrier Function), which\nachieves competitive performance without any pre-training by applying a linear\nsmoothed log barrier function to an additional safety critic. It implements an\nadaptive penalty for policy learning and alleviates the numerical issues that\nare known to complicate the application of the log barrier function method. As\na result, we show that with CSAC-LB, we achieve state-of-the-art performance on\nseveral constrained control tasks with different levels of difficulty and\nevaluate our methods in a locomotion task on a real quadruped robot platform.\n","authors":["Baohe Zhang","Yuan Zhang","Lilli Frison","Thomas Brox","Joschka Bödecker"],"pdf_url":"https://arxiv.org/pdf/2403.14508v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14504v1","updated":"2024-03-21T15:56:15Z","published":"2024-03-21T15:56:15Z","title":"Soft Learning Probabilistic Circuits","summary":"  Probabilistic Circuits (PCs) are prominent tractable probabilistic models,\nallowing for a range of exact inferences. This paper focuses on the main\nalgorithm for training PCs, LearnSPN, a gold standard due to its efficiency,\nperformance, and ease of use, in particular for tabular data. We show that\nLearnSPN is a greedy likelihood maximizer under mild assumptions. While\ninferences in PCs may use the entire circuit structure for processing queries,\nLearnSPN applies a hard method for learning them, propagating at each sum node\na data point through one and only one of the children/edges as in a hard\nclustering process. We propose a new learning procedure named SoftLearn, that\ninduces a PC using a soft clustering process. We investigate the effect of this\nlearning-inference compatibility in PCs. Our experiments show that SoftLearn\noutperforms LearnSPN in many situations, yielding better likelihoods and\narguably better samples. We also analyze comparable tractable models to\nhighlight the differences between soft/hard learning and model querying.\n","authors":["Soroush Ghandi","Benjamin Quost","Cassio de Campos"],"pdf_url":"https://arxiv.org/pdf/2403.14504v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14496v1","updated":"2024-03-21T15:44:56Z","published":"2024-03-21T15:44:56Z","title":"How Human-Centered Explainable AI Interface Are Designed and Evaluated:\n  A Systematic Survey","summary":"  Despite its technological breakthroughs, eXplainable Artificial Intelligence\n(XAI) research has limited success in producing the {\\em effective\nexplanations} needed by users. In order to improve XAI systems' usability,\npractical interpretability, and efficacy for real users, the emerging area of\n{\\em Explainable Interfaces} (EIs) focuses on the user interface and user\nexperience design aspects of XAI. This paper presents a systematic survey of 53\npublications to identify current trends in human-XAI interaction and promising\ndirections for EI design and development. This is among the first systematic\nsurvey of EI research.\n","authors":["Thu Nguyen","Alessandro Canossa","Jichen Zhu"],"pdf_url":"https://arxiv.org/pdf/2403.14496v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14494v1","updated":"2024-03-21T15:42:17Z","published":"2024-03-21T15:42:17Z","title":"Learning to Project for Cross-Task Knowledge Distillation","summary":"  Traditional knowledge distillation (KD) relies on a proficient teacher\ntrained on the target task, which is not always available. In this setting,\ncross-task distillation can be used, enabling the use of any teacher model\ntrained on a different task. However, many KD methods prove ineffective when\napplied to this cross-task setting. To address this limitation, we propose a\nsimple modification: the use of an inverted projection. We show that this\ndrop-in replacement for a standard projector is effective by learning to\ndisregard any task-specific features which might degrade the student's\nperformance. We find that this simple modification is sufficient for extending\nmany KD methods to the cross-task setting, where the teacher and student tasks\ncan be very different. In doing so, we obtain up to a 1.9% improvement in the\ncross-task setting compared to the traditional projection, at no additional\ncost. Our method can obtain significant performance improvements (up to 7%)\nwhen using even a randomly-initialised teacher on various tasks such as depth\nestimation, image translation, and semantic segmentation, despite the lack of\nany learned knowledge to transfer. To provide conceptual and analytical\ninsights into this result, we show that using an inverted projection allows the\ndistillation loss to be decomposed into a knowledge transfer and a spectral\nregularisation component. Through this analysis we are additionally able to\npropose a novel regularisation loss that allows teacher-free distillation,\nenabling performance improvements of up to 8.57% on ImageNet with no additional\ntraining costs.\n","authors":["Dylan Auty","Roy Miles","Benedikt Kolbeinsson","Krystian Mikolajczyk"],"pdf_url":"https://arxiv.org/pdf/2403.14494v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14488v1","updated":"2024-03-21T15:36:26Z","published":"2024-03-21T15:36:26Z","title":"Physics-Based Causal Reasoning for Safe & Robust Next-Best Action\n  Selection in Robot Manipulation Tasks","summary":"  Safe and efficient object manipulation is a key enabler of many real-world\nrobot applications. However, this is challenging because robot operation must\nbe robust to a range of sensor and actuator uncertainties. In this paper, we\npresent a physics-informed causal-inference-based framework for a robot to\nprobabilistically reason about candidate actions in a block stacking task in a\npartially observable setting. We integrate a physics-based simulation of the\nrigid-body system dynamics with a causal Bayesian network (CBN) formulation to\ndefine a causal generative probabilistic model of the robot decision-making\nprocess. Using simulation-based Monte Carlo experiments, we demonstrate our\nframework's ability to successfully: (1) predict block tower stability with\nhigh accuracy (Pred Acc: 88.6%); and, (2) select an approximate next-best\naction for the block stacking task, for execution by an integrated robot\nsystem, achieving 94.2% task success rate. We also demonstrate our framework's\nsuitability for real-world robot systems by demonstrating successful task\nexecutions with a domestic support robot, with perception and manipulation\nsub-system integration. Hence, we show that by embedding physics-based causal\nreasoning into robots' decision-making processes, we can make robot task\nexecution safer, more reliable, and more robust to various types of\nuncertainty.\n","authors":["Ricardo Cannizzaro","Michael Groom","Jonathan Routley","Robert Osazuwa Ness","Lars Kunze"],"pdf_url":"https://arxiv.org/pdf/2403.14488v1.pdf","comment":"8 pages, 9 figures, submitted to 2024 IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS)"},{"id":"http://arxiv.org/abs/2402.03049v3","updated":"2024-03-21T15:33:34Z","published":"2024-02-05T14:33:56Z","title":"EasyInstruct: An Easy-to-use Instruction Processing Framework for Large\n  Language Models","summary":"  In recent years, instruction tuning has gained increasing attention and\nemerged as a crucial technique to enhance the capabilities of Large Language\nModels (LLMs). To construct high-quality instruction datasets, many instruction\nprocessing approaches have been proposed, aiming to achieve a delicate balance\nbetween data quantity and data quality. Nevertheless, due to inconsistencies\nthat persist among various instruction processing methods, there is no standard\nopen-source instruction processing implementation framework available for the\ncommunity, which hinders practitioners from further developing and advancing.\nTo facilitate instruction processing research and development, we present\nEasyInstruct, an easy-to-use instruction processing framework for LLMs, which\nmodularizes instruction generation, selection, and prompting, while also\nconsidering their combination and interaction. EasyInstruct is publicly\nreleased and actively maintained at https://github.com/zjunlp/EasyInstruct,\nalong with an online demo app and a demo video for quick-start, calling for\nbroader research centered on instruction data and synthetic data.\n","authors":["Yixin Ou","Ningyu Zhang","Honghao Gui","Ziwen Xu","Shuofei Qiao","Yida Xue","Runnan Fang","Kangwei Liu","Lei Li","Zhen Bi","Guozhou Zheng","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2402.03049v3.pdf","comment":"Project website: https://zjunlp.github.io/project/EasyInstruct Code:\n  https://github.com/zjunlp/EasyInstruct Video: https://youtu.be/rfQOWYfziFo\n  Demo: https://huggingface.co/spaces/zjunlp/EasyInstruct"},{"id":"http://arxiv.org/abs/2403.14484v1","updated":"2024-03-21T15:31:28Z","published":"2024-03-21T15:31:28Z","title":"HyperGALE: ASD Classification via Hypergraph Gated Attention with\n  Learnable Hyperedges","summary":"  Autism Spectrum Disorder (ASD) is a neurodevelopmental condition\ncharacterized by varied social cognitive challenges and repetitive behavioral\npatterns. Identifying reliable brain imaging-based biomarkers for ASD has been\na persistent challenge due to the spectrum's diverse symptomatology. Existing\nbaselines in the field have made significant strides in this direction, yet\nthere remains room for improvement in both performance and interpretability. We\npropose \\emph{HyperGALE}, which builds upon the hypergraph by incorporating\nlearned hyperedges and gated attention mechanisms. This approach has led to\nsubstantial improvements in the model's ability to interpret complex brain\ngraph data, offering deeper insights into ASD biomarker characterization.\nEvaluated on the extensive ABIDE II dataset, \\emph{HyperGALE} not only improves\ninterpretability but also demonstrates statistically significant enhancements\nin key performance metrics compared to both previous baselines and the\nfoundational hypergraph model. The advancement \\emph{HyperGALE} brings to ASD\nresearch highlights the potential of sophisticated graph-based techniques in\nneurodevelopmental studies. The source code and implementation instructions are\navailable at GitHub:https://github.com/mehular0ra/HyperGALE.\n","authors":["Mehul Arora","Chirag Shantilal Jain","Lalith Bharadwaj Baru","Kamalaker Dadi","Bapi Raju Surampudi"],"pdf_url":"https://arxiv.org/pdf/2403.14484v1.pdf","comment":"Accepted to IJCNN 2024"},{"id":"http://arxiv.org/abs/2403.14483v1","updated":"2024-03-21T15:29:24Z","published":"2024-03-21T15:29:24Z","title":"Utilizing the LightGBM Algorithm for Operator User Credit Assessment\n  Research","summary":"  Mobile Internet user credit assessment is an important way for communication\noperators to establish decisions and formulate measures, and it is also a\nguarantee for operators to obtain expected benefits. However, credit evaluation\nmethods have long been monopolized by financial industries such as banks and\ncredit. As supporters and providers of platform network technology and network\nresources, communication operators are also builders and maintainers of\ncommunication networks. Internet data improves the user's credit evaluation\nstrategy. This paper uses the massive data provided by communication operators\nto carry out research on the operator's user credit evaluation model based on\nthe fusion LightGBM algorithm. First, for the massive data related to user\nevaluation provided by operators, key features are extracted by data\npreprocessing and feature engineering methods, and a multi-dimensional feature\nset with statistical significance is constructed; then, linear regression,\ndecision tree, LightGBM, and other machine learning algorithms build multiple\nbasic models to find the best basic model; finally, integrates Averaging,\nVoting, Blending, Stacking and other integrated algorithms to refine multiple\nfusion models, and finally establish the most suitable fusion model for\noperator user evaluation.\n","authors":["Shaojie Li","Xinqi Dong","Danqing Ma","Bo Dang","Hengyi Zang","Yulu Gong"],"pdf_url":"https://arxiv.org/pdf/2403.14483v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14472v1","updated":"2024-03-21T15:18:30Z","published":"2024-03-21T15:18:30Z","title":"Detoxifying Large Language Models via Knowledge Editing","summary":"  This paper investigates using knowledge editing techniques to detoxify Large\nLanguage Models (LLMs). We construct a benchmark, SafeEdit, which covers nine\nunsafe categories with various powerful attack prompts and equips comprehensive\nmetrics for systematic evaluation. We conduct experiments to compare knowledge\nediting approaches with previous baselines, indicating that knowledge editing\nhas the potential to efficiently detoxify LLMs with limited impact on general\nperformance. Then, we propose a simple yet effective baseline, dubbed\nDetoxifying with Intraoperative Neural Monitoring (DINM), to diminish the\ntoxicity of LLMs within a few tuning steps via only one instance. We further\nprovide an in-depth analysis of the internal mechanism for various detoxify\napproaches, demonstrating that previous methods like SFT and DPO may merely\nsuppress the activations of toxic parameters, while DINM mitigates the toxicity\nof the toxic parameters to a certain extent, making permanent adjustments. We\nhope that these insights could shed light on future work of developing\ndetoxifying approaches and the underlying knowledge mechanisms of LLMs. Code\nand benchmark are available at https://github.com/zjunlp/EasyEdit.\n","authors":["Mengru Wang","Ningyu Zhang","Ziwen Xu","Zekun Xi","Shumin Deng","Yunzhi Yao","Qishen Zhang","Linyi Yang","Jindong Wang","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2403.14472v1.pdf","comment":"Ongoing work. Project website:\n  https://zjunlp.github.io/project/SafeEdit Benchmark:\n  https://huggingface.co/datasets/zjunlp/SafeEdit Code:\n  https://github.com/zjunlp/EasyEdit"},{"id":"http://arxiv.org/abs/2403.14469v1","updated":"2024-03-21T15:16:50Z","published":"2024-03-21T15:16:50Z","title":"ChatGPT Alternative Solutions: Large Language Models Survey","summary":"  In recent times, the grandeur of Large Language Models (LLMs) has not only\nshone in the realm of natural language processing but has also cast its\nbrilliance across a vast array of applications. This remarkable display of LLM\ncapabilities has ignited a surge in research contributions within this domain,\nspanning a diverse spectrum of topics. These contributions encompass\nadvancements in neural network architecture, context length enhancements, model\nalignment, training datasets, benchmarking, efficiency improvements, and more.\nRecent years have witnessed a dynamic synergy between academia and industry,\npropelling the field of LLM research to new heights. A notable milestone in\nthis journey is the introduction of ChatGPT, a powerful AI chatbot grounded in\nLLMs, which has garnered widespread societal attention. The evolving technology\nof LLMs has begun to reshape the landscape of the entire AI community,\npromising a revolutionary shift in the way we create and employ AI algorithms.\nGiven this swift-paced technical evolution, our survey embarks on a journey to\nencapsulate the recent strides made in the world of LLMs. Through an\nexploration of the background, key discoveries, and prevailing methodologies,\nwe offer an up-to-the-minute review of the literature. By examining multiple\nLLM models, our paper not only presents a comprehensive overview but also\ncharts a course that identifies existing challenges and points toward potential\nfuture research trajectories. This survey furnishes a well-rounded perspective\non the current state of generative AI, shedding light on opportunities for\nfurther exploration, enhancement, and innovation.\n","authors":["Hanieh Alipour","Nick Pendar","Kohinoor Roy"],"pdf_url":"https://arxiv.org/pdf/2403.14469v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14468v1","updated":"2024-03-21T15:15:00Z","published":"2024-03-21T15:15:00Z","title":"AnyV2V: A Plug-and-Play Framework For Any Video-to-Video Editing Tasks","summary":"  Video-to-video editing involves editing a source video along with additional\ncontrol (such as text prompts, subjects, or styles) to generate a new video\nthat aligns with the source video and the provided control. Traditional methods\nhave been constrained to certain editing types, limiting their ability to meet\nthe wide range of user demands. In this paper, we introduce AnyV2V, a novel\ntraining-free framework designed to simplify video editing into two primary\nsteps: (1) employing an off-the-shelf image editing model (e.g.\nInstructPix2Pix, InstantID, etc) to modify the first frame, (2) utilizing an\nexisting image-to-video generation model (e.g. I2VGen-XL) for DDIM inversion\nand feature injection. In the first stage, AnyV2V can plug in any existing\nimage editing tools to support an extensive array of video editing tasks.\nBeyond the traditional prompt-based editing methods, AnyV2V also can support\nnovel video editing tasks, including reference-based style transfer,\nsubject-driven editing, and identity manipulation, which were unattainable by\nprevious methods. In the second stage, AnyV2V can plug in any existing\nimage-to-video models to perform DDIM inversion and intermediate feature\ninjection to maintain the appearance and motion consistency with the source\nvideo. On the prompt-based editing, we show that AnyV2V can outperform the\nprevious best approach by 35\\% on prompt alignment, and 25\\% on human\npreference. On the three novel tasks, we show that AnyV2V also achieves a high\nsuccess rate. We believe AnyV2V will continue to thrive due to its ability to\nseamlessly integrate the fast-evolving image editing methods. Such\ncompatibility can help AnyV2V to increase its versatility to cater to diverse\nuser demands.\n","authors":["Max Ku","Cong Wei","Weiming Ren","Huan Yang","Wenhu Chen"],"pdf_url":"https://arxiv.org/pdf/2403.14468v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2309.00903v2","updated":"2024-03-21T15:12:36Z","published":"2023-09-02T10:46:05Z","title":"An explainable three dimension framework to uncover learning patterns: A\n  unified look in variable sulci recognition","summary":"  Explainable AI is crucial in medical imaging. In the challenging field of\nneuroscience, visual topics present a high level of complexity, particularly\nwithin three-dimensional space. The application of neuroscience, which involves\nidentifying brain sulcal features from MRI, faces significant hurdles due to\nvarying annotation protocols among experts and the intricate three-dimension\nfunctionality of the brain. Consequently, traditional explainability approaches\nfall short in effectively validating and evaluating these networks. To address\nthis, we first present a mathematical formulation delineating various\ncategories of explanation needs across diverse computer vision tasks,\ncategorized into self-explanatory, semi-explanatory, non-explanatory, and\nnew-pattern learning applications based on the reliability of the validation\nprotocol. With respect to this mathematical formulation, we propose a 3D\nexplainability framework aimed at validating the outputs of deep learning\nnetworks in detecting the paracingulate sulcus an essential brain anatomical\nfeature. The framework integrates local 3D explanations, global explanations\nthrough dimensionality reduction, concatenated global explanations, and\nstatistical shape features, unveiling new insights into pattern learning. We\ntrained and tested two advanced 3D deep learning networks on the challenging\nTOP-OSLO dataset, significantly improving sulcus detection accuracy,\nparticularly on the left hemisphere. During evaluation with diverse annotation\nprotocols for this dataset, we highlighted the crucial role of an unbiased\nannotation process in achieving precise predictions and effective pattern\nlearning within our proposed 3D framework. The proposed framework not only\nannotates the variable sulcus but also uncovers hidden AI knowledge, promising\nto advance our understanding of brain anatomy and function.\n","authors":["Michail Mamalakis","Heloise de Vareilles","Atheer AI-Manea","Samantha C. Mitchell","Ingrid Arartz","Lynn Egeland Morch-Johnsen","Jane Garrison","Jon Simons","Pietro Lio","John Suckling","Graham Murray"],"pdf_url":"https://arxiv.org/pdf/2309.00903v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14460v1","updated":"2024-03-21T15:07:57Z","published":"2024-03-21T15:07:57Z","title":"Towards Single-System Illusion in Software-Defined Vehicles --\n  Automated, AI-Powered Workflow","summary":"  We propose a novel model- and feature-based approach to development of\nvehicle software systems, where the end architecture is not explicitly defined.\nInstead, it emerges from an iterative process of search and optimization given\ncertain constraints, requirements and hardware architecture, while retaining\nthe property of single-system illusion, where applications run in a logically\nuniform environment. One of the key points of the presented approach is the\ninclusion of modern generative AI, specifically Large Language Models (LLMs),\nin the loop. With the recent advances in the field, we expect that the LLMs\nwill be able to assist in processing of requirements, generation of formal\nsystem models, as well as generation of software deployment specification and\ntest code. The resulting pipeline is automated to a large extent, with feedback\nbeing generated at each step.\n","authors":["Krzysztof Lebioda","Viktor Vorobev","Nenad Petrovic","Fengjunjie Pan","Vahid Zolfaghari","Alois Knoll"],"pdf_url":"https://arxiv.org/pdf/2403.14460v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14459v1","updated":"2024-03-21T15:06:14Z","published":"2024-03-21T15:06:14Z","title":"Multi-Level Explanations for Generative Language Models","summary":"  Perturbation-based explanation methods such as LIME and SHAP are commonly\napplied to text classification. This work focuses on their extension to\ngenerative language models. To address the challenges of text as output and\nlong text inputs, we propose a general framework called MExGen that can be\ninstantiated with different attribution algorithms. To handle text output, we\nintroduce the notion of scalarizers for mapping text to real numbers and\ninvestigate multiple possibilities. To handle long inputs, we take a\nmulti-level approach, proceeding from coarser levels of granularity to finer\nones, and focus on algorithms with linear scaling in model queries. We conduct\na systematic evaluation, both automated and human, of perturbation-based\nattribution methods for summarization and context-grounded question answering.\nThe results show that our framework can provide more locally faithful\nexplanations of generated outputs.\n","authors":["Lucas Monteiro Paes","Dennis Wei","Hyo Jin Do","Hendrik Strobelt","Ronny Luss","Amit Dhurandhar","Manish Nagireddy","Karthikeyan Natesan Ramamurthy","Prasanna Sattigeri","Werner Geyer","Soumya Ghosh"],"pdf_url":"https://arxiv.org/pdf/2403.14459v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.10882v2","updated":"2024-03-21T14:50:18Z","published":"2024-03-16T10:26:38Z","title":"Optimizing Language Augmentation for Multilingual Large Language Models:\n  A Case Study on Korean","summary":"  Large language models (LLMs) use pretraining to predict the subsequent word;\nhowever, their expansion requires significant computing resources. Numerous big\ntech companies and research institutes have developed multilingual LLMs (MLLMs)\nto meet current demands, overlooking less-resourced languages (LRLs). This\nstudy proposed three strategies to enhance the performance of LRLs based on the\npublicly available MLLMs. First, the MLLM vocabularies of LRLs were expanded to\nenhance expressiveness. Second, bilingual data were used for pretraining to\nalign the high- and less-resourced languages. Third, a high-quality small-scale\ninstruction dataset was constructed and instruction-tuning was performed to\naugment the LRL. The experiments employed the Llama2 model and Korean was used\nas the LRL, which was quantitatively evaluated against other developed LLMs\nacross eight tasks. Furthermore, a qualitative assessment was performed based\non human evaluation and GPT4. Experimental results showed that our proposed\nBllossom model exhibited superior performance in qualitative analyses compared\nto previously proposed Korean monolingual models.\n","authors":["ChangSu Choi","Yongbin Jeong","Seoyoon Park","InHo Won","HyeonSeok Lim","SangMin Kim","Yejee Kang","Chanhyuk Yoon","Jaewan Park","Yiseul Lee","HyeJin Lee","Younggyun Hahm","Hansaem Kim","KyungTae Lim"],"pdf_url":"https://arxiv.org/pdf/2403.10882v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14443v1","updated":"2024-03-21T14:48:37Z","published":"2024-03-21T14:48:37Z","title":"Language Models Can Reduce Asymmetry in Information Markets","summary":"  This work addresses the buyer's inspection paradox for information markets.\nThe paradox is that buyers need to access information to determine its value,\nwhile sellers need to limit access to prevent theft. To study this, we\nintroduce an open-source simulated digital marketplace where intelligent\nagents, powered by language models, buy and sell information on behalf of\nexternal participants. The central mechanism enabling this marketplace is the\nagents' dual capabilities: they not only have the capacity to assess the\nquality of privileged information but also come equipped with the ability to\nforget. This ability to induce amnesia allows vendors to grant temporary access\nto proprietary information, significantly reducing the risk of unauthorized\nretention while enabling agents to accurately gauge the information's relevance\nto specific queries or tasks. To perform well, agents must make rational\ndecisions, strategically explore the marketplace through generated sub-queries,\nand synthesize answers from purchased information. Concretely, our experiments\n(a) uncover biases in language models leading to irrational behavior and\nevaluate techniques to mitigate these biases, (b) investigate how price affects\ndemand in the context of informational goods, and (c) show that inspection and\nhigher budgets both lead to higher quality outcomes.\n","authors":["Nasim Rahaman","Martin Weiss","Manuel Wüthrich","Yoshua Bengio","Li Erran Li","Chris Pal","Bernhard Schölkopf"],"pdf_url":"https://arxiv.org/pdf/2403.14443v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14440v1","updated":"2024-03-21T14:45:54Z","published":"2024-03-21T14:45:54Z","title":"Analysing Diffusion Segmentation for Medical Images","summary":"  Denoising Diffusion Probabilistic models have become increasingly popular due\nto their ability to offer probabilistic modeling and generate diverse outputs.\nThis versatility inspired their adaptation for image segmentation, where\nmultiple predictions of the model can produce segmentation results that not\nonly achieve high quality but also capture the uncertainty inherent in the\nmodel. Here, powerful architectures were proposed for improving diffusion\nsegmentation performance. However, there is a notable lack of analysis and\ndiscussions on the differences between diffusion segmentation and image\ngeneration, and thorough evaluations are missing that distinguish the\nimprovements these architectures provide for segmentation in general from their\nbenefit for diffusion segmentation specifically. In this work, we critically\nanalyse and discuss how diffusion segmentation for medical images differs from\ndiffusion image generation, with a particular focus on the training behavior.\nFurthermore, we conduct an assessment how proposed diffusion segmentation\narchitectures perform when trained directly for segmentation. Lastly, we\nexplore how different medical segmentation tasks influence the diffusion\nsegmentation behavior and the diffusion process could be adapted accordingly.\nWith these analyses, we aim to provide in-depth insights into the behavior of\ndiffusion segmentation that allow for a better design and evaluation of\ndiffusion segmentation methods in the future.\n","authors":["Mathias Öttl","Siyuan Mei","Frauke Wilm","Jana Steenpass","Matthias Rübner","Arndt Hartmann","Matthias Beckmann","Peter Fasching","Andreas Maier","Ramona Erber","Katharina Breininger"],"pdf_url":"https://arxiv.org/pdf/2403.14440v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14435v1","updated":"2024-03-21T14:41:58Z","published":"2024-03-21T14:41:58Z","title":"Biased Binary Attribute Classifiers Ignore the Majority Classes","summary":"  To visualize the regions of interest that classifiers base their decisions\non, different Class Activation Mapping (CAM) methods have been developed.\nHowever, all of these techniques target categorical classifiers only, though\nmost real-world tasks are binary classification. In this paper, we extend\ngradient-based CAM techniques to work with binary classifiers and visualize the\nactive regions for binary facial attribute classifiers. When training an\nunbalanced binary classifier on an imbalanced dataset, it is well-known that\nthe majority class, i.e. the class with many training samples, is mostly\npredicted much better than minority class with few training instances. In our\nexperiments on the CelebA dataset, we verify these results, when training an\nunbalanced classifier to extract 40 facial attributes simultaneously. One would\nexpect that the biased classifier has learned to extract features mainly for\nthe majority classes and that the proportional energy of the activations mainly\nreside in certain specific regions of the image where the attribute is located.\nHowever, we find very little regular activation for samples of majority\nclasses, while the active regions for minority classes seem mostly reasonable\nand overlap with our expectations. These results suggest that biased\nclassifiers mainly rely on bias activation for majority classes. When training\na balanced classifier on the imbalanced data by employing attribute-specific\nclass weights, majority and minority classes are classified similarly well and\nshow expected activations for almost all attributes\n","authors":["Xinyi Zhang","Johanna Sophie Bieri","Manuel Günther"],"pdf_url":"https://arxiv.org/pdf/2403.14435v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14432v1","updated":"2024-03-21T14:39:28Z","published":"2024-03-21T14:39:28Z","title":"On the continuity and smoothness of the value function in reinforcement\n  learning and optimal control","summary":"  The value function plays a crucial role as a measure for the cumulative\nfuture reward an agent receives in both reinforcement learning and optimal\ncontrol. It is therefore of interest to study how similar the values of\nneighboring states are, i.e., to investigate the continuity of the value\nfunction. We do so by providing and verifying upper bounds on the value\nfunction's modulus of continuity. Additionally, we show that the value function\nis always H\\\"older continuous under relatively weak assumptions on the\nunderlying system and that non-differentiable value functions can be made\ndifferentiable by slightly \"disturbing\" the system.\n","authors":["Hans Harder","Sebastian Peitz"],"pdf_url":"https://arxiv.org/pdf/2403.14432v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14429v1","updated":"2024-03-21T14:36:59Z","published":"2024-03-21T14:36:59Z","title":"Style-Extracting Diffusion Models for Semi-Supervised Histopathology\n  Segmentation","summary":"  Deep learning-based image generation has seen significant advancements with\ndiffusion models, notably improving the quality of generated images. Despite\nthese developments, generating images with unseen characteristics beneficial\nfor downstream tasks has received limited attention. To bridge this gap, we\npropose Style-Extracting Diffusion Models, featuring two conditioning\nmechanisms. Specifically, we utilize 1) a style conditioning mechanism which\nallows to inject style information of previously unseen images during image\ngeneration and 2) a content conditioning which can be targeted to a downstream\ntask, e.g., layout for segmentation. We introduce a trainable style encoder to\nextract style information from images, and an aggregation block that merges\nstyle information from multiple style inputs. This architecture enables the\ngeneration of images with unseen styles in a zero-shot manner, by leveraging\nstyles from unseen images, resulting in more diverse generations. In this work,\nwe use the image layout as target condition and first show the capability of\nour method on a natural image dataset as a proof-of-concept. We further\ndemonstrate its versatility in histopathology, where we combine prior knowledge\nabout tissue composition and unannotated data to create diverse synthetic\nimages with known layouts. This allows us to generate additional synthetic data\nto train a segmentation network in a semi-supervised fashion. We verify the\nadded value of the generated images by showing improved segmentation results\nand lower performance variability between patients when synthetic images are\nincluded during segmentation training. Our code will be made publicly available\nat [LINK].\n","authors":["Mathias Öttl","Frauke Wilm","Jana Steenpass","Jingna Qiu","Matthias Rübner","Arndt Hartmann","Matthias Beckmann","Peter Fasching","Andreas Maier","Ramona Erber","Bernhard Kainz","Katharina Breininger"],"pdf_url":"https://arxiv.org/pdf/2403.14429v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14410v1","updated":"2024-03-21T13:57:45Z","published":"2024-03-21T13:57:45Z","title":"GLC++: Source-Free Universal Domain Adaptation through Global-Local\n  Clustering and Contrastive Affinity Learning","summary":"  Deep neural networks often exhibit sub-optimal performance under covariate\nand category shifts. Source-Free Domain Adaptation (SFDA) presents a promising\nsolution to this dilemma, yet most SFDA approaches are restricted to closed-set\nscenarios. In this paper, we explore Source-Free Universal Domain Adaptation\n(SF-UniDA) aiming to accurately classify \"known\" data belonging to common\ncategories and segregate them from target-private \"unknown\" data. We propose a\nnovel Global and Local Clustering (GLC) technique, which comprises an adaptive\none-vs-all global clustering algorithm to discern between target classes,\ncomplemented by a local k-NN clustering strategy to mitigate negative transfer.\nDespite the effectiveness, the inherent closed-set source architecture leads to\nuniform treatment of \"unknown\" data, impeding the identification of distinct\n\"unknown\" categories. To address this, we evolve GLC to GLC++, integrating a\ncontrastive affinity learning strategy. We examine the superiority of GLC and\nGLC++ across multiple benchmarks and category shift scenarios. Remarkably, in\nthe most challenging open-partial-set scenarios, GLC and GLC++ surpass GATE by\n16.7% and 18.6% in H-score on VisDA, respectively. GLC++ enhances the novel\ncategory clustering accuracy of GLC by 4.3% in open-set scenarios on\nOffice-Home. Furthermore, the introduced contrastive learning strategy not only\nenhances GLC but also significantly facilitates existing methodologies.\n","authors":["Sanqing Qu","Tianpei Zou","Florian Röhrbein","Cewu Lu","Guang Chen","Dacheng Tao","Changjun Jiang"],"pdf_url":"https://arxiv.org/pdf/2403.14410v1.pdf","comment":"This is a substantial extension of the CVPR 2023 paper \"Upcycling\n  Models under Domain and Category Shift\""},{"id":"http://arxiv.org/abs/2403.14409v1","updated":"2024-03-21T13:57:43Z","published":"2024-03-21T13:57:43Z","title":"Locating and Mitigating Gender Bias in Large Language Models","summary":"  Large language models(LLM) are pre-trained on extensive corpora to learn\nfacts and human cognition which contain human preferences. However, this\nprocess can inadvertently lead to these models acquiring biases and stereotypes\nprevalent in society. Prior research has typically tackled the issue of bias\nthrough a one-dimensional perspective, concentrating either on locating or\nmitigating it. This limited perspective has created obstacles in facilitating\nresearch on bias to synergistically complement and progressively build upon one\nanother. In this study, we integrate the processes of locating and mitigating\nbias within a unified framework. Initially, we use causal mediation analysis to\ntrace the causal effects of different components' activation within a large\nlanguage model. Building on this, we propose the LSDM (Least Square Debias\nMethod), a knowledge-editing based method for mitigating gender bias in\noccupational pronouns, and compare it against two baselines on three gender\nbias datasets and seven knowledge competency test datasets. The experimental\nresults indicate that the primary contributors to gender bias are the bottom\nMLP modules acting on the last token of occupational pronouns and the top\nattention module acting on the final word in the sentence. Furthermore, LSDM\nmitigates gender bias in the model more effectively than the other baselines,\nwhile fully preserving the model's capabilities in all other aspects.\n","authors":["Yuchen Cai","Ding Cao","Rongxi Guo","Yaqin Wen","Guiquan Liu","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2403.14409v1.pdf","comment":"23 pages, 5 figures"},{"id":"http://arxiv.org/abs/2403.14403v1","updated":"2024-03-21T13:52:30Z","published":"2024-03-21T13:52:30Z","title":"Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language\n  Models through Question Complexity","summary":"  Retrieval-Augmented Large Language Models (LLMs), which incorporate the\nnon-parametric knowledge from external knowledge bases into LLMs, have emerged\nas a promising approach to enhancing response accuracy in several tasks, such\nas Question-Answering (QA). However, even though there are various approaches\ndealing with queries of different complexities, they either handle simple\nqueries with unnecessary computational overhead or fail to adequately address\ncomplex multi-step queries; yet, not all user requests fall into only one of\nthe simple or complex categories. In this work, we propose a novel adaptive QA\nframework, that can dynamically select the most suitable strategy for\n(retrieval-augmented) LLMs from the simplest to the most sophisticated ones\nbased on the query complexity. Also, this selection process is operationalized\nwith a classifier, which is a smaller LM trained to predict the complexity\nlevel of incoming queries with automatically collected labels, obtained from\nactual predicted outcomes of models and inherent inductive biases in datasets.\nThis approach offers a balanced strategy, seamlessly adapting between the\niterative and single-step retrieval-augmented LLMs, as well as the no-retrieval\nmethods, in response to a range of query complexities. We validate our model on\na set of open-domain QA datasets, covering multiple query complexities, and\nshow that ours enhances the overall efficiency and accuracy of QA systems,\ncompared to relevant baselines including the adaptive retrieval approaches.\nCode is available at: https://github.com/starsuzi/Adaptive-RAG.\n","authors":["Soyeong Jeong","Jinheon Baek","Sukmin Cho","Sung Ju Hwang","Jong C. Park"],"pdf_url":"https://arxiv.org/pdf/2403.14403v1.pdf","comment":"NAACL 2024"},{"id":"http://arxiv.org/abs/2403.14399v1","updated":"2024-03-21T13:47:40Z","published":"2024-03-21T13:47:40Z","title":"Building Accurate Translation-Tailored LLMs with Language Aware\n  Instruction Tuning","summary":"  Translation-tailored Large language models (LLMs) exhibit remarkable\ntranslation capabilities, even competing with supervised-trained commercial\ntranslation systems. However, off-target translation remains an unsolved\nproblem, especially for low-resource languages, hindering us from developing\naccurate LLMs-based translation models. To mitigate the off-target translation\nproblem and enhance the performance of LLMs on translation, recent works have\neither designed advanced prompting strategies to highlight the functionality of\ntranslation instructions or exploited the in-context learning ability of LLMs\nby feeding few-shot demonstrations. However, these methods essentially do not\nimprove LLM's ability to follow translation instructions, especially the\nlanguage direction information. In this work, we design a two-stage fine-tuning\nalgorithm to improve the instruction-following ability (especially the\ntranslation direction) of LLMs. Specifically, we first tune LLMs with the\nmaximum likelihood estimation loss on the translation dataset to elicit the\nbasic translation capabilities. In the second stage, we construct\ninstruction-conflicting samples by randomly replacing the translation\ndirections with a wrong one within the instruction, and then introduce an extra\nunlikelihood loss to learn those samples. Experiments on IWSLT and WMT\nbenchmarks upon the LLaMA model spanning 16 zero-shot directions show that,\ncompared to the competitive baseline -- translation-finetuned LLama, our method\ncould effectively reduce the off-target translation ratio (averagely -53.3\\%),\nthus improving translation quality with average +5.7 SacreBLEU and +16.4\nBLEURT. Analysis shows that our method could preserve the model's general task\nperformance on AlpacaEval. Code and models will be released at\n\\url{https://github.com/alphadl/LanguageAware_Tuning}.\n","authors":["Changtong Zan","Liang Ding","Li Shen","Yibing Zhen","Weifeng Liu","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2403.14399v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.11259v2","updated":"2024-03-21T13:41:35Z","published":"2023-09-20T12:35:19Z","title":"Sequence-to-Sequence Spanish Pre-trained Language Models","summary":"  In recent years, significant advancements in pre-trained language models have\ndriven the creation of numerous non-English language variants, with a\nparticular emphasis on encoder-only and decoder-only architectures. While\nSpanish language models based on BERT and GPT have demonstrated proficiency in\nnatural language understanding and generation, there remains a noticeable\nscarcity of encoder-decoder models explicitly designed for sequence-to-sequence\ntasks, which aim to map input sequences to generate output sequences\nconditionally. This paper breaks new ground by introducing the implementation\nand evaluation of renowned encoder-decoder architectures exclusively\npre-trained on Spanish corpora. Specifically, we present Spanish versions of\nBART, T5, and BERT2BERT-style models and subject them to a comprehensive\nassessment across various sequence-to-sequence tasks, including summarization,\nquestion answering, split-and-rephrase, dialogue, and translation. Our findings\nunderscore the competitive performance of all models, with the BART- and\nT5-based models emerging as top performers across all tasks. We have made all\nmodels publicly available to the research community to foster future\nexplorations and advancements in Spanish NLP:\nhttps://github.com/vgaraujov/Seq2Seq-Spanish-PLMs.\n","authors":["Vladimir Araujo","Maria Mihaela Trusca","Rodrigo Tufiño","Marie-Francine Moens"],"pdf_url":"https://arxiv.org/pdf/2309.11259v2.pdf","comment":"Accepted paper at LREC-Coling2024"},{"id":"http://arxiv.org/abs/2306.00618v2","updated":"2024-03-21T13:37:23Z","published":"2023-06-01T12:44:33Z","title":"Effective Structured Prompting by Meta-Learning and Representative\n  Verbalizer","summary":"  Prompt tuning for pre-trained masked language models (MLM) has shown\npromising performance in natural language processing tasks with few labeled\nexamples. It tunes a prompt for the downstream task, and a verbalizer is used\nto bridge the predicted token and label prediction. Due to the limited training\ndata, prompt initialization is crucial for prompt tuning. Recently,\nMetaPrompting (Hou et al., 2022) uses meta-learning to learn a shared\ninitialization for all task-specific prompts. However, a single initialization\nis insufficient to obtain good prompts for all tasks and samples when the tasks\nare complex. Moreover, MetaPrompting requires tuning the whole MLM, causing a\nheavy burden on computation and memory as the MLM is usually large. To address\nthese issues, we use a prompt pool to extract more task knowledge and construct\ninstance-dependent prompts via attention. We further propose a novel soft\nverbalizer (RepVerb) which constructs label embedding from feature embeddings\ndirectly. Combining meta-learning the prompt pool and RepVerb, we propose\nMetaPrompter for effective structured prompting. MetaPrompter is\nparameter-efficient as only the pool is required to be tuned. Experimental\nresults demonstrate that MetaPrompter performs better than the recent\nstate-of-the-arts and RepVerb outperforms existing soft verbalizers.\n","authors":["Weisen Jiang","Yu Zhang","James T. Kwok"],"pdf_url":"https://arxiv.org/pdf/2306.00618v2.pdf","comment":"Accepted at ICML 2023"},{"id":"http://arxiv.org/abs/2302.03788v3","updated":"2024-03-21T13:30:22Z","published":"2023-02-07T22:56:58Z","title":"Toward a Theory of Causation for Interpreting Neural Code Models","summary":"  Neural Language Models of Code, or Neural Code Models (NCMs), are rapidly\nprogressing from research prototypes to commercial developer tools. As such,\nunderstanding the capabilities and limitations of such models is becoming\ncritical. However, the abilities of these models are typically measured using\nautomated metrics that often only reveal a portion of their real-world\nperformance. While, in general, the performance of NCMs appears promising,\ncurrently much is unknown about how such models arrive at decisions. To this\nend, this paper introduces $do_{code}$, a post hoc interpretability method\nspecific to NCMs that is capable of explaining model predictions. $do_{code}$\nis based upon causal inference to enable programming language-oriented\nexplanations. While the theoretical underpinnings of $do_{code}$ are extensible\nto exploring different model properties, we provide a concrete instantiation\nthat aims to mitigate the impact of spurious correlations by grounding\nexplanations of model behavior in properties of programming languages. To\ndemonstrate the practical benefit of $do_{code}$, we illustrate the insights\nthat our framework can provide by performing a case study on two popular deep\nlearning architectures and ten NCMs. The results of this case study illustrate\nthat our studied NCMs are sensitive to changes in code syntax. All our NCMs,\nexcept for the BERT-like model, statistically learn to predict tokens related\nto blocks of code (\\eg brackets, parenthesis, semicolon) with less confounding\nbias as compared to other programming language constructs. These insights\ndemonstrate the potential of $do_{code}$ as a useful method to detect and\nfacilitate the elimination of confounding bias in NCMs.\n","authors":["David N. Palacio","Alejandro Velasco","Nathan Cooper","Alvaro Rodriguez","Kevin Moran","Denys Poshyvanyk"],"pdf_url":"https://arxiv.org/pdf/2302.03788v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14381v1","updated":"2024-03-21T13:15:25Z","published":"2024-03-21T13:15:25Z","title":"Editing Knowledge Representation of Language Lodel via Rephrased Prefix\n  Prompts","summary":"  Neural language models (LMs) have been extensively trained on vast corpora to\nstore factual knowledge about various aspects of the world described in texts.\nCurrent technologies typically employ knowledge editing methods or specific\nprompts to modify LM outputs. However, existing knowledge editing methods are\ncostly and inefficient, struggling to produce appropriate text. Additionally,\nprompt engineering is opaque and requires significant effort to find suitable\nprompts. To address these issues, we introduce a new method called PSPEM\n(Prefix Soft Prompt Editing Method), that can be used for a lifetime with just\none training. It resolves the inefficiencies and generalizability issues in\nknowledge editing methods and overcomes the opacity of prompt engineering by\nautomatically seeking optimal soft prompts. Specifically, PSPEM utilizes a\nprompt encoder and an encoding converter to refine key information in prompts\nand uses prompt alignment techniques to guide model generation, ensuring text\nconsistency and adherence to the intended structure and content, thereby\nmaintaining an optimal balance between efficiency and accuracy. We have\nvalidated the effectiveness of PSPEM through knowledge editing and attribute\ninserting. On the COUNTERFACT dataset, PSPEM achieved nearly 100\\% editing\naccuracy and demonstrated the highest level of fluency. We further analyzed the\nsimilarities between PSPEM and original prompts and their impact on the model's\ninternals. The results indicate that PSPEM can serve as an alternative to\noriginal prompts, supporting the model in effective editing.\n","authors":["Yuchen Cai","Ding Cao","Rongxi Guo","Yaqin Wen","Guiquan Liu","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2403.14381v1.pdf","comment":"19pages,3figures"},{"id":"http://arxiv.org/abs/2403.14371v1","updated":"2024-03-21T12:59:24Z","published":"2024-03-21T12:59:24Z","title":"Loop Improvement: An Efficient Approach for Extracting Shared Features\n  from Heterogeneous Data without Central Server","summary":"  In federated learning, data heterogeneity significantly impacts performance.\nA typical solution involves segregating these parameters into shared and\npersonalized components, a concept also relevant in multi-task learning.\nAddressing this, we propose \"Loop Improvement\" (LI), a novel method enhancing\nthis separation and feature extraction without necessitating a central server\nor data interchange among participants. Our experiments reveal LI's superiority\nin several aspects: In personalized federated learning environments, LI\nconsistently outperforms the advanced FedALA algorithm in accuracy across\ndiverse scenarios. Additionally, LI's feature extractor closely matches the\nperformance achieved when aggregating data from all clients. In global model\ncontexts, employing LI with stacked personalized layers and an additional\nnetwork also yields comparable results to combined client data scenarios.\nFurthermore, LI's adaptability extends to multi-task learning, streamlining the\nextraction of common features across tasks and obviating the need for\nsimultaneous training. This approach not only enhances individual task\nperformance but also achieves accuracy levels on par with classic multi-task\nlearning methods where all tasks are trained simultaneously. LI integrates a\nloop topology with layer-wise and end-to-end training, compatible with various\nneural network models. This paper also delves into the theoretical\nunderpinnings of LI's effectiveness, offering insights into its potential\napplications. The code is on https://github.com/axedge1983/LI\n","authors":["Fei Li","Chu Kiong Loo","Wei Shiung Liew","Xiaofeng Liu"],"pdf_url":"https://arxiv.org/pdf/2403.14371v1.pdf","comment":"11 pages, 11 figures"},{"id":"http://arxiv.org/abs/2310.10404v6","updated":"2024-03-21T12:59:04Z","published":"2023-10-16T13:49:46Z","title":"LLM4SGG: Large Language Model for Weakly Supervised Scene Graph\n  Generation","summary":"  Weakly-Supervised Scene Graph Generation (WSSGG) research has recently\nemerged as an alternative to the fully-supervised approach that heavily relies\non costly annotations. In this regard, studies on WSSGG have utilized image\ncaptions to obtain unlocalized triplets while primarily focusing on grounding\nthe unlocalized triplets over image regions. However, they have overlooked the\ntwo issues involved in the triplet formation process from the captions: 1)\nSemantic over-simplification issue arises when extracting triplets from\ncaptions, where fine-grained predicates in captions are undesirably converted\ninto coarse-grained predicates, resulting in a long-tailed predicate\ndistribution, and 2) Low-density scene graph issue arises when aligning the\ntriplets in the caption with entity/predicate classes of interest, where many\ntriplets are discarded and not used in training, leading to insufficient\nsupervision. To tackle the two issues, we propose a new approach, i.e., Large\nLanguage Model for weakly-supervised SGG (LLM4SGG), where we mitigate the two\nissues by leveraging the LLM's in-depth understanding of language and reasoning\nability during the extraction of triplets from captions and alignment of\nentity/predicate classes with target data. To further engage the LLM in these\nprocesses, we adopt the idea of Chain-of-Thought and the in-context few-shot\nlearning strategy. To validate the effectiveness of LLM4SGG, we conduct\nextensive experiments on Visual Genome and GQA datasets, showing significant\nimprovements in both Recall@K and mean Recall@K compared to the\nstate-of-the-art WSSGG methods. A further appeal is that LLM4SGG is\ndata-efficient, enabling effective model training with a small amount of\ntraining images.\n","authors":["Kibum Kim","Kanghoon Yoon","Jaehyeong Jeon","Yeonjun In","Jinyoung Moon","Donghyun Kim","Chanyoung Park"],"pdf_url":"https://arxiv.org/pdf/2310.10404v6.pdf","comment":"8 pages; CVPR 2024"},{"id":"http://arxiv.org/abs/2312.12274v2","updated":"2024-03-21T12:51:31Z","published":"2023-12-19T15:56:19Z","title":"Intrinsic Image Diffusion for Indoor Single-view Material Estimation","summary":"  We present Intrinsic Image Diffusion, a generative model for appearance\ndecomposition of indoor scenes. Given a single input view, we sample multiple\npossible material explanations represented as albedo, roughness, and metallic\nmaps. Appearance decomposition poses a considerable challenge in computer\nvision due to the inherent ambiguity between lighting and material properties\nand the lack of real datasets. To address this issue, we advocate for a\nprobabilistic formulation, where instead of attempting to directly predict the\ntrue material properties, we employ a conditional generative model to sample\nfrom the solution space. Furthermore, we show that utilizing the strong learned\nprior of recent diffusion models trained on large-scale real-world images can\nbe adapted to material estimation and highly improves the generalization to\nreal images. Our method produces significantly sharper, more consistent, and\nmore detailed materials, outperforming state-of-the-art methods by $1.5dB$ on\nPSNR and by $45\\%$ better FID score on albedo prediction. We demonstrate the\neffectiveness of our approach through experiments on both synthetic and\nreal-world datasets.\n","authors":["Peter Kocsis","Vincent Sitzmann","Matthias Nießner"],"pdf_url":"https://arxiv.org/pdf/2312.12274v2.pdf","comment":"Project page: https://peter-kocsis.github.io/IntrinsicImageDiffusion/\n  Video: https://youtu.be/lz0meJlj5cA"},{"id":"http://arxiv.org/abs/2311.14758v2","updated":"2024-03-21T12:43:32Z","published":"2023-11-23T15:57:41Z","title":"Point2RBox: Combine Knowledge from Synthetic Visual Patterns for\n  End-to-end Oriented Object Detection with Single Point Supervision","summary":"  With the rapidly increasing demand for oriented object detection (OOD),\nrecent research involving weakly-supervised detectors for learning rotated box\n(RBox) from the horizontal box (HBox) has attracted more and more attention. In\nthis paper, we explore a more challenging yet label-efficient setting, namely\nsingle point-supervised OOD, and present our approach called Point2RBox.\nSpecifically, we propose to leverage two principles: 1) Synthetic pattern\nknowledge combination: By sampling around each labeled point on the image, we\nspread the object feature to synthetic visual patterns with known boxes to\nprovide the knowledge for box regression. 2) Transform self-supervision: With a\ntransformed input image (e.g. scaled/rotated), the output RBoxes are trained to\nfollow the same transformation so that the network can perceive the relative\nsize/rotation between objects. The detector is further enhanced by a few\ndevised techniques to cope with peripheral issues, e.g. the anchor/layer\nassignment as the size of the object is not available in our point supervision\nsetting. To our best knowledge, Point2RBox is the first end-to-end solution for\npoint-supervised OOD. In particular, our method uses a lightweight paradigm,\nyet it achieves a competitive performance among point-supervised alternatives,\n41.05%/27.62%/80.01% on DOTA/DIOR/HRSC datasets.\n","authors":["Yi Yu","Xue Yang","Qingyun Li","Feipeng Da","Jifeng Dai","Yu Qiao","Junchi Yan"],"pdf_url":"https://arxiv.org/pdf/2311.14758v2.pdf","comment":"10 pages, 3 figures, 5 tables, code:\n  https://github.com/yuyi1005/point2rbox-mmrotate"},{"id":"http://arxiv.org/abs/2402.07234v3","updated":"2024-03-21T12:39:09Z","published":"2024-02-11T15:56:03Z","title":"CPSDBench: A Large Language Model Evaluation Benchmark and Baseline for\n  Chinese Public Security Domain","summary":"  Large Language Models (LLMs) have demonstrated significant potential and\neffectiveness across multiple application domains. To assess the performance of\nmainstream LLMs in public security tasks, this study aims to construct a\nspecialized evaluation benchmark tailored to the Chinese public security\ndomain--CPSDbench. CPSDbench integrates datasets related to public security\ncollected from real-world scenarios, supporting a comprehensive assessment of\nLLMs across four key dimensions: text classification, information extraction,\nquestion answering, and text generation. Furthermore, this study introduces a\nset of innovative evaluation metrics designed to more precisely quantify the\nefficacy of LLMs in executing tasks related to public security. Through the\nin-depth analysis and evaluation conducted in this research, we not only\nenhance our understanding of the performance strengths and limitations of\nexisting models in addressing public security issues but also provide\nreferences for the future development of more accurate and customized LLM\nmodels targeted at applications in this field.\n","authors":["Xin Tong","Bo Jin","Zhi Lin","Binjun Wang","Ting Yu","Qiang Cheng"],"pdf_url":"https://arxiv.org/pdf/2402.07234v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14358v1","updated":"2024-03-21T12:37:54Z","published":"2024-03-21T12:37:54Z","title":"Exploring the Potential of Large Language Models in Graph Generation","summary":"  Large language models (LLMs) have achieved great success in many fields, and\nrecent works have studied exploring LLMs for graph discriminative tasks such as\nnode classification. However, the abilities of LLMs for graph generation remain\nunexplored in the literature. Graph generation requires the LLM to generate\ngraphs with given properties, which has valuable real-world applications such\nas drug discovery, while tends to be more challenging. In this paper, we\npropose LLM4GraphGen to explore the ability of LLMs for graph generation with\nsystematical task designs and extensive experiments. Specifically, we propose\nseveral tasks tailored with comprehensive experiments to address key questions\nregarding LLMs' understanding of different graph structure rules, their ability\nto capture structural type distributions, and their utilization of domain\nknowledge for property-based graph generation. Our evaluations demonstrate that\nLLMs, particularly GPT-4, exhibit preliminary abilities in graph generation\ntasks, including rule-based and distribution-based generation. We also observe\nthat popular prompting methods, such as few-shot and chain-of-thought\nprompting, do not consistently enhance performance. Besides, LLMs show\npotential in generating molecules with specific properties. These findings may\nserve as foundations for designing good LLMs based models for graph generation\nand provide valuable insights and further research.\n","authors":["Yang Yao","Xin Wang","Zeyang Zhang","Yijian Qin","Ziwei Zhang","Xu Chu","Yuekui Yang","Wenwu Zhu","Hong Mei"],"pdf_url":"https://arxiv.org/pdf/2403.14358v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.13927v2","updated":"2024-03-21T12:37:21Z","published":"2023-12-21T15:22:07Z","title":"On the convergence of loss and uncertainty-based active learning\n  algorithms","summary":"  We consider the convergence rates of loss and uncertainty-based active\nlearning algorithms under various assumptions. Firstly, we establish a set of\nconditions that ensure convergence rates when applied to linear classifiers and\nlinearly separable datasets. This includes demonstrating convergence rate\nguarantees for loss-based sampling with various loss functions. Secondly, we\nintroduce a framework that allows us to derive convergence rate bounds for\nloss-based sampling by leveraging known convergence rate bounds for stochastic\ngradient descent algorithms. Lastly, we propose a new algorithm that combines\npoint sampling and stochastic Polyak's step size. We establish a condition on\nthe sampling process, ensuring a convergence rate guarantee for this algorithm,\nparticularly in the case of smooth convex loss functions. Our numerical results\nshowcase the efficiency of the proposed algorithm.\n","authors":["Daniel Haimovich","Dima Karamshuk","Fridolin Linder","Niek Tax","Milan Vojnovic"],"pdf_url":"https://arxiv.org/pdf/2312.13927v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.01753v2","updated":"2024-03-21T12:36:22Z","published":"2023-11-03T07:18:36Z","title":"RiskQ: Risk-sensitive Multi-Agent Reinforcement Learning Value\n  Factorization","summary":"  Multi-agent systems are characterized by environmental uncertainty, varying\npolicies of agents, and partial observability, which result in significant\nrisks. In the context of Multi-Agent Reinforcement Learning (MARL), learning\ncoordinated and decentralized policies that are sensitive to risk is\nchallenging. To formulate the coordination requirements in risk-sensitive MARL,\nwe introduce the Risk-sensitive Individual-Global-Max (RIGM) principle as a\ngeneralization of the Individual-Global-Max (IGM) and Distributional IGM (DIGM)\nprinciples. This principle requires that the collection of risk-sensitive\naction selections of each agent should be equivalent to the risk-sensitive\naction selection of the central policy. Current MARL value factorization\nmethods do not satisfy the RIGM principle for common risk metrics such as the\nValue at Risk (VaR) metric or distorted risk measurements. Therefore, we\npropose RiskQ to address this limitation, which models the joint return\ndistribution by modeling quantiles of it as weighted quantile mixtures of\nper-agent return distribution utilities. RiskQ satisfies the RIGM principle for\nthe VaR and distorted risk metrics. We show that RiskQ can obtain promising\nperformance through extensive experiments. The source code of RiskQ is\navailable in https://github.com/xmu-rl-3dv/RiskQ.\n","authors":["Siqi Shen","Chennan Ma","Chao Li","Weiquan Liu","Yongquan Fu","Songzhu Mei","Xinwang Liu","Cheng Wang"],"pdf_url":"https://arxiv.org/pdf/2311.01753v2.pdf","comment":"Accepted at NeurIPS 2023"},{"id":"http://arxiv.org/abs/2310.14525v2","updated":"2024-03-21T12:32:53Z","published":"2023-10-23T03:15:57Z","title":"Graph Ranking Contrastive Learning: A Extremely Simple yet Efficient\n  Method","summary":"  Graph contrastive learning (GCL) has emerged as a representative graph\nself-supervised method, achieving significant success. The currently prevalent\noptimization objective for GCL is InfoNCE. Typically, it employs augmentation\ntechniques to obtain two views, where a node in one view acts as the anchor,\nthe corresponding node in the other view serves as the positive sample, and all\nother nodes are regarded as negative samples. The goal is to minimize the\ndistance between the anchor node and positive samples and maximize the distance\nto negative samples. However, due to the lack of label information during\ntraining, InfoNCE inevitably treats samples from the same class as negative\nsamples, leading to the issue of false negative samples. This can impair the\nlearned node representations and subsequently hinder performance in downstream\ntasks. While numerous methods have been proposed to mitigate the impact of\nfalse negatives, they still face various challenges. For instance, while\nincreasing the number of negative samples can dilute the impact of false\nnegatives, it concurrently increases computational burden. Thus, we propose\nGraphRank, a simple yet efficient graph contrastive learning method that\naddresses the problem of false negative samples by redefining the concept of\nnegative samples to a certain extent, thereby avoiding the issue of false\nnegative samples. The effectiveness of GraphRank is empirically validated\nthrough experiments on the node, edge, and graph level tasks.\n","authors":["Yulan Hu","Sheng Ouyang","Jingyu Liu","Ge Chen","Zhirui Yang","Junchen Wan","Fuzheng Zhang","Zhongyuan Wang","Yong Liu"],"pdf_url":"https://arxiv.org/pdf/2310.14525v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.06906v2","updated":"2024-03-21T12:30:16Z","published":"2024-03-11T16:57:20Z","title":"Cost-Sensitive Learning to Defer to Multiple Experts with Workload\n  Constraints","summary":"  Learning to defer (L2D) aims to improve human-AI collaboration systems by\nlearning how to defer decisions to humans when they are more likely to be\ncorrect than an ML classifier. Existing research in L2D overlooks key aspects\nof real-world systems that impede its practical adoption, namely: i) neglecting\ncost-sensitive scenarios, where type 1 and type 2 errors have different costs;\nii) requiring concurrent human predictions for every instance of the training\ndataset and iii) not dealing with human work capacity constraints. To address\nthese issues, we propose the deferral under cost and capacity constraints\nframework (DeCCaF). DeCCaF is a novel L2D approach, employing supervised\nlearning to model the probability of human error under less restrictive data\nrequirements (only one expert prediction per instance) and using constraint\nprogramming to globally minimize the error cost subject to workload\nlimitations. We test DeCCaF in a series of cost-sensitive fraud detection\nscenarios with different teams of 9 synthetic fraud analysts, with individual\nwork capacity constraints. The results demonstrate that our approach performs\nsignificantly better than the baselines in a wide array of scenarios, achieving\nan average 8.4% reduction in the misclassification cost.\n","authors":["Jean V. Alves","Diogo Leitão","Sérgio Jesus","Marco O. P. Sampaio","Javier Liébana","Pedro Saleiro","Mário A. T. Figueiredo","Pedro Bizarro"],"pdf_url":"https://arxiv.org/pdf/2403.06906v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14340v1","updated":"2024-03-21T12:14:02Z","published":"2024-03-21T12:14:02Z","title":"Exploring Task Unification in Graph Representation Learning via\n  Generative Approach","summary":"  Graphs are ubiquitous in real-world scenarios and encompass a diverse range\nof tasks, from node-, edge-, and graph-level tasks to transfer learning.\nHowever, designing specific tasks for each type of graph data is often costly\nand lacks generalizability. Recent endeavors under the \"Pre-training +\nFine-tuning\" or \"Pre-training + Prompt\" paradigms aim to design a unified\nframework capable of generalizing across multiple graph tasks. Among these,\ngraph autoencoders (GAEs), generative self-supervised models, have demonstrated\ntheir potential in effectively addressing various graph tasks. Nevertheless,\nthese methods typically employ multi-stage training and require adaptive\ndesigns, which on one hand make it difficult to be seamlessly applied to\ndiverse graph tasks and on the other hand overlook the negative impact caused\nby discrepancies in task objectives between the different stages. To address\nthese challenges, we propose GA^2E, a unified adversarially masked autoencoder\ncapable of addressing the above challenges seamlessly. Specifically, GA^2E\nproposes to use the subgraph as the meta-structure, which remains consistent\nacross all graph tasks (ranging from node-, edge-, and graph-level to transfer\nlearning) and all stages (both during training and inference). Further, GA^2E\noperates in a \\textbf{\"Generate then Discriminate\"} manner. It leverages the\nmasked GAE to reconstruct the input subgraph whilst treating it as a generator\nto compel the reconstructed graphs resemble the input subgraph. Furthermore,\nGA^2E introduces an auxiliary discriminator to discern the authenticity between\nthe reconstructed (generated) subgraph and the input subgraph, thus ensuring\nthe robustness of the graph representation through adversarial training\nmechanisms. We validate GA^2E's capabilities through extensive experiments on\n21 datasets across four types of graph tasks.\n","authors":["Yulan Hu","Sheng Ouyang","Zhirui Yang","Ge Chen","Junchen Wan","Xiao Wang","Yong Liu"],"pdf_url":"https://arxiv.org/pdf/2403.14340v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14339v1","updated":"2024-03-21T12:11:26Z","published":"2024-03-21T12:11:26Z","title":"$\\nabla τ$: Gradient-based and Task-Agnostic machine Unlearning","summary":"  Machine Unlearning, the process of selectively eliminating the influence of\ncertain data examples used during a model's training, has gained significant\nattention as a means for practitioners to comply with recent data protection\nregulations. However, existing unlearning methods face critical drawbacks,\nincluding their prohibitively high cost, often associated with a large number\nof hyperparameters, and the limitation of forgetting only relatively small data\nportions. This often makes retraining the model from scratch a quicker and more\neffective solution. In this study, we introduce Gradient-based and\nTask-Agnostic machine Unlearning ($\\nabla \\tau$), an optimization framework\ndesigned to remove the influence of a subset of training data efficiently. It\napplies adaptive gradient ascent to the data to be forgotten while using\nstandard gradient descent for the remaining data. $\\nabla \\tau$ offers multiple\nbenefits over existing approaches. It enables the unlearning of large sections\nof the training dataset (up to 30%). It is versatile, supporting various\nunlearning tasks (such as subset forgetting or class removal) and applicable\nacross different domains (images, text, etc.). Importantly, $\\nabla \\tau$\nrequires no hyperparameter adjustments, making it a more appealing option than\nretraining the model from scratch. We evaluate our framework's effectiveness\nusing a set of well-established Membership Inference Attack metrics,\ndemonstrating up to 10% enhancements in performance compared to\nstate-of-the-art methods without compromising the original model's accuracy.\n","authors":["Daniel Trippa","Cesare Campagnano","Maria Sofia Bucarelli","Gabriele Tolomei","Fabrizio Silvestri"],"pdf_url":"https://arxiv.org/pdf/2403.14339v1.pdf","comment":"14 pages, 2 figures"},{"id":"http://arxiv.org/abs/2402.16068v3","updated":"2024-03-21T11:58:49Z","published":"2024-02-25T11:37:23Z","title":"ROS-Causal: A ROS-based Causal Analysis Framework for Human-Robot\n  Interaction Applications","summary":"  Deploying robots in human-shared spaces requires understanding interactions\namong nearby agents and objects. Modelling cause-and-effect relations through\ncausal inference aids in predicting human behaviours and anticipating robot\ninterventions. However, a critical challenge arises as existing causal\ndiscovery methods currently lack an implementation inside the ROS ecosystem,\nthe standard de facto in robotics, hindering effective utilisation in robotics.\nTo address this gap, this paper introduces ROS-Causal, a ROS-based framework\nfor onboard data collection and causal discovery in human-robot spatial\ninteractions. An ad-hoc simulator, integrated with ROS, illustrates the\napproach's effectiveness, showcasing the robot onboard generation of causal\nmodels during data collection. ROS-Causal is available on GitHub:\nhttps://github.com/lcastri/roscausal.git.\n","authors":["Luca Castri","Gloria Beraldo","Sariah Mghames","Marc Hanheide","Nicola Bellotto"],"pdf_url":"https://arxiv.org/pdf/2402.16068v3.pdf","comment":"Accepted by the \"Causal-HRI: Causal Learning for Human-Robot\n  Interaction\" workshop at the 2024 ACM/IEEE International Conference on\n  Human-Robot Interaction (HRI)"},{"id":"http://arxiv.org/abs/2403.14328v1","updated":"2024-03-21T11:54:45Z","published":"2024-03-21T11:54:45Z","title":"Distilling Reinforcement Learning Policies for Interpretable Robot\n  Locomotion: Gradient Boosting Machines and Symbolic Regression","summary":"  Recent advancements in reinforcement learning (RL) have led to remarkable\nachievements in robot locomotion capabilities. However, the complexity and\n``black-box'' nature of neural network-based RL policies hinder their\ninterpretability and broader acceptance, particularly in applications demanding\nhigh levels of safety and reliability. This paper introduces a novel approach\nto distill neural RL policies into more interpretable forms using Gradient\nBoosting Machines (GBMs), Explainable Boosting Machines (EBMs) and Symbolic\nRegression. By leveraging the inherent interpretability of generalized additive\nmodels, decision trees, and analytical expressions, we transform opaque neural\nnetwork policies into more transparent ``glass-box'' models. We train expert\nneural network policies using RL and subsequently distill them into (i) GBMs,\n(ii) EBMs, and (iii) symbolic policies. To address the inherent distribution\nshift challenge of behavioral cloning, we propose to use the Dataset\nAggregation (DAgger) algorithm with a curriculum of episode-dependent\nalternation of actions between expert and distilled policies, to enable\nefficient distillation of feedback control policies. We evaluate our approach\non various robot locomotion gaits -- walking, trotting, bounding, and pacing --\nand study the importance of different observations in joint actions for\ndistilled policies using various methods. We train neural expert policies for\n205 hours of simulated experience and distill interpretable policies with only\n10 minutes of simulated interaction for each gait using the proposed method.\n","authors":["Fernando Acero","Zhibin Li"],"pdf_url":"https://arxiv.org/pdf/2403.14328v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14300v1","updated":"2024-03-21T11:16:28Z","published":"2024-03-21T11:16:28Z","title":"DexDribbler: Learning Dexterous Soccer Manipulation via Dynamic\n  Supervision","summary":"  Learning dexterous locomotion policy for legged robots is becoming\nincreasingly popular due to its ability to handle diverse terrains and resemble\nintelligent behaviors. However, joint manipulation of moving objects and\nlocomotion with legs, such as playing soccer, receive scant attention in the\nlearning community, although it is natural for humans and smart animals. A key\nchallenge to solve this multitask problem is to infer the objectives of\nlocomotion from the states and targets of the manipulated objects. The implicit\nrelation between the object states and robot locomotion can be hard to capture\ndirectly from the training experience. We propose adding a feedback control\nblock to compute the necessary body-level movement accurately and using the\noutputs as dynamic joint-level locomotion supervision explicitly. We further\nutilize an improved ball dynamic model, an extended context-aided estimator,\nand a comprehensive ball observer to facilitate transferring policy learned in\nsimulation to the real world. We observe that our learning scheme can not only\nmake the policy network converge faster but also enable soccer robots to\nperform sophisticated maneuvers like sharp cuts and turns on flat surfaces, a\ncapability that was lacking in previous methods. Video and code are available\nat https://github.com/SysCV/soccer-player\n","authors":["Yutong Hu","Kehan Wen","Fisher Yu"],"pdf_url":"https://arxiv.org/pdf/2403.14300v1.pdf","comment":"8 pages, 7 figures, submitted to IROS 2024"},{"id":"http://arxiv.org/abs/2312.07214v3","updated":"2024-03-21T11:12:31Z","published":"2023-12-12T12:26:48Z","title":"Exploring Large Language Models to Facilitate Variable Autonomy for\n  Human-Robot Teaming","summary":"  In a rapidly evolving digital landscape autonomous tools and robots are\nbecoming commonplace. Recognizing the significance of this development, this\npaper explores the integration of Large Language Models (LLMs) like Generative\npre-trained transformer (GPT) into human-robot teaming environments to\nfacilitate variable autonomy through the means of verbal human-robot\ncommunication. In this paper, we introduce a novel framework for such a\nGPT-powered multi-robot testbed environment, based on a Unity Virtual Reality\n(VR) setting. This system allows users to interact with robot agents through\nnatural language, each powered by individual GPT cores. By means of OpenAI's\nfunction calling, we bridge the gap between unstructured natural language input\nand structure robot actions. A user study with 12 participants explores the\neffectiveness of GPT-4 and, more importantly, user strategies when being given\nthe opportunity to converse in natural language within a multi-robot\nenvironment. Our findings suggest that users may have preconceived expectations\non how to converse with robots and seldom try to explore the actual language\nand cognitive capabilities of their robot collaborators. Still, those users who\ndid explore where able to benefit from a much more natural flow of\ncommunication and human-like back-and-forth. We provide a set of lessons\nlearned for future research and technical implementations of similar systems.\n","authors":["Younes Lakhnati","Max Pascher","Jens Gerken"],"pdf_url":"https://arxiv.org/pdf/2312.07214v3.pdf","comment":"Frontiers in Robotics and AI, Variable Autonomy for Human-Robot\n  Teaming"},{"id":"http://arxiv.org/abs/2403.14298v1","updated":"2024-03-21T11:04:41Z","published":"2024-03-21T11:04:41Z","title":"From Perils to Possibilities: Understanding how Human (and AI) Biases\n  affect Online Fora","summary":"  Social media platforms are online fora where users engage in discussions,\nshare content, and build connections. This review explores the dynamics of\nsocial interactions, user-generated contents, and biases within the context of\nsocial media analysis (analyzing works that use the tools offered by complex\nnetwork analysis and natural language processing) through the lens of three key\npoints of view: online debates, online support, and human-AI interactions. On\nthe one hand, we delineate the phenomenon of online debates, where\npolarization, misinformation, and echo chamber formation often proliferate,\ndriven by algorithmic biases and extreme mechanisms of homophily. On the other\nhand, we explore the emergence of online support groups through users'\nself-disclosure and social support mechanisms. Online debates and support\nmechanisms present a duality of both perils and possibilities within social\nmedia; perils of segregated communities and polarized debates, and\npossibilities of empathy narratives and self-help groups. This dichotomy also\nextends to a third perspective: users' reliance on AI-generated content, such\nas the ones produced by Large Language Models, which can manifest both human\nbiases hidden in training sets and non-human biases that emerge from their\nartificial neural architectures. Analyzing interdisciplinary approaches, we aim\nto deepen the understanding of the complex interplay between social\ninteractions, user-generated content, and biases within the realm of social\nmedia ecosystems.\n","authors":["Virginia Morini","Valentina Pansanella","Katherine Abramski","Erica Cau","Andrea Failla","Salvatore Citraro","Giulio Rossetti"],"pdf_url":"https://arxiv.org/pdf/2403.14298v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14297v1","updated":"2024-03-21T11:03:56Z","published":"2024-03-21T11:03:56Z","title":"Impact Assessment of Missing Data in Model Predictions for Earth\n  Observation Applications","summary":"  Earth observation (EO) applications involving complex and heterogeneous data\nsources are commonly approached with machine learning models. However, there is\na common assumption that data sources will be persistently available. Different\nsituations could affect the availability of EO sources, like noise, clouds, or\nsatellite mission failures. In this work, we assess the impact of missing\ntemporal and static EO sources in trained models across four datasets with\nclassification and regression tasks. We compare the predictive quality of\ndifferent methods and find that some are naturally more robust to missing data.\nThe Ensemble strategy, in particular, achieves a prediction robustness up to\n100%. We evidence that missing scenarios are significantly more challenging in\nregression than classification tasks. Finally, we find that the optical view is\nthe most critical view when it is missing individually.\n","authors":["Francisco Mena","Diego Arenas","Marcela Charfuelan","Marlon Nuske","Andreas Dengel"],"pdf_url":"https://arxiv.org/pdf/2403.14297v1.pdf","comment":"Accepted at IEEE International Geoscience and Remote Sensing\n  Symposium 2024"},{"id":"http://arxiv.org/abs/2310.17918v2","updated":"2024-03-21T10:57:23Z","published":"2023-10-27T06:22:14Z","title":"Knowing What LLMs DO NOT Know: A Simple Yet Effective Self-Detection\n  Method","summary":"  Large Language Models (LLMs) have shown great potential in Natural Language\nProcessing (NLP) tasks. However, recent literature reveals that LLMs generate\nnonfactual responses intermittently, which impedes the LLMs' reliability for\nfurther utilization. In this paper, we propose a novel self-detection method to\ndetect which questions that a LLM does not know that are prone to generate\nnonfactual results. Specifically, we first diversify the textual expressions\nfor a given question and collect the corresponding answers. Then we examine the\ndivergencies between the generated answers to identify the questions that the\nmodel may generate falsehoods. All of the above steps can be accomplished by\nprompting the LLMs themselves without referring to any other external\nresources. We conduct comprehensive experiments and demonstrate the\neffectiveness of our method on recently released LLMs, e.g., Vicuna, ChatGPT,\nand GPT-4.\n","authors":["Yukun Zhao","Lingyong Yan","Weiwei Sun","Guoliang Xing","Chong Meng","Shuaiqiang Wang","Zhicong Cheng","Zhaochun Ren","Dawei Yin"],"pdf_url":"https://arxiv.org/pdf/2310.17918v2.pdf","comment":"Accepted by NAACL 2024"},{"id":"http://arxiv.org/abs/2403.14287v1","updated":"2024-03-21T10:51:19Z","published":"2024-03-21T10:51:19Z","title":"Enhancing Historical Image Retrieval with Compositional Cues","summary":"  In analyzing vast amounts of digitally stored historical image data, existing\ncontent-based retrieval methods often overlook significant non-semantic\ninformation, limiting their effectiveness for flexible exploration across\nvaried themes. To broaden the applicability of image retrieval methods for\ndiverse purposes and uncover more general patterns, we innovatively introduce a\ncrucial factor from computational aesthetics, namely image composition, into\nthis topic. By explicitly integrating composition-related information extracted\nby CNN into the designed retrieval model, our method considers both the image's\ncomposition rules and semantic information. Qualitative and quantitative\nexperiments demonstrate that the image retrieval network guided by composition\ninformation outperforms those relying solely on content information,\nfacilitating the identification of images in databases closer to the target\nimage in human perception. Please visit https://github.com/linty5/CCBIR to try\nour codes.\n","authors":["Tingyu Lin","Robert Sablatnig"],"pdf_url":"https://arxiv.org/pdf/2403.14287v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14282v1","updated":"2024-03-21T10:43:55Z","published":"2024-03-21T10:43:55Z","title":"How to be fair? A study of label and selection bias","summary":"  It is widely accepted that biased data leads to biased and thus potentially\nunfair models. Therefore, several measures for bias in data and model\npredictions have been proposed, as well as bias mitigation techniques whose aim\nis to learn models that are fair by design. Despite the myriad of mitigation\ntechniques developed in the past decade, however, it is still poorly understood\nunder what circumstances which methods work. Recently, Wick et al. showed, with\nexperiments on synthetic data, that there exist situations in which bias\nmitigation techniques lead to more accurate models when measured on unbiased\ndata. Nevertheless, in the absence of a thorough mathematical analysis, it\nremains unclear which techniques are effective under what circumstances. We\npropose to address this problem by establishing relationships between the type\nof bias and the effectiveness of a mitigation technique, where we categorize\nthe mitigation techniques by the bias measure they optimize. In this paper we\nillustrate this principle for label and selection bias on the one hand, and\ndemographic parity and ``We're All Equal'' on the other hand. Our theoretical\nanalysis allows to explain the results of Wick et al. and we also show that\nthere are situations where minimizing fairness measures does not result in the\nfairest possible distribution.\n","authors":["Marco Favier","Toon Calders","Sam Pinxteren","Jonathan Meyer"],"pdf_url":"https://arxiv.org/pdf/2403.14282v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14274v1","updated":"2024-03-21T10:28:18Z","published":"2024-03-21T10:28:18Z","title":"Multi-role Consensus through LLMs Discussions for Vulnerability\n  Detection","summary":"  Recent advancements in large language models (LLMs) have highlighted the\npotential for vulnerability detection, a crucial component of software quality\nassurance. Despite this progress, most studies have been limited to the\nperspective of a single role, usually testers, lacking diverse viewpoints from\ndifferent roles in a typical software development life-cycle, including both\ndevelopers and testers. To this end, this paper introduces an approach to\nemploy LLMs to act as different roles to simulate real-life code review\nprocess, engaging in discussions towards a consensus on the existence and\nclassification of vulnerabilities in the code. Preliminary evaluation of the\nproposed approach indicates a 4.73% increase in the precision rate, 58.9%\nincrease in the recall rate, and a 28.1% increase in the F1 score.\n","authors":["Zhenyu Mao","Jialong Li","Munan Li","Kenji Tei"],"pdf_url":"https://arxiv.org/pdf/2403.14274v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14273v1","updated":"2024-03-21T10:26:47Z","published":"2024-03-21T10:26:47Z","title":"Reactor Optimization Benchmark by Reinforcement Learning","summary":"  Neutronic calculations for reactors are a daunting task when using Monte\nCarlo (MC) methods. As high-performance computing has advanced, the simulation\nof a reactor is nowadays more readily done, but design and optimization with\nmultiple parameters is still a computational challenge. MC transport\nsimulations, coupled with machine learning techniques, offer promising avenues\nfor enhancing the efficiency and effectiveness of nuclear reactor optimization.\nThis paper introduces a novel benchmark problem within the OpenNeoMC framework\ndesigned specifically for reinforcement learning. The benchmark involves\noptimizing a unit cell of a research reactor with two varying parameters (fuel\ndensity and water spacing) to maximize neutron flux while maintaining reactor\ncriticality. The test case features distinct local optima, representing\ndifferent physical regimes, thus posing a challenge for learning algorithms.\nThrough extensive simulations utilizing evolutionary and neuroevolutionary\nalgorithms, we demonstrate the effectiveness of reinforcement learning in\nnavigating complex optimization landscapes with strict constraints.\nFurthermore, we propose acceleration techniques within the OpenNeoMC framework,\nincluding model updating and cross-section usage by RAM utilization, to\nexpedite simulation times. Our findings emphasize the importance of machine\nlearning integration in reactor optimization and contribute to advancing\nmethodologies for addressing intricate optimization challenges in nuclear\nengineering. The sources of this work are available at our GitHub repository:\nhttps://github.com/Scientific-Computing-Lab-NRCN/RLOpenNeoMC\n","authors":["Deborah Schwarcz","Nadav Schneider","Gal Oren","Uri Steinitz"],"pdf_url":"https://arxiv.org/pdf/2403.14273v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.00823v2","updated":"2024-03-21T10:21:37Z","published":"2024-02-01T18:07:33Z","title":"SLIM: Skill Learning with Multiple Critics","summary":"  Self-supervised skill learning aims to acquire useful behaviors that leverage\nthe underlying dynamics of the environment. Latent variable models, based on\nmutual information maximization, have been successful in this task but still\nstruggle in the context of robotic manipulation. As it requires impacting a\npossibly large set of degrees of freedom composing the environment, mutual\ninformation maximization fails alone in producing useful and safe manipulation\nbehaviors. Furthermore, tackling this by augmenting skill discovery rewards\nwith additional rewards through a naive combination might fail to produce\ndesired behaviors. To address this limitation, we introduce SLIM, a\nmulti-critic learning approach for skill discovery with a particular focus on\nrobotic manipulation. Our main insight is that utilizing multiple critics in an\nactor-critic framework to gracefully combine multiple reward functions leads to\na significant improvement in latent-variable skill discovery for robotic\nmanipulation while overcoming possible interference occurring among rewards\nwhich hinders convergence to useful skills. Furthermore, in the context of\ntabletop manipulation, we demonstrate the applicability of our novel skill\ndiscovery approach to acquire safe and efficient motor primitives in a\nhierarchical reinforcement learning fashion and leverage them through planning,\nsignificantly surpassing baseline approaches for skill discovery.\n","authors":["David Emukpere","Bingbing Wu","Julien Perez","Jean-Michel Renders"],"pdf_url":"https://arxiv.org/pdf/2402.00823v2.pdf","comment":"Accepted at IEEE ICRA 2024"},{"id":"http://arxiv.org/abs/2403.00862v2","updated":"2024-03-21T10:14:09Z","published":"2024-02-29T21:05:14Z","title":"NewsBench: Systematic Evaluation of LLMs for Writing Proficiency and\n  Safety Adherence in Chinese Journalistic Editorial Applications","summary":"  This study presents NewsBench, a novel benchmark framework developed to\nevaluate the capability of Large Language Models (LLMs) in Chinese Journalistic\nWriting Proficiency (JWP) and their Safety Adherence (SA), addressing the gap\nbetween journalistic ethics and the risks associated with AI utilization.\nComprising 1,267 tasks across 5 editorial applications, 7 aspects (including\nsafety and journalistic writing with 4 detailed facets), and spanning 24 news\ntopics domains, NewsBench employs two GPT-4 based automatic evaluation\nprotocols validated by human assessment. Our comprehensive analysis of 10 LLMs\nhighlighted GPT-4 and ERNIE Bot as top performers, yet revealed a relative\ndeficiency in journalistic ethic adherence during creative writing tasks. These\nfindings underscore the need for enhanced ethical guidance in AI-generated\njournalistic content, marking a step forward in aligning AI capabilities with\njournalistic standards and safety considerations.\n","authors":["Miao Li","Ming-Bin Chen","Bo Tang","Shengbin Hou","Pengyu Wang","Haiying Deng","Zhiyu Li","Feiyu Xiong","Keming Mao","Peng Cheng","Yi Luo"],"pdf_url":"https://arxiv.org/pdf/2403.00862v2.pdf","comment":"27 pages"},{"id":"http://arxiv.org/abs/2403.12821v2","updated":"2024-03-21T10:02:39Z","published":"2024-03-19T15:21:10Z","title":"FlowerFormer: Empowering Neural Architecture Encoding using a Flow-aware\n  Graph Transformer","summary":"  The success of a specific neural network architecture is closely tied to the\ndataset and task it tackles; there is no one-size-fits-all solution. Thus,\nconsiderable efforts have been made to quickly and accurately estimate the\nperformances of neural architectures, without full training or evaluation, for\ngiven tasks and datasets. Neural architecture encoding has played a crucial\nrole in the estimation, and graphbased methods, which treat an architecture as\na graph, have shown prominent performance. For enhanced representation learning\nof neural architectures, we introduce FlowerFormer, a powerful graph\ntransformer that incorporates the information flows within a neural\narchitecture. FlowerFormer consists of two key components: (a) bidirectional\nasynchronous message passing, inspired by the flows; (b) global attention built\non flow-based masking. Our extensive experiments demonstrate the superiority of\nFlowerFormer over existing neural encoding methods, and its effectiveness\nextends beyond computer vision models to include graph neural networks and auto\nspeech recognition models. Our code is available at\nhttp://github.com/y0ngjaenius/CVPR2024_FLOWERFormer.\n","authors":["Dongyeong Hwang","Hyunju Kim","Sunwoo Kim","Kijung Shin"],"pdf_url":"https://arxiv.org/pdf/2403.12821v2.pdf","comment":"CVPR 2024 Camera-Ready"},{"id":"http://arxiv.org/abs/2403.14264v1","updated":"2024-03-21T09:59:53Z","published":"2024-03-21T09:59:53Z","title":"A Framework for Portrait Stylization with Skin-Tone Awareness and Nudity\n  Identification","summary":"  Portrait stylization is a challenging task involving the transformation of an\ninput portrait image into a specific style while preserving its inherent\ncharacteristics. The recent introduction of Stable Diffusion (SD) has\nsignificantly improved the quality of outcomes in this field. However, a\npractical stylization framework that can effectively filter harmful input\ncontent and preserve the distinct characteristics of an input, such as\nskin-tone, while maintaining the quality of stylization remains lacking. These\nchallenges have hindered the wide deployment of such a framework. To address\nthese issues, this study proposes a portrait stylization framework that\nincorporates a nudity content identification module (NCIM) and a\nskin-tone-aware portrait stylization module (STAPSM). In experiments, NCIM\nshowed good performance in enhancing explicit content filtering, and STAPSM\naccurately represented a diverse range of skin tones. Our proposed framework\nhas been successfully deployed in practice, and it has effectively satisfied\ncritical requirements of real-world applications.\n","authors":["Seungkwon Kim","Sangyeon Kim","Seung-Hun Nam"],"pdf_url":"https://arxiv.org/pdf/2403.14264v1.pdf","comment":"Accepted to ICASSP 2024"},{"id":"http://arxiv.org/abs/2306.02090v3","updated":"2024-03-21T09:58:15Z","published":"2023-06-03T11:45:16Z","title":"Deep Classifier Mimicry without Data Access","summary":"  Access to pre-trained models has recently emerged as a standard across\nnumerous machine learning domains. Unfortunately, access to the original data\nthe models were trained on may not equally be granted. This makes it\ntremendously challenging to fine-tune, compress models, adapt continually, or\nto do any other type of data-driven update. We posit that original data access\nmay however not be required. Specifically, we propose Contrastive Abductive\nKnowledge Extraction (CAKE), a model-agnostic knowledge distillation procedure\nthat mimics deep classifiers without access to the original data. To this end,\nCAKE generates pairs of noisy synthetic samples and diffuses them contrastively\ntoward a model's decision boundary. We empirically corroborate CAKE's\neffectiveness using several benchmark datasets and various architectural\nchoices, paving the way for broad application.\n","authors":["Steven Braun","Martin Mundt","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2306.02090v3.pdf","comment":"11 pages main, 4 figures, 2 tables, 4 pages appendix"},{"id":"http://arxiv.org/abs/2403.14252v1","updated":"2024-03-21T09:25:24Z","published":"2024-03-21T09:25:24Z","title":"LayoutLLM: Large Language Model Instruction Tuning for Visually Rich\n  Document Understanding","summary":"  This paper proposes LayoutLLM, a more flexible document analysis method for\nunderstanding imaged documents. Visually Rich Document Understanding tasks,\nsuch as document image classification and information extraction, have gained\nsignificant attention due to their importance. Existing methods have been\ndeveloped to enhance document comprehension by incorporating pre-training\nawareness of images, text, and layout structure. However, these methods require\nfine-tuning for each task and dataset, and the models are expensive to train\nand operate. To overcome this limitation, we propose a new LayoutLLM that\nintegrates these with large-scale language models (LLMs). By leveraging the\nstrengths of existing research in document image understanding and LLMs'\nsuperior language understanding capabilities, the proposed model, fine-tuned\nwith multimodal instruction datasets, performs an understanding of document\nimages in a single model. Our experiments demonstrate improvement over the\nbaseline model in various document analysis tasks.\n","authors":["Masato Fujitake"],"pdf_url":"https://arxiv.org/pdf/2403.14252v1.pdf","comment":"LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2403.14246v1","updated":"2024-03-21T09:06:28Z","published":"2024-03-21T09:06:28Z","title":"CATSE: A Context-Aware Framework for Causal Target Sound Extraction","summary":"  Target Sound Extraction (TSE) focuses on the problem of separating sources of\ninterest, indicated by a user's cue, from the input mixture. Most existing\nsolutions operate in an offline fashion and are not suited to the low-latency\ncausal processing constraints imposed by applications in live-streamed content\nsuch as augmented hearing. We introduce a family of context-aware low-latency\ncausal TSE models suitable for real-time processing. First, we explore the\nutility of context by providing the TSE model with oracle information about\nwhat sound classes make up the input mixture, where the objective of the model\nis to extract one or more sources of interest indicated by the user. Since the\npractical applications of oracle models are limited due to their assumptions,\nwe introduce a composite multi-task training objective involving separation and\nclassification losses. Our evaluation involving single- and multi-source\nextraction shows the benefit of using context information in the model either\nby means of providing full context or via the proposed multi-task training loss\nwithout the need for full context information. Specifically, we show that our\nproposed model outperforms size- and latency-matched Waveformer, a\nstate-of-the-art model for real-time TSE.\n","authors":["Shrishail Baligar","Mikolaj Kegler","Bryce Irvin","Marko Stamenovic","Shawn Newsam"],"pdf_url":"https://arxiv.org/pdf/2403.14246v1.pdf","comment":"Submitted to EUSIPCO 2024"},{"id":"http://arxiv.org/abs/2309.02094v3","updated":"2024-03-21T09:03:48Z","published":"2023-09-05T10:00:33Z","title":"TensorBank: Tensor Lakehouse for Foundation Model Training","summary":"  Storing and streaming high dimensional data for foundation model training\nbecame a critical requirement with the rise of foundation models beyond natural\nlanguage. In this paper we introduce TensorBank, a petabyte scale tensor\nlakehouse capable of streaming tensors from Cloud Object Store (COS) to GPU\nmemory at wire speed based on complex relational queries. We use Hierarchical\nStatistical Indices (HSI) for query acceleration. Our architecture allows to\ndirectly address tensors on block level using HTTP range reads. Once in GPU\nmemory, data can be transformed using PyTorch transforms. We provide a generic\nPyTorch dataset type with a corresponding dataset factory translating\nrelational queries and requested transformations as an instance. By making use\nof the HSI, irrelevant blocks can be skipped without reading them as those\nindices contain statistics on their content at different hierarchical\nresolution levels. This is an opinionated architecture powered by open\nstandards and making heavy use of open-source technology. Although, hardened\nfor production use using geospatial-temporal data, this architecture\ngeneralizes to other use case like computer vision, computational neuroscience,\nbiological sequence analysis and more.\n","authors":["Romeo Kienzler","Leonardo Pondian Tizzei","Benedikt Blumenstiel","Zoltan Arnold Nagy","S. Karthik Mukkavilli","Johannes Schmude","Marcus Freitag","Michael Behrendt","Daniel Salles Civitarese","Naomi Simumba","Daiki Kimura","Hendrik Hamann"],"pdf_url":"https://arxiv.org/pdf/2309.02094v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14244v1","updated":"2024-03-21T09:02:31Z","published":"2024-03-21T09:02:31Z","title":"Isotropic Gaussian Splatting for Real-Time Radiance Field Rendering","summary":"  The 3D Gaussian splatting method has drawn a lot of attention, thanks to its\nhigh performance in training and high quality of the rendered image. However,\nit uses anisotropic Gaussian kernels to represent the scene. Although such\nanisotropic kernels have advantages in representing the geometry, they lead to\ndifficulties in terms of computation, such as splitting or merging two kernels.\nIn this paper, we propose to use isotropic Gaussian kernels to avoid such\ndifficulties in the computation, leading to a higher performance method. The\nexperiments confirm that the proposed method is about {\\bf 100X} faster without\nlosing the geometry representation accuracy. The proposed method can be applied\nin a large range applications where the radiance field is needed, such as 3D\nreconstruction, view synthesis, and dynamic object modeling.\n","authors":["Yuanhao Gong","Lantao Yu","Guanghui Yue"],"pdf_url":"https://arxiv.org/pdf/2403.14244v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14243v1","updated":"2024-03-21T09:02:17Z","published":"2024-03-21T09:02:17Z","title":"Dermacen Analytica: A Novel Methodology Integrating Multi-Modal Large\n  Language Models with Machine Learning in tele-dermatology","summary":"  The rise of Artificial Intelligence creates great promise in the field of\nmedical discovery, diagnostics and patient management. However, the vast\ncomplexity of all medical domains require a more complex approach that combines\nmachine learning algorithms, classifiers, segmentation algorithms and, lately,\nlarge language models. In this paper, we describe, implement and assess an\nArtificial Intelligence-empowered system and methodology aimed at assisting the\ndiagnosis process of skin lesions and other skin conditions within the field of\ndermatology that aims to holistically address the diagnostic process in this\ndomain. The workflow integrates large language, transformer-based vision models\nand sophisticated machine learning tools. This holistic approach achieves a\nnuanced interpretation of dermatological conditions that simulates and\nfacilitates a dermatologist's workflow. We assess our proposed methodology\nthrough a thorough cross-model validation technique embedded in an evaluation\npipeline that utilizes publicly available medical case studies of skin\nconditions and relevant images. To quantitatively score the system performance,\nadvanced machine learning and natural language processing tools are employed\nwhich focus on similarity comparison and natural language inference.\nAdditionally, we incorporate a human expert evaluation process based on a\nstructured checklist to further validate our results. We implemented the\nproposed methodology in a system which achieved approximate (weighted) scores\nof 0.87 for both contextual understanding and diagnostic accuracy,\ndemonstrating the efficacy of our approach in enhancing dermatological\nanalysis. The proposed methodology is expected to prove useful in the\ndevelopment of next-generation tele-dermatology applications, enhancing remote\nconsultation capabilities and access to care, especially in underserved areas.\n","authors":["Dimitrios P. Panagoulias","Evridiki Tsoureli-Nikita","Maria Virvou","George A. Tsihrintzis"],"pdf_url":"https://arxiv.org/pdf/2403.14243v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14238v1","updated":"2024-03-21T08:57:27Z","published":"2024-03-21T08:57:27Z","title":"Reinforcement Learning from Reflective Feedback (RLRF): Aligning and\n  Improving LLMs via Fine-Grained Self-Reflection","summary":"  Despite the promise of RLHF in aligning LLMs with human preferences, it often\nleads to superficial alignment, prioritizing stylistic changes over improving\ndownstream performance of LLMs. Underspecified preferences could obscure\ndirections to align the models. Lacking exploration restricts identification of\ndesirable outputs to improve the models. To overcome these challenges, we\npropose a novel framework: Reinforcement Learning from Reflective Feedback\n(RLRF), which leverages fine-grained feedback based on detailed criteria to\nimprove the core capabilities of LLMs. RLRF employs a self-reflection mechanism\nto systematically explore and refine LLM responses, then fine-tuning the models\nvia a RL algorithm along with promising responses. Our experiments across\nJust-Eval, Factuality, and Mathematical Reasoning demonstrate the efficacy and\ntransformative potential of RLRF beyond superficial surface-level adjustment.\n","authors":["Kyungjae Lee","Dasol Hwang","Sunghyun Park","Youngsoo Jang","Moontae Lee"],"pdf_url":"https://arxiv.org/pdf/2403.14238v1.pdf","comment":"22 pages, 5 figures, Submitted to ACL 2024"},{"id":"http://arxiv.org/abs/2403.14236v1","updated":"2024-03-21T08:54:24Z","published":"2024-03-21T08:54:24Z","title":"A Unified Framework for Model Editing","summary":"  Model editing is a growing area focused on updating the knowledge embedded\nwithin models. Among the various methodologies, ROME and MEMIT stand out as\nleading \"locate-and-edit\" model editing techniques. While MEMIT enables batched\nediting of memories, ROME is limited to changing one fact at a time. This paper\nintroduces a unifying framework that brings ROME and MEMIT under a single\nconceptual umbrella, optimizing for the same goal, which we call the\n\"preservation-memorization\" objective. This objective aims to preserve the\nrepresentations of certain selected vectors while memorizing the\nrepresentations of new factual information. Specifically, ROME optimizes this\nobjective using an equality constraint, whereas MEMIT employs a more flexible\nleast-square constraint. In addition to making batched edits, MEMIT also edits\nthe model at multiple layers. We disentangle the distribution of edits to\nmultiple layers from the optimization objective of MEMIT and show that these\nedit-distribution algorithms should be considered separate entities worthy of\ntheir own line of research.\n  Finally, we present EMMET - an Equality-constrained Mass Model Editing\nalgorithm for Transformers, a new batched memory-editing algorithm. With EMMET,\nwe present a closed form solution for the equality-constrained version of the\npreservation-memorization objective. We show that EMMET is able to perform\nbatched-edits on par with MEMIT up to a batch-size of 256 and discuss the\nchallenges in stabilizing EMMET. By articulating the \"locate-and-edit\" model\nediting algorithms under a simple conceptual framework of\n\"preservation-memorization\", we aim to bridge the gap between intuition and\nmathematics and hope to simplify the journey for future researchers in model\nediting.\n","authors":["Akshat Gupta","Dev Sajnani","Gopala Anumanchipalli"],"pdf_url":"https://arxiv.org/pdf/2403.14236v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.14974v2","updated":"2024-03-21T08:50:44Z","published":"2023-09-25T09:21:25Z","title":"Detecting Sexual Content at the Sentence Level in First Millennium Latin\n  Texts","summary":"  In this study, we propose to evaluate the use of deep learning methods for\nsemantic classification at the sentence level to accelerate the process of\ncorpus building in the field of humanities and linguistics, a traditional and\ntime-consuming task. We introduce a novel corpus comprising around 2500\nsentences spanning from 300 BCE to 900 CE including sexual semantics (medical,\nerotica, etc.). We evaluate various sentence classification approaches and\ndifferent input embedding layers, and show that all consistently outperform\nsimple token-based searches. We explore the integration of idiolectal and\nsociolectal metadata embeddings (centuries, author, type of writing), but find\nthat it leads to overfitting. Our results demonstrate the effectiveness of this\napproach, achieving high precision and true positive rates (TPR) of\nrespectively 70.60% and 86.33% using HAN. We evaluate the impact of the dataset\nsize on the model performances (420 instead of 2013), and show that, while our\nmodels perform worse, they still offer a high enough precision and TPR, even\nwithout MLM, respectively 69% and 51%. Given the result, we provide an analysis\nof the attention mechanism as a supporting added value for humanists in order\nto produce more data.\n","authors":["Thibault Clérice"],"pdf_url":"https://arxiv.org/pdf/2309.14974v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14233v1","updated":"2024-03-21T08:49:34Z","published":"2024-03-21T08:49:34Z","title":"SoftPatch: Unsupervised Anomaly Detection with Noisy Data","summary":"  Although mainstream unsupervised anomaly detection (AD) algorithms perform\nwell in academic datasets, their performance is limited in practical\napplication due to the ideal experimental setting of clean training data.\nTraining with noisy data is an inevitable problem in real-world anomaly\ndetection but is seldom discussed. This paper considers label-level noise in\nimage sensory anomaly detection for the first time. To solve this problem, we\nproposed a memory-based unsupervised AD method, SoftPatch, which efficiently\ndenoises the data at the patch level. Noise discriminators are utilized to\ngenerate outlier scores for patch-level noise elimination before coreset\nconstruction. The scores are then stored in the memory bank to soften the\nanomaly detection boundary. Compared with existing methods, SoftPatch maintains\na strong modeling ability of normal data and alleviates the overconfidence\nproblem in coreset. Comprehensive experiments in various noise scenes\ndemonstrate that SoftPatch outperforms the state-of-the-art AD methods on the\nMVTecAD and BTAD benchmarks and is comparable to those methods under the\nsetting without noise.\n","authors":["Xi Jiang","Ying Chen","Qiang Nie","Yong Liu","Jianlin Liu","Bin-Bin Gao","Jun Liu","Chengjie Wang","Feng Zheng"],"pdf_url":"https://arxiv.org/pdf/2403.14233v1.pdf","comment":"36th Conference on Neural Information Processing Systems"},{"id":"http://arxiv.org/abs/2403.14227v1","updated":"2024-03-21T08:37:15Z","published":"2024-03-21T08:37:15Z","title":"PeerGPT: Probing the Roles of LLM-based Peer Agents as Team Moderators\n  and Participants in Children's Collaborative Learning","summary":"  In children's collaborative learning, effective peer conversations can\nsignificantly enhance the quality of children's collaborative interactions. The\nintegration of Large Language Model (LLM) agents into this setting explores\ntheir novel role as peers, assessing impacts as team moderators and\nparticipants. We invited two groups of participants to engage in a\ncollaborative learning workshop, where they discussed and proposed conceptual\nsolutions to a design problem. The peer conversation transcripts were analyzed\nusing thematic analysis. We discovered that peer agents, while managing\ndiscussions effectively as team moderators, sometimes have their instructions\ndisregarded. As participants, they foster children's creative thinking but may\nnot consistently provide timely feedback. These findings highlight potential\ndesign improvements and considerations for peer agents in both roles.\n","authors":["Jiawen Liu","Yuanyuan Yao","Pengcheng An","Qi Wang"],"pdf_url":"https://arxiv.org/pdf/2403.14227v1.pdf","comment":"To appear at CHI EA '24"},{"id":"http://arxiv.org/abs/2403.13372v2","updated":"2024-03-21T08:36:39Z","published":"2024-03-20T08:08:54Z","title":"LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models","summary":"  Efficient fine-tuning is vital for adapting large language models (LLMs) to\ndownstream tasks. However, it requires non-trivial efforts to implement these\nmethods on different models. We present LlamaFactory, a unified framework that\nintegrates a suite of cutting-edge efficient training methods. It allows users\nto flexibly customize the fine-tuning of 100+ LLMs without the need for coding\nthrough the built-in web UI LlamaBoard. We empirically validate the efficiency\nand effectiveness of our framework on language modeling and text generation\ntasks. It has been released at https://github.com/hiyouga/LLaMA-Factory and\nalready received over 13,000 stars and 1,600 forks.\n","authors":["Yaowei Zheng","Richong Zhang","Junhao Zhang","Yanhan Ye","Zheyan Luo","Yongqiang Ma"],"pdf_url":"https://arxiv.org/pdf/2403.13372v2.pdf","comment":"12 pages, preprint"},{"id":"http://arxiv.org/abs/2403.14203v1","updated":"2024-03-21T07:56:09Z","published":"2024-03-21T07:56:09Z","title":"Unsupervised Audio-Visual Segmentation with Modality Alignment","summary":"  Audio-Visual Segmentation (AVS) aims to identify, at the pixel level, the\nobject in a visual scene that produces a given sound. Current AVS methods rely\non costly fine-grained annotations of mask-audio pairs, making them impractical\nfor scalability. To address this, we introduce unsupervised AVS, eliminating\nthe need for such expensive annotation. To tackle this more challenging\nproblem, we propose an unsupervised learning method, named Modality\nCorrespondence Alignment (MoCA), which seamlessly integrates off-the-shelf\nfoundation models like DINO, SAM, and ImageBind. This approach leverages their\nknowledge complementarity and optimizes their joint usage for multi-modality\nassociation. Initially, we estimate positive and negative image pairs in the\nfeature space. For pixel-level association, we introduce an audio-visual\nadapter and a novel pixel matching aggregation strategy within the image-level\ncontrastive learning framework. This allows for a flexible connection between\nobject appearance and audio signal at the pixel level, with tolerance to\nimaging variations such as translation and rotation. Extensive experiments on\nthe AVSBench (single and multi-object splits) and AVSS datasets demonstrate\nthat our MoCA outperforms strongly designed baseline methods and approaches\nsupervised counterparts, particularly in complex scenarios with multiple\nauditory objects. Notably when comparing mIoU, MoCA achieves a substantial\nimprovement over baselines in both the AVSBench (S4: +17.24%; MS3: +67.64%) and\nAVSS (+19.23%) audio-visual segmentation challenges.\n","authors":["Swapnil Bhosale","Haosen Yang","Diptesh Kanojia","Jiangkang Deng","Xiatian Zhu"],"pdf_url":"https://arxiv.org/pdf/2403.14203v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14200v1","updated":"2024-03-21T07:50:45Z","published":"2024-03-21T07:50:45Z","title":"Debiasing surgeon: fantastic weights and how to find them","summary":"  Nowadays an ever-growing concerning phenomenon, the emergence of algorithmic\nbiases that can lead to unfair models, emerges. Several debiasing approaches\nhave been proposed in the realm of deep learning, employing more or less\nsophisticated approaches to discourage these models from massively employing\nthese biases. However, a question emerges: is this extra complexity really\nnecessary? Is a vanilla-trained model already embodying some ``unbiased\nsub-networks'' that can be used in isolation and propose a solution without\nrelying on the algorithmic biases? In this work, we show that such a\nsub-network typically exists, and can be extracted from a vanilla-trained model\nwithout requiring additional training. We further validate that such specific\narchitecture is incapable of learning a specific bias, suggesting that there\nare possible architectural countermeasures to the problem of biases in deep\nneural networks.\n","authors":["Rémi Nahon","Ivan Luiz De Moura Matos","Van-Tam Nguyen","Enzo Tartaglione"],"pdf_url":"https://arxiv.org/pdf/2403.14200v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15876v2","updated":"2024-03-21T07:38:51Z","published":"2023-11-27T14:49:06Z","title":"LMM-Assisted Breast Cancer Treatment Target Segmentation with\n  Consistency Embedding","summary":"  Recent advancements in Artificial Intelligence (AI) have profoundly\ninfluenced medical fields, by providing tools to reduce clinical workloads.\nHowever, most AI models are constrained to execute unimodal tasks, in stark\ncontrast to the comprehensive approaches utilized by medical professionals. To\naddress this, here we present RO-LMM, a multi-purpose large multimodal model\n(LMM) tailored for the field of radiation oncology. This model covers series of\ntasks within clinical workflow, adept at clinical report summarization,\nradiation treatment plan suggestion, and plan-guided target volume\nsegmentation. In particular, to perform consecutive clinical tasks, we further\npresent a novel Consistency Embedding Fine-Tuning (CEFTune) technique, which\nboosts LMM's robustness to noisy inputs while preserving the capability of\nhandling clean inputs, and transform this concept into LMM-driven segmentation\nframework as Consistency Embedding Segmentation~(CESEG). Experimental results\non multi-centre cohorts demonstrate our RO-LMM's promising performance for\nmultiple clinical tasks with generalization capabilities.\n","authors":["Kwanyoung Kim","Yujin Oh","Sangjoon Park","Hwa Kyung Byun","Jin Sung Kim","Yong Bae Kim","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2311.15876v2.pdf","comment":"30 pages, 16 table, 5 figures"},{"id":"http://arxiv.org/abs/2403.14188v1","updated":"2024-03-21T07:25:52Z","published":"2024-03-21T07:25:52Z","title":"Quantum-activated neural reservoirs on-chip open up large hardware\n  security models for resilient authentication","summary":"  Quantum artificial intelligence is a frontier of artificial intelligence\nresearch, pioneering quantum AI-powered circuits to address problems beyond the\nreach of deep learning with classical architectures. This work implements a\nlarge-scale quantum-activated recurrent neural network possessing more than 3\ntrillion hardware nodes/cm$^2$, originating from repeatable atomic-scale\nnucleation dynamics in an amorphous material integrated on-chip, controlled\nwith 0.07 nW electric power per readout channel. Compared to the\nbest-performing reservoirs currently reported, this implementation increases\nthe scale of the network by two orders of magnitude and reduces the power\nconsumption by six, reaching power efficiencies in the range of the human\nbrain, dissipating 0.2 nW/neuron. When interrogated by a classical input, the\nchip implements a large-scale hardware security model, enabling dictionary-free\nauthentication secure against statistical inference attacks, including AI's\npresent and future development, even for an adversary with a copy of all the\nclassical components available. Experimental tests report 99.6% reliability,\n100% user authentication accuracy, and an ideal 50% key uniqueness. Due to its\nquantum nature, the chip supports a bit density per feature size area three\ntimes higher than the best technology available, with the capacity to store\nmore than $2^{1104}$ keys in a footprint of 1 cm$^2$. Such a quantum-powered\nplatform could help counteract the emerging form of warfare led by the\ncybercrime industry in breaching authentication to target small to large-scale\nfacilities, from private users to intelligent energy grids.\n","authors":["Zhao He","Maxim S. Elizarov","Ning Li","Fei Xiang","Andrea Fratalocchi"],"pdf_url":"https://arxiv.org/pdf/2403.14188v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14186v1","updated":"2024-03-21T07:21:51Z","published":"2024-03-21T07:21:51Z","title":"StyleCineGAN: Landscape Cinemagraph Generation using a Pre-trained\n  StyleGAN","summary":"  We propose a method that can generate cinemagraphs automatically from a still\nlandscape image using a pre-trained StyleGAN. Inspired by the success of recent\nunconditional video generation, we leverage a powerful pre-trained image\ngenerator to synthesize high-quality cinemagraphs. Unlike previous approaches\nthat mainly utilize the latent space of a pre-trained StyleGAN, our approach\nutilizes its deep feature space for both GAN inversion and cinemagraph\ngeneration. Specifically, we propose multi-scale deep feature warping (MSDFW),\nwhich warps the intermediate features of a pre-trained StyleGAN at different\nresolutions. By using MSDFW, the generated cinemagraphs are of high resolution\nand exhibit plausible looping animation. We demonstrate the superiority of our\nmethod through user studies and quantitative comparisons with state-of-the-art\ncinemagraph generation methods and a video generation method that uses a\npre-trained StyleGAN.\n","authors":["Jongwoo Choi","Kwanggyoon Seo","Amirsaman Ashtari","Junyong Noh"],"pdf_url":"https://arxiv.org/pdf/2403.14186v1.pdf","comment":"Project website: https://jeolpyeoni.github.io/stylecinegan_project/"},{"id":"http://arxiv.org/abs/2310.02712v2","updated":"2024-03-21T07:20:35Z","published":"2023-10-04T10:28:38Z","title":"ED-NeRF: Efficient Text-Guided Editing of 3D Scene with Latent Space\n  NeRF","summary":"  Recently, there has been a significant advancement in text-to-image diffusion\nmodels, leading to groundbreaking performance in 2D image generation. These\nadvancements have been extended to 3D models, enabling the generation of novel\n3D objects from textual descriptions. This has evolved into NeRF editing\nmethods, which allow the manipulation of existing 3D objects through textual\nconditioning. However, existing NeRF editing techniques have faced limitations\nin their performance due to slow training speeds and the use of loss functions\nthat do not adequately consider editing. To address this, here we present a\nnovel 3D NeRF editing approach dubbed ED-NeRF by successfully embedding\nreal-world scenes into the latent space of the latent diffusion model (LDM)\nthrough a unique refinement layer. This approach enables us to obtain a NeRF\nbackbone that is not only faster but also more amenable to editing compared to\ntraditional image space NeRF editing. Furthermore, we propose an improved loss\nfunction tailored for editing by migrating the delta denoising score (DDS)\ndistillation loss, originally used in 2D image editing to the three-dimensional\ndomain. This novel loss function surpasses the well-known score distillation\nsampling (SDS) loss in terms of suitability for editing purposes. Our\nexperimental results demonstrate that ED-NeRF achieves faster editing speed\nwhile producing improved output quality compared to state-of-the-art 3D editing\nmodels.\n","authors":["Jangho Park","Gihyun Kwon","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2310.02712v2.pdf","comment":"ICLR 2024; Project Page: https://jhq1234.github.io/ed-nerf.github.io/"},{"id":"http://arxiv.org/abs/2306.09549v4","updated":"2024-03-21T07:16:03Z","published":"2023-06-15T23:39:07Z","title":"QH9: A Quantum Hamiltonian Prediction Benchmark for QM9 Molecules","summary":"  Supervised machine learning approaches have been increasingly used in\naccelerating electronic structure prediction as surrogates of first-principle\ncomputational methods, such as density functional theory (DFT). While numerous\nquantum chemistry datasets focus on chemical properties and atomic forces, the\nability to achieve accurate and efficient prediction of the Hamiltonian matrix\nis highly desired, as it is the most important and fundamental physical\nquantity that determines the quantum states of physical systems and chemical\nproperties. In this work, we generate a new Quantum Hamiltonian dataset, named\nas QH9, to provide precise Hamiltonian matrices for 999 or 2998 molecular\ndynamics trajectories and 130,831 stable molecular geometries, based on the QM9\ndataset. By designing benchmark tasks with various molecules, we show that\ncurrent machine learning models have the capacity to predict Hamiltonian\nmatrices for arbitrary molecules. Both the QH9 dataset and the baseline models\nare provided to the community through an open-source benchmark, which can be\nhighly valuable for developing machine learning methods and accelerating\nmolecular and materials design for scientific and technological applications.\nOur benchmark is publicly available at\nhttps://github.com/divelab/AIRS/tree/main/OpenDFT/QHBench.\n","authors":["Haiyang Yu","Meng Liu","Youzhi Luo","Alex Strasser","Xiaofeng Qian","Xiaoning Qian","Shuiwang Ji"],"pdf_url":"https://arxiv.org/pdf/2306.09549v4.pdf","comment":"Accepted by NeurIPS 2023, Track on Datasets and Benchmarks"},{"id":"http://arxiv.org/abs/2403.14183v1","updated":"2024-03-21T07:15:37Z","published":"2024-03-21T07:15:37Z","title":"OTSeg: Multi-prompt Sinkhorn Attention for Zero-Shot Semantic\n  Segmentation","summary":"  The recent success of CLIP has demonstrated promising results in zero-shot\nsemantic segmentation by transferring muiltimodal knowledge to pixel-level\nclassification. However, leveraging pre-trained CLIP knowledge to closely align\ntext embeddings with pixel embeddings still has limitations in existing\napproaches. To address this issue, we propose OTSeg, a novel multimodal\nattention mechanism aimed at enhancing the potential of multiple text prompts\nfor matching associated pixel embeddings. We first propose Multi-Prompts\nSinkhorn (MPS) based on the Optimal Transport (OT) algorithm, which leads\nmultiple text prompts to selectively focus on various semantic features within\nimage pixels. Moreover, inspired by the success of Sinkformers in unimodal\nsettings, we introduce the extension of MPS, called Multi-Prompts Sinkhorn\nAttention (MPSA), which effectively replaces cross-attention mechanisms within\nTransformer framework in multimodal settings. Through extensive experiments, we\ndemonstrate that OTSeg achieves state-of-the-art (SOTA) performance with\nsignificant gains on Zero-Shot Semantic Segmentation (ZS3) tasks across three\nbenchmark datasets.\n","authors":["Kwanyoung Kim","Yujin Oh","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2403.14183v1.pdf","comment":"22 pages, 7 figures"},{"id":"http://arxiv.org/abs/2403.14163v1","updated":"2024-03-21T06:32:36Z","published":"2024-03-21T06:32:36Z","title":"Leveraging Large Language Model-based Room-Object Relationships\n  Knowledge for Enhancing Multimodal-Input Object Goal Navigation","summary":"  Object-goal navigation is a crucial engineering task for the community of\nembodied navigation; it involves navigating to an instance of a specified\nobject category within unseen environments. Although extensive investigations\nhave been conducted on both end-to-end and modular-based, data-driven\napproaches, fully enabling an agent to comprehend the environment through\nperceptual knowledge and perform object-goal navigation as efficiently as\nhumans remains a significant challenge. Recently, large language models have\nshown potential in this task, thanks to their powerful capabilities for\nknowledge extraction and integration. In this study, we propose a data-driven,\nmodular-based approach, trained on a dataset that incorporates common-sense\nknowledge of object-to-room relationships extracted from a large language\nmodel. We utilize the multi-channel Swin-Unet architecture to conduct\nmulti-task learning incorporating with multimodal inputs. The results in the\nHabitat simulator demonstrate that our framework outperforms the baseline by an\naverage of 10.6% in the efficiency metric, Success weighted by Path Length\n(SPL). The real-world demonstration shows that the proposed approach can\nefficiently conduct this task by traversing several rooms. For more details and\nreal-world demonstrations, please check our project webpage\n(https://sunleyuan.github.io/ObjectNav).\n","authors":["Leyuan Sun","Asako Kanezaki","Guillaume Caron","Yusuke Yoshiyasu"],"pdf_url":"https://arxiv.org/pdf/2403.14163v1.pdf","comment":"will soon submit to the Elsevier journal, Advanced Engineering\n  Informatics"},{"id":"http://arxiv.org/abs/2403.14156v1","updated":"2024-03-21T06:10:51Z","published":"2024-03-21T06:10:51Z","title":"Policy Mirror Descent with Lookahead","summary":"  Policy Mirror Descent (PMD) stands as a versatile algorithmic framework\nencompassing several seminal policy gradient algorithms such as natural policy\ngradient, with connections with state-of-the-art reinforcement learning (RL)\nalgorithms such as TRPO and PPO. PMD can be seen as a soft Policy Iteration\nalgorithm implementing regularized 1-step greedy policy improvement. However,\n1-step greedy policies might not be the best choice and recent remarkable\nempirical successes in RL such as AlphaGo and AlphaZero have demonstrated that\ngreedy approaches with respect to multiple steps outperform their 1-step\ncounterpart. In this work, we propose a new class of PMD algorithms called\n$h$-PMD which incorporates multi-step greedy policy improvement with lookahead\ndepth $h$ to the PMD update rule. To solve discounted infinite horizon Markov\nDecision Processes with discount factor $\\gamma$, we show that $h$-PMD which\ngeneralizes the standard PMD enjoys a faster dimension-free $\\gamma^h$-linear\nconvergence rate, contingent on the computation of multi-step greedy policies.\nWe propose an inexact version of $h$-PMD where lookahead action values are\nestimated. Under a generative model, we establish a sample complexity for\n$h$-PMD which improves over prior work. Finally, we extend our result to linear\nfunction approximation to scale to large state spaces. Under suitable\nassumptions, our sample complexity only involves dependence on the dimension of\nthe feature map space instead of the state space size.\n","authors":["Kimon Protopapas","Anas Barakat"],"pdf_url":"https://arxiv.org/pdf/2403.14156v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.03848v3","updated":"2024-03-21T05:58:10Z","published":"2024-02-06T09:50:08Z","title":"ANLS* -- A Universal Document Processing Metric for Generative Large\n  Language Models","summary":"  Traditionally, discriminative models have been the predominant choice for\ntasks like document classification and information extraction. These models\nmake predictions that fall into a limited number of predefined classes,\nfacilitating a binary true or false evaluation and enabling the direct\ncalculation of metrics such as the F1 score. However, recent advancements in\ngenerative large language models (GLLMs) have prompted a shift in the field due\nto their enhanced zero-shot capabilities, which eliminate the need for a\ndownstream dataset and computationally expensive fine-tuning. However,\nevaluating GLLMs presents a challenge as the binary true or false evaluation\nused for discriminative models is not applicable to the predictions made by\nGLLMs.\n  This paper introduces a new metric for generative models called ANLS* for\nevaluating a wide variety of tasks, including information extraction and\nclassification tasks. The ANLS* metric extends existing ANLS metrics as a\ndrop-in-replacement and is still compatible with previously reported ANLS\nscores. An evaluation of 7 different datasets, 6 different GLLMs and 3\ndifferent prompting methods using the ANLS* metric is also provided,\ndemonstrating the importance of the proposed metric.\n  We also benchmark a novel approach to generate prompts for documents, called\nSFT, against other prompting techniques such as LATIN. In 27 out of 35 cases,\nSFT outperforms other techniques and improves the state-of-the-art, sometimes\nby as much as $18$ percentage points.\n  Sources are available at https://github.com/deepopinion/anls_star_metric\n","authors":["David Peer","Philemon Schöpf","Volckmar Nebendahl","Alexander Rietzler","Sebastian Stabinger"],"pdf_url":"https://arxiv.org/pdf/2402.03848v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14151v1","updated":"2024-03-21T05:57:27Z","published":"2024-03-21T05:57:27Z","title":"Deep Learning for Trajectory Data Management and Mining: A Survey and\n  Beyond","summary":"  Trajectory computing is a pivotal domain encompassing trajectory data\nmanagement and mining, garnering widespread attention due to its crucial role\nin various practical applications such as location services, urban traffic, and\npublic safety. Traditional methods, focusing on simplistic spatio-temporal\nfeatures, face challenges of complex calculations, limited scalability, and\ninadequate adaptability to real-world complexities. In this paper, we present a\ncomprehensive review of the development and recent advances in deep learning\nfor trajectory computing (DL4Traj). We first define trajectory data and provide\na brief overview of widely-used deep learning models. Systematically, we\nexplore deep learning applications in trajectory management (pre-processing,\nstorage, analysis, and visualization) and mining (trajectory-related\nforecasting, trajectory-related recommendation, trajectory classification,\ntravel time estimation, anomaly detection, and mobility generation). Notably,\nwe encapsulate recent advancements in Large Language Models (LLMs) that hold\nthe potential to augment trajectory computing. Additionally, we summarize\napplication scenarios, public datasets, and toolkits. Finally, we outline\ncurrent challenges in DL4Traj research and propose future directions. Relevant\npapers and open-source resources have been collated and are continuously\nupdated at:\n\\href{https://github.com/yoshall/Awesome-Trajectory-Computing}{DL4Traj Repo}.\n","authors":["Wei Chen","Yuxuan Liang","Yuanshao Zhu","Yanchuan Chang","Kang Luo","Haomin Wen","Lei Li","Yanwei Yu","Qingsong Wen","Chao Chen","Kai Zheng","Yunjun Gao","Xiaofang Zhou","Yu Zheng"],"pdf_url":"https://arxiv.org/pdf/2403.14151v1.pdf","comment":"25 pages, 12 figures, 5 tables"},{"id":"http://arxiv.org/abs/2311.10678v2","updated":"2024-03-21T05:47:22Z","published":"2023-11-17T18:00:20Z","title":"Distilling and Retrieving Generalizable Knowledge for Robot Manipulation\n  via Language Corrections","summary":"  Today's robot policies exhibit subpar performance when faced with the\nchallenge of generalizing to novel environments. Human corrective feedback is a\ncrucial form of guidance to enable such generalization. However, adapting to\nand learning from online human corrections is a non-trivial endeavor: not only\ndo robots need to remember human feedback over time to retrieve the right\ninformation in new settings and reduce the intervention rate, but also they\nwould need to be able to respond to feedback that can be arbitrary corrections\nabout high-level human preferences to low-level adjustments to skill\nparameters. In this work, we present Distillation and Retrieval of Online\nCorrections (DROC), a large language model (LLM)-based system that can respond\nto arbitrary forms of language feedback, distill generalizable knowledge from\ncorrections, and retrieve relevant past experiences based on textual and visual\nsimilarity for improving performance in novel settings. DROC is able to respond\nto a sequence of online language corrections that address failures in both\nhigh-level task plans and low-level skill primitives. We demonstrate that DROC\neffectively distills the relevant information from the sequence of online\ncorrections in a knowledge base and retrieves that knowledge in settings with\nnew task or object instances. DROC outperforms other techniques that directly\ngenerate robot code via LLMs by using only half of the total number of\ncorrections needed in the first round and requires little to no corrections\nafter two iterations. We show further results, videos, prompts and code on\nhttps://sites.google.com/stanford.edu/droc .\n","authors":["Lihan Zha","Yuchen Cui","Li-Heng Lin","Minae Kwon","Montserrat Gonzalez Arenas","Andy Zeng","Fei Xia","Dorsa Sadigh"],"pdf_url":"https://arxiv.org/pdf/2311.10678v2.pdf","comment":"8 pages, 4 figures, videos and code links on website\n  https://sites.google.com/stanford.edu/droc"},{"id":"http://arxiv.org/abs/2403.14146v1","updated":"2024-03-21T05:42:17Z","published":"2024-03-21T05:42:17Z","title":"Evolving Benchmark Functions to Compare Evolutionary Algorithms via\n  Genetic Programming","summary":"  In this study, we use Genetic Programming (GP) to compose new optimization\nbenchmark functions. Optimization benchmarks have the important role of showing\nthe differences between evolutionary algorithms, making it possible for further\nanalysis and comparisons. We show that the benchmarks generated by GP are able\nto differentiate algorithms better than human-made benchmark functions. The\nfitness measure of the GP is the Wasserstein distance of the solutions found by\na pair of optimizers. Additionally, we use MAP-Elites to both enhance the\nsearch power of the GP and also illustrate how the difference between\noptimizers changes by various landscape features. Our approach provides a novel\nway to automate the design of benchmark functions and to compare evolutionary\nalgorithms.\n","authors":["Yifan He","Claus Aranha"],"pdf_url":"https://arxiv.org/pdf/2403.14146v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.09099v4","updated":"2024-03-21T05:33:23Z","published":"2024-02-14T11:20:09Z","title":"Exploring Neuron Interactions and Emergence in LLMs: From the\n  Multifractal Analysis Perspective","summary":"  Prior studies on the emergence in large models have primarily focused on how\nthe functional capabilities of large language models (LLMs) scale with model\nsize. Our research, however, transcends this traditional paradigm, aiming to\ndeepen our understanding of the emergence within LLMs by placing a special\nemphasis not just on the model size but more significantly on the complex\nbehavior of neuron interactions during the training process. By introducing the\nconcepts of \"self-organization\" and \"multifractal analysis,\" we explore how\nneuron interactions dynamically evolve during training, leading to \"emergence,\"\nmirroring the phenomenon in natural systems where simple micro-level\ninteractions give rise to complex macro-level behaviors. To quantitatively\nanalyze the continuously evolving interactions among neurons in large models\nduring training, we propose the Neuron-based Multifractal Analysis (NeuroMFA).\nUtilizing NeuroMFA, we conduct a comprehensive examination of the emergent\nbehavior in LLMs through the lens of both model size and training process,\npaving new avenues for research into the emergence in large models.\n","authors":["Xiongye Xiao","Chenyu Zhou","Heng Ping","Defu Cao","Yaxing Li","Yizhuo Zhou","Shixuan Li","Paul Bogdan"],"pdf_url":"https://arxiv.org/pdf/2402.09099v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01385v2","updated":"2024-03-21T04:16:58Z","published":"2023-02-02T19:45:50Z","title":"Hyper-parameter Tuning for Fair Classification without Sensitive\n  Attribute Access","summary":"  Fair machine learning methods seek to train models that balance model\nperformance across demographic subgroups defined over sensitive attributes like\nrace and gender. Although sensitive attributes are typically assumed to be\nknown during training, they may not be available in practice due to privacy and\nother logistical concerns. Recent work has sought to train fair models without\nsensitive attributes on training data. However, these methods need extensive\nhyper-parameter tuning to achieve good results, and hence assume that sensitive\nattributes are known on validation data. However, this assumption too might not\nbe practical. Here, we propose Antigone, a framework to train fair classifiers\nwithout access to sensitive attributes on either training or validation data.\nInstead, we generate pseudo sensitive attributes on the validation data by\ntraining a biased classifier and using the classifier's incorrectly (correctly)\nlabeled examples as proxies for minority (majority) groups. Since fairness\nmetrics like demographic parity, equal opportunity and subgroup accuracy can be\nestimated to within a proportionality constant even with noisy sensitive\nattribute information, we show theoretically and empirically that these proxy\nlabels can be used to maximize fairness under average accuracy constraints. Key\nto our results is a principled approach to select the hyper-parameters of the\nbiased classifier in a completely unsupervised fashion (meaning without access\nto ground truth sensitive attributes) that minimizes the gap between fairness\nestimated using noisy versus ground-truth sensitive labels.\n","authors":["Akshaj Kumar Veldanda","Ivan Brugere","Sanghamitra Dutta","Alan Mishler","Siddharth Garg"],"pdf_url":"https://arxiv.org/pdf/2302.01385v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14120v1","updated":"2024-03-21T04:15:56Z","published":"2024-03-21T04:15:56Z","title":"Advancing IIoT with Over-the-Air Federated Learning: The Role of\n  Iterative Magnitude Pruning","summary":"  The industrial Internet of Things (IIoT) under Industry 4.0 heralds an era of\ninterconnected smart devices where data-driven insights and machine learning\n(ML) fuse to revolutionize manufacturing. A noteworthy development in IIoT is\nthe integration of federated learning (FL), which addresses data privacy and\nsecurity among devices. FL enables edge sensors, also known as peripheral\nintelligence units (PIUs) to learn and adapt using their data locally, without\nexplicit sharing of confidential data, to facilitate a collaborative yet\nconfidential learning process. However, the lower memory footprint and\ncomputational power of PIUs inherently require deep neural network (DNN) models\nthat have a very compact size. Model compression techniques such as pruning can\nbe used to reduce the size of DNN models by removing unnecessary connections\nthat have little impact on the model's performance, thus making the models more\nsuitable for the limited resources of PIUs. Targeting the notion of compact yet\nrobust DNN models, we propose the integration of iterative magnitude pruning\n(IMP) of the DNN model being trained in an over-the-air FL (OTA-FL) environment\nfor IIoT. We provide a tutorial overview and also present a case study of the\neffectiveness of IMP in OTA-FL for an IIoT environment. Finally, we present\nfuture directions for enhancing and optimizing these deep compression\ntechniques further, aiming to push the boundaries of IIoT capabilities in\nacquiring compact yet robust and high-performing DNN models.\n","authors":["Fazal Muhammad Ali Khan","Hatem Abou-Zeid","Aryan Kaushik","Syed Ali Hassan"],"pdf_url":"https://arxiv.org/pdf/2403.14120v1.pdf","comment":"6 pages, 6 figures"},{"id":"http://arxiv.org/abs/2403.14119v1","updated":"2024-03-21T04:08:29Z","published":"2024-03-21T04:08:29Z","title":"C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via\n  Text Feature Dispersion","summary":"  In deep learning, test-time adaptation has gained attention as a method for\nmodel fine-tuning without the need for labeled data. A prime exemplification is\nthe recently proposed test-time prompt tuning for large-scale vision-language\nmodels such as CLIP. Unfortunately, these prompts have been mainly developed to\nimprove accuracy, overlooking the importance of calibration-a crucial aspect\nfor quantifying prediction uncertainty. However, traditional calibration\nmethods rely on substantial amounts of labeled data, making them impractical\nfor test-time scenarios. To this end, this paper explores calibration during\ntest-time prompt tuning by leveraging the inherent properties of CLIP. Through\na series of observations, we find that the prompt choice significantly affects\nthe calibration in CLIP, where the prompts leading to higher text feature\ndispersion result in better-calibrated predictions. Introducing the Average\nText Feature Dispersion (ATFD), we establish its relationship with calibration\nerror and present a novel method, Calibrated Test-time Prompt Tuning (C-TPT),\nfor optimizing prompts during test-time with enhanced calibration. Through\nextensive experiments on different CLIP architectures and datasets, we show\nthat C-TPT can effectively improve the calibration of test-time prompt tuning\nwithout needing labeled data.\n","authors":["Hee Suk Yoon","Eunseop Yoon","Joshua Tian Jin Tee","Mark Hasegawa-Johnson","Yingzhen Li","Chang D. Yoo"],"pdf_url":"https://arxiv.org/pdf/2403.14119v1.pdf","comment":"ICLR 2024"},{"id":"http://arxiv.org/abs/2312.08977v2","updated":"2024-03-21T04:04:25Z","published":"2023-12-14T14:26:57Z","title":"Weighted Ensemble Models Are Strong Continual Learners","summary":"  In this work, we study the problem of continual learning (CL) where the goal\nis to learn a model on a sequence of tasks, such that the data from the\nprevious tasks becomes unavailable while learning on the current task data. CL\nis essentially a balancing act between being able to learn on the new task\n(i.e., plasticity) and maintaining the performance on the previously learned\nconcepts (i.e., stability). Intending to address the stability-plasticity\ntrade-off, we propose to perform weight-ensembling of the model parameters of\nthe previous and current tasks. This weighted-ensembled model, which we call\nContinual Model Averaging (or CoMA), attains high accuracy on the current task\nby leveraging plasticity, while not deviating too far from the previous weight\nconfiguration, ensuring stability. We also propose an improved variant of CoMA,\nnamed Continual Fisher-weighted Model Averaging (or CoFiMA), that selectively\nweighs each parameter in the weights ensemble by leveraging the Fisher\ninformation of the weights of the model. Both variants are conceptually simple,\neasy to implement, and effective in attaining state-of-the-art performance on\nseveral standard CL benchmarks. Code is available at:\nhttps://github.com/IemProg/CoFiMA.\n","authors":["Imad Eddine Marouf","Subhankar Roy","Enzo Tartaglione","Stéphane Lathuilière"],"pdf_url":"https://arxiv.org/pdf/2312.08977v2.pdf","comment":"Code: https://github.com/IemProg/CoFiMA"},{"id":"http://arxiv.org/abs/2403.14110v1","updated":"2024-03-21T03:42:39Z","published":"2024-03-21T03:42:39Z","title":"Heuristic Algorithm-based Action Masking Reinforcement Learning\n  (HAAM-RL) with Ensemble Inference Method","summary":"  This paper presents a novel reinforcement learning (RL) approach called\nHAAM-RL (Heuristic Algorithm-based Action Masking Reinforcement Learning) for\noptimizing the color batching re-sequencing problem in automobile painting\nprocesses. The existing heuristic algorithms have limitations in adequately\nreflecting real-world constraints and accurately predicting logistics\nperformance. Our methodology incorporates several key techniques including a\ntailored Markov Decision Process (MDP) formulation, reward setting including\nPotential-Based Reward Shaping, action masking using heuristic algorithms\n(HAAM-RL), and an ensemble inference method that combines multiple RL models.\nThe RL agent is trained and evaluated using FlexSim, a commercial 3D simulation\nsoftware, integrated with our RL MLOps platform BakingSoDA. Experimental\nresults across 30 scenarios demonstrate that HAAM-RL with an ensemble inference\nmethod achieves a 16.25% performance improvement over the conventional\nheuristic algorithm, with stable and consistent results. The proposed approach\nexhibits superior performance and generalization capability, indicating its\neffectiveness in optimizing complex manufacturing processes. The study also\ndiscusses future research directions, including alternative state\nrepresentations, incorporating model-based RL methods, and integrating\nadditional real-world constraints.\n","authors":["Kyuwon Choi","Cheolkyun Rho","Taeyoun Kim","Daewoo Choi"],"pdf_url":"https://arxiv.org/pdf/2403.14110v1.pdf","comment":"7 pages, 8 figures"},{"id":"http://arxiv.org/abs/2403.14102v1","updated":"2024-03-21T03:25:49Z","published":"2024-03-21T03:25:49Z","title":"DouRN: Improving DouZero by Residual Neural Networks","summary":"  Deep reinforcement learning has made significant progress in games with\nimperfect information, but its performance in the card game Doudizhu (Chinese\nPoker/Fight the Landlord) remains unsatisfactory. Doudizhu is different from\nconventional games as it involves three players and combines elements of\ncooperation and confrontation, resulting in a large state and action space. In\n2021, a Doudizhu program called DouZero\\cite{zha2021douzero} surpassed previous\nmodels without prior knowledge by utilizing traditional Monte Carlo methods and\nmultilayer perceptrons. Building on this work, our study incorporates residual\nnetworks into the model, explores different architectural designs, and conducts\nmulti-role testing. Our findings demonstrate that this model significantly\nimproves the winning rate within the same training time. Additionally, we\nintroduce a call scoring system to assist the agent in deciding whether to\nbecome a landlord. With these enhancements, our model consistently outperforms\nthe existing version of DouZero and even experienced human players.\n\\footnote{The source code is available at\n\\url{https://github.com/Yingchaol/Douzero_Resnet.git.}\n","authors":["Yiquan Chen","Yingchao Lyu","Di Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.14102v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14100v1","updated":"2024-03-21T03:23:34Z","published":"2024-03-21T03:23:34Z","title":"Causal knowledge engineering: A case study from COVID-19","summary":"  COVID-19 appeared abruptly in early 2020, requiring a rapid response amid a\ncontext of great uncertainty. Good quality data and knowledge was initially\nlacking, and many early models had to be developed with causal assumptions and\nestimations built in to supplement limited data, often with no reliable\napproach for identifying, validating and documenting these causal assumptions.\nOur team embarked on a knowledge engineering process to develop a causal\nknowledge base consisting of several causal BNs for diverse aspects of\nCOVID-19. The unique challenges of the setting lead to experiments with the\nelicitation approach, and what emerged was a knowledge engineering method we\ncall Causal Knowledge Engineering (CKE). The CKE provides a structured approach\nfor building a causal knowledge base that can support the development of a\nvariety of application-specific models. Here we describe the CKE method, and\nuse our COVID-19 work as a case study to provide a detailed discussion and\nanalysis of the method.\n","authors":["Steven Mascaro","Yue Wu","Ross Pearson","Owen Woodberry","Jessica Ramsay","Tom Snelling","Ann E. Nicholson"],"pdf_url":"https://arxiv.org/pdf/2403.14100v1.pdf","comment":"22 pages (plus 19 pages in appendices), 9 figures, submitted for\n  review"},{"id":"http://arxiv.org/abs/2309.06255v3","updated":"2024-03-21T03:21:24Z","published":"2023-09-12T14:16:34Z","title":"Enhancing Multimodal Cooperation via Fine-grained Modality Valuation","summary":"  One primary topic of multimodal learning is to jointly incorporate\nheterogeneous information from different modalities. However, most models often\nsuffer from unsatisfactory multimodal cooperation, which cannot jointly utilize\nall modalities well. Some methods are proposed to identify and enhance the\nworse learnt modality, but they are often hard to provide the fine-grained\nobservation of multimodal cooperation at sample-level with theoretical support.\nHence, it is essential to reasonably observe and improve the fine-grained\ncooperation between modalities, especially when facing realistic scenarios\nwhere the modality discrepancy could vary across different samples. To this\nend, we introduce a sample-level modality valuation metric to evaluate the\ncontribution of each modality for each sample. Via modality valuation, we\nobserve that modality discrepancy indeed could be different at sample-level,\nbeyond the global contribution discrepancy at dataset-level. We further analyze\nthis issue and improve cooperation between modalities at sample-level by\nenhancing the discriminative ability of low-contributing modalities in a\ntargeted manner. Overall, our methods reasonably observe the fine-grained\nuni-modal contribution and achieve considerable improvement. The source code\nand dataset are available at\n\\url{https://github.com/GeWu-Lab/Valuate-and-Enhance-Multimodal-Cooperation}.\n","authors":["Yake Wei","Ruoxuan Feng","Zihe Wang","Di Hu"],"pdf_url":"https://arxiv.org/pdf/2309.06255v3.pdf","comment":"Accepted by CVPR 2024"},{"id":"http://arxiv.org/abs/2403.13257v2","updated":"2024-03-21T03:13:30Z","published":"2024-03-20T02:38:01Z","title":"Arcee's MergeKit: A Toolkit for Merging Large Language Models","summary":"  The rapid expansion of the open-source language model landscape presents an\nopportunity to merge the competencies of these model checkpoints by combining\ntheir parameters. Advances in transfer learning, the process of fine-tuning\npretrained models for specific tasks, has resulted in the development of vast\namounts of task-specific models, typically specialized in individual tasks and\nunable to utilize each other's strengths. Model merging facilitates the\ncreation of multitask models without the need for additional training, offering\na promising avenue for enhancing model performance and versatility. By\npreserving the intrinsic capabilities of the original models, model merging\naddresses complex challenges in AI - including the difficulties of catastrophic\nforgetting and multitask learning. To support this expanding area of research,\nwe introduce MergeKit, a comprehensive, open-source library designed to\nfacilitate the application of model merging strategies. MergeKit offers an\nextensible framework to efficiently merge models on any hardware, providing\nutility to researchers and practitioners. To date, thousands of models have\nbeen merged by the open-source community, leading to the creation of some of\nthe worlds most powerful open-source model checkpoints, as assessed by the Open\nLLM Leaderboard. The library is accessible at\nhttps://github.com/arcee-ai/MergeKit.\n","authors":["Charles Goddard","Shamane Siriwardhana","Malikeh Ehghaghi","Luke Meyers","Vlad Karpukhin","Brian Benedict","Mark McQuade","Jacob Solawetz"],"pdf_url":"https://arxiv.org/pdf/2403.13257v2.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2403.14092v1","updated":"2024-03-21T02:59:56Z","published":"2024-03-21T02:59:56Z","title":"Carbon Footprint Reduction for Sustainable Data Centers in Real-Time","summary":"  As machine learning workloads significantly increase energy consumption,\nsustainable data centers with low carbon emissions are becoming a top priority\nfor governments and corporations worldwide. This requires a paradigm shift in\noptimizing power consumption in cooling and IT loads, shifting flexible loads\nbased on the availability of renewable energy in the power grid, and leveraging\nbattery storage from the uninterrupted power supply in data centers, using\ncollaborative agents. The complex association between these optimization\nstrategies and their dependencies on variable external factors like weather and\nthe power grid carbon intensity makes this a hard problem. Currently, a\nreal-time controller to optimize all these goals simultaneously in a dynamic\nreal-world setting is lacking. We propose a Data Center Carbon Footprint\nReduction (DC-CFR) multi-agent Reinforcement Learning (MARL) framework that\noptimizes data centers for the multiple objectives of carbon footprint\nreduction, energy consumption, and energy cost. The results show that the\nDC-CFR MARL agents effectively resolved the complex interdependencies in\noptimizing cooling, load shifting, and energy storage in real-time for various\nlocations under real-world dynamic weather and grid carbon intensity\nconditions. DC-CFR significantly outperformed the industry standard ASHRAE\ncontroller with a considerable reduction in carbon emissions (14.5%), energy\nusage (14.4%), and energy cost (13.7%) when evaluated over one year across\nmultiple geographical regions.\n","authors":["Soumyendu Sarkar","Avisek Naug","Ricardo Luna","Antonio Guillen","Vineet Gundecha","Sahand Ghorbanpour","Sajad Mousavi","Dejan Markovikj","Ashwin Ramesh Babu"],"pdf_url":"https://arxiv.org/pdf/2403.14092v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14077v1","updated":"2024-03-21T01:57:30Z","published":"2024-03-21T01:57:30Z","title":"Can ChatGPT Detect DeepFakes? A Study of Using Multimodal Large Language\n  Models for Media Forensics","summary":"  DeepFakes, which refer to AI-generated media content, have become an\nincreasing concern due to their use as a means for disinformation. Detecting\nDeepFakes is currently solved with programmed machine learning algorithms. In\nthis work, we investigate the capabilities of multimodal large language models\n(LLMs) in DeepFake detection. We conducted qualitative and quantitative\nexperiments to demonstrate multimodal LLMs and show that they can expose\nAI-generated images through careful experimental design and prompt engineering.\nThis is interesting, considering that LLMs are not inherently tailored for\nmedia forensic tasks, and the process does not require programming. We discuss\nthe limitations of multimodal LLMs for these tasks and suggest possible\nimprovements.\n","authors":["Shan Jia","Reilin Lyu","Kangran Zhao","Yize Chen","Zhiyuan Yan","Yan Ju","Chuanbo Hu","Xin Li","Baoyuan Wu","Siwei Lyu"],"pdf_url":"https://arxiv.org/pdf/2403.14077v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.15662v3","updated":"2024-03-21T01:42:43Z","published":"2023-03-28T01:07:38Z","title":"ChatGPT4PCG Competition: Character-like Level Generation for Science\n  Birds","summary":"  This paper presents the first ChatGPT4PCG Competition at the 2023 IEEE\nConference on Games. The objective of this competition is for participants to\ncreate effective prompts for ChatGPT--enabling it to generate Science Birds\nlevels with high stability and character-like qualities--fully using their\ncreativity as well as prompt engineering skills. ChatGPT is a conversational\nagent developed by OpenAI. Science Birds is selected as the competition\nplatform because designing an Angry Birds-like level is not a trivial task due\nto the in-game gravity; the quality of the levels is determined by their\nstability. To lower the entry barrier to the competition, we limit the task to\nthe generation of capitalized English alphabetical characters. We also allow\nonly a single prompt to be used for generating all the characters. Here, the\nquality of the generated levels is determined by their stability and similarity\nto the given characters. A sample prompt is provided to participants for their\nreference. An experiment is conducted to determine the effectiveness of several\nmodified versions of this sample prompt on level stability and similarity by\ntesting them on several characters. To the best of our knowledge, we believe\nthat ChatGPT4PCG is the first competition of its kind and hope to inspire\nenthusiasm for prompt engineering in procedural content generation.\n","authors":["Pittawat Taveekitworachai","Febri Abdullah","Mury F. Dewantoro","Ruck Thawonmas","Julian Togelius","Jochen Renz"],"pdf_url":"https://arxiv.org/pdf/2303.15662v3.pdf","comment":"This paper accepted for presentation at IEEE CoG 2023 is made\n  available for participants of ChatGPT4PCG Competition\n  (https://chatgpt4pcg.github.io/) and readers interested in relevant areas. In\n  this PDF version, the affiliation symbol of Julian Togelius has been revised"},{"id":"http://arxiv.org/abs/2211.13854v4","updated":"2024-03-21T00:53:19Z","published":"2022-11-25T01:37:48Z","title":"ComCLIP: Training-Free Compositional Image and Text Matching","summary":"  Contrastive Language-Image Pretraining (CLIP) has demonstrated great\nzero-shot performance for matching images and text. However, it is still\nchallenging to adapt vision-lanaguage pretrained models like CLIP to\ncompositional image and text matching -- a more challenging image and text\nmatching task requiring the model understanding of compositional word concepts\nand visual components. Towards better compositional generalization in zero-shot\nimage and text matching, in this paper, we study the problem from a causal\nperspective: the erroneous semantics of individual entities are essentially\nconfounders that cause the matching failure. Therefore, we propose a novel\n\\textbf{\\textit{training-free}} compositional CLIP model (ComCLIP). ComCLIP\ndisentangles input images into subjects, objects, and action sub-images and\ncomposes CLIP's vision encoder and text encoder to perform evolving matching\nover compositional text embedding and sub-image embeddings. In this way,\nComCLIP can mitigate spurious correlations introduced by the pretrained CLIP\nmodels and dynamically evaluate the importance of each component. Experiments\non four compositional image-text matching datasets: SVO, ComVG, Winoground, and\nVL-checklist, and two general image-text retrieval datasets: Flick30K, and\nMSCOCO demonstrate the effectiveness of our plug-and-play method, which boosts\nthe \\textbf{\\textit{zero-shot}} inference ability of CLIP, SLIP, and BLIP2 even\nwithout further training or fine-tuning. Our codes can be found at\nhttps://github.com/eric-ai-lab/ComCLIP.\n","authors":["Kenan Jiang","Xuehai He","Ruize Xu","Xin Eric Wang"],"pdf_url":"https://arxiv.org/pdf/2211.13854v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.05584v2","updated":"2024-03-21T00:42:39Z","published":"2024-01-10T23:30:48Z","title":"FourCastNeXt: Optimizing FourCastNet Training for Limited Compute","summary":"  FourCastNeXt is an optimization of FourCastNet - a global machine learning\nweather forecasting model - that performs with a comparable level of accuracy\nand can be trained using around 5% of the original FourCastNet computational\nrequirements. This technical report presents strategies for model optimization\nthat maintain similar performance as measured by the root-mean-square error\n(RMSE) of the modelled variables. By providing a model with very low\ncomparative training costs, FourCastNeXt makes Neural Earth System Modelling\nmuch more accessible to researchers looking to conduct training experiments and\nablation studies. FourCastNeXt training and inference code are available at\nhttps://github.com/nci/FourCastNeXt\n","authors":["Edison Guo","Maruf Ahmed","Yue Sun","Rui Yang","Harrison Cook","Tennessee Leeuwenburg","Ben Evans"],"pdf_url":"https://arxiv.org/pdf/2401.05584v2.pdf","comment":"Major revision. All prior content (text, figures, table) has been\n  updated. Additionally, new text, tables and figures have been added. Updated\n  title. Updated author list"},{"id":"http://arxiv.org/abs/2308.05374v2","updated":"2024-03-21T00:21:14Z","published":"2023-08-10T06:43:44Z","title":"Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language\n  Models' Alignment","summary":"  Ensuring alignment, which refers to making models behave in accordance with\nhuman intentions [1,2], has become a critical task before deploying large\nlanguage models (LLMs) in real-world applications. For instance, OpenAI devoted\nsix months to iteratively aligning GPT-4 before its release [3]. However, a\nmajor challenge faced by practitioners is the lack of clear guidance on\nevaluating whether LLM outputs align with social norms, values, and\nregulations. This obstacle hinders systematic iteration and deployment of LLMs.\nTo address this issue, this paper presents a comprehensive survey of key\ndimensions that are crucial to consider when assessing LLM trustworthiness. The\nsurvey covers seven major categories of LLM trustworthiness: reliability,\nsafety, fairness, resistance to misuse, explainability and reasoning, adherence\nto social norms, and robustness. Each major category is further divided into\nseveral sub-categories, resulting in a total of 29 sub-categories.\nAdditionally, a subset of 8 sub-categories is selected for further\ninvestigation, where corresponding measurement studies are designed and\nconducted on several widely-used LLMs. The measurement results indicate that,\nin general, more aligned models tend to perform better in terms of overall\ntrustworthiness. However, the effectiveness of alignment varies across the\ndifferent trustworthiness categories considered. This highlights the importance\nof conducting more fine-grained analyses, testing, and making continuous\nimprovements on LLM alignment. By shedding light on these key dimensions of LLM\ntrustworthiness, this paper aims to provide valuable insights and guidance to\npractitioners in the field. Understanding and addressing these concerns will be\ncrucial in achieving reliable and ethically sound deployment of LLMs in various\napplications.\n","authors":["Yang Liu","Yuanshun Yao","Jean-Francois Ton","Xiaoying Zhang","Ruocheng Guo","Hao Cheng","Yegor Klochkov","Muhammad Faaiz Taufiq","Hang Li"],"pdf_url":"https://arxiv.org/pdf/2308.05374v2.pdf","comment":"Fixed several typos"},{"id":"http://arxiv.org/abs/2403.14049v1","updated":"2024-03-21T00:14:53Z","published":"2024-03-21T00:14:53Z","title":"A Roadmap Towards Automated and Regulated Robotic Systems","summary":"  The rapid development of generative technology opens up possibility for\nhigher level of automation, and artificial intelligence (AI) embodiment in\nrobotic systems is imminent. However, due to the blackbox nature of the\ngenerative technology, the generation of the knowledge and workflow scheme is\nuncontrolled, especially in a dynamic environment and a complex scene. This\nposes challenges to regulations in safety-demanding applications such as\nmedical scenes. We argue that the unregulated generative processes from AI is\nfitted for low level end tasks, but intervention in the form of manual or\nautomated regulation should happen post-workflow-generation and\npre-robotic-execution. To address this, we propose a roadmap that can lead to\nfully automated and regulated robotic systems. In this paradigm, the high level\npolicies are generated as structured graph data, enabling regulatory oversight\nand reusability, while the code base for lower level tasks is generated by\ngenerative models. Our approach aims the transitioning from expert knowledge to\nregulated action, akin to the iterative processes of study, practice, scrutiny,\nand execution in human tasks. We identify the generative and deterministic\nprocesses in a design cycle, where generative processes serve as a text-based\nworld simulator and the deterministic processes generate the executable system.\nWe propose State Machine Seralization Language (SMSL) to be the conversion\npoint between text simulator and executable workflow control. From there, we\nanalyze the modules involved based on the current literature, and discuss human\nin the loop. As a roadmap, this work identifies the current possible\nimplementation and future work. This work does not provide an implemented\nsystem but envisions to inspire the researchers working on the direction in the\nroadmap. We implement the SMSL and D-SFO paradigm that serve as the starting\npoint of the roadmap.\n","authors":["Yihao Liu","Mehran Armand"],"pdf_url":"https://arxiv.org/pdf/2403.14049v1.pdf","comment":"17 pages, 9 figures"},{"id":"http://arxiv.org/abs/2311.01623v2","updated":"2024-03-21T00:05:23Z","published":"2023-11-03T16:58:10Z","title":"VQPy: An Object-Oriented Approach to Modern Video Analytics","summary":"  Video analytics is widely used in contemporary systems and services. At the\nforefront of video analytics are video queries that users develop to find\nobjects of particular interest. Building upon the insight that video objects\n(e.g., human, animals, cars, etc.), the center of video analytics, are similar\nin spirit to objects modeled by traditional object-oriented languages, we\npropose to develop an object-oriented approach to video analytics. This\napproach, named VQPy, consists of a frontend$\\unicode{x2015}$a Python variant\nwith constructs that make it easy for users to express video objects and their\ninteractions$\\unicode{x2015}$as well as an extensible backend that can\nautomatically construct and optimize pipelines based on video objects. We have\nimplemented and open-sourced VQPy, which has been productized in Cisco as part\nof its DeepVision framework.\n","authors":["Shan Yu","Zhenting Zhu","Yu Chen","Hanchen Xu","Pengzhan Zhao","Yang Wang","Arthi Padmanabhan","Hugo Latapie","Harry Xu"],"pdf_url":"https://arxiv.org/pdf/2311.01623v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.16828v2","updated":"2024-03-21T17:56:19Z","published":"2023-10-25T17:57:07Z","title":"TD-MPC2: Scalable, Robust World Models for Continuous Control","summary":"  TD-MPC is a model-based reinforcement learning (RL) algorithm that performs\nlocal trajectory optimization in the latent space of a learned implicit\n(decoder-free) world model. In this work, we present TD-MPC2: a series of\nimprovements upon the TD-MPC algorithm. We demonstrate that TD-MPC2 improves\nsignificantly over baselines across 104 online RL tasks spanning 4 diverse task\ndomains, achieving consistently strong results with a single set of\nhyperparameters. We further show that agent capabilities increase with model\nand data size, and successfully train a single 317M parameter agent to perform\n80 tasks across multiple task domains, embodiments, and action spaces. We\nconclude with an account of lessons, opportunities, and risks associated with\nlarge TD-MPC2 agents. Explore videos, models, data, code, and more at\nhttps://tdmpc2.com\n","authors":["Nicklas Hansen","Hao Su","Xiaolong Wang"],"pdf_url":"https://arxiv.org/pdf/2310.16828v2.pdf","comment":"ICLR 2024. Explore videos, models, data, code, and more at\n  https://tdmpc2.com"},{"id":"http://arxiv.org/abs/2403.14606v1","updated":"2024-03-21T17:55:16Z","published":"2024-03-21T17:55:16Z","title":"The Elements of Differentiable Programming","summary":"  Artificial intelligence has recently experienced remarkable advances, fueled\nby large models, vast datasets, accelerated hardware, and, last but not least,\nthe transformative power of differentiable programming. This new programming\nparadigm enables end-to-end differentiation of complex computer programs\n(including those with control flows and data structures), making gradient-based\noptimization of program parameters possible. As an emerging paradigm,\ndifferentiable programming builds upon several areas of computer science and\napplied mathematics, including automatic differentiation, graphical models,\noptimization and statistics. This book presents a comprehensive review of the\nfundamental concepts useful for differentiable programming. We adopt two main\nperspectives, that of optimization and that of probability, with clear\nanalogies between the two. Differentiable programming is not merely the\ndifferentiation of programs, but also the thoughtful design of programs\nintended for differentiation. By making programs differentiable, we inherently\nintroduce probability distributions over their execution, providing a means to\nquantify the uncertainty associated with program outputs.\n","authors":["Mathieu Blondel","Vincent Roulet"],"pdf_url":"https://arxiv.org/pdf/2403.14606v1.pdf","comment":"Draft version 1"},{"id":"http://arxiv.org/abs/2305.00969v7","updated":"2024-03-21T17:52:22Z","published":"2023-05-01T17:56:32Z","title":"CryCeleb: A Speaker Verification Dataset Based on Infant Cry Sounds","summary":"  This paper describes the Ubenwa CryCeleb dataset - a labeled collection of\ninfant cries - and the accompanying CryCeleb 2023 task, which is a public\nspeaker verification challenge based on cry sounds. We released more than 6\nhours of manually segmented cry sounds from 786 newborns for academic use,\naiming to encourage research in infant cry analysis. The inaugural public\ncompetition attracted 59 participants, 11 of whom improved the baseline\nperformance. The top-performing system achieved a significant improvement\nscoring 25.8% equal error rate, which is still far from the performance of\nstate-of-the-art adult speaker verification systems. Therefore, we believe\nthere is room for further research on this dataset, potentially extending\nbeyond the verification task.\n","authors":["David Budaghyan","Charles C. Onu","Arsenii Gorin","Cem Subakan","Doina Precup"],"pdf_url":"https://arxiv.org/pdf/2305.00969v7.pdf","comment":"ICASSP 2024"},{"id":"http://arxiv.org/abs/2403.14578v1","updated":"2024-03-21T17:30:59Z","published":"2024-03-21T17:30:59Z","title":"RAmBLA: A Framework for Evaluating the Reliability of LLMs as Assistants\n  in the Biomedical Domain","summary":"  Large Language Models (LLMs) increasingly support applications in a wide\nrange of domains, some with potential high societal impact such as biomedicine,\nyet their reliability in realistic use cases is under-researched. In this work\nwe introduce the Reliability AssesMent for Biomedical LLM Assistants (RAmBLA)\nframework and evaluate whether four state-of-the-art foundation LLMs can serve\nas reliable assistants in the biomedical domain. We identify prompt robustness,\nhigh recall, and a lack of hallucinations as necessary criteria for this use\ncase. We design shortform tasks and tasks requiring LLM freeform responses\nmimicking real-world user interactions. We evaluate LLM performance using\nsemantic similarity with a ground truth response, through an evaluator LLM.\n","authors":["William James Bolton","Rafael Poyiadzi","Edward R. Morrell","Gabriela van Bergen Gonzalez Bueno","Lea Goetz"],"pdf_url":"https://arxiv.org/pdf/2403.14578v1.pdf","comment":"Published at ICLR 2024 Workshop on Reliable and Responsible\n  Foundation Models"},{"id":"http://arxiv.org/abs/2403.14377v1","updated":"2024-03-21T13:09:23Z","published":"2024-03-21T13:09:23Z","title":"Knowledge-Enhanced Recommendation with User-Centric Subgraph Network","summary":"  Recommendation systems, as widely implemented nowadays on various platforms,\nrecommend relevant items to users based on their preferences. The classical\nmethods which rely on user-item interaction matrices has limitations,\nespecially in scenarios where there is a lack of interaction data for new\nitems. Knowledge graph (KG)-based recommendation systems have emerged as a\npromising solution. However, most KG-based methods adopt node embeddings, which\ndo not provide personalized recommendations for different users and cannot\ngeneralize well to the new items. To address these limitations, we propose\nKnowledge-enhanced User-Centric subgraph Network (KUCNet), a subgraph learning\napproach with graph neural network (GNN) for effective recommendation. KUCNet\nconstructs a U-I subgraph for each user-item pair that captures both the\nhistorical information of user-item interactions and the side information\nprovided in KG. An attention-based GNN is designed to encode the U-I subgraphs\nfor recommendation. Considering efficiency, the pruned user-centric computation\ngraph is further introduced such that multiple U-I subgraphs can be\nsimultaneously computed and that the size can be pruned by Personalized\nPageRank. Our proposed method achieves accurate, efficient, and interpretable\nrecommendations especially for new items. Experimental results demonstrate the\nsuperiority of KUCNet over state-of-the-art KG-based and collaborative\nfiltering (CF)-based methods.\n","authors":["Guangyi Liu","Quanming Yao","Yongqi Zhang","Lei Chen"],"pdf_url":"https://arxiv.org/pdf/2403.14377v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14888v1","updated":"2024-03-21T23:48:21Z","published":"2024-03-21T23:48:21Z","title":"AutoRE: Document-Level Relation Extraction with Large Language Models","summary":"  Large Language Models (LLMs) have demonstrated exceptional abilities in\ncomprehending and generating text, motivating numerous researchers to utilize\nthem for Information Extraction (IE) purposes, including Relation Extraction\n(RE). Nonetheless, most existing methods are predominantly designed for\nSentence-level Relation Extraction (SentRE) tasks, which typically encompass a\nrestricted set of relations and triplet facts within a single sentence.\nFurthermore, certain approaches resort to treating relations as candidate\nchoices integrated into prompt templates, leading to inefficient processing and\nsuboptimal performance when tackling Document-Level Relation Extraction (DocRE)\ntasks, which entail handling multiple relations and triplet facts distributed\nacross a given document, posing distinct challenges. To overcome these\nlimitations, we introduce AutoRE, an end-to-end DocRE model that adopts a novel\nRE extraction paradigm named RHF (Relation-Head-Facts). Unlike existing\napproaches, AutoRE does not rely on the assumption of known relation options,\nmaking it more reflective of real-world scenarios. Additionally, we have\ndeveloped an easily extensible RE framework using a Parameters Efficient Fine\nTuning (PEFT) algorithm (QLoRA). Our experiments on the RE-DocRED dataset\nshowcase AutoRE's best performance, achieving state-of-the-art results,\nsurpassing TAG by 10.03% and 9.03% respectively on the dev and test set.\n","authors":["Xue Lilong","Zhang Dan","Dong Yuxiao","Tang Jie"],"pdf_url":"https://arxiv.org/pdf/2403.14888v1.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2403.14885v1","updated":"2024-03-21T23:42:00Z","published":"2024-03-21T23:42:00Z","title":"Establishing a leader in a pairwise comparisons method","summary":"  Abstract Like electoral systems, decision-making methods are also vulnerable\nto manipulation by decision-makers. The ability to effectively defend against\nsuch threats can only come from thoroughly understanding the manipulation\nmechanisms. In the presented article, we show two algorithms that can be used\nto launch a manipulation attack. They allow for equating the weights of two\nselected alternatives in the pairwise comparison method and, consequently,\nchoosing a leader. The theoretical considerations are accompanied by a Monte\nCarlo simulation showing the relationship between the size of the PC matrix,\nthe degree of inconsistency, and the ease of manipulation. This work is a\ncontinuation of our previous research published in the paper (Szybowski et al.,\n2023)\n","authors":["Jacek Szybowski","Konrad Kułakowski","Jiri Mazurek","Sebastian Ernst"],"pdf_url":"https://arxiv.org/pdf/2403.14885v1.pdf","comment":"9 figures, 19 pages"},{"id":"http://arxiv.org/abs/2310.14098v2","updated":"2024-03-21T22:49:40Z","published":"2023-10-21T19:32:11Z","title":"Stabilizing reinforcement learning control: A modular framework for\n  optimizing over all stable behavior","summary":"  We propose a framework for the design of feedback controllers that combines\nthe optimization-driven and model-free advantages of deep reinforcement\nlearning with the stability guarantees provided by using the Youla-Kucera\nparameterization to define the search domain. Recent advances in behavioral\nsystems allow us to construct a data-driven internal model; this enables an\nalternative realization of the Youla-Kucera parameterization based entirely on\ninput-output exploration data. Perhaps of independent interest, we formulate\nand analyze the stability of such data-driven models in the presence of noise.\nThe Youla-Kucera approach requires a stable \"parameter\" for controller design.\nFor the training of reinforcement learning agents, the set of all stable linear\noperators is given explicitly through a matrix factorization approach.\nMoreover, a nonlinear extension is given using a neural network to express a\nparameterized set of stable operators, which enables seamless integration with\nstandard deep learning libraries. Finally, we show how these ideas can also be\napplied to tune fixed-structure controllers.\n","authors":["Nathan P. Lawrence","Philip D. Loewen","Shuyuan Wang","Michael G. Forbes","R. Bhushan Gopaluni"],"pdf_url":"https://arxiv.org/pdf/2310.14098v2.pdf","comment":"Postprint; 31 pages. arXiv admin note: text overlap with\n  arXiv:2304.03422"},{"id":"http://arxiv.org/abs/2311.09682v2","updated":"2024-03-21T22:44:41Z","published":"2023-11-16T08:52:27Z","title":"MacGyver: Are Large Language Models Creative Problem Solvers?","summary":"  We explore the creative problem-solving capabilities of modern LLMs in a\nnovel constrained setting. To this end, we create MACGYVER, an automatically\ngenerated dataset consisting of over 1,600 real-world problems deliberately\ndesigned to trigger innovative usage of objects and necessitate out-of-the-box\nthinking. We then present our collection to both LLMs and humans to compare and\ncontrast their problem-solving abilities. MACGYVER is challenging for both\ngroups, but in unique and complementary ways. For instance, humans excel in\ntasks they are familiar with but struggle with domain-specific knowledge,\nleading to a higher variance. In contrast, LLMs, exposed to a variety of\nspecialized knowledge, attempt broader problems but fail by proposing\nphysically-infeasible actions. Finally, we provide a detailed error analysis of\nLLMs, and demonstrate the potential of enhancing their problem-solving ability\nwith novel prompting techniques such as iterative step-wise reflection and\ndivergent-convergent thinking.\n  This work (1) introduces a fresh arena for intelligent agents focusing on\nintricate aspects of physical reasoning, planning, and unconventional thinking,\nwhich supplements the existing spectrum of machine intelligence; and (2)\nprovides insight into the constrained problem-solving capabilities of both\nhumans and AI.\n","authors":["Yufei Tian","Abhilasha Ravichander","Lianhui Qin","Ronan Le Bras","Raja Marjieh","Nanyun Peng","Yejin Choi","Thomas L. Griffiths","Faeze Brahman"],"pdf_url":"https://arxiv.org/pdf/2311.09682v2.pdf","comment":"NAACL 2024"},{"id":"http://arxiv.org/abs/2403.14864v1","updated":"2024-03-21T22:18:59Z","published":"2024-03-21T22:18:59Z","title":"Learning Quadruped Locomotion Using Differentiable Simulation","summary":"  While most recent advancements in legged robot control have been driven by\nmodel-free reinforcement learning, we explore the potential of differentiable\nsimulation. Differentiable simulation promises faster convergence and more\nstable training by computing low-variant first-order gradients using the robot\nmodel, but so far, its use for legged robot control has remained limited to\nsimulation. The main challenge with differentiable simulation lies in the\ncomplex optimization landscape of robotic tasks due to discontinuities in\ncontact-rich environments, e.g., quadruped locomotion. This work proposes a\nnew, differentiable simulation framework to overcome these challenges. The key\nidea involves decoupling the complex whole-body simulation, which may exhibit\ndiscontinuities due to contact, into two separate continuous domains.\nSubsequently, we align the robot state resulting from the simplified model with\na more precise, non-differentiable simulator to maintain sufficient simulation\naccuracy. Our framework enables learning quadruped walking in minutes using a\nsingle simulated robot without any parallelization. When augmented with GPU\nparallelization, our approach allows the quadruped robot to master diverse\nlocomotion skills, including trot, pace, bound, and gallop, on challenging\nterrains in minutes. Additionally, our policy achieves robust locomotion\nperformance in the real world zero-shot. To the best of our knowledge, this\nwork represents the first demonstration of using differentiable simulation for\ncontrolling a real quadruped robot. This work provides several important\ninsights into using differentiable simulations for legged locomotion in the\nreal world.\n","authors":["Yunlong Song","Sangbae Kim","Davide Scaramuzza"],"pdf_url":"https://arxiv.org/pdf/2403.14864v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14859v1","updated":"2024-03-21T22:08:44Z","published":"2024-03-21T22:08:44Z","title":"Comparing Plausibility Estimates in Base and Instruction-Tuned Large\n  Language Models","summary":"  Instruction-tuned LLMs can respond to explicit queries formulated as prompts,\nwhich greatly facilitates interaction with human users. However, prompt-based\napproaches might not always be able to tap into the wealth of implicit\nknowledge acquired by LLMs during pre-training. This paper presents a\ncomprehensive study of ways to evaluate semantic plausibility in LLMs. We\ncompare base and instruction-tuned LLM performance on an English sentence\nplausibility task via (a) explicit prompting and (b) implicit estimation via\ndirect readout of the probabilities models assign to strings. Experiment 1\nshows that, across model architectures and plausibility datasets, (i) log\nlikelihood ($\\textit{LL}$) scores are the most reliable indicator of sentence\nplausibility, with zero-shot prompting yielding inconsistent and typically poor\nresults; (ii) $\\textit{LL}$-based performance is still inferior to human\nperformance; (iii) instruction-tuned models have worse $\\textit{LL}$-based\nperformance than base models. In Experiment 2, we show that $\\textit{LL}$\nscores across models are modulated by context in the expected way, showing high\nperformance on three metrics of context-sensitive plausibility and providing a\ndirect match to explicit human plausibility judgments. Overall, $\\textit{LL}$\nestimates remain a more reliable measure of plausibility in LLMs than direct\nprompting.\n","authors":["Carina Kauf","Emmanuele Chersoni","Alessandro Lenci","Evelina Fedorenko","Anna A. Ivanova"],"pdf_url":"https://arxiv.org/pdf/2403.14859v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11905v2","updated":"2024-03-21T21:57:13Z","published":"2024-03-18T16:06:30Z","title":"Tur[k]ingBench: A Challenge Benchmark for Web Agents","summary":"  Recent chatbots have demonstrated impressive ability to understand and\ncommunicate in raw-text form. However, there is more to the world than raw\ntext. For example, humans spend long hours of their time on web pages, where\ntext is intertwined with other modalities and tasks are accomplished in the\nform of various complex interactions. Can state-of-the-art multi-modal models\ngeneralize to such complex domains?\n  To address this question, we introduce TurkingBench, a benchmark of tasks\nformulated as web pages containing textual instructions with multi-modal\ncontext. Unlike existing work which employs artificially synthesized web pages,\nhere we use natural HTML pages that were originally designed for crowdsourcing\nworkers for various annotation purposes. The HTML instructions of each task are\nalso instantiated with various values (obtained from the crowdsourcing tasks)\nto form new instances of the task. This benchmark contains 32.2K instances\ndistributed across 158 tasks.\n  Additionally, to facilitate the evaluation on TurkingBench, we develop an\nevaluation framework that connects the responses of chatbots to modifications\non web pages (modifying a text box, checking a radio, etc.). We evaluate the\nperformance of state-of-the-art models, including language-only, vision-only,\nand layout-only models, and their combinations, on this benchmark. Our findings\nreveal that these models perform significantly better than random chance, yet\nconsiderable room exists for improvement. We hope this benchmark will help\nfacilitate the evaluation and development of web-based agents.\n","authors":["Kevin Xu","Yeganeh Kordi","Kate Sanders","Yizhong Wang","Adam Byerly","Jack Zhang","Benjamin Van Durme","Daniel Khashabi"],"pdf_url":"https://arxiv.org/pdf/2403.11905v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13362v2","updated":"2024-03-21T21:56:49Z","published":"2024-03-20T07:44:06Z","title":"Incentivizing News Consumption on Social Media Platforms Using Large\n  Language Models and Realistic Bot Accounts","summary":"  Polarization, declining trust, and wavering support for democratic norms are\npressing threats to U.S. democracy. Exposure to verified and quality news may\nlower individual susceptibility to these threats and make citizens more\nresilient to misinformation, populism, and hyperpartisan rhetoric. This project\nexamines how to enhance users' exposure to and engagement with verified and\nideologically balanced news in an ecologically valid setting. We rely on a\nlarge-scale two-week long field experiment (from 1/19/2023 to 2/3/2023) on\n28,457 Twitter users. We created 28 bots utilizing GPT-2 that replied to users\ntweeting about sports, entertainment, or lifestyle with a contextual reply\ncontaining two hardcoded elements: a URL to the topic-relevant section of\nquality news organization and an encouragement to follow its Twitter account.\nTo further test differential effects by gender of the bots, treated users were\nrandomly assigned to receive responses by bots presented as female or male. We\nexamine whether our over-time intervention enhances the following of news media\norganization, the sharing and the liking of news content and the tweeting about\npolitics and the liking of political content. We find that the treated users\nfollowed more news accounts and the users in the female bot treatment were more\nlikely to like news content than the control. Most of these results, however,\nwere small in magnitude and confined to the already politically interested\nTwitter users, as indicated by their pre-treatment tweeting about politics.\nThese findings have implications for social media and news organizations, and\nalso offer direction for future work on how Large Language Models and other\ncomputational interventions can effectively enhance individual on-platform\nengagement with quality news and public affairs.\n","authors":["Hadi Askari","Anshuman Chhabra","Bernhard Clemm von Hohenberg","Michael Heseltine","Magdalena Wojcieszak"],"pdf_url":"https://arxiv.org/pdf/2403.13362v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14843v1","updated":"2024-03-21T21:27:39Z","published":"2024-03-21T21:27:39Z","title":"Local Causal Discovery with Linear non-Gaussian Cyclic Models","summary":"  Local causal discovery is of great practical significance, as there are often\nsituations where the discovery of the global causal structure is unnecessary,\nand the interest lies solely on a single target variable. Most existing local\nmethods utilize conditional independence relations, providing only a partially\ndirected graph, and assume acyclicity for the ground-truth structure, even\nthough real-world scenarios often involve cycles like feedback mechanisms. In\nthis work, we present a general, unified local causal discovery method with\nlinear non-Gaussian models, whether they are cyclic or acyclic. We extend the\napplication of independent component analysis from the global context to\nindependent subspace analysis, enabling the exact identification of the\nequivalent local directed structures and causal strengths from the Markov\nblanket of the target variable. We also propose an alternative regression-based\nmethod in the particular acyclic scenarios. Our identifiability results are\nempirically validated using both synthetic and real-world datasets.\n","authors":["Haoyue Dai","Ignavier Ng","Yujia Zheng","Zhengqing Gao","Kun Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.14843v1.pdf","comment":"Appears at AISTATS 2024"},{"id":"http://arxiv.org/abs/2403.14817v1","updated":"2024-03-21T20:14:53Z","published":"2024-03-21T20:14:53Z","title":"Crowdsourced Multilingual Speech Intelligibility Testing","summary":"  With the advent of generative audio features, there is an increasing need for\nrapid evaluation of their impact on speech intelligibility. Beyond the existing\nlaboratory measures, which are expensive and do not scale well, there has been\ncomparatively little work on crowdsourced assessment of intelligibility.\nStandards and recommendations are yet to be defined, and publicly available\nmultilingual test materials are lacking. In response to this challenge, we\npropose an approach for a crowdsourced intelligibility assessment. We detail\nthe test design, the collection and public release of the multilingual speech\ndata, and the results of our early experiments.\n","authors":["Laura Lechler","Kamil Wojcicki"],"pdf_url":"https://arxiv.org/pdf/2403.14817v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14814v1","updated":"2024-03-21T19:59:52Z","published":"2024-03-21T19:59:52Z","title":"The opportunities and risks of large language models in mental health","summary":"  Global rates of mental health concerns are rising and there is increasing\nrealization that existing models of mental healthcare will not adequately\nexpand to meet the demand. With the emergence of large language models (LLMs)\nhas come great optimism regarding their promise to create novel, large-scale\nsolutions to support mental health. Despite their nascence, LLMs have already\nbeen applied to mental health-related tasks. In this review, we summarize the\nextant literature on efforts to use LLMs to provide mental health education,\nassessment, and intervention and highlight key opportunities for positive\nimpact in each area. We then highlight risks associated with LLMs application\nto mental health and encourage adoption of strategies to mitigate these risks.\nThe urgent need for mental health support must be balanced with responsible\ndevelopment, testing, and deployment of mental health LLMs. Especially critical\nis ensuring that mental health LLMs are fine-tuned for mental health, enhance\nmental health equity, adhere to ethical standards, and that people, including\nthose with lived experience with mental health concerns, are involved in all\nstages from development through deployment. Prioritizing these efforts will\nminimize potential harms to mental health and maximize the likelihood that LLMs\nwill positively impact mental health globally.\n","authors":["Hannah R. Lawrence","Renee A. Schneider","Susan B. Rubin","Maja J. Mataric","Daniel J. McDuff","Megan Jones Bell"],"pdf_url":"https://arxiv.org/pdf/2403.14814v1.pdf","comment":"12 pages, 2 tables, 4 figures"},{"id":"http://arxiv.org/abs/2403.07869v2","updated":"2024-03-21T19:57:46Z","published":"2024-03-12T17:58:01Z","title":"TeleMoMa: A Modular and Versatile Teleoperation System for Mobile\n  Manipulation","summary":"  A critical bottleneck limiting imitation learning in robotics is the lack of\ndata. This problem is more severe in mobile manipulation, where collecting\ndemonstrations is harder than in stationary manipulation due to the lack of\navailable and easy-to-use teleoperation interfaces. In this work, we\ndemonstrate TeleMoMa, a general and modular interface for whole-body\nteleoperation of mobile manipulators. TeleMoMa unifies multiple human\ninterfaces including RGB and depth cameras, virtual reality controllers,\nkeyboard, joysticks, etc., and any combination thereof. In its more accessible\nversion, TeleMoMa works using simply vision (e.g., an RGB-D camera), lowering\nthe entry bar for humans to provide mobile manipulation demonstrations. We\ndemonstrate the versatility of TeleMoMa by teleoperating several existing\nmobile manipulators - PAL Tiago++, Toyota HSR, and Fetch - in simulation and\nthe real world. We demonstrate the quality of the demonstrations collected with\nTeleMoMa by training imitation learning policies for mobile manipulation tasks\ninvolving synchronized whole-body motion. Finally, we also show that TeleMoMa's\nteleoperation channel enables teleoperation on site, looking at the robot, or\nremote, sending commands and observations through a computer network, and\nperform user studies to evaluate how easy it is for novice users to learn to\ncollect demonstrations with different combinations of human interfaces enabled\nby our system. We hope TeleMoMa becomes a helpful tool for the community\nenabling researchers to collect whole-body mobile manipulation demonstrations.\nFor more information and video results,\nhttps://robin-lab.cs.utexas.edu/telemoma-web.\n","authors":["Shivin Dass","Wensi Ai","Yuqian Jiang","Samik Singh","Jiaheng Hu","Ruohan Zhang","Peter Stone","Ben Abbatematteo","Roberto Martín-Martín"],"pdf_url":"https://arxiv.org/pdf/2403.07869v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14800v1","updated":"2024-03-21T19:28:17Z","published":"2024-03-21T19:28:17Z","title":"Deep Active Learning: A Reality Check","summary":"  We conduct a comprehensive evaluation of state-of-the-art deep active\nlearning methods. Surprisingly, under general settings, no single-model method\ndecisively outperforms entropy-based active learning, and some even fall short\nof random sampling. We delve into overlooked aspects like starting budget,\nbudget step, and pretraining's impact, revealing their significance in\nachieving superior results. Additionally, we extend our evaluation to other\ntasks, exploring the active learning effectiveness in combination with\nsemi-supervised learning, and object detection. Our experiments provide\nvaluable insights and concrete recommendations for future active learning\nstudies. By uncovering the limitations of current methods and understanding the\nimpact of different experimental settings, we aim to inspire more efficient\ntraining of deep learning models in real-world scenarios with limited\nannotation budgets. This work contributes to advancing active learning's\nefficacy in deep learning and empowers researchers to make informed decisions\nwhen applying active learning to their tasks.\n","authors":["Edrina Gashi","Jiankang Deng","Ismail Elezi"],"pdf_url":"https://arxiv.org/pdf/2403.14800v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14796v1","updated":"2024-03-21T19:18:47Z","published":"2024-03-21T19:18:47Z","title":"Planning and Acting While the Clock Ticks","summary":"  Standard temporal planning assumes that planning takes place offline and then\nexecution starts at time 0. Recently, situated temporal planning was\nintroduced, where planning starts at time 0 and execution occurs after planning\nterminates. Situated temporal planning reflects a more realistic scenario where\ntime passes during planning. However, in situated temporal planning a complete\nplan must be generated before any action is executed. In some problems with\ntime pressure, timing is too tight to complete planning before the first action\nmust be executed. For example, an autonomous car that has a truck backing\ntowards it should probably move out of the way now and plan how to get to its\ndestination later. In this paper, we propose a new problem setting: concurrent\nplanning and execution, in which actions can be dispatched (executed) before\nplanning terminates. Unlike previous work on planning and execution, we must\nhandle wall clock deadlines that affect action applicability and goal\nachievement (as in situated planning) while also supporting dispatching actions\nbefore a complete plan has been found. We extend previous work on metareasoning\nfor situated temporal planning to develop an algorithm for this new setting.\nOur empirical evaluation shows that when there is strong time pressure, our\napproach outperforms situated temporal planning.\n","authors":["Andrew Coles","Erez Karpas","Andrey Lavrinenko","Wheeler Ruml","Solomon Eyal Shimony","Shahaf Shperberg"],"pdf_url":"https://arxiv.org/pdf/2403.14796v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.03187v2","updated":"2024-03-21T19:14:04Z","published":"2023-12-05T23:33:49Z","title":"FERGI: Automatic Annotation of User Preferences for Text-to-Image\n  Generation from Spontaneous Facial Expression Reaction","summary":"  Researchers have proposed to use data of human preference feedback to\nfine-tune text-to-image generative models. However, the scalability of human\nfeedback collection has been limited by its reliance on manual annotation.\nTherefore, we develop and test a method to automatically annotate user\npreferences from their spontaneous facial expression reaction to the generated\nimages. We collect a dataset of Facial Expression Reaction to Generated Images\n(FERGI) and show that the activations of multiple facial action units (AUs) are\nhighly correlated with user evaluations of the generated images. Specifically,\nAU4 (brow lowerer) is reflective of negative evaluations of the generated image\nwhereas AU12 (lip corner puller) is reflective of positive evaluations. These\ncan be useful in two ways. Firstly, we can automatically annotate user\npreferences between image pairs with substantial difference in these AU\nresponses with an accuracy significantly outperforming state-of-the-art scoring\nmodels. Secondly, directly integrating the AU responses with the scoring models\nimproves their consistency with human preferences. Finally, this method of\nautomatic annotation with facial expression analysis can be potentially\ngeneralized to other generation tasks. The code is available at\nhttps://github.com/ShuangquanFeng/FERGI, and the dataset is also available at\nthe same link for research purposes.\n","authors":["Shuangquan Feng","Junhua Ma","Virginia R. de Sa"],"pdf_url":"https://arxiv.org/pdf/2312.03187v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14791v1","updated":"2024-03-21T19:12:37Z","published":"2024-03-21T19:12:37Z","title":"Particip-AI: A Democratic Surveying Framework for Anticipating Future AI\n  Use Cases, Harms and Benefits","summary":"  General purpose AI, such as ChatGPT, seems to have lowered the barriers for\nthe public to use AI and harness its power. However, the governance and\ndevelopment of AI still remain in the hands of a few, and the pace of\ndevelopment is accelerating without proper assessment of risks. As a first step\ntowards democratic governance and risk assessment of AI, we introduce\nParticip-AI, a framework to gather current and future AI use cases and their\nharms and benefits from non-expert public. Our framework allows us to study\nmore nuanced and detailed public opinions on AI through collecting use cases,\nsurfacing diverse harms through risk assessment under alternate scenarios\n(i.e., developing and not developing a use case), and illuminating tensions\nover AI development through making a concluding choice on its development. To\nshowcase the promise of our framework towards guiding democratic AI, we gather\nresponses from 295 demographically diverse participants. We find that\nparticipants' responses emphasize applications for personal life and society,\ncontrasting with most current AI development's business focus. This shows the\nvalue of surfacing diverse harms that are complementary to expert assessments.\nFurthermore, we found that perceived impact of not developing use cases\npredicted participants' judgements of whether AI use cases should be developed,\nand highlighted lay users' concerns of techno-solutionism. We conclude with a\ndiscussion on how frameworks like Particip-AI can further guide democratic AI\ngovernance and regulation.\n","authors":["Jimin Mun","Liwei Jiang","Jenny Liang","Inyoung Cheong","Nicole DeCario","Yejin Choi","Tadayoshi Kohno","Maarten Sap"],"pdf_url":"https://arxiv.org/pdf/2403.14791v1.pdf","comment":"35 pages, 4 figures, 23 tables"},{"id":"http://arxiv.org/abs/2403.14790v1","updated":"2024-03-21T19:09:21Z","published":"2024-03-21T19:09:21Z","title":"Latent Diffusion Models for Attribute-Preserving Image Anonymization","summary":"  Generative techniques for image anonymization have great potential to\ngenerate datasets that protect the privacy of those depicted in the images,\nwhile achieving high data fidelity and utility. Existing methods have focused\nextensively on preserving facial attributes, but failed to embrace a more\ncomprehensive perspective that considers the scene and background into the\nanonymization process. This paper presents, to the best of our knowledge, the\nfirst approach to image anonymization based on Latent Diffusion Models (LDMs).\nEvery element of a scene is maintained to convey the same meaning, yet\nmanipulated in a way that makes re-identification difficult. We propose two\nLDMs for this purpose: CAMOUFLaGE-Base exploits a combination of pre-trained\nControlNets, and a new controlling mechanism designed to increase the distance\nbetween the real and anonymized images. CAMOFULaGE-Light is based on the\nAdapter technique, coupled with an encoding designed to efficiently represent\nthe attributes of different persons in a scene. The former solution achieves\nsuperior performance on most metrics and benchmarks, while the latter cuts the\ninference time in half at the cost of fine-tuning a lightweight module. We show\nthrough extensive experimental comparison that the proposed method is\ncompetitive with the state-of-the-art concerning identity obfuscation whilst\nbetter preserving the original content of the image and tackling unresolved\nchallenges that current solutions fail to address.\n","authors":["Luca Piano","Pietro Basci","Fabrizio Lamberti","Lia Morra"],"pdf_url":"https://arxiv.org/pdf/2403.14790v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14783v1","updated":"2024-03-21T18:57:25Z","published":"2024-03-21T18:57:25Z","title":"Multi-Agent VQA: Exploring Multi-Agent Foundation Models in Zero-Shot\n  Visual Question Answering","summary":"  This work explores the zero-shot capabilities of foundation models in Visual\nQuestion Answering (VQA) tasks. We propose an adaptive multi-agent system,\nnamed Multi-Agent VQA, to overcome the limitations of foundation models in\nobject detection and counting by using specialized agents as tools. Unlike\nexisting approaches, our study focuses on the system's performance without\nfine-tuning it on specific VQA datasets, making it more practical and robust in\nthe open world. We present preliminary experimental results under zero-shot\nscenarios and highlight some failure cases, offering new directions for future\nresearch.\n","authors":["Bowen Jiang","Zhijun Zhuang","Shreyas S. Shivakumar","Dan Roth","Camillo J. Taylor"],"pdf_url":"https://arxiv.org/pdf/2403.14783v1.pdf","comment":"A full version of the paper will be released soon. The codes are\n  available at https://github.com/bowen-upenn/Multi-Agent-VQA"},{"id":"http://arxiv.org/abs/2403.14773v1","updated":"2024-03-21T18:27:29Z","published":"2024-03-21T18:27:29Z","title":"StreamingT2V: Consistent, Dynamic, and Extendable Long Video Generation\n  from Text","summary":"  Text-to-video diffusion models enable the generation of high-quality videos\nthat follow text instructions, making it easy to create diverse and individual\ncontent. However, existing approaches mostly focus on high-quality short video\ngeneration (typically 16 or 24 frames), ending up with hard-cuts when naively\nextended to the case of long video synthesis. To overcome these limitations, we\nintroduce StreamingT2V, an autoregressive approach for long video generation of\n80, 240, 600, 1200 or more frames with smooth transitions. The key components\nare:(i) a short-term memory block called conditional attention module (CAM),\nwhich conditions the current generation on the features extracted from the\nprevious chunk via an attentional mechanism, leading to consistent chunk\ntransitions, (ii) a long-term memory block called appearance preservation\nmodule, which extracts high-level scene and object features from the first\nvideo chunk to prevent the model from forgetting the initial scene, and (iii) a\nrandomized blending approach that enables to apply a video enhancer\nautoregressively for infinitely long videos without inconsistencies between\nchunks. Experiments show that StreamingT2V generates high motion amount. In\ncontrast, all competing image-to-video methods are prone to video stagnation\nwhen applied naively in an autoregressive manner. Thus, we propose with\nStreamingT2V a high-quality seamless text-to-long video generator that\noutperforms competitors with consistency and motion. Our code will be available\nat: https://github.com/Picsart-AI-Research/StreamingT2V\n","authors":["Roberto Henschel","Levon Khachatryan","Daniil Hayrapetyan","Hayk Poghosyan","Vahram Tadevosyan","Zhangyang Wang","Shant Navasardyan","Humphrey Shi"],"pdf_url":"https://arxiv.org/pdf/2403.14773v1.pdf","comment":"https://github.com/Picsart-AI-Research/StreamingT2V"},{"id":"http://arxiv.org/abs/2403.14772v1","updated":"2024-03-21T18:26:23Z","published":"2024-03-21T18:26:23Z","title":"Improving Robustness to Model Inversion Attacks via Sparse Coding\n  Architectures","summary":"  Recent model inversion attack algorithms permit adversaries to reconstruct a\nneural network's private training data just by repeatedly querying the network\nand inspecting its outputs. In this work, we develop a novel network\narchitecture that leverages sparse-coding layers to obtain superior robustness\nto this class of attacks. Three decades of computer science research has\nstudied sparse coding in the context of image denoising, object recognition,\nand adversarial misclassification settings, but to the best of our knowledge,\nits connection to state-of-the-art privacy vulnerabilities remains unstudied.\nHowever, sparse coding architectures suggest an advantageous means to defend\nagainst model inversion attacks because they allow us to control the amount of\nirrelevant private information encoded in a network's intermediate\nrepresentations in a manner that can be computed efficiently during training\nand that is known to have little effect on classification accuracy.\nSpecifically, compared to networks trained with a variety of state-of-the-art\ndefenses, our sparse-coding architectures maintain comparable or higher\nclassification accuracy while degrading state-of-the-art training data\nreconstructions by factors of 1.1 to 18.3 across a variety of reconstruction\nquality metrics (PSNR, SSIM, FID). This performance advantage holds across 5\ndatasets ranging from CelebA faces to medical images and CIFAR-10, and across\nvarious state-of-the-art SGD-based and GAN-based inversion attacks, including\nPlug-&-Play attacks. We provide a cluster-ready PyTorch codebase to promote\nresearch and standardize defense evaluations.\n","authors":["Sayanton V. Dibbo","Adam Breuer","Juston Moore","Michael Teti"],"pdf_url":"https://arxiv.org/pdf/2403.14772v1.pdf","comment":"32 pages, 15 Tables, and 9 Figures"},{"id":"http://arxiv.org/abs/2403.13784v2","updated":"2024-03-21T18:03:46Z","published":"2024-03-20T17:47:08Z","title":"The Model Openness Framework: Promoting Completeness and Openness for\n  Reproducibility, Transparency and Usability in AI","summary":"  Generative AI (GAI) offers unprecedented possibilities but its\ncommercialization has raised concerns about transparency, reproducibility,\nbias, and safety. Many \"open-source\" GAI models lack the necessary components\nfor full understanding and reproduction, and some use restrictive licenses, a\npractice known as \"openwashing.\" We propose the Model Openness Framework (MOF),\na ranked classification system that rates machine learning models based on\ntheir completeness and openness, following principles of open science, open\nsource, open data, and open access. The MOF requires specific components of the\nmodel development lifecycle to be included and released under appropriate open\nlicenses. This framework aims to prevent misrepresentation of models claiming\nto be open, guide researchers and developers in providing all model components\nunder permissive licenses, and help companies, academia, and hobbyists identify\nmodels that can be safely adopted without restrictions. Wide adoption of the\nMOF will foster a more open AI ecosystem, accelerating research, innovation,\nand adoption.\n","authors":["Matt White","Ibrahim Haddad","Cailean Osborne"," Xiao-Yang"," Liu","Ahmed Abdelmonsef","Sachin Varghese"],"pdf_url":"https://arxiv.org/pdf/2403.13784v2.pdf","comment":"45 pages"}],"Optimization and Control":[{"id":"http://arxiv.org/abs/2403.14556v1","updated":"2024-03-21T16:55:29Z","published":"2024-03-21T16:55:29Z","title":"Rescue Craft Allocation in Tidal Waters of the North and Baltic Sea","summary":"  This paper aims to improve the average response time for naval accidents in\nthe North and Baltic Sea. To do this we optimize the strategic distribution of\nthe vessel fleet used by the Deutsche Gesellschaft zur Rettung\nSchiffbr\\\"uchiger (German Maritime Search and Rescue Service) (DGzRS) across\nseveral home stations. Based on these locations, in case of an incoming\ndistress call the vessel with the lowest response time is dispatched. A\nparticularity of the region considered is the fact that due to low tide, at\npredictable times some vessels and stations are not operational. In our work,\nwe build a corresponding mathematical model for the allocation of rescue crafts\nto multiple stations. Thereafter, we show that the problem is NP-hard. Next, we\nprovide an Integer Programming (IP) formulation. Finally, we propose several\nmethods of simplifying the model and do a case study to compare their\neffectiveness. For this, we generate test instances based on real-world data.\n","authors":["Tom Mucke","Alexander Renneke","Finn Seesemann","Felix Engelhardt"],"pdf_url":"https://arxiv.org/pdf/2403.14556v1.pdf","comment":"Code URL: https://github.com/veni-vidi-code/RCA"},{"id":"http://arxiv.org/abs/2403.14555v1","updated":"2024-03-21T16:53:17Z","published":"2024-03-21T16:53:17Z","title":"A Joint Optimization Approach for Power-Efficient Heterogeneous OFDMA\n  Radio Access Networks","summary":"  Heterogeneous networks have emerged as a popular solution for accommodating\nthe growing number of connected devices and increasing traffic demands in\ncellular networks. While offering broader coverage, higher capacity, and lower\nlatency, the escalating energy consumption poses sustainability challenges. In\nthis paper a novel optimization approach for OFDMA heterogeneous networks is\nproposed to minimize transmission power while respecting individual users\nthroughput constraints. The problem is formulated as a mixed integer geometric\nprogram, and optimizes at once multiple system variables such as user\nassociation, working bandwidth, and base stations transmission powers.\nCrucially, the proposed approach becomes a convex optimization problem when\nuser-base station associations are provided. Evaluations in multiple realistic\nscenarios from the production mobile network of a major European operator and\nbased on precise channel gains and throughput requirements from measured data\nvalidate the effectiveness of the proposed approach. Overall, our original\nsolution paves the road for greener connectivity by reducing the energy\nfootprint of heterogeneous mobile networks, hence fostering more sustainable\ncommunication systems.\n","authors":["Gabriel O. Ferreira","André F. Zanella","Stefanos Bakirtzis","Chiara Ravazzi","Fabrizio Dabbene","Giuseppe C. Calafiore","Ian Wassel","Jie Zhang","Marco Fiore"],"pdf_url":"https://arxiv.org/pdf/2403.14555v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.15151v2","updated":"2024-03-21T16:42:43Z","published":"2023-12-23T03:36:13Z","title":"Complexity of trust-region methods with unbounded Hessian approximations\n  for smooth and nonsmooth optimization","summary":"  We develop a worst-case evaluation complexity bound for trust-region methods\nin the presence of unbounded Hessian approximations. We use the algorithm of\narXiv:2103.15993v3 as a model, which is designed for nonsmooth regularized\nproblems, but applies to unconstrained smooth problems as a special case. Our\nanalysis assumes that the growth of the Hessian approximation is controlled by\nthe number of successful iterations. We show that the best known complexity\nbound of $\\epsilon^{-2}$ deteriorates to $\\epsilon^{-2/(1-p)}$, where $0 \\le p\n< 1$ is a parameter that controls the growth of the Hessian approximation. The\nfaster the Hessian approximation grows, the more the bound deteriorates. We\nconstruct an objective that satisfies all of our assumptions and for which our\ncomplexity bound is attained, which establishes that our bound is sharp.\nNumerical experiments conducted in double precision arithmetic are consistent\nwith the analysis.\n","authors":["Geoffroy Leconte","Dominique Orban"],"pdf_url":"https://arxiv.org/pdf/2312.15151v2.pdf","comment":"20 pages, 2 figures, 1 table"},{"id":"http://arxiv.org/abs/2403.14540v1","updated":"2024-03-21T16:40:26Z","published":"2024-03-21T16:40:26Z","title":"Quantitative Indicators for Strength of Inequalities with Respect to a\n  Polyhedron, Part II: Applications and Computational Evidence","summary":"  The first paper explored two strength indicators (extreme point ratio (EPR)\nand centroid distance (CD)), both of which predict that subtours of the\nspanning tree in hypergraph polytope STHGP having large cardinality are\nsignificantly stronger than the corresponding subtours of small cardinality. In\nthis second paper, we exploit this previously unknown property algorithmically\nwithin GeoSteiner, presenting strong computational evidence that the EPR and CD\nindicators are highly predictive of actual computational strength, at least for\nsubtour inequalities of STHGP. The GeoSteiner package for geometric Steiner\ntrees in the plane uses STHGP to solve the Full Steiner Tree (FST)\nconcatenation problem. The separation algorithms in previous versions of\nGeoSteiner find violated subtours of only relatively small cardinality, and we\nexamine the underlying algorithmic causes. We present improvements in\nGeoSteiner specifically designed to strengthen violated subtours by\naugmentation (instead of reduction), yielding violated subtours of large\ncardinality. Across all distance metrics and instance classes studied, the\ncomputational results are remarkable -- culminating with an optimal solution of\na 1,000,000 terminal random Euclidean instance. The conclusion is that the EPR\nand CD strength indicators presented in the first paper have strong predictive\npower regarding actual computational strength (at least regarding STHGP\nsubtours). The ability to accurately measure the strength of inequalities has\nnumerous applications of great importance, both in theory and practice.\n","authors":["David M. Warme"],"pdf_url":"https://arxiv.org/pdf/2403.14540v1.pdf","comment":"112 pages, 18 figures"},{"id":"http://arxiv.org/abs/2403.14535v1","updated":"2024-03-21T16:37:34Z","published":"2024-03-21T16:37:34Z","title":"First-Order Methods for Linear Programming","summary":"  Linear programming is the seminal optimization problem that has spawned and\ngrown into today's rich and diverse optimization modeling and algorithmic\nlandscape. This article provides an overview of the recent development of\nfirst-order methods for solving large-scale linear programming.\n","authors":["Haihao Lu"],"pdf_url":"https://arxiv.org/pdf/2403.14535v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14522v1","updated":"2024-03-21T16:21:22Z","published":"2024-03-21T16:21:22Z","title":"Quantitative Indicators for Strength of Inequalities with Respect to a\n  Polyhedron, Part I: Theory","summary":"  We study strength of inequalities used in mixed-integer programming, and in\nbranch-and-cut algorithms that solve such problems. Strength is an ethereal\nproperty lacking good formal definition, but crucial for computational speed.\nWe review several quantitative indicators proposed in the literature we claim\nprovide a measure of the relative strength of inequalities with respect to a\ngiven polyhedron. We evaluate two of these indicators (extreme point ratio\n(EPR) and centroid distance (CD)) on various facet classes for both the\ntraveling salesman polytope TSP, and spanning tree in hypergraph polytope\nSTHGP, obtaining closed-forms for EPR and CD on each facet class. Within each\nfacet class, the two indicators yield strikingly similar strength rankings,\nwith excellent agreement on which facets are strongest and which are weakest.\nBoth indicators corroborate all known computational experience with both\npolytopes. The indicators also reveal previously unknown properties of STHGP\nsubtours. We also evaluate EPR and CD for the subtour inequalities of the\nspanning tree in graphs polytope STGP, obtaining surprising and unexpected\nresults that (at least for STGP and STHGP subtours) lead us to believe EPR to\nbe a more accurate estimate of strength than CD. Applications include:\ncomparing the relative strength of different classes of inequalities; design of\nrapidly-converging separation algorithms; design or justification for\nconstraint strengthening procedures.\n  The companion paper exploits one of the newly revealed properties of STHGP\nsubtours in GeoSteiner, with detailed computational results. Across all\ndistance metrics and instances studied, these results are remarkable --\nculminating with an optimal solution of a 1,000,000 terminal random Euclidean\ninstance. This confirms these indicators to be highly predictive and strongly\ncorrelated with actual computational strength.\n","authors":["David M. Warme"],"pdf_url":"https://arxiv.org/pdf/2403.14522v1.pdf","comment":"74 pages, 47 figures"},{"id":"http://arxiv.org/abs/2403.14509v1","updated":"2024-03-21T16:06:27Z","published":"2024-03-21T16:06:27Z","title":"Modeling and optimization for arrays of water turbine OWC devices","summary":"  Wave energy conversion is emerging as a promising technology for generating\nenergy from renewable sources. Large-scale implementation of this technology\nrequires the installation of parks of devices. We study the problem of\noptimizing the park layout and control for wave energy converters of the\noscillating water column type. As a test case, we consider a device with a\nsemi-submerged chamber and a Wells turbine working in the liquid phase. First,\na novel model based on a nonlinear ordinary differential equation is derived to\ndescribe the behavior of the water column and used to estimate the power matrix\nof an isolated device. Then, its linearization is derived in order to enable\nthe fast simulation of large parks with a high number of devices. The choice of\nthe hydrodynamic model allows obtaining the gradient of the power with respect\nto the positions through an adjoint approach, making it especially convenient\nfor optimization. We consider in particular the case of interaction with the\npiles of a floating wind energy plant. The results from the developed\ncomputational framework allow us to draw interesting conclusions that are\nuseful when designing the layout of a park. In particular, we observe that\ninteraction effects can be significant even in parks made up of devices of\nsmall size, which would exhibit negligible diffraction and radiation properties\nin isolated conditions, if the number of devices is large enough. Moreover,\nresults show that wave reflection from the piles of an offshore platform can\nhave positive effects on energy production.\n","authors":["M. Gambarini","G. Agate","G. Ciaramella","E. Miglio","S. Maran"],"pdf_url":"https://arxiv.org/pdf/2403.14509v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.07041v3","updated":"2024-03-21T15:57:31Z","published":"2023-12-12T07:53:22Z","title":"Probabilistic Lookahead Strong Branching via a Stochastic Abstract\n  Branching Model","summary":"  Strong Branching (SB) is a cornerstone of all modern branching rules used in\nthe Branch-and-Bound (BnB) algorithm, which is at the center of Mixed-Integer\nProgramming solvers. In its full form, SB evaluates all variables to branch on\nand then selects the one producing the best relaxation, leading to small trees,\nbut high runtimes. State-of-the-art branching rules therefore use SB with\nworking limits to achieve both small enough trees and short run times. So far,\nthese working limits have been established empirically. In this paper, we\nintroduce a theoretical approach to guide how much SB to use at each node\nwithin the BnB. We first define an abstract stochastic tree model of the BnB\nalgorithm where the geometric mean dual gains of all variables follow a given\nprobability distribution. This model allows us to relate expected dual gains to\ntree sizes and explicitly compare the cost of sampling an additional SB\ncandidate with the reward in expected tree size reduction. We then leverage the\ninsight from the abstract model to design a new stopping criterion for SB,\nwhich fits a distribution to the dual gains and, at each node, dynamically\ncontinues or interrupts SB. This algorithm, which we refer to as Probabilistic\nLookahead Strong Branching, improves both the tree size and runtime over MIPLIB\ninstances, providing evidence that the method not only changes the amount of\nSB, but allocates it better.\n","authors":["Gioni Mexi","Somayeh Shamsi","Mathieu Besançon","Pierre Le Bodic"],"pdf_url":"https://arxiv.org/pdf/2312.07041v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.16763v2","updated":"2024-03-21T15:42:41Z","published":"2023-06-29T08:07:11Z","title":"Sampling-Based Methods for Multi-Block Optimization Problems over\n  Transport Polytopes","summary":"  This paper focuses on multi-block optimization problems over transport\npolytopes, which underlie various applications including strongly correlated\nquantum physics and machine learning. Conventional block coordinate\ndescent-type methods for the general multi-block problems store and operate on\nthe matrix variables directly, resulting in formidable expenditure for\nlarge-scale settings. On the other hand, optimal transport problems, as a\nspecial case, have attracted extensive attention and numerical techniques that\nwaive the use of the full matrices have recently emerged. However, it remains\nnontrivial to apply these techniques to the multi-block, possibly nonconvex\nproblems with theoretical guarantees. In this work, we leverage the benefits of\nboth sides and develop novel sampling-based block coordinate descent-type\nmethods, which are equipped with either entropy regularization or\nKullback-Leibler divergence. Each iteration of these methods solves subproblems\nrestricted on the sampled degrees of freedom. Consequently, they involve only\nsparse matrices, which amounts to considerable complexity reductions. We\nexplicitly characterize the sampling-induced errors and establish convergence\nand asymptotic properties for the methods equipped with the entropy\nregularization. Numerical experiments on typical strongly correlated electron\nsystems corroborate their superior scalability over the methods utilizing full\nmatrices. The advantage also enables the first visualization of approximate\noptimal transport maps between electron positions in three-dimensional\ncontexts.\n","authors":["Yukuan Hu","Mengyu Li","Xin Liu","Cheng Meng"],"pdf_url":"https://arxiv.org/pdf/2306.16763v2.pdf","comment":"38 pages, 11 figures, 5 tables"},{"id":"http://arxiv.org/abs/2403.14470v1","updated":"2024-03-21T15:17:05Z","published":"2024-03-21T15:17:05Z","title":"CBX: Python and Julia packages for consensus-based interacting particle\n  methods","summary":"  We introduce CBXPy and ConsensusBasedX.jl, Python and Julia implementations\nof consensus-based interacting particle systems (CBX), which generalise\nconsensus-based optimization methods (CBO) for global, derivative-free\noptimisation. The raison d'\\^etre of our libraries is twofold: on the one hand,\nto offer high-performance implementations of CBX methods that the community can\nuse directly, while on the other, providing a general interface that can\naccommodate and be extended to further variations of the CBX family. Python and\nJulia were selected as the leading high-level languages in terms of usage and\nperformance, as well as their popularity among the scientific computing\ncommunity. Both libraries have been developed with a common ethos, ensuring a\nsimilar API and core functionality, while leveraging the strengths of each\nlanguage and writing idiomatic code.\n","authors":["Rafael Bailo","Alethea Barbaro","Susana N. Gomes","Konstantin Riedl","Tim Roith","Claudia Totzeck","Urbain Vaes"],"pdf_url":"https://arxiv.org/pdf/2403.14470v1.pdf","comment":"7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2403.14436v1","updated":"2024-03-21T14:42:37Z","published":"2024-03-21T14:42:37Z","title":"Spectral Methods for Quantum Optimal Control: Artificial Boundary\n  Conditions","summary":"  The problem of quantum state preparation is one of the main challenges in\nachieving the quantum advantage. Furthermore, classically, for multi-level\nproblems, our ability to solve the corresponding quantum optimal control\nproblems is rather limited. The ability of the latter to feed into the former\nmay result in significant progress in quantum computing. To address this\nchallenge, we propose a formulation of quantum optimal control that makes use\nof artificial boundary conditions for the Schr\\\"odinger equation in combination\nwith spectral methods. The resulting formulations are well suited for\ninvestigating periodic potentials and lend themselves to direct numerical\ntreatment using conventional methods for bounded domains.\n","authors":["Ales Wodecki","Jakub Marecek","Vyacheslav Kungurtsev","Pavel Eichler","Georgios Korpas","Philip Intallura"],"pdf_url":"https://arxiv.org/pdf/2403.14436v1.pdf","comment":"10 pages plus references"},{"id":"http://arxiv.org/abs/2403.14431v1","updated":"2024-03-21T14:37:53Z","published":"2024-03-21T14:37:53Z","title":"Breaking consensus in kinetic opinion formation models on graphons","summary":"  In this work we propose and investigate a strategy to prevent consensus in\nkinetic models for opinion formation. We consider a large interacting agent\nsystem, and assume that agent interactions are driven by compromise as well as\nself-thinking dynamics and also modulated by an underlying static social\nnetwork. This network structure is included using so-called graphons, which\nmodulate the interaction frequency in the corresponding kinetic formulation. We\nthen derive the corresponding limiting Fokker Planck equation, and analyze its\nlarge time behavior. This microscopic setting serves as a starting point for\nthe proposed control strategy, which steers agents away from mean opinion and\nis characterised by a suitable penalization depending on the properties of the\ngraphon. We show that this minimalist approach is very effective by analyzing\nthe quasi-stationary solutions mean-field model in a plurality of graphon\nstructures. Several numerical experiments are also provided the show the\neffectiveness of the approach in preventing the formation of consensus steering\nthe system towards a declustered state.\n","authors":["Bertram Düring","Jonathan Franceschi","Marie-Therese Wolfram","Mattia Zanella"],"pdf_url":"https://arxiv.org/pdf/2403.14431v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14425v1","updated":"2024-03-21T14:28:43Z","published":"2024-03-21T14:28:43Z","title":"Task-optimal data-driven surrogate models for eNMPC via differentiable\n  simulation and optimization","summary":"  We present a method for end-to-end learning of Koopman surrogate models for\noptimal performance in control. In contrast to previous contributions that\nemploy standard reinforcement learning (RL) algorithms, we use a training\nalgorithm that exploits the potential differentiability of environments based\non mechanistic simulation models. We evaluate the performance of our method by\ncomparing it to that of other controller type and training algorithm\ncombinations on a literature known eNMPC case study. Our method exhibits\nsuperior performance on this problem, thereby constituting a promising avenue\ntowards more capable controllers that employ dynamic surrogate models.\n","authors":["Daniel Mayfrank","Na Young Ahn","Alexander Mitsos","Manuel Dahmen"],"pdf_url":"https://arxiv.org/pdf/2403.14425v1.pdf","comment":"6 pages, 4 figures, 1 table"},{"id":"http://arxiv.org/abs/2209.08995v6","updated":"2024-03-21T14:17:18Z","published":"2022-09-19T13:17:23Z","title":"Data-Driven Output Prediction and Control of Stochastic Systems: An\n  Innovation-Based Approach","summary":"  Recent years have witnessed a booming interest in data-driven control of\ndynamical systems. However, the implicit data-driven output predictors are\nvulnerable to uncertainty such as process disturbance and measurement noise,\ncausing unreliable predictions and unexpected control actions. In this brief,\nwe put forward a new data-driven approach to output prediction of stochastic\nlinear time-invariant (LTI) systems. By utilizing the innovation form, the\nuncertainty in stochastic LTI systems is recast as innovations that can be\nreadily estimated from input-output data without knowing system matrices. In\nthis way, by applying the fundamental lemma to the innovation form, we propose\na new innovation-based data-driven output predictor (OP) of stochastic LTI\nsystems, which bypasses the need for identifying state-space matrices\nexplicitly and building a state estimator. The boundedness of the second moment\nof prediction errors in closed-loop is established under mild conditions. The\nproposed data-driven OP can be integrated into optimal control design for\nbetter performance. Numerical simulations are carried out to demonstrate the\noutperformance of the proposed innovation-based methods in output prediction\nand control design over existing formulations.\n","authors":["Yibo Wang","Keyou You","Dexian Huang","Chao Shang"],"pdf_url":"https://arxiv.org/pdf/2209.08995v6.pdf","comment":"Submitted to Automatica"},{"id":"http://arxiv.org/abs/2403.14398v1","updated":"2024-03-21T13:43:49Z","published":"2024-03-21T13:43:49Z","title":"Regularized Adaptive Momentum Dual Averaging with an Efficient Inexact\n  Subproblem Solver for Training Structured Neural Network","summary":"  We propose a Regularized Adaptive Momentum Dual Averaging (RAMDA) algorithm\nfor training structured neural networks. Similar to existing regularized\nadaptive methods, the subproblem for computing the update direction of RAMDA\ninvolves a nonsmooth regularizer and a diagonal preconditioner, and therefore\ndoes not possess a closed-form solution in general. We thus also carefully\ndevise an implementable inexactness condition that retains convergence\nguarantees similar to the exact versions, and propose a companion efficient\nsolver for the subproblems of both RAMDA and existing methods to make them\npractically feasible. We leverage the theory of manifold identification in\nvariational analysis to show that, even in the presence of such inexactness,\nthe iterates of RAMDA attain the ideal structure induced by the regularizer at\nthe stationary point of asymptotic convergence. This structure is locally\noptimal near the point of convergence, so RAMDA is guaranteed to obtain the\nbest structure possible among all methods converging to the same point, making\nit the first regularized adaptive method outputting models that possess\noutstanding predictive performance while being (locally) optimally structured.\nExtensive numerical experiments in large-scale modern computer vision, language\nmodeling, and speech tasks show that the proposed RAMDA is efficient and\nconsistently outperforms state of the art for training structured neural\nnetwork. Implementation of our algorithm is available at\nhttp://www.github.com/ismoptgroup/RAMDA/.\n","authors":["Zih-Syuan Huang","Ching-pei Lee"],"pdf_url":"https://arxiv.org/pdf/2403.14398v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14396v1","updated":"2024-03-21T13:40:50Z","published":"2024-03-21T13:40:50Z","title":"Infinite horizon McKean-Vlasov FBSDEs and applications to mean field\n  control problems","summary":"  In this paper, we study a class of infinite horizon fully coupled\nMcKean-Vlasov forward-backward stochastic differential equations (FBSDEs). We\npropose a generalized monotonicity condition involving two flexible functions.\nUnder this condition, we establish the well-posedness results for infinite\nhorizon McKean-Vlasov FBSDEs by the method of continuation, including the\nunique solvability, an estimate of the solution, and the related continuous\ndependence property of the solution on the coefficients. Based on the\nsolvability result, we study an infinite horizon mean field control problem.\nMoreover, by choosing appropriate form of the flexible functions, we can\neliminate the different phenomenon between the linear-quadratic (LQ) problems\non infinite horizon and finite horizon proposed in Wei and Yu (SIAM J. Control\nOptim. 59: 2594-2623, 2021).\n","authors":["Tianjiao Hua","Peng Luo"],"pdf_url":"https://arxiv.org/pdf/2403.14396v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.14476v3","updated":"2024-03-21T13:37:39Z","published":"2023-08-28T10:27:42Z","title":"An iterative sample scenario approach for the dynamic dispatch waves\n  problem","summary":"  A challenge in same-day delivery operations is that delivery requests are\ntypically not known beforehand, but are instead revealed dynamically during the\nday. This uncertainty introduces a trade-off between dispatching vehicles to\nserve requests as soon as they are revealed to ensure timely delivery, and\ndelaying the dispatching decision to consolidate routing decisions with future,\ncurrently unknown requests. In this paper, we study the dynamic dispatch waves\nproblem, a same-day delivery problem in which vehicles are dispatched at fixed\ndecision moments. At each decision moment, the system operator must decide\nwhich of the known requests to dispatch, and how to route these dispatched\nrequests. The operator's goal is to minimize the total routing cost while\nensuring that all requests are served on time. We propose iterative conditional\ndispatch (ICD), an iterative solution construction procedure based on a sample\nscenario approach. ICD iteratively solves sample scenarios to classify requests\nto be dispatched, postponed, or undecided. The set of undecided requests\nshrinks in each iteration until a final dispatching decision is made in the\nlast iteration. We develop two variants of ICD: one variant based on\nthresholds, and another variant based on similarity. A significant strength of\nICD is that it is conceptually simple and easy to implement. This simplicity\ndoes not harm performance: through rigorous numerical experiments, we show that\nboth variants efficiently navigate the large state and action spaces of the\ndynamic dispatch waves problem and quickly converge to a high-quality solution.\nFinally, we demonstrate that the threshold-based ICD variant achieves excellent\nresults on instances from the EURO meets NeurIPS 2022 vehicle routing\ncompetition, nearly matching the performance of the winning machine\nlearning-based strategy.\n","authors":["Leon Lan","Jasper van Doorn","Niels A. Wouda","Arpan Rijal","Sandjai Bhulai"],"pdf_url":"https://arxiv.org/pdf/2308.14476v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.03054v3","updated":"2024-03-21T12:43:34Z","published":"2023-10-04T11:40:02Z","title":"Posterior Sampling Based on Gradient Flows of the MMD with Negative\n  Distance Kernel","summary":"  We propose conditional flows of the maximum mean discrepancy (MMD) with the\nnegative distance kernel for posterior sampling and conditional generative\nmodeling. This MMD, which is also known as energy distance, has several\nadvantageous properties like efficient computation via slicing and sorting. We\napproximate the joint distribution of the ground truth and the observations\nusing discrete Wasserstein gradient flows and establish an error bound for the\nposterior distributions. Further, we prove that our particle flow is indeed a\nWasserstein gradient flow of an appropriate functional. The power of our method\nis demonstrated by numerical examples including conditional image generation\nand inverse problems like superresolution, inpainting and computed tomography\nin low-dose and limited-angle settings.\n","authors":["Paul Hagemann","Johannes Hertrich","Fabian Altekrüger","Robert Beinert","Jannis Chemseddine","Gabriele Steidl"],"pdf_url":"https://arxiv.org/pdf/2310.03054v3.pdf","comment":"Published as a conference paper at ICLR 2024"},{"id":"http://arxiv.org/abs/2301.11624v3","updated":"2024-03-21T12:34:14Z","published":"2023-01-27T09:57:36Z","title":"Neural Wasserstein Gradient Flows for Maximum Mean Discrepancies with\n  Riesz Kernels","summary":"  Wasserstein gradient flows of maximum mean discrepancy (MMD) functionals with\nnon-smooth Riesz kernels show a rich structure as singular measures can become\nabsolutely continuous ones and conversely. In this paper we contribute to the\nunderstanding of such flows. We propose to approximate the backward scheme of\nJordan, Kinderlehrer and Otto for computing such Wasserstein gradient flows as\nwell as a forward scheme for so-called Wasserstein steepest descent flows by\nneural networks (NNs). Since we cannot restrict ourselves to absolutely\ncontinuous measures, we have to deal with transport plans and velocity plans\ninstead of usual transport maps and velocity fields. Indeed, we approximate the\ndisintegration of both plans by generative NNs which are learned with respect\nto appropriate loss functions. In order to evaluate the quality of both neural\nschemes, we benchmark them on the interaction energy. Here we provide analytic\nformulas for Wasserstein schemes starting at a Dirac measure and show their\nconvergence as the time step size tends to zero. Finally, we illustrate our\nneural MMD flows by numerical examples.\n","authors":["Fabian Altekrüger","Johannes Hertrich","Gabriele Steidl"],"pdf_url":"https://arxiv.org/pdf/2301.11624v3.pdf","comment":"Accepted at ICML 2023"},{"id":"http://arxiv.org/abs/2301.05932v5","updated":"2024-03-21T10:16:12Z","published":"2023-01-14T15:09:09Z","title":"On continuation and convex Lyapunov functions","summary":"  Suppose that the origin is globally asymptotically stable under a set of\ncontinuous vector fields on Euclidean space and suppose that all those vector\nfields come equipped with -- possibly different -- convex Lyapunov functions.\nWe show that this implies there is a homotopy between any two of those vector\nfields such that the origin remains globally asymptotically stable along the\nhomotopy. Relaxing the assumption on the origin to any compact convex set or\nrelaxing convexity to geodesic convexity does not alter the conclusion.\nImposing the same convexity assumptions on control Lyapunov functions leads to\na Hautus-like stabilizability test. These results ought to be of interest in\nthe context of learning stability certificates, policy gradient methods and\nswitched systems.\n","authors":["Wouter Jongeneel","Roland Schwan"],"pdf_url":"https://arxiv.org/pdf/2301.05932v5.pdf","comment":"Final version, 12 pages, to appear in the IEEE Transactions on\n  Automatic Control"},{"id":"http://arxiv.org/abs/2403.14259v1","updated":"2024-03-21T09:37:11Z","published":"2024-03-21T09:37:11Z","title":"Minimal covariance realization and system identification algorithm for a\n  class of stochastic linear switched systems with i.i.d. switching","summary":"  In this paper, we work with Linear Switched Systems (LSS). We show the\nexistence of minimality in innovation form for such systems. We also present a\nrealization algorithm to compute a minimal LSS in innovation form, by\ncalculating the covariances of the state-pace matrices. Finally, a system\nidentification algorithm statically consistent is presented. The later, based\non the realization algorithm, uses the collected data in order to compute the\ncovariances of the inputs and outputs.\n","authors":["Elie Rouphael","Manas Mejari","Mihaly Petreczky","Lotfi Belkoura"],"pdf_url":"https://arxiv.org/pdf/2403.14259v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.02872v2","updated":"2024-03-21T08:47:02Z","published":"2023-09-06T09:53:19Z","title":"Input-output linearization and decoupling of mechanical control systems","summary":"  In this work, we present a problem of simultaneous input-output feedback\nlinearization and decoupling (non-interacting) for mechanical control systems\nwith outputs. We show that the natural requirement of preserving mechanical\nstructure of the system and of transformations imposes supplementary conditions\nwhen compared to the classical solution of the same problem for general control\nsystems. These conditions can be expressed using objects on the configuration\nspace only. We illustrate our results with several examples of mechanical\ncontrol systems.\n","authors":["Marcin Nowicki","Witold Respondek"],"pdf_url":"https://arxiv.org/pdf/2309.02872v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14226v1","updated":"2024-03-21T08:37:05Z","published":"2024-03-21T08:37:05Z","title":"On unifying control barrier and Lyapunov functions using QP and Sontag's\n  formula with an application to tumor dynamics","summary":"  A common tool in system theory for formulating control laws that achieve\nlocal asymptotic stability are Control Lyapunov functions (CLFs), while Control\nBarrier functions (CBFs) are typically employed to enforce safety constraints.\nCombining these two types of functions is of interest, because it leads to\nstabilizing controllers with safety guarantees. A common approach to merge CLFs\nand CBFs is to solve an optimization problem where both CLF and CBF\ninequalities are imposed as constraints. In this paper, we show via an example\nfrom the literature that this approach can lead to undesirable behavior (i.e.,\nslow convergence and oscillating inputs). Then, we propose a novel cost\nfunction that penalizes the deviation from Sontag's formula by using a\nstate-dependent weighting matrix. We show that by minimizing the developed cost\nfunction subject to a CBF constraint, local asymptotic stability is obtained\nwith an explicit domain of attraction, without using a CLF constraint. To deal\nwith vanishing properties of the weight matrix as the state approaches the\nequilibrium, we introduce a hybrid continuous control law that recovers\nSontag's formula locally. The effectiveness of the developed hybrid stabilizing\ncontrol law based on CLFs and CBFs is illustrated in stabilization of a 3D\ntumor model, subject to physiological constraints (i.e., all states must be\npositive), which yields useful insights into optimal cancer treatment design.\n","authors":["Jarne J. H. van Gemert","Mircea Lazar","Siep Weiland"],"pdf_url":"https://arxiv.org/pdf/2403.14226v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14209v1","updated":"2024-03-21T08:01:31Z","published":"2024-03-21T08:01:31Z","title":"Multi Methods of Matrix Analysis Use for Control and Optimization system\n  in Control Engineering","summary":"  Matrix analysis plays a crucial role in the field of control engineering,\nproviding a powerful mathematical framework for the analysis and design of\ncontrol systems. This research report explores various applications of matrix\nanalysis in control engineering, focusing on its contributions to system\nmodeling, stability analysis, controllablity, observability, and optimization.\nThe report also discusses specific examples and case studies to illustrate the\npractical significance of matrix analysis in addressing real-world control\nengineering challenges Analyze controllability. Informally, a system is\ncontrollable if we can construct a set of inputs that will drive the system to\nany given state. Analyze observability. Informally, observability means that by\ncontrolling the inputs and watching the outputs of a system we can determine\nwhat the states were. Optimal Control is a control method that aims to find the\noptimal control input to achieve the best performance of the system under\ncertain constraints. This performance index can be the system output, energy\nconsumption, time, etc.\n","authors":["Si Kheang Moeurn"],"pdf_url":"https://arxiv.org/pdf/2403.14209v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2403.14189v1","updated":"2024-03-21T07:26:17Z","published":"2024-03-21T07:26:17Z","title":"Optimal Scheduling of Uplink-Downlink Networked Control Systems with\n  Energy Harvesting Sensor","summary":"  In this work, we consider a wireless networked control system (WNCS)\nconsisting of a plant, a battery-operated sensor, a controller, and an\nactuator. The battery in the sensor harvests energy from the environment. The\nsensor then uses this energy for packet transmissions. There are two types of\nwireless communication channels, (i) sensor--controller channel (also called\nuplink channel), and (ii) controller--actuator channel (also called downlink\nchannel). The controller is \\emph{half-duplex}, and this prevents it from\nsimultaneously receiving an update from the sensor, and also transmitting a\ncontrol packet to the actuator. Though frequent transmissions via uplink\nchannel improve controller's estimate of the plant state, but this also reduces\nthe timely control of the plant. Hence, in order to strike a balance between\nthese two, we consider the problem of designing an optimal scheduling policy\nthat minimizes the expected cumulative infinite horizon discounted cost, where\nthe instantaneous cost is equal to the square of the plant state. At each time\n$t$, the scheduler at the sensor has to decide whether it should activate the\nuplink channel, or downlink. We pose this dynamic optimization problem as a\nMarkov decision process (MDP), in which the state at time $t$ is composed of\n(i) the plant state $x(t)$, (ii) the age of the data packet available at the\ncontroller, denoted by $\\tau(t)$, (iii) a binary variable $y(t)$ which\nindicates the availability of a control packet at the controller, and (iv) the\nenergy level of the battery at the sensor $b(t)$. We show that there exists an\noptimal scheduling policy that exhibits a threshold structure, meaning that for\neach time $t$, if there is a control packet available with the controller, then\nthe sensor activates the downlink channel in case $|x(t)|$ exceeds a threshold\n$x\\ust(\\tau(t),b(t))$.\n","authors":["Manali Dutta","Rahul Singh"],"pdf_url":"https://arxiv.org/pdf/2403.14189v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14184v1","updated":"2024-03-21T07:20:14Z","published":"2024-03-21T07:20:14Z","title":"Conservative Linear Envelopes for High-Dimensional, Hamilton-Jacobi\n  Reachability for Nonlinear Systems via the Hopf Formula","summary":"  Hamilton-Jacobi reachability (HJR) analysis provides a value function that\nencodes (1) the set of states from which a nonlinear system with bounded\ncontrol inputs can reach a goal (or avoid a failure set) despite any bounded\ndisturbance, and (2) the corresponding optimal control policy to reach (or\navoid). Though powerful, traditional methods for HJR rely on dynamic\nprogramming and suffer from exponential computation growth with respect to\nstate dimension. The recently favored Hopf formula mitigates this ''curse of\ndimensionality'' by providing an efficient and space-parallelizable approach\nfor solving the reachability problem. However, the Hopf formula can only be\napplied to linear time-varying systems. To overcome this limitation, we show\nthat the error between a nonlinear system and a linear model can be transformed\ninto an adversarial bounded artificial disturbance, making an envelope of the\ntrue value. One may then solve the dimension-robust Hopf formula for a linear\ngame with this ''antagonistic error\" to perform guaranteed conservative\nreachability analysis and control synthesis of nonlinear systems; this can be\ndone for problem formulations in which no other HJR method is both\ncomputationally feasible and guaranteed. In addition, we offer several\ntechnical methods for reducing conservativeness in the analysis. We demonstrate\nthe theory by solving the safe linear envelope in the controlled Van der Pol\nsystem, where the true reachable set may be observed, and by solving a 5 agent\n(15D) pursuit-evasion game with Dubins cars.\n","authors":["Will Sharpless","Yat Tin Chow","Sylvia Herbert"],"pdf_url":"https://arxiv.org/pdf/2403.14184v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14159v1","updated":"2024-03-21T06:23:38Z","published":"2024-03-21T06:23:38Z","title":"Robust Locomotion via Zero-order Stochastic Nonlinear Model Predictive\n  Control with Guard Saltation Matrix","summary":"  This paper presents a stochastic/robust nonlinear model predictive control\n(NMPC) to enhance the robustness of legged locomotion against contact\nuncertainties. We integrate the contact uncertainties into the covariance\npropagation of stochastic/robust NMPC framework by leveraging the guard\nsaltation matrix and an extended Kalman filter-like covariance update. We\nachieve fast stochastic/robust NMPC computation by utilizing the zero-order\nstochastic/robust NMPC algorithm with additional improvements in computational\nefficiency concerning the feedback gains. We conducted numerical experiments\nand demonstrate that the proposed method can accurately forecast future state\ncovariance and generate trajectories that satisfies constraints even in the\npresence of the contact uncertainties. Hardware experiments on the perceptive\nlocomotion of a wheeled-legged robot were also carried out, validating the\nfeasibility of the proposed method in a real-world system with limited on-board\ncomputation.\n","authors":["Sotaro Katayama","Noriaki Takasugi","Mitsuhisa Kaneko","Norio Nagatsuka","and Masaya Kinoshita"],"pdf_url":"https://arxiv.org/pdf/2403.14159v1.pdf","comment":"8 pages, 8 figures"},{"id":"http://arxiv.org/abs/2308.07812v3","updated":"2024-03-21T04:16:41Z","published":"2023-08-15T14:41:17Z","title":"An efficient sieving based secant method for sparse optimization\n  problems with least-squares constraints","summary":"  In this paper, we propose an efficient sieving based secant method to address\nthe computational challenges of solving sparse optimization problems with\nleast-squares constraints. A level-set method has been introduced in [X. Li,\nD.F. Sun, and K.-C. Toh, SIAM J. Optim., 28 (2018), pp. 1842--1866] that solves\nthese problems by using the bisection method to find a root of a univariate\nnonsmooth equation $\\varphi(\\lambda) = \\varrho$ for some $\\varrho > 0$, where\n$\\varphi(\\cdot)$ is the value function computed by a solution of the\ncorresponding regularized least-squares optimization problem. When the\nobjective function in the constrained problem is a polyhedral gauge function,\nwe prove that (i) for any positive integer $k$, $\\varphi(\\cdot)$ is piecewise\n$C^k$ in an open interval containing the solution $\\lambda^*$ to the equation\n$\\varphi(\\lambda) = \\varrho$; (ii) the Clarke Jacobian of $\\varphi(\\cdot)$ is\nalways positive. These results allow us to establish the essential ingredients\nof the fast convergence rates of the secant method. Moreover, an adaptive\nsieving technique is incorporated into the secant method to effectively reduce\nthe dimension of the level-set subproblems for computing the value of\n$\\varphi(\\cdot)$. The high efficiency of the proposed algorithm is demonstrated\nby extensive numerical results.\n","authors":["Qian Li","Defeng Sun","Yancheng Yuan"],"pdf_url":"https://arxiv.org/pdf/2308.07812v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14109v1","updated":"2024-03-21T03:41:10Z","published":"2024-03-21T03:41:10Z","title":"Reinforcement Learning Design for Quickest Change Detection","summary":"  The field of quickest change detection (QCD) concerns design and analysis of\nalgorithms to estimate in real time the time at which an important event takes\nplace, and identify properties of the post-change behavior. It is shown in this\npaper that approaches based on reinforcement learning (RL) can be adapted based\non any \"surrogate information state\" that is adapted to the observations. Hence\nwe are left to choose both the surrogate information state process and the\nalgorithm. For the former, it is argued that there are many choices available,\nbased on a rich theory of asymptotic statistics for QCD. Two approaches to RL\ndesign are considered: (i) Stochastic gradient descent based on an actor-critic\nformulation. Theory is largely complete for this approach: the algorithm is\nunbiased, and will converge to a local minimum. However, it is shown that\nvariance of stochastic gradients can be very large, necessitating the need for\ncommensurately long run times; (ii) Q-learning algorithms based on a version of\nthe projected Bellman equation. It is shown that the algorithm is stable, in\nthe sense of bounded sample paths, and that a solution to the projected Bellman\nequation exists under mild conditions. Numerical experiments illustrate these\nfindings, and provide a roadmap for algorithm design in more general settings.\n","authors":["Austin Cooper","Sean Meyn"],"pdf_url":"https://arxiv.org/pdf/2403.14109v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14079v1","updated":"2024-03-21T02:04:54Z","published":"2024-03-21T02:04:54Z","title":"Addressing complex boundary conditions of miscible flow and transport in\n  two and three dimensions with application to optimal control","summary":"  We investigate complex boundary conditions of the miscible displacement\nsystem in two and three space dimensions with the commonly-used\nBear-Scheidegger diffusion-dispersion tensor, which describes, e.g., the porous\nmedium flow processes in petroleum reservoir simulation or groundwater\ncontaminant transport. Specifically, we incorporate the no-flux boundary\ncondition for the Darcy velocity to prove that the general no-flux boundary\ncondition for the transport equation is equivalent to the normal derivative\nboundary condition of the concentration, based on which we further prove\nseveral complex boundary conditions by the Bear-Scheidegger tensor and its\nderivative. The derived boundary conditions not only provide new insights and\ndistinct properties of the Bear-Scheidegger diffusion-dispersion tensor, but\naccommodate the coupling and the nonlinearity of the miscible displacement\nsystem and the Bear-Scheidegger tensor in deriving the first-order optimality\ncondition of the corresponding optimal control problem for practical\napplication.\n","authors":["Yiqun Li","Hong Wang","Xiangcheng Zheng"],"pdf_url":"https://arxiv.org/pdf/2403.14079v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14067v1","updated":"2024-03-21T01:30:24Z","published":"2024-03-21T01:30:24Z","title":"Automatic Outlier Rectification via Optimal Transport","summary":"  In this paper, we propose a novel conceptual framework to detect outliers\nusing optimal transport with a concave cost function. Conventional outlier\ndetection approaches typically use a two-stage procedure: first, outliers are\ndetected and removed, and then estimation is performed on the cleaned data.\nHowever, this approach does not inform outlier removal with the estimation\ntask, leaving room for improvement. To address this limitation, we propose an\nautomatic outlier rectification mechanism that integrates rectification and\nestimation within a joint optimization framework. We take the first step to\nutilize an optimal transport distance with a concave cost function to construct\na rectification set in the space of probability distributions. Then, we select\nthe best distribution within the rectification set to perform the estimation\ntask. Notably, the concave cost function we introduced in this paper is the key\nto making our estimator effectively identify the outlier during the\noptimization process. We discuss the fundamental differences between our\nestimator and optimal transport-based distributionally robust optimization\nestimator. finally, we demonstrate the effectiveness and superiority of our\napproach over conventional approaches in extensive simulation and empirical\nanalyses for mean estimation, least absolute regression, and the fitting of\noption implied volatility surfaces.\n","authors":["Jose Blanchet","Jiajin Li","Markus Pelger","Greg Zanotti"],"pdf_url":"https://arxiv.org/pdf/2403.14067v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11737v2","updated":"2024-03-21T00:14:34Z","published":"2023-11-20T12:58:52Z","title":"On the Congruency-Constrained Matroid Base","summary":"  Consider a matroid where all elements are labeled with an element in\n$\\mathbb{Z}$. We are interested in finding a base where the sum of the labels\nis congruent to $g \\pmod m$. We show that this problem can be solved in\n$\\tilde{O}(2^{4m} n r^{5/6})$ time for a matroid with $n$ elements and rank\n$r$, when $m$ is either the product of two primes or a prime power. The\nalgorithm can be generalized to all moduli and, in fact, to all abelian groups\nif a classic additive combinatorics conjecture by Schrijver and Seymour holds\ntrue. We also discuss the optimization version of the problem.\n","authors":["Siyue Liu","Chao Xu"],"pdf_url":"https://arxiv.org/pdf/2311.11737v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.01632v2","updated":"2024-03-21T13:44:02Z","published":"2021-09-03T17:18:36Z","title":"Riemannian preconditioned coordinate descent for low multi-linear rank\n  approximation","summary":"  This paper presents a memory efficient, first-order method for low\nmulti-linear rank approximation of high-order, high-dimensional tensors. In our\nmethod, we exploit the second-order information of the cost function and the\nconstraints to suggest a new Riemannian metric on the Grassmann manifold. We\nuse a Riemmanian coordinate descent method for solving the problem, and also\nprovide a global convergence analysis matching that of the coordinate descent\nmethod in the Euclidean setting. We also show that each step of our method with\nthe unit step-size is actually a step of the orthogonal iteration algorithm.\nExperimental results show the computational advantage of our method for\nhigh-dimensional tensors.\n","authors":["Mohammad Hamed","Reshad Hosseini"],"pdf_url":"https://arxiv.org/pdf/2109.01632v2.pdf","comment":"22 pages, 3 figures"},{"id":"http://arxiv.org/abs/2111.02554v2","updated":"2024-03-21T17:18:11Z","published":"2021-11-03T23:00:40Z","title":"Callable convertible bonds under liquidity constraints and hybrid\n  priorities","summary":"  This paper investigates the callable convertible bond problem in the presence\nof a liquidity constraint modelled by Poisson signals. We assume that neither\nthe bondholder nor the firm has absolute priority when they stop the game\nsimultaneously, but instead, a proportion $m\\in[0,1]$ of the bond is converted\nto the firm's stock and the rest is called by the firm. The paper thus\ngeneralizes the special case studied in [Liang and Sun, Dynkin games with\nPoisson random intervention times, SIAM Journal on Control and Optimization, 57\n(2019), 2962-2991] where the bondholder has priority ($m=1$), and presents a\ncomplete solution to the callable convertible bond problem with liquidity\nconstraint. The callable convertible bond is an example of a Dynkin game, but\nfalls outside the standard paradigm since the payoffs do not depend in an\nordered way upon which agent stops the game. We show how to deal with this\nnon-ordered situation by introducing a new technique which may be of interest\nin its own right, and then apply it to the bond problem.\n","authors":["David Hobson","Gechun Liang","Edward Wang"],"pdf_url":"https://arxiv.org/pdf/2111.02554v2.pdf","comment":"45 pages"},{"id":"http://arxiv.org/abs/2205.14116v3","updated":"2024-03-21T16:14:01Z","published":"2022-05-27T17:28:54Z","title":"Don't Explain Noise: Robust Counterfactuals for Randomized Ensembles","summary":"  Counterfactual explanations describe how to modify a feature vector in order\nto flip the outcome of a trained classifier. Obtaining robust counterfactual\nexplanations is essential to provide valid algorithmic recourse and meaningful\nexplanations. We study the robustness of explanations of randomized ensembles,\nwhich are always subject to algorithmic uncertainty even when the training data\nis fixed. We formalize the generation of robust counterfactual explanations as\na probabilistic problem and show the link between the robustness of ensemble\nmodels and the robustness of base learners. We develop a practical method with\ngood empirical performance and support it with theoretical guarantees for\nensembles of convex base learners. Our results show that existing methods give\nsurprisingly low robustness: the validity of naive counterfactuals is below\n$50\\%$ on most data sets and can fall to $20\\%$ on problems with many features.\nIn contrast, our method achieves high robustness with only a small increase in\nthe distance from counterfactual explanations to their initial observations.\n","authors":["Alexandre Forel","Axel Parmentier","Thibaut Vidal"],"pdf_url":"https://arxiv.org/pdf/2205.14116v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.14098v2","updated":"2024-03-21T22:49:40Z","published":"2023-10-21T19:32:11Z","title":"Stabilizing reinforcement learning control: A modular framework for\n  optimizing over all stable behavior","summary":"  We propose a framework for the design of feedback controllers that combines\nthe optimization-driven and model-free advantages of deep reinforcement\nlearning with the stability guarantees provided by using the Youla-Kucera\nparameterization to define the search domain. Recent advances in behavioral\nsystems allow us to construct a data-driven internal model; this enables an\nalternative realization of the Youla-Kucera parameterization based entirely on\ninput-output exploration data. Perhaps of independent interest, we formulate\nand analyze the stability of such data-driven models in the presence of noise.\nThe Youla-Kucera approach requires a stable \"parameter\" for controller design.\nFor the training of reinforcement learning agents, the set of all stable linear\noperators is given explicitly through a matrix factorization approach.\nMoreover, a nonlinear extension is given using a neural network to express a\nparameterized set of stable operators, which enables seamless integration with\nstandard deep learning libraries. Finally, we show how these ideas can also be\napplied to tune fixed-structure controllers.\n","authors":["Nathan P. Lawrence","Philip D. Loewen","Shuyuan Wang","Michael G. Forbes","R. Bhushan Gopaluni"],"pdf_url":"https://arxiv.org/pdf/2310.14098v2.pdf","comment":"Postprint; 31 pages. arXiv admin note: text overlap with\n  arXiv:2304.03422"},{"id":"http://arxiv.org/abs/2403.14866v1","updated":"2024-03-21T22:21:46Z","published":"2024-03-21T22:21:46Z","title":"Joint Planning of Charging Stations and Power Systems for Heavy-Duty\n  Drayage Trucks","summary":"  As global concerns about climate change intensify, the transition towards\nzero-emission freight is becoming increasingly vital. Drayage is an important\nsegment of the freight system, typically involving the transport of goods from\nseaports or intermodal terminals to nearby warehouses. This sector\nsignificantly contributes to not only greenhouse gas emissions, but also\npollution in densely populated areas. This study presents a holistic\noptimization model designed for an efficient transition to zero-emission\ndrayage, offering cost-effective strategies for the coordinated investment\nplanning for power systems, charging infrastructure, and electric drayage\ntrucks. The model is validated in the Greater Los Angeles area, where\nregulatory goals are among the most ambitious. Furthermore, the model's design\nallows for easy adaptation to other regions. By focusing on drayage trucks,\nthis study also paves the way for future research into other freight\ncategories, establishing a foundation for a more extensive exploration in this\nfield.\n","authors":["Zuzhao Ye","Nanpeng Yu","Ran Wei"],"pdf_url":"https://arxiv.org/pdf/2403.14866v1.pdf","comment":"34 pages, 10 figures"},{"id":"http://arxiv.org/abs/2208.13276v4","updated":"2024-03-21T22:08:28Z","published":"2022-08-28T19:39:55Z","title":"Mean viability theorems and second-order Hamilton-Jacobi equations","summary":"  We introduce the notion of mean viability for controlled stochastic\ndifferential equations and establish counterparts of Nagumo's classical\nviability theorems (necessary and sufficient conditions for mean viability). As\nan application, we provide a purely probabilistic proof of a comparison\nprinciple and of existence for contingent and viscosity solutions of\nsecond-order fully nonlinear path-dependent Hamilton-Jacobi-Bellman equations.\nWe do not use compactness and optimal stopping arguments, which are usually\nemployed in the literature on viscosity solutions for second-order\npath-dependent PDEs.\n","authors":["Christian Keller"],"pdf_url":"https://arxiv.org/pdf/2208.13276v4.pdf","comment":"28 pages, to appear in SIAM Journal on Control and Optimization"},{"id":"http://arxiv.org/abs/2307.12943v4","updated":"2024-03-21T20:59:59Z","published":"2023-07-24T17:15:38Z","title":"Gaussian Cooling and Dikin Walks: The Interior-Point Method for\n  Logconcave Sampling","summary":"  The connections between (convex) optimization and (logconcave) sampling have\nbeen considerably enriched in the past decade with many conceptual and\nmathematical analogies. For instance, the Langevin algorithm can be viewed as a\nsampling analogue of gradient descent and has condition-number-dependent\nguarantees on its performance. In the early 1990s, Nesterov and Nemirovski\ndeveloped the Interior-Point Method (IPM) for convex optimization based on\nself-concordant barriers, providing efficient algorithms for structured convex\noptimization, often faster than the general method. This raises the following\nquestion: can we develop an analogous IPM for structured sampling problems?\n  In 2012, Kannan and Narayanan proposed the Dikin walk for uniformly sampling\npolytopes, and an improved analysis was given in 2020 by Laddha-Lee-Vempala.\nThe Dikin walk uses a local metric defined by a self-concordant barrier for\nlinear constraints. Here we generalize this approach by developing and adapting\nIPM machinery together with the Dikin walk for poly-time sampling algorithms.\nOur IPM-based sampling framework provides an efficient warm start and goes\nbeyond uniform distributions and linear constraints. We illustrate the approach\non important special cases, in particular giving the fastest algorithms to\nsample uniform, exponential, or Gaussian distributions on a truncated PSD cone.\nThe framework is general and can be applied to other sampling algorithms.\n","authors":["Yunbum Kook","Santosh S. Vempala"],"pdf_url":"https://arxiv.org/pdf/2307.12943v4.pdf","comment":"Improved writing with minor errors fixed"},{"id":"http://arxiv.org/abs/2403.04860v2","updated":"2024-03-21T20:58:25Z","published":"2024-03-07T19:18:33Z","title":"The stochastic Ravine accelerated gradient method with general\n  extrapolation coefficients","summary":"  In a real Hilbert space domain setting, we study the convergence properties\nof the stochastic Ravine accelerated gradient method for convex differentiable\noptimization. We consider the general form of this algorithm where the\nextrapolation coefficients can vary with each iteration, and where the\nevaluation of the gradient is subject to random errors. This general treatment\nmodels a breadth of practical algorithms and numerical implementations. We show\nthat, under a proper tuning of the extrapolation parameters, and when the error\nvariance associated with the gradient evaluations or the step-size sequences\nvanish sufficiently fast, the Ravine method provides fast convergence of the\nvalues both in expectation and almost surely. We also improve the convergence\nrates from O(.) to o(.). Moreover, we show almost sure summability property of\nthe gradients, which implies the fast convergence of the gradients towards\nzero. This property reflects the fact that the high-resolution ODE of the\nRavine method includes a Hessian-driven damping term. When the space is also\nseparable, our analysis allows also to establish almost sure weak convergence\nof the sequence of iterates provided by the algorithm. We finally specialize\nthe analysis to consider different parameter choices, including vanishing and\nconstant (heavy ball method with friction) damping parameter, and present a\ncomprehensive landscape of the tradeoffs in speed and accuracy associated with\nthese parameter choices and statistical properties on the sequence of errors in\nthe gradient computations. We provide a thorough discussion of the similarities\nand differences with the Nesterov accelerated gradient which satisfies similar\nasymptotic convergence rates.\n","authors":["Hedy Attouch","Jalal Fadili","Vyacheslav Kungurtsev"],"pdf_url":"https://arxiv.org/pdf/2403.04860v2.pdf","comment":"The insight and motivation for the study of the Ravine method and\n  many of the derivations were the work of our beloved friend and colleague\n  Hedy Attouch. As one of the final contributions of his long and illustrious\n  career before his unfortunate recent departure, the other authors hope that\n  the polished manuscript is an appreciated step in honoring his legacy"},{"id":"http://arxiv.org/abs/2304.03765v4","updated":"2024-03-21T20:42:20Z","published":"2023-04-07T17:58:19Z","title":"Markov Decision Process Design: A Framework for Integrating Strategic\n  and Operational Decisions","summary":"  We consider the problem of optimally designing a system for repeated use\nunder uncertainty. We develop a modeling framework that integrates design and\noperational phases, which are represented by a mixed-integer program and\ndiscounted-cost infinite-horizon Markov decision processes, respectively. We\nseek to simultaneously minimize the design costs and the subsequent expected\noperational costs. This problem setting arises naturally in several application\nareas, as we illustrate through examples. We derive a bilevel mixed-integer\nlinear programming formulation for the problem and perform a computational\nstudy to demonstrate that realistic instances can be solved numerically.\n","authors":["Seth Brown","Saumya Sinha","Andrew J Schaefer"],"pdf_url":"https://arxiv.org/pdf/2304.03765v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14822v1","updated":"2024-03-21T20:29:43Z","published":"2024-03-21T20:29:43Z","title":"Non-Convex Robust Hypothesis Testing using Sinkhorn Uncertainty Sets","summary":"  We present a new framework to address the non-convex robust hypothesis\ntesting problem, wherein the goal is to seek the optimal detector that\nminimizes the maximum of worst-case type-I and type-II risk functions. The\ndistributional uncertainty sets are constructed to center around the empirical\ndistribution derived from samples based on Sinkhorn discrepancy. Given that the\nobjective involves non-convex, non-smooth probabilistic functions that are\noften intractable to optimize, existing methods resort to approximations rather\nthan exact solutions. To tackle the challenge, we introduce an exact\nmixed-integer exponential conic reformulation of the problem, which can be\nsolved into a global optimum with a moderate amount of input data.\nSubsequently, we propose a convex approximation, demonstrating its superiority\nover current state-of-the-art methodologies in literature. Furthermore, we\nestablish connections between robust hypothesis testing and regularized\nformulations of non-robust risk functions, offering insightful interpretations.\nOur numerical study highlights the satisfactory testing performance and\ncomputational efficiency of the proposed framework.\n","authors":["Jie Wang","Rui Gao","Yao Xie"],"pdf_url":"https://arxiv.org/pdf/2403.14822v1.pdf","comment":"26 pages, 2 figures"},{"id":"http://arxiv.org/abs/2112.04160v2","updated":"2024-03-21T20:09:09Z","published":"2021-12-08T08:17:44Z","title":"A Finitely Convergent Cutting Plane, and a Bender's Decomposition\n  Algorithm for Mixed-Integer Convex and Two-Stage Convex Programs using\n  Cutting Planes","summary":"  We present a finitely convergent cutting-plane algorithm for solving a\ngeneral mixed-integer convex programs given an oracle for solving general\nconvex programs. This method is extended to solve a family of two-stage\nmixed-integer convex programs using cutting planes, with applications to\nsolving distributionally-robust two-stage stochastic mixed-integer convex\nprograms. Since algorithms purely using cutting planes are not very practical\nfor implementation, we combined the cut generation with a branch-and-union\nscheme to develop a more practical algorithm. Analysis is also given for the\ncase where convex programming oracle provides an $\\epsilon-$optimal solution.\nComputational results on generated test problems show the practicality of our\nalgorithm. Specifically, results show that addition of cuts speed up solution\ntimes by nearly 10-fold on the largest test problems that are solved.\n","authors":["Fengqiao Luo","Sanjay Mehrotra"],"pdf_url":"https://arxiv.org/pdf/2112.04160v2.pdf","comment":"50 pages, 2 tables and 1 figure"},{"id":"http://arxiv.org/abs/2208.10360v4","updated":"2024-03-21T20:01:11Z","published":"2022-08-22T14:40:42Z","title":"On Some Mean Field Games and Master Equations through the lens of\n  conservation laws","summary":"  In this manuscript we derive a new nonlinear transport equation written on\nthe space of probability measures that allows to study a class of deterministic\nmean field games and master equations, where the interaction of the agents\nhappens only at the terminal time. The point of view via this transport\nequation has two important consequences. First, this equation reveals a new\nmonotonicity condition that is sufficient both for the uniqueness of MFG Nash\nequilibria and for the global in time well-posedness of master equations.\nInterestingly, this condition is in general in dichotomy with both the\nLasry--Lions and displacement monotonicity conditions, studied so far in the\nliterature. Second, in the absence of monotonicity, the conservative form of\nthe transport equation can be used to define weak entropy solutions to the\nmaster equation. We construct several concrete examples to demonstrate that MFG\nNash equilibria, whether or not they actually exist, may not be selected by the\nentropy solutions of the master equation.\n","authors":["P. Jameson Graber","Alpár R. Mészáros"],"pdf_url":"https://arxiv.org/pdf/2208.10360v4.pdf","comment":"final version; to appear in Math. Ann"},{"id":"http://arxiv.org/abs/2403.14792v1","updated":"2024-03-21T19:13:15Z","published":"2024-03-21T19:13:15Z","title":"CASPER: Carbon-Aware Scheduling and Provisioning for Distributed Web\n  Services","summary":"  There has been a significant societal push towards sustainable practices,\nincluding in computing. Modern interactive workloads such as geo-distributed\nweb-services exhibit various spatiotemporal and performance flexibility,\nenabling the possibility to adapt the location, time, and intensity of\nprocessing to align with the availability of renewable and low-carbon energy.\nAn example is a web application hosted across multiple cloud regions, each with\nvarying carbon intensity based on their local electricity mix. Distributed\nload-balancing enables the exploitation of low-carbon energy through load\nmigration across regions, reducing web applications carbon footprint. In this\npaper, we present CASPER, a carbon-aware scheduling and provisioning system\nthat primarily minimizes the carbon footprint of distributed web services while\nalso respecting their Service Level Objectives (SLO). We formulate CASPER as an\nmulti-objective optimization problem that considers both the variable carbon\nintensity and latency constraints of the network. Our evaluation reveals the\nsignificant potential of CASPER in achieving substantial reductions in carbon\nemissions. Compared to baseline methods, CASPER demonstrates improvements of up\nto 70% with no latency performance degradation.\n","authors":["Abel Souza","Shruti Jasoria","Basundhara Chakrabarty","Alexander Bridgwater","Axel Lundberg","Filip Skogh","Ahmed Ali-Eldin","David Irwin","Prashant Shenoy"],"pdf_url":"https://arxiv.org/pdf/2403.14792v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.10326v2","updated":"2024-03-21T12:54:04Z","published":"2024-02-15T21:01:29Z","title":"Mathematical Opportunities in Digital Twins (MATH-DT)","summary":"  The report describes the discussions from the Workshop on Mathematical\nOpportunities in Digital Twins (MATH-DT) from December 11-13, 2023, George\nMason University.\n  It illustrates that foundational Mathematical advances are required for\nDigital Twins (DTs) that are different from traditional approaches. A\ntraditional model, in biology, physics, engineering or medicine, starts with a\ngeneric physical law (e.g., equations) and is often a simplification of\nreality. A DT starts with a specific ecosystem, object or person (e.g.,\npersonalized care) representing reality, requiring multi -scale, -physics\nmodeling and coupling. Thus, these processes begin at opposite ends of the\nsimulation and modeling pipeline, requiring different reliability criteria and\nuncertainty assessments. Additionally, unlike existing approaches, a DT assists\nhumans to make decisions for the physical system, which (via sensors) in turn\nfeeds data into the DT, and operates for the life of the physical system.\n  While some of the foundational mathematical research can be done without a\nspecific application context, one must also keep specific applications in mind\nfor DTs. E.g., modeling a bridge or a biological system (a patient), or a\nsocio-technical system (a city) is very different. The models range from\ndifferential equations (deterministic/uncertain) in engineering, to stochastic\nin biology, including agent-based. These are multi-scale hybrid models or large\nscale (multi-objective) optimization problems under uncertainty. There are no\nuniversal models or approaches. For e.g., Kalman filters for forecasting might\nwork in engineering, but can fail in biomedical domain. Ad hoc studies, with\nlimited systematic work, have shown that AI/ML methods can fail for simple\nengineering systems and can work well for biomedical problems.\n  A list of `Mathematical Opportunities and Challenges' concludes the report.\n","authors":["Harbir Antil"],"pdf_url":"https://arxiv.org/pdf/2402.10326v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.11035v2","updated":"2024-03-21T21:00:00Z","published":"2021-10-21T10:23:01Z","title":"Optimal First-Order Algorithms as a Function of Inequalities","summary":"  In this work, we present a novel algorithm design methodology that finds the\noptimal algorithm as a function of inequalities. Specifically, we restrict\nconvergence analyses of algorithms to use a prespecified subset of\ninequalities, rather than utilizing all true inequalities, and find the optimal\nalgorithm subject to this restriction. This methodology allows us to design\nalgorithms with certain desired characteristics. As concrete demonstrations of\nthis methodology, we find new state-of-the-art accelerated first-order gradient\nmethods using randomized coordinate updates and backtracking line searches.\n","authors":["Chanwoo Park","Ernest K. Ryu"],"pdf_url":"https://arxiv.org/pdf/2110.11035v2.pdf","comment":null}],"Systems and Control":[{"id":"http://arxiv.org/abs/2403.14605v1","updated":"2024-03-21T17:54:56Z","published":"2024-03-21T17:54:56Z","title":"SDP Synthesis of Maximum Coverage Trees for Probabilistic Planning under\n  Control Constraints","summary":"  The paper presents Maximal Covariance Backward Reachable Trees (MAXCOVAR\nBRT), which is a multi-query algorithm for planning of dynamic systems under\nstochastic motion uncertainty and constraints on the control input with\nexplicit coverage guarantees. In contrast to existing roadmap-based\nprobabilistic planning methods that sample belief nodes randomly and draw edges\nbetween them \\cite{csbrm_tro2024}, under control constraints, the reachability\nof belief nodes needs to be explicitly established and is determined by\nchecking the feasibility of a non-convex program. Moreover, there is no\nexplicit consideration of coverage of the roadmap while adding nodes and edges\nduring the construction procedure for the existing methods. Our contribution is\na novel optimization formulation to add nodes and construct the corresponding\nedge controllers such that the generated roadmap results in provably maximal\ncoverage under control constraints as compared to any other method of adding\nnodes and edges. We characterize formally the notion of coverage of a roadmap\nin this stochastic domain via introduction of the h-$\\operatorname{BRS}$\n(Backward Reachable Set of Distributions) of a tree of distributions under\ncontrol constraints, and also support our method with extensive simulations on\na 6 DoF model.\n","authors":["Naman Aggarwal","Jonathan P. How"],"pdf_url":"https://arxiv.org/pdf/2403.14605v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14545v1","updated":"2024-03-21T16:44:49Z","published":"2024-03-21T16:44:49Z","title":"Learning Hierarchical Control For Constrained Dynamic Task Assignment","summary":"  This paper introduces a novel data-driven hierarchical control scheme for\nmanaging a fleet of nonlinear, capacity-constrained autonomous agents in an\niterative environment. We propose a control framework consisting of a\nhigh-level dynamic task assignment and routing layer and low-level motion\nplanning and tracking layer. Each layer of the control hierarchy uses a\ndata-driven MPC policy, maintaining bounded computational complexity at each\ncalculation of a new task assignment or actuation input. We utilize collected\ndata to iteratively refine estimates of agent capacity usage, and update MPC\npolicy parameters accordingly. Our approach leverages tools from iterative\nlearning control to integrate learning at both levels of the hierarchy, and\ncoordinates learning between levels in order to maintain closed-loop\nfeasibility and performance improvement of the connected architecture.\n","authors":["Charlott Vallon","Alessandro Pinto","Bartolomeo Stellato","Francesco Borrelli"],"pdf_url":"https://arxiv.org/pdf/2403.14545v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14536v1","updated":"2024-03-21T16:38:10Z","published":"2024-03-21T16:38:10Z","title":"Learning Hierarchical Control Systems for Autonomous Systems with Energy\n  Constraints","summary":"  This paper focuses on the design of hierarchical control architectures for\nautonomous systems with energy constraints. We focus on systems where energy\nstorage limitations and slow recharge rates drastically affect the way the\nautonomous systems are operated. Using examples from space robotics and public\ntransportation, we motivate the need for formally designed learning\nhierarchical control systems. We propose a learning control architecture which\nincorporates learning mechanisms at various levels of the control hierarchy to\nimprove performance and resource utilization. The proposed hierarchical control\nscheme relies on high-level energy-aware task planning and assignment,\ncomplemented by a low-level predictive control mechanism responsible for the\nautonomous execution of tasks, including motion control and energy management.\nSimulation examples show the benefits and the limitations of the proposed\narchitecture when learning is used to obtain a more energy-efficient task\nallocation.\n","authors":["Charlott Vallon","Mark Pustilnik","Alessandro Pinto","Francesco Borrelli"],"pdf_url":"https://arxiv.org/pdf/2403.14536v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14525v1","updated":"2024-03-21T16:25:41Z","published":"2024-03-21T16:25:41Z","title":"Optimizing queues with deadlines under infrequent monitoring","summary":"  In this paper, we aim to improve the percentage of packets meeting their\ndeadline in discrete-time M/M/1 queues with infrequent monitoring. More\nspecifically, we look into policies that only monitor the system (and\nsubsequently take actions) after a packet arrival. We model the system as an\nMDP and provide the optimal policy for some special cases. Furthermore, we\nintroduce a heuristic algorithm called \"AB-n\" for general deadlines. Finally,\nwe provide numerical results demonstrating the desirable performance of \"AB-n\"\npolicies.\n","authors":["Faraz Farahvash","Ao Tang"],"pdf_url":"https://arxiv.org/pdf/2403.14525v1.pdf","comment":"11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2403.14519v1","updated":"2024-03-21T16:17:39Z","published":"2024-03-21T16:17:39Z","title":"Designing Robust Linear Output Feedback Controller based on CLF-CBF\n  framework via Linear~Programming(LP-CLF-CBF)","summary":"  We consider the problem of designing output feedback controllers that use\nmeasurements from a set of landmarks to navigate through a cell-decomposable\nenvironment using duality, Control Lyapunov and Barrier Functions (CLF, CBF),\nand Linear Programming. We propose two objectives for navigating in an\nenvironment, one to traverse the environment by making loops and one by\nconverging to a stabilization point while smoothing the transition between\nconsecutive cells. We test our algorithms in a simulation environment,\nevaluating the robustness of the approach to practical conditions, such as\nbearing-only measurements, and measurements acquired with a camera with a\nlimited field of view.\n","authors":["Mahroo Bahreinian","Mehdi Kermanshah","Roberto Tron"],"pdf_url":"https://arxiv.org/pdf/2403.14519v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2203.04416"},{"id":"http://arxiv.org/abs/2403.14508v1","updated":"2024-03-21T16:02:52Z","published":"2024-03-21T16:02:52Z","title":"Constrained Reinforcement Learning with Smoothed Log Barrier Function","summary":"  Reinforcement Learning (RL) has been widely applied to many control tasks and\nsubstantially improved the performances compared to conventional control\nmethods in many domains where the reward function is well defined. However, for\nmany real-world problems, it is often more convenient to formulate optimization\nproblems in terms of rewards and constraints simultaneously. Optimizing such\nconstrained problems via reward shaping can be difficult as it requires tedious\nmanual tuning of reward functions with several interacting terms. Recent\nformulations which include constraints mostly require a pre-training phase,\nwhich often needs human expertise to collect data or assumes having a\nsub-optimal policy readily available. We propose a new constrained RL method\ncalled CSAC-LB (Constrained Soft Actor-Critic with Log Barrier Function), which\nachieves competitive performance without any pre-training by applying a linear\nsmoothed log barrier function to an additional safety critic. It implements an\nadaptive penalty for policy learning and alleviates the numerical issues that\nare known to complicate the application of the log barrier function method. As\na result, we show that with CSAC-LB, we achieve state-of-the-art performance on\nseveral constrained control tasks with different levels of difficulty and\nevaluate our methods in a locomotion task on a real quadruped robot platform.\n","authors":["Baohe Zhang","Yuan Zhang","Lilli Frison","Thomas Brox","Joschka Bödecker"],"pdf_url":"https://arxiv.org/pdf/2403.14508v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14500v1","updated":"2024-03-21T15:52:49Z","published":"2024-03-21T15:52:49Z","title":"Meta-learning of data-driven controllers with automatic model reference\n  tuning: theory and experimental case study","summary":"  Data-driven control offers a viable option for control scenarios where\nconstructing a system model is expensive or time-consuming. Nonetheless, many\nof these algorithms are not entirely automated, often necessitating the\nadjustment of multiple hyperparameters through cumbersome trial-and-error\nprocesses and demanding significant amounts of data. In this paper, we explore\na meta-learning approach to leverage potentially existing prior knowledge about\nanalogous (though not identical) systems, aiming to reduce both the\nexperimental workload and ease the tuning of the available degrees of freedom.\nWe validate this methodology through an experimental case study involving the\ntuning of proportional, integral (PI) controllers for brushless DC (BLDC)\nmotors with variable loads and architectures.\n","authors":["Riccardo Busetto","Valentina Breschi","Federica Baracchi","Simone Formentin"],"pdf_url":"https://arxiv.org/pdf/2403.14500v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.03133v2","updated":"2024-03-21T15:18:20Z","published":"2023-04-06T15:06:28Z","title":"Deep learning reduces sensor requirements for gust rejection on a small\n  uncrewed aerial vehicle morphing wing","summary":"  There is a growing need for uncrewed aerial vehicles (UAVs) to operate in\ncities. However, the uneven urban landscape and complex street systems cause\nlarge-scale wind gusts that challenge the safe and effective operation of UAVs.\nCurrent gust alleviation methods rely on traditional control surfaces and\ncomputationally expensive modeling to select a control action, leading to a\nslower response. Here, we used deep reinforcement learning to create an\nautonomous gust alleviation controller for a camber-morphing wing. This method\nreduced gust impact by 84%, directly from real-time, on-board pressure signals.\nNotably, we found that gust alleviation using signals from only three pressure\ntaps was statistically indistinguishable from using six signals. This\nreduced-sensor fly-by-feel control opens the door to UAV missions in previously\ninoperable locations.\n","authors":["Kevin PT. Haughn","Christina Harvey","Daniel J. Inman"],"pdf_url":"https://arxiv.org/pdf/2304.03133v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14464v1","updated":"2024-03-21T15:13:05Z","published":"2024-03-21T15:13:05Z","title":"Synthesizing Controller for Safe Navigation using Control Density\n  Function","summary":"  We consider the problem of navigating a nonlinear dynamical system from some\ninitial set to some target set while avoiding collision with an unsafe set. We\nextend the concept of density function to control density function (CDF) for\nsolving navigation problems with safety constraints. The occupancy-based\ninterpretation of the measure associated with the density function is\ninstrumental in imposing the safety constraints. The navigation problem with\nsafety constraints is formulated as a quadratic program (QP) using CDF. The\nexisting approach using the control barrier function (CBF) also formulates the\nnavigation problem with safety constraints as QP. One of the main advantages of\nthe proposed QP using CDF compared to QP formulated using CBF is that both the\nconvergence/stability and safety can be combined and imposed using the CDF.\nSimulation results involving the Duffing oscillator and safe navigation of\nDubin car models are provided to verify the main findings of the paper.\n","authors":["Joseph Moyalan","Sriram S. K. S Narayanan","Andrew Zheng","Umesh Vaidya"],"pdf_url":"https://arxiv.org/pdf/2403.14464v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14432v1","updated":"2024-03-21T14:39:28Z","published":"2024-03-21T14:39:28Z","title":"On the continuity and smoothness of the value function in reinforcement\n  learning and optimal control","summary":"  The value function plays a crucial role as a measure for the cumulative\nfuture reward an agent receives in both reinforcement learning and optimal\ncontrol. It is therefore of interest to study how similar the values of\nneighboring states are, i.e., to investigate the continuity of the value\nfunction. We do so by providing and verifying upper bounds on the value\nfunction's modulus of continuity. Additionally, we show that the value function\nis always H\\\"older continuous under relatively weak assumptions on the\nunderlying system and that non-differentiable value functions can be made\ndifferentiable by slightly \"disturbing\" the system.\n","authors":["Hans Harder","Sebastian Peitz"],"pdf_url":"https://arxiv.org/pdf/2403.14432v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14386v1","updated":"2024-03-21T13:24:24Z","published":"2024-03-21T13:24:24Z","title":"Exploiting Over-The-Air Consensus for Collision Avoidance and Formation\n  Control in Multi-Agent Systems","summary":"  This paper introduces a distributed control method for multi-agent robotic\nsystems employing Over the Air Consensus (OTA-Consensus). Designed for agents\nwith decoupled single-integrator dynamics, this approach aims at efficient\nformation achievement and collision avoidance. As a distinctive feature, it\nleverages OTA's ability to exploit interference in wireless channels, a\nproperty traditionally considered a drawback, thus enhancing communication\nefficiency among robots. An analytical proof of asymptotic convergence is\nestablished for systems with time-varying communication topologies represented\nby sequences of strongly connected directed graphs. Comparative evaluations\ndemonstrate significant efficiency improvements over current state-of-the-art\nmethods, especially in scenarios with a large number of agents.\n","authors":["Michael Epp","Fabio Molinari","Joerg Raisch"],"pdf_url":"https://arxiv.org/pdf/2403.14386v1.pdf","comment":"Submitted to CDC 2024"},{"id":"http://arxiv.org/abs/2403.13502v2","updated":"2024-03-21T13:18:47Z","published":"2024-03-20T10:59:06Z","title":"Adversarial Attacks and Defenses in Automated Control Systems: A\n  Comprehensive Benchmark","summary":"  Integrating machine learning into Automated Control Systems (ACS) enhances\ndecision-making in industrial process management. One of the limitations to the\nwidespread adoption of these technologies in industry is the vulnerability of\nneural networks to adversarial attacks. This study explores the threats in\ndeploying deep learning models for fault diagnosis in ACS using the Tennessee\nEastman Process dataset. By evaluating three neural networks with different\narchitectures, we subject them to six types of adversarial attacks and explore\nfive different defense methods. Our results highlight the strong vulnerability\nof models to adversarial samples and the varying effectiveness of defense\nstrategies. We also propose a novel protection approach by combining multiple\ndefense methods and demonstrate it's efficacy. This research contributes\nseveral insights into securing machine learning within ACS, ensuring robust\nfault diagnosis in industrial processes.\n","authors":["Vitaliy Pozdnyakov","Aleksandr Kovalenko","Ilya Makarov","Mikhail Drobyshevskiy","Kirill Lukyanov"],"pdf_url":"https://arxiv.org/pdf/2403.13502v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14373v1","updated":"2024-03-21T13:05:16Z","published":"2024-03-21T13:05:16Z","title":"A new control-oriented METANET model to encompass service stations on\n  highways","summary":"  In this paper, we propose the METANET with service station (METANET-s) model,\na second-order macroscopic traffic model that, compared to the classical\nMETANET, incorporates the dynamics of service stations on highways.\nSpecifically, we employ the (so-called) store-and-forward links to model the\nstop of vehicles and the possible queue forming in the process of merging back\ninto the highway mainstream. We explore the capability of the METANET-s to\ncapture well both traffic back propagation and capacity drops, which are\ntypically caused by the presence of vehicles joining again the mainstream\ntraffic from the service station. Therefore, capturing these effects is crucial\nto improving the model's predictive capabilities. Finally, we perform a\ncomparative analysis with the Cell Transmission Model with service station\n(CTM-s), showcasing that the METANET-s describes the traffic evolution much\nbetter than its first-order counterpart.\n","authors":["Ayda Kamalifar","Carlo Cenedese","Michele Cucuzzella","Antonella Ferrara"],"pdf_url":"https://arxiv.org/pdf/2403.14373v1.pdf","comment":"7 pages, 4 figures, to be published in European Control Conference\n  (ECC) 2024"},{"id":"http://arxiv.org/abs/2403.14372v1","updated":"2024-03-21T13:02:14Z","published":"2024-03-21T13:02:14Z","title":"A Benchmark for the Application of Distributed Control Techniques to the\n  Electricity Network of the European Economic Area","summary":"  The European Economic Area Electricity Network Benchmark (EEA-ENB) is a\nmulti-area power system representing the European network of transmission\nsystems for electricity to facilitate the application of distributed control\ntechniques. In the EEA-ENB we consider the Load Frequency Control (LFC) problem\nin the presence of renewable energy sources (RESs), and energy storage systems\n(ESSs). RESs are known to cause instability in power networks due to their\ninertia-less and intermittent characteristics, while ESSs are introduced as a\nresource to mitigate the problem. In the EEA-ENB, particular attention is\ndedicated to Distributed Model Predictive Control (DMPC), whose application is\noften limited to small and homogeneous test cases due to the lack of\nstandardized large-scale scenarios for testing, and due to the large\ncomputation time required to obtain a centralized MPC action for performance\ncomparison with DMPC strategies under consideration. The second problem is\nexacerbated when the scale of the system grows. To address these challenges and\nto provide a real-world-based and control-independent benchmark, the EEA-ENB\nhas been developed. The benchmark includes a centralized MPC strategy providing\nperformance and computation time metrics to compare distributed control within\na repeatable and realistic simulation environment.\n","authors":["A. Riccardi","L. Laurenti","B. De Schutter"],"pdf_url":"https://arxiv.org/pdf/2403.14372v1.pdf","comment":"20 pages, 19 figures, 22 references, book chapter"},{"id":"http://arxiv.org/abs/2403.14369v1","updated":"2024-03-21T12:56:11Z","published":"2024-03-21T12:56:11Z","title":"A Control Barrier Function Composition Approach for Multi-Agent Systems\n  in Marine Applications","summary":"  The agents within a multi-agent system (MAS) operating in marine environments\noften need to utilize task payloads and avoid collisions in coordination,\nnecessitating adherence to a set of relative-pose constraints, which may\ninclude field-of-view, line-of-sight, collision-avoidance, and range\nconstraints. A nominal controller designed for reference tracking may not\nguarantee the marine MAS stays safe w.r.t. these constraints. To modify the\nnominal input as one that enforces safety, we introduce a framework to\nsystematically encode the relative-pose constraints as nonsmooth control\nbarrier functions (NCBFs) and combine them as a single NCBF using Boolean\ncomposition, which enables a simplified verification process compared to using\nthe NCBFs individually. While other relative-pose constraint functions have\nexplicit derivatives, the challenging line-of-sight constraint is encoded with\nthe minimum distance function between the line-of-sight set and other agents,\nwhose derivative is not explicit. Hence, existing safe control design methods\nthat consider composite NCBFs cannot be applied. To address this challenge, we\npropose a novel quadratic program formulation based on the dual of the minimum\ndistance problem and develop a new theory to ensure the resulting control input\nguarantees constraint satisfaction. Lastly, we validate the effectiveness of\nour proposed framework on a simulated large-scale marine MAS and a real-world\nmarine MAS comprising one Unmanned Surface Vehicle and two Unmanned Underwater\nVehicles.\n","authors":["Yujia Yang","Chris Manzie","Ye Pu"],"pdf_url":"https://arxiv.org/pdf/2403.14369v1.pdf","comment":"11 pages, 8 figures"},{"id":"http://arxiv.org/abs/2403.14310v1","updated":"2024-03-21T11:32:10Z","published":"2024-03-21T11:32:10Z","title":"Transformation-Free Fixed-Structure Model Reduction for LPV Systems","summary":"  In this paper, we propose a model reduction technique for linear parameter\nvarying (LPV) systems based on available tools for fixed-structure controller\nsynthesis. We start by transforming a model reduction problem into an\nequivalent controller synthesis problem by defining an appropriate generalized\nplant. The controller synthesis problem is then solved by using gradient-based\ntools available in the literature. Owing to the flexibility of the\ngradient-based synthesis tools, we are able to impose a desired structure on\nthe obtained reduced model. Additionally, we obtain a bound on the\napproximation error as a direct output of the optimization problem. The\nproposed methods are applied on a benchmark mechanical system of interconnected\nmasses, springs and dampers. To evaluate the effect of the proposed\nmodel-reduction approach on controller design, LPV controllers designed using\nthe reduced models (with and without an imposed structure) are compared in\nclosed-loop with the original model.\n","authors":["Lennart Heeren","Adwait Datar","Antonio Mendez Gonzalez","Herbert Werner"],"pdf_url":"https://arxiv.org/pdf/2403.14310v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.19353v3","updated":"2024-03-21T11:08:07Z","published":"2023-05-30T18:31:02Z","title":"Bearing-Constrained Leader-Follower Formation of Single-Integrators with\n  Disturbance Rejection: Adaptive Variable-Structure Approaches","summary":"  This paper studies the problem of stabilizing a leader-follower formation\nspecified by a set of bearing constraints and being disturbed by unknown\nuniformly bounded disturbance. A set of leaders are positioned at the desired\npositions, while each follower agent is modeled by a single integrator with\ndisturbance of which the upper bound is unavailable for the control design.\nAdaptive variable-structure formation control laws using only displacements or\nbearing vectors are provided to stabilize the agents to a desired formation.\nThanks to the adaptive mechanism, the control laws require neither the\ninformation of the bearing Laplacian nor the directions and the upper bounds of\nthe disturbance. It is further proved that when the leaders are moving with the\nsame bounded uniformly continuous velocity, the moving target formation can\nstill be achieved under the proposed control laws. Simulation results are also\ngiven to support the stability analysis.\n","authors":["Thanh Truong Nguyen","Dung Van Vu","Tuynh Van Pham","Minh Hoang Trinh"],"pdf_url":"https://arxiv.org/pdf/2305.19353v3.pdf","comment":"18 pages, 6 figures. This work has been submitted to the IEEE for\n  possible publication. Copyright may be transferred without notice, after\n  which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2403.09526v2","updated":"2024-03-21T09:37:13Z","published":"2024-03-14T16:10:23Z","title":"Optimizing the Electrical Interface for Large-Scale Color-Center Quantum\n  Processors","summary":"  Quantum processors based on color centers in diamond are promising candidates\nfor future large-scale quantum computers thanks to their flexible optical\ninterface, (relatively) high operating temperature, and high-fidelity\noperation. Similar to other quantum-computing platforms, the electrical\ninterface required to control and read out such qubits may limit both the\nperformance of the whole system and its scalability. To address this challenge,\nthis work analyzes the requirements of the electrical interface and\ninvestigates how to efficiently implement the electronic controller in a\nscalable architecture comprising a large number of identical unit cells. Among\nthe different discussed functionalities, a specific focus is devoted to the\ngeneration of the static and dynamic magnetic fields driving the electron and\nnuclear spins, because of their major impact on fidelity and scalability.\nFollowing the derived requirements, different system architectures, such as a\nqubit frequency-multiplexing scheme, are considered to identify the most power\nefficient approach, especially in the presence of inhomogeneity of the qubit\nLarmor frequency across the processor. As a result, a\nnon-frequency-multiplexed, 1-mm$^2$ unit-cell architecture is proposed as the\noptimal solution, able to address up to one electron-spin qubit and 9\nnuclear-spin qubits within a 3-mW average power consumption, thus establishing\nthe baseline for the scalable electrical interface for future large-scale\ncolor-center quantum computers.\n","authors":["Luc Enthoven","Masoud Babaie","Fabio Sebastiano"],"pdf_url":"https://arxiv.org/pdf/2403.09526v2.pdf","comment":"20 pages, 10 figures; Revision 21-03-2024: Corrected affiliation,\n  corrected typo Fig. 2, corrected DC noise PSD value (Z-field noise, X/Y-field\n  noise) in Tab.1"},{"id":"http://arxiv.org/abs/2309.02872v2","updated":"2024-03-21T08:47:02Z","published":"2023-09-06T09:53:19Z","title":"Input-output linearization and decoupling of mechanical control systems","summary":"  In this work, we present a problem of simultaneous input-output feedback\nlinearization and decoupling (non-interacting) for mechanical control systems\nwith outputs. We show that the natural requirement of preserving mechanical\nstructure of the system and of transformations imposes supplementary conditions\nwhen compared to the classical solution of the same problem for general control\nsystems. These conditions can be expressed using objects on the configuration\nspace only. We illustrate our results with several examples of mechanical\ncontrol systems.\n","authors":["Marcin Nowicki","Witold Respondek"],"pdf_url":"https://arxiv.org/pdf/2309.02872v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14209v1","updated":"2024-03-21T08:01:31Z","published":"2024-03-21T08:01:31Z","title":"Multi Methods of Matrix Analysis Use for Control and Optimization system\n  in Control Engineering","summary":"  Matrix analysis plays a crucial role in the field of control engineering,\nproviding a powerful mathematical framework for the analysis and design of\ncontrol systems. This research report explores various applications of matrix\nanalysis in control engineering, focusing on its contributions to system\nmodeling, stability analysis, controllablity, observability, and optimization.\nThe report also discusses specific examples and case studies to illustrate the\npractical significance of matrix analysis in addressing real-world control\nengineering challenges Analyze controllability. Informally, a system is\ncontrollable if we can construct a set of inputs that will drive the system to\nany given state. Analyze observability. Informally, observability means that by\ncontrolling the inputs and watching the outputs of a system we can determine\nwhat the states were. Optimal Control is a control method that aims to find the\noptimal control input to achieve the best performance of the system under\ncertain constraints. This performance index can be the system output, energy\nconsumption, time, etc.\n","authors":["Si Kheang Moeurn"],"pdf_url":"https://arxiv.org/pdf/2403.14209v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2403.14194v1","updated":"2024-03-21T07:40:52Z","published":"2024-03-21T07:40:52Z","title":"Event-triggered Boundary Control of Mixed-autonomy Traffic","summary":"  Control problems of mixed-autonomy traffic system consisting of both\nHuman-driven Vehicles (HV) and Autonomous Vehicles (AV) have gained increasing\nattention. This paper is focused on suppressing traffic oscillations of the\nmixed-autonomy traffic system using boundary control design. The mixed traffic\ndynamics are described by a 4 x 4 hyperbolic partial differential equations\n(PDE) which governs propagation of four properties in traffic including density\nof HV, density of AV, friction between two classes of vehicles from driving\ninteractions, and averaged velocity. We propose event-triggered boundary\ncontrol design since control signal of traffic light on ramp or varying speed\nlimit cannot be updated in a continuous time fashion. We apply event-triggered\nmechanism for a PDE backstepping controller and obtain dynamic triggering\ncondition. Lyapunov analysis is conducted to prove the exponential stability of\nthe closed loop system with the event-triggered controller. Numerical\nsimulation demonstrates how car-following spacing of AV affects\nevent-triggering mechanism of control input in mixed-autonomy traffic.\n","authors":["Yihuai Zhang","Huan Yu"],"pdf_url":"https://arxiv.org/pdf/2403.14194v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14184v1","updated":"2024-03-21T07:20:14Z","published":"2024-03-21T07:20:14Z","title":"Conservative Linear Envelopes for High-Dimensional, Hamilton-Jacobi\n  Reachability for Nonlinear Systems via the Hopf Formula","summary":"  Hamilton-Jacobi reachability (HJR) analysis provides a value function that\nencodes (1) the set of states from which a nonlinear system with bounded\ncontrol inputs can reach a goal (or avoid a failure set) despite any bounded\ndisturbance, and (2) the corresponding optimal control policy to reach (or\navoid). Though powerful, traditional methods for HJR rely on dynamic\nprogramming and suffer from exponential computation growth with respect to\nstate dimension. The recently favored Hopf formula mitigates this ''curse of\ndimensionality'' by providing an efficient and space-parallelizable approach\nfor solving the reachability problem. However, the Hopf formula can only be\napplied to linear time-varying systems. To overcome this limitation, we show\nthat the error between a nonlinear system and a linear model can be transformed\ninto an adversarial bounded artificial disturbance, making an envelope of the\ntrue value. One may then solve the dimension-robust Hopf formula for a linear\ngame with this ''antagonistic error\" to perform guaranteed conservative\nreachability analysis and control synthesis of nonlinear systems; this can be\ndone for problem formulations in which no other HJR method is both\ncomputationally feasible and guaranteed. In addition, we offer several\ntechnical methods for reducing conservativeness in the analysis. We demonstrate\nthe theory by solving the safe linear envelope in the controlled Van der Pol\nsystem, where the true reachable set may be observed, and by solving a 5 agent\n(15D) pursuit-evasion game with Dubins cars.\n","authors":["Will Sharpless","Yat Tin Chow","Sylvia Herbert"],"pdf_url":"https://arxiv.org/pdf/2403.14184v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14172v1","updated":"2024-03-21T06:50:41Z","published":"2024-03-21T06:50:41Z","title":"Lane level joint control of off-ramp and main line speed guidance on\n  expressway in rainy weather","summary":"  In the upstream of the exit ramp of the expressway, the speed limit\ndifference leads to a significant deceleration of the vehicle in the area\nadjacent to the off-ramp. The friction coefficient of the road surface\ndecreases under rainy weather, and the above deceleration process can easily\nlead to sideslip and rollover of the vehicle. Dynamic speed guidance is an\neffective way to improve the status quo. Currently, there is an emerging trend\nto utilize I2V technology and high-precision map technology for lane level\nspeed guidance control. This paper presents an optimized joint control strategy\nfor main line-off-ramp speed guidance, which can adjust the guidance speed in\nreal time according to the rainfall intensity. At the same time, this paper\ndesigns a progressive deceleration strategy, which works together with the\nspeed guidance control to ensure the safe deceleration of vehicles. The\nsimulation results show that the proposed control strategy outperforms the\nfixed speed limit control in terms of improving the total traveled time (TTT),\ntotal traveled distance (TTD) and standard deviation of speed (SD). Sensitivity\nanalysis shows that the proposed control strategy can improve performance with\nthe increase of the compliance rate of drivers. The speed guidance control\nmethod established in this paper can improve the vehicle operation efficiency\nin the off-ramp area of the expressway and reduce the speed difference of each\nvehicle in rainy weather, which guarantee the safety of expressway driving in\nthe rainy day.\n","authors":["Boyao Peng","Lexing Zhang","Enkai Li"],"pdf_url":"https://arxiv.org/pdf/2403.14172v1.pdf","comment":"103rd TRB Conference"},{"id":"http://arxiv.org/abs/2403.14154v1","updated":"2024-03-21T06:01:02Z","published":"2024-03-21T06:01:02Z","title":"LR-FHSS Transceiver for Direct-to-Satellite IoT Communications: Design,\n  Implementation, and Verification","summary":"  This paper proposes a long range-frequency hopping spread spectrum (LR-FHSS)\ntransceiver design for the Direct-to-Satellite Internet of Things (DtS-IoT)\ncommunication system. The DtS-IoT system has recently attracted attention as a\npromising nonterrestrial network (NTN) solution to provide high-traffic and\nlow-latency data transfer services to IoT devices in global coverage. In\nparticular, this study provides guidelines for the overall DtS-IoT system\narchitecture and design details that conform to the Long Range Wide-Area\nNetwork (LoRaWAN). Furthermore, we also detail various DtS-IoT use cases.\nConsidering the multiple low-Earth orbit (LEO) satellites, we developed the\nLR-FHSS transceiver to improve system efficiency, which is the first attempt in\nreal satellite communication systems using LR-FHSS. Moreover, as an extension\nof our previous work with perfect synchronization, we applied a robust\nsynchronization scheme against the Doppler effect and co-channel interference\n(CCI) caused by LEO satellite channel environments, including signal detection\nfor the simultaneous reception of numerous frequency hopping signals and an\nenhanced soft-output-Viterbi-algorithm (SOVA) for the header and payload\nreceptions. Lastly, we present proof-of-concept implementation and testbeds\nusing an application-specific integrated circuit (ASIC) chipset and a\nfield-programmable gate array (FPGA) that verify the performance of the\nproposed LR-FHSS transceiver design of DtS-IoT communication systems. The\nlaboratory test results reveal that the proposed LR-FHSS-based framework with\nthe robust synchronization technique can provide wide coverage, seamless\nconnectivity, and high throughput communication links for the realization of\nfuture sixth-generation (6G) networks.\n","authors":["Sooyeob Jung","Seongah Jeong","Jinkyu Kang","Gyeongrae Im","Sangjae Lee","Mi-Kyung Oh","Joon Gyu Ryu","Joonhyuk Kang"],"pdf_url":"https://arxiv.org/pdf/2403.14154v1.pdf","comment":"17pages, 23 figures"},{"id":"http://arxiv.org/abs/2403.14092v1","updated":"2024-03-21T02:59:56Z","published":"2024-03-21T02:59:56Z","title":"Carbon Footprint Reduction for Sustainable Data Centers in Real-Time","summary":"  As machine learning workloads significantly increase energy consumption,\nsustainable data centers with low carbon emissions are becoming a top priority\nfor governments and corporations worldwide. This requires a paradigm shift in\noptimizing power consumption in cooling and IT loads, shifting flexible loads\nbased on the availability of renewable energy in the power grid, and leveraging\nbattery storage from the uninterrupted power supply in data centers, using\ncollaborative agents. The complex association between these optimization\nstrategies and their dependencies on variable external factors like weather and\nthe power grid carbon intensity makes this a hard problem. Currently, a\nreal-time controller to optimize all these goals simultaneously in a dynamic\nreal-world setting is lacking. We propose a Data Center Carbon Footprint\nReduction (DC-CFR) multi-agent Reinforcement Learning (MARL) framework that\noptimizes data centers for the multiple objectives of carbon footprint\nreduction, energy consumption, and energy cost. The results show that the\nDC-CFR MARL agents effectively resolved the complex interdependencies in\noptimizing cooling, load shifting, and energy storage in real-time for various\nlocations under real-world dynamic weather and grid carbon intensity\nconditions. DC-CFR significantly outperformed the industry standard ASHRAE\ncontroller with a considerable reduction in carbon emissions (14.5%), energy\nusage (14.4%), and energy cost (13.7%) when evaluated over one year across\nmultiple geographical regions.\n","authors":["Soumyendu Sarkar","Avisek Naug","Ricardo Luna","Antonio Guillen","Vineet Gundecha","Sahand Ghorbanpour","Sajad Mousavi","Dejan Markovikj","Ashwin Ramesh Babu"],"pdf_url":"https://arxiv.org/pdf/2403.14092v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14059v1","updated":"2024-03-21T01:10:56Z","published":"2024-03-21T01:10:56Z","title":"PE-GPT: A Physics-Informed Interactive Large Language Model for Power\n  Converter Modulation Design","summary":"  This paper proposes PE-GPT, a custom-tailored large language model uniquely\nadapted for power converter modulation design. By harnessing in-context\nlearning and specialized tiered physics-informed neural networks, PE-GPT guides\nusers through text-based dialogues, recommending actionable modulation\nparameters. The effectiveness of PE-GPT is validated through a practical design\ncase involving dual active bridge converters, supported by hardware\nexperimentation. This research underscores the transformative potential of\nlarge language models in power converter modulation design, offering enhanced\naccessibility, explainability, and efficiency, thereby setting a new paradigm\nin the field.\n","authors":["Fanfan Lin","Junhua Liu","Xinze Li","Shuai Zhao","Bohui Zhao","Hao Ma","Xin Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.14059v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.14098v2","updated":"2024-03-21T22:49:40Z","published":"2023-10-21T19:32:11Z","title":"Stabilizing reinforcement learning control: A modular framework for\n  optimizing over all stable behavior","summary":"  We propose a framework for the design of feedback controllers that combines\nthe optimization-driven and model-free advantages of deep reinforcement\nlearning with the stability guarantees provided by using the Youla-Kucera\nparameterization to define the search domain. Recent advances in behavioral\nsystems allow us to construct a data-driven internal model; this enables an\nalternative realization of the Youla-Kucera parameterization based entirely on\ninput-output exploration data. Perhaps of independent interest, we formulate\nand analyze the stability of such data-driven models in the presence of noise.\nThe Youla-Kucera approach requires a stable \"parameter\" for controller design.\nFor the training of reinforcement learning agents, the set of all stable linear\noperators is given explicitly through a matrix factorization approach.\nMoreover, a nonlinear extension is given using a neural network to express a\nparameterized set of stable operators, which enables seamless integration with\nstandard deep learning libraries. Finally, we show how these ideas can also be\napplied to tune fixed-structure controllers.\n","authors":["Nathan P. Lawrence","Philip D. Loewen","Shuyuan Wang","Michael G. Forbes","R. Bhushan Gopaluni"],"pdf_url":"https://arxiv.org/pdf/2310.14098v2.pdf","comment":"Postprint; 31 pages. arXiv admin note: text overlap with\n  arXiv:2304.03422"},{"id":"http://arxiv.org/abs/2403.14866v1","updated":"2024-03-21T22:21:46Z","published":"2024-03-21T22:21:46Z","title":"Joint Planning of Charging Stations and Power Systems for Heavy-Duty\n  Drayage Trucks","summary":"  As global concerns about climate change intensify, the transition towards\nzero-emission freight is becoming increasingly vital. Drayage is an important\nsegment of the freight system, typically involving the transport of goods from\nseaports or intermodal terminals to nearby warehouses. This sector\nsignificantly contributes to not only greenhouse gas emissions, but also\npollution in densely populated areas. This study presents a holistic\noptimization model designed for an efficient transition to zero-emission\ndrayage, offering cost-effective strategies for the coordinated investment\nplanning for power systems, charging infrastructure, and electric drayage\ntrucks. The model is validated in the Greater Los Angeles area, where\nregulatory goals are among the most ambitious. Furthermore, the model's design\nallows for easy adaptation to other regions. By focusing on drayage trucks,\nthis study also paves the way for future research into other freight\ncategories, establishing a foundation for a more extensive exploration in this\nfield.\n","authors":["Zuzhao Ye","Nanpeng Yu","Ran Wei"],"pdf_url":"https://arxiv.org/pdf/2403.14866v1.pdf","comment":"34 pages, 10 figures"},{"id":"http://arxiv.org/abs/2403.14860v1","updated":"2024-03-21T22:15:09Z","published":"2024-03-21T22:15:09Z","title":"Robust Model Based Reinforcement Learning Using $\\mathcal{L}_1$ Adaptive\n  Control","summary":"  We introduce $\\mathcal{L}_1$-MBRL, a control-theoretic augmentation scheme\nfor Model-Based Reinforcement Learning (MBRL) algorithms. Unlike model-free\napproaches, MBRL algorithms learn a model of the transition function using data\nand use it to design a control input. Our approach generates a series of\napproximate control-affine models of the learned transition function according\nto the proposed switching law. Using the approximate model, control input\nproduced by the underlying MBRL is perturbed by the $\\mathcal{L}_1$ adaptive\ncontrol, which is designed to enhance the robustness of the system against\nuncertainties. Importantly, this approach is agnostic to the choice of MBRL\nalgorithm, enabling the use of the scheme with various MBRL algorithms. MBRL\nalgorithms with $\\mathcal{L}_1$ augmentation exhibit enhanced performance and\nsample efficiency across multiple MuJoCo environments, outperforming the\noriginal MBRL algorithms, both with and without system noise.\n","authors":["Minjun Sung","Sambhu H. Karumanchi","Aditya Gahlawat","Naira Hovakimyan"],"pdf_url":"https://arxiv.org/pdf/2403.14860v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.04239v2","updated":"2024-03-21T21:21:12Z","published":"2023-10-06T13:22:00Z","title":"Representative Days and Hours with Piecewise Linear Transitions for\n  Power System Planning","summary":"  Electric demand and renewable power are highly variable, and the solution of\na planning model relies on capturing this variability. This paper proposes a\nhybrid multi-area method that effectively captures both the intraday and\ninterday chronology of real data considering extreme values, using a limited\nnumber of representative days, and time points within each day. An\noptimization-based representative extraction method is proposed to improve\nintraday chronology capturing. It ensures higher precision in preserving data\nchronology and extreme values than hierarchical clustering methods. The\nproposed method is based on a piecewise linear demand and supply\nrepresentation, which reduces approximation errors compared to the traditional\npiecewise constant formulation. Additionally, sequentially linked day blocks\nwith identical representatives, created through a mapping process, are employed\nfor interday chronology capturing. To evaluate the efficiency of the proposed\nmethod, a comprehensive expansion co-planning model is developed, including\ntransmission lines, energy storage systems, and wind farms.\n","authors":["Mojtaba Moradi-Sepahvand","Simon H. Tindemans"],"pdf_url":"https://arxiv.org/pdf/2310.04239v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.16201v2","updated":"2024-03-21T21:10:04Z","published":"2023-10-24T21:36:37Z","title":"A Convex Parameterization of Controllers Constrained to use only\n  Relative Measurements","summary":"  The optimal controller design problem for systems equipped with sensors that\nmeasure only relative, rather than absolute, quantities is considered. This\nrelative measurement structure is formulated as a design constraint; it is\ndemonstrated that the resulting constrained controller design problem can be\nwritten as a convex program. Certain additional network structural constraints\ncan be incorporated into this formulation, making it especially useful in\ndistributed or networked settings. An illustrative example highlights the\nadvantage of the proposed methodology over the standard formulation of the\noutput feedback controller design problem. A numerical example is provided.\n","authors":["Walden Marshall","Bassam Bamieh","Emily Jensen"],"pdf_url":"https://arxiv.org/pdf/2310.16201v2.pdf","comment":"6 pages, 2 figures"},{"id":"http://arxiv.org/abs/2403.14833v1","updated":"2024-03-21T21:05:59Z","published":"2024-03-21T21:05:59Z","title":"Model order reduction of deep structured state-space models: A\n  system-theoretic approach","summary":"  With a specific emphasis on control design objectives, achieving accurate\nsystem modeling with limited complexity is crucial in parametric system\nidentification. The recently introduced deep structured state-space models\n(SSM), which feature linear dynamical blocks as key constituent components,\noffer high predictive performance. However, the learned representations often\nsuffer from excessively large model orders, which render them unsuitable for\ncontrol design purposes. The current paper addresses this challenge by means of\nsystem-theoretic model order reduction techniques that target the linear\ndynamical blocks of SSMs. We introduce two regularization terms which can be\nincorporated into the training loss for improved model order reduction. In\nparticular, we consider modal $\\ell_1$ and Hankel nuclear norm regularization\nto promote sparsity, allowing one to retain only the relevant states without\nsacrificing accuracy. The presented regularizers lead to advantages in terms of\nparsimonious representations and faster inference resulting from the reduced\norder models. The effectiveness of the proposed methodology is demonstrated\nusing real-world ground vibration data from an aircraft.\n","authors":["Marco Forgione","Manas Mejari","Dario Piga"],"pdf_url":"https://arxiv.org/pdf/2403.14833v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.03765v4","updated":"2024-03-21T20:42:20Z","published":"2023-04-07T17:58:19Z","title":"Markov Decision Process Design: A Framework for Integrating Strategic\n  and Operational Decisions","summary":"  We consider the problem of optimally designing a system for repeated use\nunder uncertainty. We develop a modeling framework that integrates design and\noperational phases, which are represented by a mixed-integer program and\ndiscounted-cost infinite-horizon Markov decision processes, respectively. We\nseek to simultaneously minimize the design costs and the subsequent expected\noperational costs. This problem setting arises naturally in several application\nareas, as we illustrate through examples. We derive a bilevel mixed-integer\nlinear programming formulation for the problem and perform a computational\nstudy to demonstrate that realistic instances can be solved numerically.\n","authors":["Seth Brown","Saumya Sinha","Andrew J Schaefer"],"pdf_url":"https://arxiv.org/pdf/2304.03765v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14803v1","updated":"2024-03-21T19:31:10Z","published":"2024-03-21T19:31:10Z","title":"Transmission Benefits and Cost Allocation under Ambiguity","summary":"  Disputes over cost allocation can present a significant barrier to investment\nin shared infrastructure. While it may be desirable to allocate cost in a way\nthat corresponds to expected benefits, investments in long-lived projects are\nmade under conditions of substantial uncertainty. In the context of electricity\ntransmission, uncertainty combined with the inherent complexity of power\nsystems analysis prevents the calculation of an estimated distribution of\nbenefits that is agreeable to all participants. To analyze aspects of the cost\nallocation problem, we construct a model for transmission and generation\nexpansion planning under uncertainty, enabling the identification of\ntransmission investments as well as the calculation of benefits for users of\nthe network. Numerical tests confirm the potential for realized benefits at the\nparticipant level to differ significantly from ex ante estimates. Based on the\nmodel and numerical tests we discuss several issues, including 1) establishing\na valid counterfactual against which to measure benefits, 2) allocating cost to\nnew and incumbent generators vs. solely allocating to loads, 3) calculating\nbenefits at the portfolio vs. the individual project level, 4) identifying\nlosers in a surplus-enhancing transmission expansion, and 5) quantifying the\ndivergence between cost allocation decisions made ex ante and benefits realized\nex post.\n","authors":["Han Shu","Jacob Mays"],"pdf_url":"https://arxiv.org/pdf/2403.14803v1.pdf","comment":"32 pages, 7 figures, 7 tables"},{"id":"http://arxiv.org/abs/2309.16950v2","updated":"2024-03-21T19:12:39Z","published":"2023-09-29T03:31:14Z","title":"Scalable Neural Dynamic Equivalence for Power Systems","summary":"  Traditional grid analytics are model-based, relying strongly on accurate\nmodels of power systems, especially the dynamic models of generators,\ncontrollers, loads and other dynamic components. However, acquiring thorough\npower system models can be impractical in real operation due to inaccessible\nsystem parameters and privacy of consumers, which necessitate data-driven\ndynamic equivalencing of unknown subsystems. Learning reliable dynamic\nequivalent models for the external systems from SCADA and PMU data, however, is\na long-standing intractable problem in power system analysis due to complicated\nnonlinearity and unforeseeable dynamic modes of power systems. This paper\nadvances a practical application of neural dynamic equivalence (NeuDyE) called\nDriving Port NeuDyE (DP-NeuDyE), which exploits physics-informed machine\nlearning and neural-ordinary-differential-equations (ODE-NET) to discover a\ndynamic equivalence of external power grids while preserving its dynamic\nbehaviors after disturbances. The new contributions are threefold: A NeuDyE\nformulation to enable a continuous-time, data-driven dynamic equivalence of\npower systems, saving the effort and expense of acquiring inaccessible system;\nAn introduction of a Physics-Informed NeuDyE learning (PI-NeuDyE) to actively\ncontrol the closed-loop accuracy of NeuDyE; and A DP-NeuDyE to reduce the\nnumber of inputs required for the training. We conduct extensive case studies\non the NPCC system to validate the generalizability and accuracy of both\nPI-NeuDyE and DP-NeuDyE, which span a multitude of scenarios, differing in the\ntime required for fault clearance, the specific fault locations, and the\nlimitations of data. Test results have demonstrated the scalability and\npracticality of NeuDyE, showing its potential to be used in ISO and utility\ncontrol centers for online transient stability analysis and for planning\npurposes.\n","authors":["Qing Shen","Yifan Zhou","Huanfeng Zhao","Peng Zhang","Qiang Zhang","Slava Maslenniko","Xiaochuan Luo"],"pdf_url":"https://arxiv.org/pdf/2309.16950v2.pdf","comment":null}]},"2024-03-22T00:00:00Z":{"Robotics":[{"id":"http://arxiv.org/abs/2312.10070v2","updated":"2024-03-22T17:59:09Z","published":"2023-12-06T10:47:53Z","title":"Gaussian-SLAM: Photo-realistic Dense SLAM with Gaussian Splatting","summary":"  We present a dense simultaneous localization and mapping (SLAM) method that\nuses 3D Gaussians as a scene representation. Our approach enables\ninteractive-time reconstruction and photo-realistic rendering from real-world\nsingle-camera RGBD videos. To this end, we propose a novel effective strategy\nfor seeding new Gaussians for newly explored areas and their effective online\noptimization that is independent of the scene size and thus scalable to larger\nscenes. This is achieved by organizing the scene into sub-maps which are\nindependently optimized and do not need to be kept in memory. We further\naccomplish frame-to-model camera tracking by minimizing photometric and\ngeometric losses between the input and rendered frames. The Gaussian\nrepresentation allows for high-quality photo-realistic real-time rendering of\nreal-world scenes. Evaluation on synthetic and real-world datasets demonstrates\ncompetitive or superior performance in mapping, tracking, and rendering\ncompared to existing neural dense SLAM methods.\n","authors":["Vladimir Yugay","Yue Li","Theo Gevers","Martin R. Oswald"],"pdf_url":"https://arxiv.org/pdf/2312.10070v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15370v1","updated":"2024-03-22T17:49:11Z","published":"2024-03-22T17:49:11Z","title":"Augmented Reality based Simulated Data (ARSim) with multi-view\n  consistency for AV perception networks","summary":"  Detecting a diverse range of objects under various driving scenarios is\nessential for the effectiveness of autonomous driving systems. However, the\nreal-world data collected often lacks the necessary diversity presenting a\nlong-tail distribution. Although synthetic data has been utilized to overcome\nthis issue by generating virtual scenes, it faces hurdles such as a significant\ndomain gap and the substantial efforts required from 3D artists to create\nrealistic environments. To overcome these challenges, we present ARSim, a fully\nautomated, comprehensive, modular framework designed to enhance real multi-view\nimage data with 3D synthetic objects of interest. The proposed method\nintegrates domain adaptation and randomization strategies to address covariate\nshift between real and simulated data by inferring essential domain attributes\nfrom real data and employing simulation-based randomization for other\nattributes. We construct a simplified virtual scene using real data and\nstrategically place 3D synthetic assets within it. Illumination is achieved by\nestimating light distribution from multiple images capturing the surroundings\nof the vehicle. Camera parameters from real data are employed to render\nsynthetic assets in each frame. The resulting augmented multi-view consistent\ndataset is used to train a multi-camera perception network for autonomous\nvehicles. Experimental results on various AV perception tasks demonstrate the\nsuperior performance of networks trained on the augmented dataset.\n","authors":["Aqeel Anwar","Tae Eun Choe","Zian Wang","Sanja Fidler","Minwoo Park"],"pdf_url":"https://arxiv.org/pdf/2403.15370v1.pdf","comment":"17 pages, 15 figures, 7 tables"},{"id":"http://arxiv.org/abs/2403.15369v1","updated":"2024-03-22T17:48:13Z","published":"2024-03-22T17:48:13Z","title":"OceanPlan: Hierarchical Planning and Replanning for Natural Language AUV\n  Piloting in Large-scale Unexplored Ocean Environments","summary":"  We develop a hierarchical LLM-task-motion planning and replanning framework\nto efficiently ground an abstracted human command into tangible Autonomous\nUnderwater Vehicle (AUV) control through enhanced representations of the world.\nWe also incorporate a holistic replanner to provide real-world feedback with\nall planners for robust AUV operation. While there has been extensive research\nin bridging the gap between LLMs and robotic missions, they are unable to\nguarantee success of AUV applications in the vast and unknown ocean\nenvironment. To tackle specific challenges in marine robotics, we design a\nhierarchical planner to compose executable motion plans, which achieves\nplanning efficiency and solution quality by decomposing long-horizon missions\ninto sub-tasks. At the same time, real-time data stream is obtained by a\nreplanner to address environmental uncertainties during plan execution.\nExperiments validate that our proposed framework delivers successful AUV\nperformance of long-duration missions through natural language piloting.\n","authors":["Ruochu Yang","Fumin Zhang","Mengxue Hou"],"pdf_url":"https://arxiv.org/pdf/2403.15369v1.pdf","comment":"submitted to IROS 2024"},{"id":"http://arxiv.org/abs/2403.13783v2","updated":"2024-03-22T17:17:14Z","published":"2024-03-20T17:44:33Z","title":"A Convex Formulation of Frictional Contact for the Material Point Method\n  and Rigid Bodies","summary":"  In this paper, we introduce a novel convex formulation that seamlessly\nintegrates the Material Point Method (MPM) with articulated rigid body dynamics\nin frictional contact scenarios. We extend the linear corotational hyperelastic\nmodel into the realm of elastoplasticity and include an efficient return\nmapping algorithm. This approach is particularly effective for MPM simulations\ninvolving significant deformation and topology changes, while preserving the\nconvexity of the optimization problem. Our method ensures global convergence,\nenabling the use of large simulation time steps without compromising\nrobustness. We have validated our approach through rigorous testing and\nperformance evaluations, highlighting its superior capabilities in managing\ncomplex simulations relevant to robotics. Compared to previous MPM based\nrobotic simulators, our method significantly improves the stability of contact\nresolution -- a critical factor in robot manipulation tasks. We make our method\navailable in the open-source robotics toolkit, Drake.\n","authors":["Zeshun Zong","Chenfanfu Jiang","Xuchen Han"],"pdf_url":"https://arxiv.org/pdf/2403.13783v2.pdf","comment":"The supplemental video is available at https://youtu.be/5jrQtF5D0DA"},{"id":"http://arxiv.org/abs/2403.15335v1","updated":"2024-03-22T16:40:48Z","published":"2024-03-22T16:40:48Z","title":"Safe and Stable Teleoperation of Quadrotor UAVs under Haptic Shared\n  Autonomy","summary":"  We present a novel approach that aims to address both safety and stability of\na haptic teleoperation system within a framework of Haptic Shared Autonomy\n(HSA). We use Control Barrier Functions (CBFs) to generate the control input\nthat follows the user's input as closely as possible while guaranteeing safety.\nIn the context of stability of the human-in-the-loop system, we limit the force\nfeedback perceived by the user via a small $L_2$-gain, which is achieved by\nlimiting the control and the force feedback via a differential constraint.\nSpecifically, with the property of HSA, we propose two pathways to design the\ncontrol and the force feedback: Sequential Control Force (SCF) and Joint\nControl Force (JCF). Both designs can achieve safety and stability but with\ndifferent responses to the user's commands. We conducted experimental\nsimulations to evaluate and investigate the properties of the designed methods.\nWe also tested the proposed method on a physical quadrotor UAV and a haptic\ninterface.\n","authors":["Dawei Zhang","Roberto Tron"],"pdf_url":"https://arxiv.org/pdf/2403.15335v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15333v1","updated":"2024-03-22T16:39:13Z","published":"2024-03-22T16:39:13Z","title":"Gesture-Controlled Aerial Robot Formation for Human-Swarm Interaction in\n  Safety Monitoring Applications","summary":"  This paper presents a formation control approach for contactless\ngesture-based Human-Swarm Interaction (HSI) between a team of multi-rotor\nUnmanned Aerial Vehicles (UAVs) and a human worker. The approach is intended\nfor monitoring the safety of human workers, especially those working at\nheights. In the proposed dynamic formation scheme, one UAV acts as the leader\nof the formation and is equipped with sensors for human worker detection and\ngesture recognition. The follower UAVs maintain a predetermined formation\nrelative to the worker's position, thereby providing additional perspectives of\nthe monitored scene. Hand gestures allow the human worker to specify movements\nand action commands for the UAV team and initiate other mission-related\ncommands without the need for an additional communication channel or specific\nmarkers. Together with a novel unified human detection and tracking algorithm,\nhuman pose estimation approach and gesture detection pipeline, the proposed\napproach forms a first instance of an HSI system incorporating all these\nmodules onboard real-world UAVs. Simulations and field experiments with three\nUAVs and a human worker in a mock-up scenario showcase the effectiveness and\nresponsiveness of the proposed approach.\n","authors":["Vít Krátký","Giuseppe Silano","Matouš Vrba","Christos Papaioannidis","Ioannis Mademlis","Robert Pěnička","Ioannis Pitas","Martin Saska"],"pdf_url":"https://arxiv.org/pdf/2403.15333v1.pdf","comment":"8 pages, 9 figures"},{"id":"http://arxiv.org/abs/2310.00401v2","updated":"2024-03-22T16:32:24Z","published":"2023-09-30T14:54:31Z","title":"Learning High-level Semantic-Relational Concepts for SLAM","summary":"  Recent works on SLAM extend their pose graphs with higher-level semantic\nconcepts like Rooms exploiting relationships between them, to provide, not only\na richer representation of the situation/environment but also to improve the\naccuracy of its estimation. Concretely, our previous work, Situational Graphs\n(S-Graphs+), a pioneer in jointly leveraging semantic relationships in the\nfactor optimization process, relies on semantic entities such as Planes and\nRooms, whose relationship is mathematically defined. Nevertheless, there is no\nunique approach to finding all the hidden patterns in lower-level factor-graphs\nthat correspond to high-level concepts of different natures. It is currently\ntackled with ad-hoc algorithms, which limits its graph expressiveness.\n  To overcome this limitation, in this work, we propose an algorithm based on\nGraph Neural Networks for learning high-level semantic-relational concepts that\ncan be inferred from the low-level factor graph. Given a set of mapped Planes\nour algorithm is capable of inferring Room entities relating to the Planes.\nAdditionally, to demonstrate the versatility of our method, our algorithm can\ninfer an additional semantic-relational concept, i.e. Wall, and its\nrelationship with its Planes. We validate our method in both simulated and real\ndatasets demonstrating improved performance over two baseline approaches.\nFurthermore, we integrate our method into the S-Graphs+ algorithm providing\nimproved pose and map accuracy compared to the baseline while further enhancing\nthe scene representation.\n","authors":["Jose Andres Millan-Romera","Hriday Bavle","Muhammad Shaheer","Martin R. Oswald","Holger Voos","Jose Luis Sanchez-Lopez"],"pdf_url":"https://arxiv.org/pdf/2310.00401v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15323v1","updated":"2024-03-22T16:19:56Z","published":"2024-03-22T16:19:56Z","title":"Introduction to Human-Robot Interaction: A Multi-Perspective\n  Introductory Course","summary":"  In this paper I describe the design of an introductory course in Human-Robot\nInteraction. This project-driven course is designed to introduce undergraduate\nand graduate engineering students, especially those enrolled in Computer\nScience, Mechanical Engineering, and Robotics degree programs, to key theories\nand methods used in the field of Human-Robot Interaction that they would\notherwise be unlikely to see in those degree programs. To achieve this aim, the\ncourse takes students all the way from stakeholder analysis to empirical\nevaluation, covering and integrating key Qualitative, Design, Computational,\nand Quantitative methods along the way. I detail the goals, audience, and\nformat of the course, and provide a detailed walkthrough of the course\nsyllabus.\n","authors":["Tom Williams"],"pdf_url":"https://arxiv.org/pdf/2403.15323v1.pdf","comment":"Presented at the Designing an Intro to HRI Course Workshop at HRI\n  2024 (arXiv:2403.05588)"},{"id":"http://arxiv.org/abs/2403.15306v1","updated":"2024-03-22T15:58:34Z","published":"2024-03-22T15:58:34Z","title":"HortiBot: An Adaptive Multi-Arm System for Robotic Horticulture of Sweet\n  Peppers","summary":"  Horticultural tasks such as pruning and selective harvesting are labor\nintensive and horticultural staff are hard to find. Automating these tasks is\nchallenging due to the semi-structured greenhouse workspaces, changing\nenvironmental conditions such as lighting, dense plant growth with many\nocclusions, and the need for gentle manipulation of non-rigid plant organs. In\nthis work, we present the three-armed system HortiBot, with two arms for\nmanipulation and a third arm as an articulated head for active perception using\nstereo cameras. Its perception system detects not only peppers, but also\npeduncles and stems in real time, and performs online data association to build\na world model of pepper plants. Collision-aware online trajectory generation\nallows all three arms to safely track their respective targets for observation,\ngrasping, and cutting. We integrated perception and manipulation to perform\nselective harvesting of peppers and evaluated the system in lab experiments.\nUsing active perception coupled with end-effector force torque sensing for\ncompliant manipulation, HortiBot achieves high success rates.\n","authors":["Christian Lenz","Rohit Menon","Michael Schreiber","Melvin Paul Jacob","Sven Behnke","Maren Bennewitz"],"pdf_url":"https://arxiv.org/pdf/2403.15306v1.pdf","comment":"Submitted to International Conference on Intelligent Robots and\n  Systems (IROS) 2024. C. Lenz and R. Menon contributed equally"},{"id":"http://arxiv.org/abs/2401.15174v3","updated":"2024-03-22T15:02:37Z","published":"2024-01-26T19:39:33Z","title":"LaMI: Large Language Models for Multi-Modal Human-Robot Interaction","summary":"  This paper presents an innovative large language model (LLM)-based robotic\nsystem for enhancing multi-modal human-robot interaction (HRI). Traditional HRI\nsystems relied on complex designs for intent estimation, reasoning, and\nbehavior generation, which were resource-intensive. In contrast, our system\nempowers researchers and practitioners to regulate robot behavior through three\nkey aspects: providing high-level linguistic guidance, creating \"atomic\nactions\" and expressions the robot can use, and offering a set of examples.\nImplemented on a physical robot, it demonstrates proficiency in adapting to\nmulti-modal inputs and determining the appropriate manner of action to assist\nhumans with its arms, following researchers' defined guidelines.\nSimultaneously, it coordinates the robot's lid, neck, and ear movements with\nspeech output to produce dynamic, multi-modal expressions. This showcases the\nsystem's potential to revolutionize HRI by shifting from conventional, manual\nstate-and-flow design methods to an intuitive, guidance-based, and\nexample-driven approach. Supplementary material can be found at\nhttps://hri-eu.github.io/Lami/\n","authors":["Chao Wang","Stephan Hasler","Daniel Tanneberg","Felix Ocker","Frank Joublin","Antonello Ceravola","Joerg Deigmoeller","Michael Gienger"],"pdf_url":"https://arxiv.org/pdf/2401.15174v3.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2403.15239v1","updated":"2024-03-22T14:32:27Z","published":"2024-03-22T14:32:27Z","title":"Guided Decoding for Robot Motion Generation and Adaption","summary":"  We address motion generation for high-DoF robot arms in complex settings with\nobstacles, via points, etc. A significant advancement in this domain is\nachieved by integrating Learning from Demonstration (LfD) into the motion\ngeneration process. This integration facilitates rapid adaptation to new tasks\nand optimizes the utilization of accumulated expertise by allowing robots to\nlearn and generalize from demonstrated trajectories.\n  We train a transformer architecture on a large dataset of simulated\ntrajectories. This architecture, based on a conditional variational autoencoder\ntransformer, learns essential motion generation skills and adapts these to meet\nauxiliary tasks and constraints. Our auto-regressive approach enables real-time\nintegration of feedback from the physical system, enhancing the adaptability\nand efficiency of motion generation. We show that our model can generate motion\nfrom initial and target points, but also that it can adapt trajectories in\nnavigating complex tasks, including obstacle avoidance, via points, and meeting\nvelocity and acceleration constraints, across platforms.\n","authors":["Nutan Chen","Elie Aljalbout","Botond Cseke","Patrick van der Smagt"],"pdf_url":"https://arxiv.org/pdf/2403.15239v1.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2403.15223v1","updated":"2024-03-22T14:15:27Z","published":"2024-03-22T14:15:27Z","title":"TriHelper: Zero-Shot Object Navigation with Dynamic Assistance","summary":"  Navigating toward specific objects in unknown environments without additional\ntraining, known as Zero-Shot object navigation, poses a significant challenge\nin the field of robotics, which demands high levels of auxiliary information\nand strategic planning. Traditional works have focused on holistic solutions,\noverlooking the specific challenges agents encounter during navigation such as\ncollision, low exploration efficiency, and misidentification of targets. To\naddress these challenges, our work proposes TriHelper, a novel framework\ndesigned to assist agents dynamically through three primary navigation\nchallenges: collision, exploration, and detection. Specifically, our framework\nconsists of three innovative components: (i) Collision Helper, (ii) Exploration\nHelper, and (iii) Detection Helper. These components work collaboratively to\nsolve these challenges throughout the navigation process. Experiments on the\nHabitat-Matterport 3D (HM3D) and Gibson datasets demonstrate that TriHelper\nsignificantly outperforms all existing baseline methods in Zero-Shot object\nnavigation, showcasing superior success rates and exploration efficiency. Our\nablation studies further underscore the effectiveness of each helper in\naddressing their respective challenges, notably enhancing the agent's\nnavigation capabilities. By proposing TriHelper, we offer a fresh perspective\non advancing the object navigation task, paving the way for future research in\nthe domain of Embodied AI and visual-based navigation.\n","authors":["Lingfeng Zhang","Qiang Zhang","Hao Wang","Erjia Xiao","Zixuan Jiang","Honglei Chen","Renjing Xu"],"pdf_url":"https://arxiv.org/pdf/2403.15223v1.pdf","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2403.15203v1","updated":"2024-03-22T13:46:51Z","published":"2024-03-22T13:46:51Z","title":"DITTO: Demonstration Imitation by Trajectory Transformation","summary":"  Teaching robots new skills quickly and conveniently is crucial for the\nbroader adoption of robotic systems. In this work, we address the problem of\none-shot imitation from a single human demonstration, given by an RGB-D video\nrecording through a two-stage process. In the first stage which is offline, we\nextract the trajectory of the demonstration. This entails segmenting\nmanipulated objects and determining their relative motion in relation to\nsecondary objects such as containers. Subsequently, in the live online\ntrajectory generation stage, we first \\mbox{re-detect} all objects, then we\nwarp the demonstration trajectory to the current scene, and finally, we trace\nthe trajectory with the robot. To complete these steps, our method makes\nleverages several ancillary models, including those for segmentation, relative\nobject pose estimation, and grasp prediction. We systematically evaluate\ndifferent combinations of correspondence and re-detection methods to validate\nour design decision across a diverse range of tasks. Specifically, we collect\ndemonstrations of ten different tasks including pick-and-place tasks as well as\narticulated object manipulation. Finally, we perform extensive evaluations on a\nreal robot system to demonstrate the effectiveness and utility of our approach\nin real-world scenarios. We make the code publicly available at\nhttp://ditto.cs.uni-freiburg.de.\n","authors":["Nick Heppert","Max Argus","Tim Welschehold","Thomas Brox","Abhinav Valada"],"pdf_url":"https://arxiv.org/pdf/2403.15203v1.pdf","comment":"8 pages, 4 figures, 3 tables, submitted to IROS 2024"},{"id":"http://arxiv.org/abs/2403.15183v1","updated":"2024-03-22T13:12:30Z","published":"2024-03-22T13:12:30Z","title":"CRPlace: Camera-Radar Fusion with BEV Representation for Place\n  Recognition","summary":"  The integration of complementary characteristics from camera and radar data\nhas emerged as an effective approach in 3D object detection. However, such\nfusion-based methods remain unexplored for place recognition, an equally\nimportant task for autonomous systems. Given that place recognition relies on\nthe similarity between a query scene and the corresponding candidate scene, the\nstationary background of a scene is expected to play a crucial role in the\ntask. As such, current well-designed camera-radar fusion methods for 3D object\ndetection can hardly take effect in place recognition because they mainly focus\non dynamic foreground objects. In this paper, a background-attentive\ncamera-radar fusion-based method, named CRPlace, is proposed to generate\nbackground-attentive global descriptors from multi-view images and radar point\nclouds for accurate place recognition. To extract stationary background\nfeatures effectively, we design an adaptive module that generates the\nbackground-attentive mask by utilizing the camera BEV feature and radar dynamic\npoints. With the guidance of a background mask, we devise a bidirectional\ncross-attention-based spatial fusion strategy to facilitate comprehensive\nspatial interaction between the background information of the camera BEV\nfeature and the radar BEV feature. As the first camera-radar fusion-based place\nrecognition network, CRPlace has been evaluated thoroughly on the nuScenes\ndataset. The results show that our algorithm outperforms a variety of baseline\nmethods across a comprehensive set of metrics (recall@1 reaches 91.2%).\n","authors":["Shaowei Fu","Yifan Duan","Yao Li","Chengzhen Meng","Yingjie Wang","Jianmin Ji","Yanyong Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.15183v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15171v1","updated":"2024-03-22T12:48:00Z","published":"2024-03-22T12:48:00Z","title":"AV-Occupant Perceived Risk Model for Cut-In Scenarios with Empirical\n  Evaluation","summary":"  Advancements in autonomous vehicle (AV) technologies necessitate precise\nestimation of perceived risk to enhance user comfort, acceptance and trust.\nThis paper introduces a novel AV-Occupant Risk (AVOR) model designed for\nperceived risk estimation during AV cut-in scenarios. An empirical study is\nconducted with 18 participants with realistic cut-in scenarios. Two factors\nwere investigated: scenario risk and scene population. 76% of subjective risk\nresponses indicate an increase in perceived risk at cut-in initiation. The\nexisting perceived risk model did not capture this critical phenomenon. Our\nAVOR model demonstrated a significant improvement in estimating perceived risk\nduring the early stages of cut-ins, especially for the high-risk scenario,\nenhancing modelling accuracy by up to 54%. The concept of the AVOR model can\nquantify perceived risk in other diverse driving contexts characterized by\ndynamic uncertainties, enhancing the reliability and human-centred focus of AV\nsystems.\n","authors":["Sarah Barendswaard","Tong Duy Son"],"pdf_url":"https://arxiv.org/pdf/2403.15171v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.03270v2","updated":"2024-03-22T12:40:23Z","published":"2024-03-05T19:11:17Z","title":"Bi-KVIL: Keypoints-based Visual Imitation Learning of Bimanual\n  Manipulation Tasks","summary":"  Visual imitation learning has achieved impressive progress in learning\nunimanual manipulation tasks from a small set of visual observations, thanks to\nthe latest advances in computer vision. However, learning bimanual coordination\nstrategies and complex object relations from bimanual visual demonstrations, as\nwell as generalizing them to categorical objects in novel cluttered scenes\nremain unsolved challenges. In this paper, we extend our previous work on\nkeypoints-based visual imitation learning (\\mbox{K-VIL})~\\cite{gao_kvil_2023}\nto bimanual manipulation tasks. The proposed Bi-KVIL jointly extracts so-called\n\\emph{Hybrid Master-Slave Relationships} (HMSR) among objects and hands,\nbimanual coordination strategies, and sub-symbolic task representations. Our\nbimanual task representation is object-centric, embodiment-independent, and\nviewpoint-invariant, thus generalizing well to categorical objects in novel\nscenes. We evaluate our approach in various real-world applications, showcasing\nits ability to learn fine-grained bimanual manipulation tasks from a small\nnumber of human demonstration videos. Videos and source code are available at\nhttps://sites.google.com/view/bi-kvil.\n","authors":["Jianfeng Gao","Xiaoshu Jin","Franziska Krebs","Noémie Jaquier","Tamim Asfour"],"pdf_url":"https://arxiv.org/pdf/2403.03270v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15156v1","updated":"2024-03-22T12:11:06Z","published":"2024-03-22T12:11:06Z","title":"Infrastructure-Assisted Collaborative Perception in Automated Valet\n  Parking: A Safety Perspective","summary":"  Environmental perception in Automated Valet Parking (AVP) has been a\nchallenging task due to severe occlusions in parking garages. Although\nCollaborative Perception (CP) can be applied to broaden the field of view of\nconnected vehicles, the limited bandwidth of vehicular communications restricts\nits application. In this work, we propose a BEV feature-based CP network\narchitecture for infrastructure-assisted AVP systems. The model takes the\nroadside camera and LiDAR as optional inputs and adaptively fuses them with\nonboard sensors in a unified BEV representation. Autoencoder and downsampling\nare applied for channel-wise and spatial-wise dimension reduction, while\nsparsification and quantization further compress the feature map with little\nloss in data precision. Combining these techniques, the size of a BEV feature\nmap is effectively compressed to fit in the feasible data rate of the NR-V2X\nnetwork. With the synthetic AVP dataset, we observe that CP can effectively\nincrease perception performance, especially for pedestrians. Moreover, the\nadvantage of infrastructure-assisted CP is demonstrated in two typical\nsafety-critical scenarios in the AVP setting, increasing the maximum safe\ncruising speed by up to 3m/s in both scenarios.\n","authors":["Yukuan Jia","Jiawen Zhang","Shimeng Lu","Baokang Fan","Ruiqing Mao","Sheng Zhou","Zhisheng Niu"],"pdf_url":"https://arxiv.org/pdf/2403.15156v1.pdf","comment":"7 pages, 7 figures, 4 tables, accepted by IEEE VTC2024-Spring"},{"id":"http://arxiv.org/abs/2403.15151v1","updated":"2024-03-22T12:07:03Z","published":"2024-03-22T12:07:03Z","title":"RHINO-VR Experience: Teaching Mobile Robotics Concepts in an Interactive\n  Museum Exhibit","summary":"  In 1997, the very first tour guide robot RHINO was deployed in a museum in\nGermany. With the ability to navigate autonomously through the environment, the\nrobot gave tours to over 2,000 visitors. Today, RHINO itself has become an\nexhibit and is no longer operational. In this paper, we present RHINO-VR, an\ninteractive museum exhibit using virtual reality (VR) that allows museum\nvisitors to experience the historical robot RHINO in operation in a virtual\nmuseum. RHINO-VR, unlike static exhibits, enables users to familiarize\nthemselves with basic mobile robotics concepts without the fear of damaging the\nexhibit. In the virtual environment, the user is able to interact with RHINO in\nVR by pointing to a location to which the robot should navigate and observing\nthe corresponding actions of the robot. To include other visitors who cannot\nuse the VR, we provide an external observation view to make RHINO visible to\nthem. We evaluated our system by measuring the frame rate of the VR simulation,\ncomparing the generated virtual 3D models with the originals, and conducting a\nuser study. The user-study showed that RHINO-VR improved the visitors'\nunderstanding of the robot's functionality and that they would recommend\nexperiencing the VR exhibit to others.\n","authors":["Erik Schlachhoff","Nils Dengler","Leif Van Holland","Patrick Stotko","Jorge de Heuvel","Reinhard Klein","Maren Bennewitz"],"pdf_url":"https://arxiv.org/pdf/2403.15151v1.pdf","comment":"Submitted to IEEE International Symposium on Robot and Human\n  Interactive Communication (RO-MAN)"},{"id":"http://arxiv.org/abs/2403.15142v1","updated":"2024-03-22T11:52:31Z","published":"2024-03-22T11:52:31Z","title":"ALPINE: a climbing robot for operations in mountain environments","summary":"  Mountain slopes are perfect examples of harsh environments in which humans\nare required to perform difficult and dangerous operations such as removing\nunstable boulders, dangerous vegetation or deploying safety nets. A good\nreplacement for human intervention can be offered by climbing robots. The\ndifferent solutions existing in the literature are not up to the task for the\ndifficulty of the requirements (navigation, heavy payloads, flexibility in the\nexecution of the tasks). In this paper, we propose a robotic platform that can\nfill this gap. Our solution is based on a robot that hangs on ropes, and uses a\nretractable leg to jump away from the mountain walls. Our package of mechanical\nsolutions, along with the algorithms developed for motion planning and control,\ndelivers swift navigation on irregular and steep slopes, the possibility to\novercome or travel around significant natural barriers, and the ability to\ncarry heavy payloads and execute complex tasks. In the paper, we give a full\naccount of our main design and algorithmic choices and show the feasibility of\nthe solution through a large number of physically simulated scenarios.\n","authors":["Michele Focchi","Andrea Del Prete","Daniele Fontanelli","Marco Frego","Angelika Peer","Luigi Palopoli"],"pdf_url":"https://arxiv.org/pdf/2403.15142v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15116v1","updated":"2024-03-22T11:20:30Z","published":"2024-03-22T11:20:30Z","title":"Collision Avoidance Safety Filter for an Autonomous E-Scooter using\n  Ultrasonic Sensors","summary":"  In this paper, we propose a collision avoidance safety filter for autonomous\nelectric scooters to enable safe operation of such vehicles in pedestrian\nareas. In particular, we employ multiple low-cost ultrasonic sensors to detect\na wide range of possible obstacles in front of the e-scooter. Based on possibly\nfaulty distance measurements, we design a filter to mitigate measurement noise\nand missing values as well as a gain-scheduled controller to limit the velocity\ncommanded to the e-scooter when required due to imminent collisions. The\nproposed controller structure is able to prevent collisions with unknown\nobstacles by deploying a reduced safe velocity ensuring a sufficiently large\nsafety distance. The collision avoidance approach is designed such that it may\nbe easily deployed in similar applications of general micromobility vehicles.\nThe effectiveness of our proposed safety filter is demonstrated in real-world\nexperiments.\n","authors":["Robin Strässer","Marc Seidel","Felix Brändle","David Meister","Raffaele Soloperto","David Hambach Ferrer","Frank Allgöwer"],"pdf_url":"https://arxiv.org/pdf/2403.15116v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15113v1","updated":"2024-03-22T11:08:56Z","published":"2024-03-22T11:08:56Z","title":"Set-membership target search and tracking within an unknown cluttered\n  area using cooperating UAVs equipped with vision systems","summary":"  This paper addresses the problem of target search and tracking using a fleet\nof cooperating UAVs evolving in some unknown region of interest containing an a\npriori unknown number of moving ground targets. Each drone is equipped with an\nembedded Computer Vision System (CVS), providing an image with labeled pixels\nand a depth map of the observed part of its environment. Moreover, a box\ncontaining the corresponding pixels in the image frame is available when a UAV\nidentifies a target. Hypotheses regarding information provided by the pixel\nclassification, depth map construction, and target identification algorithms\nare proposed to allow its exploitation by set-membership approaches. A\nset-membership target location estimator is developed using the information\nprovided by the CVS. Each UAV evaluates sets guaranteed to contain the location\nof the identified targets and a set possibly containing the locations of\ntargets still to be identified. Then, each UAV uses these sets to search and\ntrack targets cooperatively.\n","authors":["Maxime Zagar","Luc Meyer","Michel Kieffer","Hélène Piet-Lahanier"],"pdf_url":"https://arxiv.org/pdf/2403.15113v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15107v1","updated":"2024-03-22T10:51:31Z","published":"2024-03-22T10:51:31Z","title":"PseudoTouch: Efficiently Imaging the Surface Feel of Objects for Robotic\n  Manipulation","summary":"  Humans seemingly incorporate potential touch signals in their perception. Our\ngoal is to equip robots with a similar capability, which we term \\ourmodel.\n\\ourmodel aims to predict the expected touch signal based on a visual patch\nrepresenting the touched area. We frame this problem as the task of learning a\nlow-dimensional visual-tactile embedding, wherein we encode a depth patch from\nwhich we decode the tactile signal. To accomplish this task, we employ ReSkin,\nan inexpensive and replaceable magnetic-based tactile sensor. Using ReSkin, we\ncollect and train PseudoTouch on a dataset comprising aligned tactile and\nvisual data pairs obtained through random touching of eight basic geometric\nshapes. We demonstrate the efficacy of PseudoTouch through its application to\ntwo downstream tasks: object recognition and grasp stability prediction. In the\nobject recognition task, we evaluate the learned embedding's performance on a\nset of five basic geometric shapes and five household objects. Using\nPseudoTouch, we achieve an object recognition accuracy 84% after just ten\ntouches, surpassing a proprioception baseline. For the grasp stability task, we\nuse ACRONYM labels to train and evaluate a grasp success predictor using\nPseudoTouch's predictions derived from virtual depth information. Our approach\nyields an impressive 32% absolute improvement in accuracy compared to the\nbaseline relying on partial point cloud data. We make the data, code, and\ntrained models publicly available at http://pseudotouch.cs.uni-freiburg.de.\n","authors":["Adrian Röfer","Nick Heppert","Abdallah Ayman","Eugenio Chisari","Abhinav Valada"],"pdf_url":"https://arxiv.org/pdf/2403.15107v1.pdf","comment":"8 pages, 7 figures, 2 tables, submitted to IROS2024"},{"id":"http://arxiv.org/abs/2403.15102v1","updated":"2024-03-22T10:41:25Z","published":"2024-03-22T10:41:25Z","title":"Learning from Visual Demonstrations through Differentiable Nonlinear MPC\n  for Personalized Autonomous Driving","summary":"  Human-like autonomous driving controllers have the potential to enhance\npassenger perception of autonomous vehicles. This paper proposes DriViDOC: a\nmodel for Driving from Vision through Differentiable Optimal Control, and its\napplication to learn personalized autonomous driving controllers from human\ndemonstrations. DriViDOC combines the automatic inference of relevant features\nfrom camera frames with the properties of nonlinear model predictive control\n(NMPC), such as constraint satisfaction. Our approach leverages the\ndifferentiability of parametric NMPC, allowing for end-to-end learning of the\ndriving model from images to control. The model is trained on an offline\ndataset comprising various driving styles collected on a motion-base driving\nsimulator. During online testing, the model demonstrates successful imitation\nof different driving styles, and the interpreted NMPC parameters provide\ninsights into the achievement of specific driving behaviors. Our experimental\nresults show that DriViDOC outperforms other methods involving NMPC and neural\nnetworks, exhibiting an average improvement of 20% in imitation scores.\n","authors":["Flavia Sofia Acerbo","Jan Swevers","Tinne Tuytelaars","Tong Duy Son"],"pdf_url":"https://arxiv.org/pdf/2403.15102v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible. Accompanying video available at:\n  https://youtu.be/WxWPuAtJ08E"},{"id":"http://arxiv.org/abs/2403.15100v1","updated":"2024-03-22T10:39:22Z","published":"2024-03-22T10:39:22Z","title":"Subequivariant Reinforcement Learning Framework for Coordinated Motion\n  Control","summary":"  Effective coordination is crucial for motion control with reinforcement\nlearning, especially as the complexity of agents and their motions increases.\nHowever, many existing methods struggle to account for the intricate\ndependencies between joints. We introduce CoordiGraph, a novel architecture\nthat leverages subequivariant principles from physics to enhance coordination\nof motion control with reinforcement learning. This method embeds the\nprinciples of equivariance as inherent patterns in the learning process under\ngravity influence, which aids in modeling the nuanced relationships between\njoints vital for motion control. Through extensive experimentation with\nsophisticated agents in diverse environments, we highlight the merits of our\napproach. Compared to current leading methods, CoordiGraph notably enhances\ngeneralization and sample efficiency.\n","authors":["Haoyu Wang","Xiaoyu Tan","Xihe Qiu","Chao Qu"],"pdf_url":"https://arxiv.org/pdf/2403.15100v1.pdf","comment":"7 pages, 7 figures, 2024 IEEE International Conference on Robotics\n  and Automation"},{"id":"http://arxiv.org/abs/2304.09793v2","updated":"2024-03-22T10:36:32Z","published":"2023-04-19T16:21:14Z","title":"Event-based Simultaneous Localization and Mapping: A Comprehensive\n  Survey","summary":"  In recent decades, visual simultaneous localization and mapping (vSLAM) has\ngained significant interest in both academia and industry. It estimates camera\nmotion and reconstructs the environment concurrently using visual sensors on a\nmoving robot. However, conventional cameras are limited by hardware, including\nmotion blur and low dynamic range, which can negatively impact performance in\nchallenging scenarios like high-speed motion and high dynamic range\nillumination. Recent studies have demonstrated that event cameras, a new type\nof bio-inspired visual sensor, offer advantages such as high temporal\nresolution, dynamic range, low power consumption, and low latency. This paper\npresents a timely and comprehensive review of event-based vSLAM algorithms that\nexploit the benefits of asynchronous and irregular event streams for\nlocalization and mapping tasks. The review covers the working principle of\nevent cameras and various event representations for preprocessing event data.\nIt also categorizes event-based vSLAM methods into four main categories:\nfeature-based, direct, motion-compensation, and deep learning methods, with\ndetailed discussions and practical guidance for each approach. Furthermore, the\npaper evaluates the state-of-the-art methods on various benchmarks,\nhighlighting current challenges and future opportunities in this emerging\nresearch area. A public repository will be maintained to keep track of the\nrapid developments in this field at\n{\\url{https://github.com/kun150kun/ESLAM-survey}}.\n","authors":["Kunping Huang","Sen Zhang","Jing Zhang","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2304.09793v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.16973v2","updated":"2024-03-22T10:27:53Z","published":"2023-06-29T14:28:22Z","title":"Robust Direct Data-Driven Control for Probabilistic Systems","summary":"  We propose a data-driven control method for systems with aleatoric\nuncertainty, for example, robot fleets with variations between agents. Our\nmethod leverages shared trajectory data to increase the robustness of the\ndesigned controller and thus facilitate transfer to new variations without the\nneed for prior parameter and uncertainty estimations. In contrast to existing\nwork on experience transfer for performance, our approach focuses on robustness\nand uses data collected from multiple realizations to guarantee generalization\nto unseen ones. Our method is based on scenario optimization combined with\nrecent formulations for direct data-driven control. We derive lower bounds on\nthe amount of data required to achieve quadratic stability for probabilistic\nsystems with aleatoric uncertainty and demonstrate the benefits of our\ndata-driven method through a numerical example. We find that the learned\ncontrollers generalize well to high variations in the dynamics even when based\non only a few short open-loop trajectories. Robust experience transfer enables\nthe design of safe and robust controllers that work out of the box without any\nadditional learning during deployment.\n","authors":["Alexander von Rohr","Dmitrii Likhachev","Sebastian Trimpe"],"pdf_url":"https://arxiv.org/pdf/2306.16973v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15079v1","updated":"2024-03-22T10:05:21Z","published":"2024-03-22T10:05:21Z","title":"Automated Feature Selection for Inverse Reinforcement Learning","summary":"  Inverse reinforcement learning (IRL) is an imitation learning approach to\nlearning reward functions from expert demonstrations. Its use avoids the\ndifficult and tedious procedure of manual reward specification while retaining\nthe generalization power of reinforcement learning. In IRL, the reward is\nusually represented as a linear combination of features. In continuous state\nspaces, the state variables alone are not sufficiently rich to be used as\nfeatures, but which features are good is not known in general. To address this\nissue, we propose a method that employs polynomial basis functions to form a\ncandidate set of features, which are shown to allow the matching of statistical\nmoments of state distributions. Feature selection is then performed for the\ncandidates by leveraging the correlation between trajectory probabilities and\nfeature expectations. We demonstrate the approach's effectiveness by recovering\nreward functions that capture expert policies across non-linear control tasks\nof increasing complexity. Code, data, and videos are available at\nhttps://sites.google.com/view/feature4irl.\n","authors":["Daulet Baimukashev","Gokhan Alcan","Ville Kyrki"],"pdf_url":"https://arxiv.org/pdf/2403.15079v1.pdf","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2403.15067v1","updated":"2024-03-22T09:48:40Z","published":"2024-03-22T09:48:40Z","title":"A Twin Delayed Deep Deterministic Policy Gradient Algorithm for\n  Autonomous Ground Vehicle Navigation via Digital Twin Perception Awareness","summary":"  Autonomous ground vehicle (UGV) navigation has the potential to revolutionize\nthe transportation system by increasing accessibility to disabled people,\nensure safety and convenience of use. However, UGV requires extensive and\nefficient testing and evaluation to ensure its acceptance for public use. This\ntesting are mostly done in a simulator which result to sim2real transfer gap.\nIn this paper, we propose a digital twin perception awareness approach for the\ncontrol of robot navigation without prior creation of the virtual environment\n(VT) environment state. To achieve this, we develop a twin delayed deep\ndeterministic policy gradient (TD3) algorithm that ensures collision avoidance\nand goal-based path planning. We demonstrate the performance of our approach on\ndifferent environment dynamics. We show that our approach is capable of\nefficiently avoiding collision with obstacles and navigating to its desired\ndestination, while at the same time safely avoids obstacles using the\ninformation received from the LIDAR sensor mounted on the robot. Our approach\nbridges the gap between sim-to-real transfer and contributes to the adoption of\nUGVs in real world. We validate our approach in simulation and a real-world\napplication in an office space.\n","authors":["Kabirat Olayemi","Mien Van","Sean McLoone","Yuzhu Sun","Jack Close","Nguyen Minh Nhat","Stephen McIlvanna"],"pdf_url":"https://arxiv.org/pdf/2403.15067v1.pdf","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2403.15054v1","updated":"2024-03-22T09:26:52Z","published":"2024-03-22T09:26:52Z","title":"Rethinking 6-Dof Grasp Detection: A Flexible Framework for High-Quality\n  Grasping","summary":"  Robotic grasping is a primitive skill for complex tasks and is fundamental to\nintelligence. For general 6-Dof grasping, most previous methods directly\nextract scene-level semantic or geometric information, while few of them\nconsider the suitability for various downstream applications, such as\ntarget-oriented grasping. Addressing this issue, we rethink 6-Dof grasp\ndetection from a grasp-centric view and propose a versatile grasp framework\ncapable of handling both scene-level and target-oriented grasping. Our\nframework, FlexLoG, is composed of a Flexible Guidance Module and a Local Grasp\nModel. Specifically, the Flexible Guidance Module is compatible with both\nglobal (e.g., grasp heatmap) and local (e.g., visual grounding) guidance,\nenabling the generation of high-quality grasps across various tasks. The Local\nGrasp Model focuses on object-agnostic regional points and predicts grasps\nlocally and intently. Experiment results reveal that our framework achieves\nover 18% and 23% improvement on unseen splits of the GraspNet-1Billion Dataset.\nFurthermore, real-world robotic tests in three distinct settings yield a 95%\nsuccess rate.\n","authors":["Wei Tang","Siang Chen","Pengwei Xie","Dingchang Hu","Wenming Yang","Guijin Wang"],"pdf_url":"https://arxiv.org/pdf/2403.15054v1.pdf","comment":"8 pages, 8 figures"},{"id":"http://arxiv.org/abs/2401.10519v2","updated":"2024-03-22T09:09:45Z","published":"2024-01-19T06:32:54Z","title":"A Wind-Aware Path Planning Method for UAV-Asisted Bridge Inspection","summary":"  In response to the gap in considering wind conditions in the bridge\ninspection using unmanned aerial vehicle (UAV) , this paper proposes a path\nplanning method for UAVs that takes into account the influence of wind, based\non the simulated annealing algorithm. The algorithm considers the wind factors,\nincluding the influence of different wind speeds and directions at the same\ntime on the path planning of the UAV. Firstly, An environment model is\nconstructed specifically for UAV bridge inspection, taking into account the\nvarious objective functions and constraint conditions of UAVs. A more\nsophisticated and precise mathematical model is then developed based on this\nenvironmental model to enable efficient and effective UAV path planning.\nSecondly, the bridge separation planning model is applied in a novel way, and a\nseries of parameters are simulated, including the adjustment of the initial\ntemperature value. The experimental results demonstrate that, compared with\ntraditional local search algorithms, the proposed method achieves a cost\nreduction of 30.05\\% and significantly improves effectiveness. Compared to path\nplanning methods that do not consider wind factors, the proposed approach\nyields more realistic and practical results for UAV applications, as\ndemonstrated by its improved effectiveness in simulations. These findings\nhighlight the value of our method in facilitating more accurate and efficient\nUAV path planning in wind-prone environments.\n","authors":["Jian Xu","Hua Dai"],"pdf_url":"https://arxiv.org/pdf/2401.10519v2.pdf","comment":"After carefully analysis, there is a bit design flaws in Algorithm 1.\n  The experimental work of the paper is not comprehensive,which lacks an\n  evaluation of the algorithm's running time"},{"id":"http://arxiv.org/abs/2402.17587v3","updated":"2024-03-22T07:23:51Z","published":"2024-02-25T07:59:10Z","title":"Instance-aware Exploration-Verification-Exploitation for Instance\n  ImageGoal Navigation","summary":"  As a new embodied vision task, Instance ImageGoal Navigation (IIN) aims to\nnavigate to a specified object depicted by a goal image in an unexplored\nenvironment.\n  The main challenge of this task lies in identifying the target object from\ndifferent viewpoints while rejecting similar distractors.\n  Existing ImageGoal Navigation methods usually adopt the simple\nExploration-Exploitation framework and ignore the identification of specific\ninstance during navigation.\n  In this work, we propose to imitate the human behaviour of ``getting closer\nto confirm\" when distinguishing objects from a distance.\n  Specifically, we design a new modular navigation framework named\nInstance-aware Exploration-Verification-Exploitation (IEVE) for instance-level\nimage goal navigation.\n  Our method allows for active switching among the exploration, verification,\nand exploitation actions, thereby facilitating the agent in making reasonable\ndecisions under different situations.\n  On the challenging HabitatMatterport 3D semantic (HM3D-SEM) dataset, our\nmethod surpasses previous state-of-the-art work, with a classical segmentation\nmodel (0.684 vs. 0.561 success) or a robust model (0.702 vs. 0.561 success)\n","authors":["Xiaohan Lei","Min Wang","Wengang Zhou","Li Li","Houqiang Li"],"pdf_url":"https://arxiv.org/pdf/2402.17587v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14997v1","updated":"2024-03-22T07:17:56Z","published":"2024-03-22T07:17:56Z","title":"Linear Quadratic Guidance Law for Joint Motion Planning of a\n  Pursuer-Turret Assembly","summary":"  This paper presents joint motion planning of a vehicle with an attached\nrotating turret. The turret has a limited range as well as the field of view.\nThe objective is capture a maneuvering target such that at the terminal time it\nis withing the field-of-view and range limits. Catering to it, we present a\nminimum effort guidance law that commensurate for the turn rate abilities of\nthe vehicle and the turret. The guidance law is obtained using linearization\nabout the collision triangle and admits an analytical solution. Simulation\nresults are presented to exemplify the cooperation between the turret and the\nvehicle.\n","authors":["Bhargav Jha","Shaunak Bopardikar","Alexander Von Moll","David Casbeer"],"pdf_url":"https://arxiv.org/pdf/2403.14997v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.07433v5","updated":"2024-03-22T06:42:03Z","published":"2023-02-15T02:32:26Z","title":"A Survey on Global LiDAR Localization: Challenges, Advances and Open\n  Problems","summary":"  Knowledge about the own pose is key for all mobile robot applications. Thus\npose estimation is part of the core functionalities of mobile robots. Over the\nlast two decades, LiDAR scanners have become the standard sensor for robot\nlocalization and mapping. This article aims to provide an overview of recent\nprogress and advancements in LiDAR-based global localization. We begin by\nformulating the problem and exploring the application scope. We then present a\nreview of the methodology, including recent advancements in several topics,\nsuch as maps, descriptor extraction, and cross-robot localization. The contents\nof the article are organized under three themes. The first theme concerns the\ncombination of global place retrieval and local pose estimation. The second\ntheme is upgrading single-shot measurements to sequential ones for sequential\nglobal localization. Finally, the third theme focuses on extending single-robot\nglobal localization to cross-robot localization in multi-robot systems. We\nconclude the survey with a discussion of open challenges and promising\ndirections in global LiDAR localization. To our best knowledge, this is the\nfirst comprehensive survey on global LiDAR localization for mobile robots.\n","authors":["Huan Yin","Xuecheng Xu","Sha Lu","Xieyuanli Chen","Rong Xiong","Shaojie Shen","Cyrill Stachniss","Yue Wang"],"pdf_url":"https://arxiv.org/pdf/2302.07433v5.pdf","comment":"Publishe on International Journal of Computer Vision (IJCV)"},{"id":"http://arxiv.org/abs/2403.14956v1","updated":"2024-03-22T05:21:05Z","published":"2024-03-22T05:21:05Z","title":"Boundary-Aware Value Function Generation for Safe Stochastic Motion\n  Planning","summary":"  Navigation safety is critical for many autonomous systems such as\nself-driving vehicles in an urban environment. It requires an explicit\nconsideration of boundary constraints that describe the borders of any\ninfeasible, non-navigable, or unsafe regions. We propose a principled\nboundary-aware safe stochastic planning framework with promising results. Our\nmethod generates a value function that can strictly distinguish the state\nvalues between free (safe) and non-navigable (boundary) spaces in the\ncontinuous state, naturally leading to a safe boundary-aware policy. At the\ncore of our solution lies a seamless integration of finite elements and\nkernel-based functions, where the finite elements allow us to characterize\nsafety-critical states' borders accurately, and the kernel-based function\nspeeds up computation for the non-safety-critical states. The proposed method\nwas evaluated through extensive simulations and demonstrated safe navigation\nbehaviors in mobile navigation tasks. Additionally, we demonstrate that our\napproach can maneuver safely and efficiently in cluttered real-world\nenvironments using a ground vehicle with strong external disturbances, such as\nnavigating on a slippery floor and against external human intervention.\n","authors":["Junhong Xu","Kai Yin","Jason M. Gregory","Kris Hauser","Lantao Liu"],"pdf_url":"https://arxiv.org/pdf/2403.14956v1.pdf","comment":"Accepted by International Journal of Robotics Research"},{"id":"http://arxiv.org/abs/2309.15271v2","updated":"2024-03-22T03:32:09Z","published":"2023-09-26T21:10:12Z","title":"Kinematic Modularity of Elementary Dynamic Actions","summary":"  In this paper, a kinematically modular approach to robot control is\npresented. The method involves structures called Elementary Dynamic Actions and\na network model combining these elements. With this control framework, a rich\nrepertoire of movements can be generated by combination of basic modules. The\nproblems of solving inverse kinematics, managing kinematic singularity and\nkinematic redundancy are avoided. The modular approach is robust against\ncontact and physical interaction, which makes it particularly effective for\ncontact-rich manipulation. Each kinematic module can be learned by Imitation\nLearning, thereby resulting in a modular learning strategy for robot control.\nThe theoretical foundations and their real robot implementation are presented.\nUsing a KUKA LBR iiwa14 robot, three tasks were considered: (1) generating a\nsequence of discrete movements, (2) generating a combination of discrete and\nrhythmic movements, and (3) a drawing and erasing task. The results obtained\nindicate that this modular approach has the potential to simplify the\ngeneration of a diverse range of robot actions.\n","authors":["Moses C. Nah","Johannes Lachner","Federico Tessari","Neville Hogan"],"pdf_url":"https://arxiv.org/pdf/2309.15271v2.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2403.14545v2","updated":"2024-03-22T03:19:50Z","published":"2024-03-21T16:44:49Z","title":"Learning Hierarchical Control For Multi-Agent Capacity-Constrained\n  Systems","summary":"  This paper introduces a novel data-driven hierarchical control scheme for\nmanaging a fleet of nonlinear, capacity-constrained autonomous agents in an\niterative environment. We propose a control framework consisting of a\nhigh-level dynamic task assignment and routing layer and low-level motion\nplanning and tracking layer. Each layer of the control hierarchy uses a\ndata-driven Model Predictive Control (MPC) policy, maintaining bounded\ncomputational complexity at each calculation of a new task assignment or\nactuation input. We utilize collected data to iteratively refine estimates of\nagent capacity usage, and update MPC policy parameters accordingly. Our\napproach leverages tools from iterative learning control to integrate learning\nat both levels of the hierarchy, and coordinates learning between levels in\norder to maintain closed-loop feasibility and performance improvement of the\nconnected architecture.\n","authors":["Charlott Vallon","Alessandro Pinto","Bartolomeo Stellato","Francesco Borrelli"],"pdf_url":"https://arxiv.org/pdf/2403.14545v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.07894v5","updated":"2024-03-22T02:10:49Z","published":"2023-06-13T16:39:39Z","title":"iSLAM: Imperative SLAM","summary":"  Simultaneous Localization and Mapping (SLAM) stands as one of the critical\nchallenges in robot navigation. A SLAM system often consists of a front-end\ncomponent for motion estimation and a back-end system for eliminating\nestimation drifts. Recent advancements suggest that data-driven methods are\nhighly effective for front-end tasks, while geometry-based methods continue to\nbe essential in the back-end processes. However, such a decoupled paradigm\nbetween the data-driven front-end and geometry-based back-end can lead to\nsub-optimal performance, consequently reducing the system's capabilities and\ngeneralization potential. To solve this problem, we proposed a novel\nself-supervised imperative learning framework, named imperative SLAM (iSLAM),\nwhich fosters reciprocal correction between the front-end and back-end, thus\nenhancing performance without necessitating any external supervision.\nSpecifically, we formulate the SLAM problem as a bilevel optimization so that\nthe front-end and back-end are bidirectionally connected. As a result, the\nfront-end model can learn global geometric knowledge obtained through pose\ngraph optimization by back-propagating the residuals from the back-end\ncomponent. We showcase the effectiveness of this new framework through an\napplication of stereo-inertial SLAM. The experiments show that the iSLAM\ntraining strategy achieves an accuracy improvement of 22% on average over a\nbaseline model. To the best of our knowledge, iSLAM is the first SLAM system\nshowing that the front-end and back-end components can mutually correct each\nother in a self-supervised manner.\n","authors":["Taimeng Fu","Shaoshu Su","Yiren Lu","Chen Wang"],"pdf_url":"https://arxiv.org/pdf/2306.07894v5.pdf","comment":"The paper has been accepted by IEEE Robotics and Automation Letters\n  (RA-L)"},{"id":"http://arxiv.org/abs/2306.06531v3","updated":"2024-03-22T00:21:04Z","published":"2023-06-10T21:58:29Z","title":"AutoTAMP: Autoregressive Task and Motion Planning with LLMs as\n  Translators and Checkers","summary":"  For effective human-robot interaction, robots need to understand, plan, and\nexecute complex, long-horizon tasks described by natural language. Recent\nadvances in large language models (LLMs) have shown promise for translating\nnatural language into robot action sequences for complex tasks. However,\nexisting approaches either translate the natural language directly into robot\ntrajectories or factor the inference process by decomposing language into task\nsub-goals and relying on a motion planner to execute each sub-goal. When\ncomplex environmental and temporal constraints are involved, inference over\nplanning tasks must be performed jointly with motion plans using traditional\ntask-and-motion planning (TAMP) algorithms, making factorization into subgoals\nuntenable. Rather than using LLMs to directly plan task sub-goals, we instead\nperform few-shot translation from natural language task descriptions to an\nintermediate task representation that can then be consumed by a TAMP algorithm\nto jointly solve the task and motion plan. To improve translation, we\nautomatically detect and correct both syntactic and semantic errors via\nautoregressive re-prompting, resulting in significant improvements in task\ncompletion. We show that our approach outperforms several methods using LLMs as\nplanners in complex task domains. See our project website\nhttps://yongchao98.github.io/MIT-REALM-AutoTAMP/ for prompts, videos, and code.\n","authors":["Yongchao Chen","Jacob Arkin","Charles Dawson","Yang Zhang","Nicholas Roy","Chuchu Fan"],"pdf_url":"https://arxiv.org/pdf/2306.06531v3.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2309.15943v2","updated":"2024-03-22T00:11:21Z","published":"2023-09-27T18:40:36Z","title":"Scalable Multi-Robot Collaboration with Large Language Models:\n  Centralized or Decentralized Systems?","summary":"  A flurry of recent work has demonstrated that pre-trained large language\nmodels (LLMs) can be effective task planners for a variety of single-robot\ntasks. The planning performance of LLMs is significantly improved via prompting\ntechniques, such as in-context learning or re-prompting with state feedback,\nplacing new importance on the token budget for the context window. An\nunder-explored but natural next direction is to investigate LLMs as multi-robot\ntask planners. However, long-horizon, heterogeneous multi-robot planning\nintroduces new challenges of coordination while also pushing up against the\nlimits of context window length. It is therefore critical to find\ntoken-efficient LLM planning frameworks that are also able to reason about the\ncomplexities of multi-robot coordination. In this work, we compare the task\nsuccess rate and token efficiency of four multi-agent communication frameworks\n(centralized, decentralized, and two hybrid) as applied to four\ncoordination-dependent multi-agent 2D task scenarios for increasing numbers of\nagents. We find that a hybrid framework achieves better task success rates\nacross all four tasks and scales better to more agents. We further demonstrate\nthe hybrid frameworks in 3D simulations where the vision-to-text problem and\ndynamical errors are considered. See our project website\nhttps://yongchao98.github.io/MIT-REALM-Multi-Robot/ for prompts, videos, and\ncode.\n","authors":["Yongchao Chen","Jacob Arkin","Yang Zhang","Nicholas Roy","Chuchu Fan"],"pdf_url":"https://arxiv.org/pdf/2309.15943v2.pdf","comment":"7 pages, 8 figures"},{"id":"http://arxiv.org/abs/2403.15648v1","updated":"2024-03-22T23:12:28Z","published":"2024-03-22T23:12:28Z","title":"SRLM: Human-in-Loop Interactive Social Robot Navigation with Large\n  Language Model and Deep Reinforcement Learning","summary":"  An interactive social robotic assistant must provide services in complex and\ncrowded spaces while adapting its behavior based on real-time human language\ncommands or feedback. In this paper, we propose a novel hybrid approach called\nSocial Robot Planner (SRLM), which integrates Large Language Models (LLM) and\nDeep Reinforcement Learning (DRL) to navigate through human-filled public\nspaces and provide multiple social services. SRLM infers global planning from\nhuman-in-loop commands in real-time, and encodes social information into a\nLLM-based large navigation model (LNM) for low-level motion execution.\nMoreover, a DRL-based planner is designed to maintain benchmarking performance,\nwhich is blended with LNM by a large feedback model (LFM) to address the\ninstability of current text and LLM-driven LNM. Finally, SRLM demonstrates\noutstanding performance in extensive experiments. More details about this work\nare available at: https://sites.google.com/view/navi-srlm\n","authors":["Weizheng Wang","Le Mao","Ruiqi Wang","Byung-Cheol Min"],"pdf_url":"https://arxiv.org/pdf/2403.15648v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15637v1","updated":"2024-03-22T22:27:42Z","published":"2024-03-22T22:27:42Z","title":"CoNVOI: Context-aware Navigation using Vision Language Models in Outdoor\n  and Indoor Environments","summary":"  We present ConVOI, a novel method for autonomous robot navigation in\nreal-world indoor and outdoor environments using Vision Language Models (VLMs).\nWe employ VLMs in two ways: first, we leverage their zero-shot image\nclassification capability to identify the context or scenario (e.g., indoor\ncorridor, outdoor terrain, crosswalk, etc) of the robot's surroundings, and\nformulate context-based navigation behaviors as simple text prompts (e.g.\n``stay on the pavement\"). Second, we utilize their state-of-the-art semantic\nunderstanding and logical reasoning capabilities to compute a suitable\ntrajectory given the identified context. To this end, we propose a novel\nmulti-modal visual marking approach to annotate the obstacle-free regions in\nthe RGB image used as input to the VLM with numbers, by correlating it with a\nlocal occupancy map of the environment. The marked numbers ground image\nlocations in the real-world, direct the VLM's attention solely to navigable\nlocations, and elucidate the spatial relationships between them and terrains\ndepicted in the image to the VLM. Next, we query the VLM to select numbers on\nthe marked image that satisfy the context-based behavior text prompt, and\nconstruct a reference path using the selected numbers. Finally, we propose a\nmethod to extrapolate the reference trajectory when the robot's environmental\ncontext has not changed to prevent unnecessary VLM queries. We use the\nreference trajectory to guide a motion planner, and demonstrate that it leads\nto human-like behaviors (e.g. not cutting through a group of people, using\ncrosswalks, etc.) in various real-world indoor and outdoor scenarios.\n","authors":["Adarsh Jagan Sathyamoorthy","Kasun Weerakoon","Mohamed Elnoor","Anuj Zore","Brian Ichter","Fei Xia","Jie Tan","Wenhao Yu","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2403.15637v1.pdf","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2308.00186v3","updated":"2024-03-22T22:06:29Z","published":"2023-07-31T22:50:14Z","title":"Learning Complex Motion Plans using Neural ODEs with Safety and\n  Stability Guarantees","summary":"  We propose a Dynamical System (DS) approach to learn complex, possibly\nperiodic motion plans from kinesthetic demonstrations using Neural Ordinary\nDifferential Equations (NODE). To ensure reactivity and robustness to\ndisturbances, we propose a novel approach that selects a target point at each\ntime step for the robot to follow, by combining tools from control theory and\nthe target trajectory generated by the learned NODE. A correction term to the\nNODE model is computed online by solving a quadratic program that guarantees\nstability and safety using control Lyapunov functions and control barrier\nfunctions, respectively. Our approach outperforms baseline DS learning\ntechniques on the LASA handwriting dataset and complex periodic trajectories.\nIt is also validated on the Franka Emika robot arm to produce stable motions\nfor wiping and stirring tasks that do not have a single attractor, while being\nrobust to perturbations and safe around humans and obstacles.\n","authors":["Farhad Nawaz","Tianyu Li","Nikolai Matni","Nadia Figueroa"],"pdf_url":"https://arxiv.org/pdf/2308.00186v3.pdf","comment":"accepted to ICRA 2024"},{"id":"http://arxiv.org/abs/2403.15621v1","updated":"2024-03-22T21:16:25Z","published":"2024-03-22T21:16:25Z","title":"Global Games with Negative Feedback for Autonomous Colony Maintenance\n  using Robot Teams","summary":"  In this article we address the colony maintenance problem, where a team of\nrobots are tasked with continuously maintaining the energy supply of an\nautonomous colony. We model this as a global game, where robots measure the\nenergy level of a central nest to determine whether or not to forage for energy\nsources. We design a mechanism that avoids the trivial equilibrium where all\nrobots always forage. Furthermore, we demonstrate that when the game is played\niteratively a negative feedback term stabilizes the number of foraging robots\nat a non-trivial Nash equilibrium. We compare our approach qualitatively to\nexisting global games, where a positive positive feedback term admits\nthreshold-based decision making, and encourages many robots to forage\nsimultaneously. We discuss how positive feedback can lead to a cascading\nfailure in the presence of a human who recruits robots for external tasks, and\nwe demonstrate the performance of our approach in simulation.\n","authors":["Logan E. Beaver"],"pdf_url":"https://arxiv.org/pdf/2403.15621v1.pdf","comment":"6 pages, 5 figures"},{"id":"http://arxiv.org/abs/2309.07139v2","updated":"2024-03-22T20:49:54Z","published":"2023-09-01T16:19:27Z","title":"A Traffic Management Framework for On-Demand Urban Air Mobility Systems","summary":"  Urban Air Mobility (UAM) offers a solution to current traffic congestion by\nproviding on-demand air mobility in urban areas. Effective traffic management\nis crucial for efficient operation of UAM systems, especially for high-demand\nscenarios. In this paper, we present a centralized traffic management framework\nfor on-demand UAM systems. Specifically, we provide a scheduling policy, called\nVertiSync, which schedules the aircraft for either servicing trip requests or\nrebalancing in the system subject to aircraft safety margins and energy\nrequirements. We characterize the system-level throughput of VertiSync, which\ndetermines the demand threshold at which passenger waiting times transition\nfrom being stabilized to being increasing over time. We show that the proposed\npolicy is able to maximize throughput for sufficiently large fleet sizes. We\ndemonstrate the performance of VertiSync through a case study for the city of\nLos Angeles, and show that it significantly reduces passenger waiting times\ncompared to a first-come first-serve scheduling policy.\n","authors":["Milad Pooladsanj","Ketan Savla","Petros A. Ioannou"],"pdf_url":"https://arxiv.org/pdf/2309.07139v2.pdf","comment":"9 pages, 6 figures"},{"id":"http://arxiv.org/abs/2403.15577v1","updated":"2024-03-22T19:04:58Z","published":"2024-03-22T19:04:58Z","title":"Autonomous Driving With Perception Uncertainties: Deep-Ensemble Based\n  Adaptive Cruise Control","summary":"  Autonomous driving depends on perception systems to understand the\nenvironment and to inform downstream decision-making. While advanced perception\nsystems utilizing black-box Deep Neural Networks (DNNs) demonstrate human-like\ncomprehension, their unpredictable behavior and lack of interpretability may\nhinder their deployment in safety critical scenarios. In this paper, we develop\nan Ensemble of DNN regressors (Deep Ensemble) that generates predictions with\nquantification of prediction uncertainties. In the scenario of Adaptive Cruise\nControl (ACC), we employ the Deep Ensemble to estimate distance headway to the\nlead vehicle from RGB images and enable the downstream controller to account\nfor the estimation uncertainty. We develop an adaptive cruise controller that\nutilizes Stochastic Model Predictive Control (MPC) with chance constraints to\nprovide a probabilistic safety guarantee. We evaluate our ACC algorithm using a\nhigh-fidelity traffic simulator and a real-world traffic dataset and\ndemonstrate the ability of the proposed approach to effect speed tracking and\ncar following while maintaining a safe distance headway. The\nout-of-distribution scenarios are also examined.\n","authors":["Xiao Li","H. Eric Tseng","Anouck Girard","Ilya Kolmanovsky"],"pdf_url":"https://arxiv.org/pdf/2403.15577v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.09317v2","updated":"2024-03-22T18:59:15Z","published":"2023-09-17T16:06:38Z","title":"Kinematics-aware Trajectory Generation and Prediction with Latent\n  Stochastic Differential Modeling","summary":"  Trajectory generation and trajectory prediction are two critical tasks in\nautonomous driving, which generate various trajectories for testing during\ndevelopment and predict the trajectories of surrounding vehicles during\noperation, respectively. In recent years, emerging data-driven deep\nlearning-based methods have shown great promise for these two tasks in learning\nvarious traffic scenarios and improving average performance without assuming\nphysical models. However, it remains a challenging problem for these methods to\nensure that the generated/predicted trajectories are physically realistic. This\nchallenge arises because learning-based approaches often function as opaque\nblack boxes and do not adhere to physical laws. Conversely, existing\nmodel-based methods provide physically feasible results but are constrained by\npredefined model structures, limiting their capabilities to address complex\nscenarios. To address the limitations of these two types of approaches, we\npropose a new method that integrates kinematic knowledge into neural stochastic\ndifferential equations (SDE) and designs a variational autoencoder based on\nthis latent kinematics-aware SDE (LK-SDE) to generate vehicle motions.\nExperimental results demonstrate that our method significantly outperforms both\nmodel-based and learning-based baselines in producing physically realistic and\nprecisely controllable vehicle trajectories. Additionally, it performs well in\npredicting unobservable physical variables in the latent space.\n","authors":["Ruochen Jiao","Yixuan Wang","Xiangguo Liu","Chao Huang","Qi Zhu"],"pdf_url":"https://arxiv.org/pdf/2309.09317v2.pdf","comment":"8 pages, conference paper in motion generation"},{"id":"http://arxiv.org/abs/2403.15569v1","updated":"2024-03-22T18:47:54Z","published":"2024-03-22T18:47:54Z","title":"Music to Dance as Language Translation using Sequence Models","summary":"  Synthesising appropriate choreographies from music remains an open problem.\nWe introduce MDLT, a novel approach that frames the choreography generation\nproblem as a translation task. Our method leverages an existing data set to\nlearn to translate sequences of audio into corresponding dance poses. We\npresent two variants of MDLT: one utilising the Transformer architecture and\nthe other employing the Mamba architecture. We train our method on AIST++ and\nPhantomDance data sets to teach a robotic arm to dance, but our method can be\napplied to a full humanoid robot. Evaluation metrics, including Average Joint\nError and Frechet Inception Distance, consistently demonstrate that, when given\na piece of music, MDLT excels at producing realistic and high-quality\nchoreography. The code can be found at github.com/meowatthemoon/MDLT.\n","authors":["André Correia","Luís A. Alexandre"],"pdf_url":"https://arxiv.org/pdf/2403.15569v1.pdf","comment":null}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2403.15388v1","updated":"2024-03-22T17:59:52Z","published":"2024-03-22T17:59:52Z","title":"LLaVA-PruMerge: Adaptive Token Reduction for Efficient Large Multimodal\n  Models","summary":"  Large Multimodal Models (LMMs) have shown significant reasoning capabilities\nby connecting a visual encoder and a large language model. LMMs typically use a\nfixed amount of visual tokens, such as the penultimate layer features in the\nCLIP visual encoder, as the prefix content. Recent LMMs incorporate more\ncomplex visual inputs, such as high-resolution images and videos, which\nincrease the number of visual tokens significantly. However, due to the design\nof the Transformer architecture, computational costs associated with these\nmodels tend to increase quadratically with the number of input tokens. To\ntackle this problem, we explore a token reduction mechanism and find, similar\nto prior work, that many visual tokens are spatially redundant. Based on this,\nwe propose PruMerge, a novel adaptive visual token reduction approach, which\nlargely reduces the number of visual tokens while maintaining comparable model\nperformance. We first select the unpruned visual tokens based on their\nsimilarity to class tokens and spatial tokens. We then cluster the pruned\ntokens based on key similarity and merge the clustered tokens with the unpruned\ntokens to supplement their information. Empirically, when applied to LLaVA-1.5,\nour approach can compress the visual tokens by 14.4 times on average, and\nachieve comparable performance across diverse visual question-answering and\nreasoning tasks. Code and checkpoints are at https://llava-prumerge.github.io/.\n","authors":["Yuzhang Shang","Mu Cai","Bingxin Xu","Yong Jae Lee","Yan Yan"],"pdf_url":"https://arxiv.org/pdf/2403.15388v1.pdf","comment":"Project page: https://llava-prumerge.github.io/"},{"id":"http://arxiv.org/abs/2403.15385v1","updated":"2024-03-22T17:59:37Z","published":"2024-03-22T17:59:37Z","title":"LATTE3D: Large-scale Amortized Text-To-Enhanced3D Synthesis","summary":"  Recent text-to-3D generation approaches produce impressive 3D results but\nrequire time-consuming optimization that can take up to an hour per prompt.\nAmortized methods like ATT3D optimize multiple prompts simultaneously to\nimprove efficiency, enabling fast text-to-3D synthesis. However, they cannot\ncapture high-frequency geometry and texture details and struggle to scale to\nlarge prompt sets, so they generalize poorly. We introduce LATTE3D, addressing\nthese limitations to achieve fast, high-quality generation on a significantly\nlarger prompt set. Key to our method is 1) building a scalable architecture and\n2) leveraging 3D data during optimization through 3D-aware diffusion priors,\nshape regularization, and model initialization to achieve robustness to diverse\nand complex training prompts. LATTE3D amortizes both neural field and textured\nsurface generation to produce highly detailed textured meshes in a single\nforward pass. LATTE3D generates 3D objects in 400ms, and can be further\nenhanced with fast test-time optimization.\n","authors":["Kevin Xie","Jonathan Lorraine","Tianshi Cao","Jun Gao","James Lucas","Antonio Torralba","Sanja Fidler","Xiaohui Zeng"],"pdf_url":"https://arxiv.org/pdf/2403.15385v1.pdf","comment":"See the project website at\n  https://research.nvidia.com/labs/toronto-ai/LATTE3D/"},{"id":"http://arxiv.org/abs/2403.08763v2","updated":"2024-03-22T17:56:38Z","published":"2024-03-13T17:58:57Z","title":"Simple and Scalable Strategies to Continually Pre-train Large Language\n  Models","summary":"  Large language models (LLMs) are routinely pre-trained on billions of tokens,\nonly to start the process over again once new data becomes available. A much\nmore efficient solution is to continually pre-train these models, saving\nsignificant compute compared to re-training. However, the distribution shift\ninduced by new data typically results in degraded performance on previous data\nor poor adaptation to the new data. In this work, we show that a simple and\nscalable combination of learning rate (LR) re-warming, LR re-decaying, and\nreplay of previous data is sufficient to match the performance of fully\nre-training from scratch on all available data, as measured by final loss and\nlanguage model (LM) evaluation benchmarks. Specifically, we show this for a\nweak but realistic distribution shift between two commonly used LLM\npre-training datasets (English$\\rightarrow$English) and a stronger distribution\nshift (English$\\rightarrow$German) at the $405$M parameter model scale with\nlarge dataset sizes (hundreds of billions of tokens). Selecting the weak but\nrealistic shift for larger-scale experiments, we also find that our continual\nlearning strategies match the re-training baseline for a 10B parameter LLM. Our\nresults demonstrate that LLMs can be successfully updated via simple and\nscalable continual learning strategies, matching the re-training baseline using\nonly a fraction of the compute. Finally, inspired by previous work, we propose\nalternatives to the cosine learning rate schedule that help circumvent\nforgetting induced by LR re-warming and that are not bound to a fixed token\nbudget.\n","authors":["Adam Ibrahim","Benjamin Thérien","Kshitij Gupta","Mats L. Richter","Quentin Anthony","Timothée Lesort","Eugene Belilovsky","Irina Rish"],"pdf_url":"https://arxiv.org/pdf/2403.08763v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00652v2","updated":"2024-03-22T17:56:05Z","published":"2023-03-01T16:54:48Z","title":"Finding the right XAI method -- A Guide for the Evaluation and Ranking\n  of Explainable AI Methods in Climate Science","summary":"  Explainable artificial intelligence (XAI) methods shed light on the\npredictions of machine learning algorithms. Several different approaches exist\nand have already been applied in climate science. However, usually missing\nground truth explanations complicate their evaluation and comparison,\nsubsequently impeding the choice of the XAI method. Therefore, in this work, we\nintroduce XAI evaluation in the climate context and discuss different desired\nexplanation properties, namely robustness, faithfulness, randomization,\ncomplexity, and localization. To this end, we chose previous work as a case\nstudy where the decade of annual-mean temperature maps is predicted. After\ntraining both a multi-layer perceptron (MLP) and a convolutional neural network\n(CNN), multiple XAI methods are applied and their skill scores in reference to\na random uniform explanation are calculated for each property. Independent of\nthe network, we find that XAI methods Integrated Gradients, layer-wise\nrelevance propagation, and input times gradients exhibit considerable\nrobustness, faithfulness, and complexity while sacrificing randomization\nperformance. Sensitivity methods -- gradient, SmoothGrad, NoiseGrad, and\nFusionGrad, match the robustness skill but sacrifice faithfulness and\ncomplexity for randomization skill. We find architecture-dependent performance\ndifferences regarding robustness, complexity and localization skills of\ndifferent XAI methods, highlighting the necessity for research task-specific\nevaluation. Overall, our work offers an overview of different evaluation\nproperties in the climate science context and shows how to compare and\nbenchmark different explanation methods, assessing their suitability based on\nstrengths and weaknesses, for the specific research problem at hand. By that,\nwe aim to support climate researchers in the selection of a suitable XAI\nmethod.\n","authors":["Philine Bommer","Marlene Kretschmer","Anna Hedström","Dilyara Bareeva","Marina M. -C. Höhne"],"pdf_url":"https://arxiv.org/pdf/2303.00652v2.pdf","comment":"19 pages, 10 figure, accepted at AIES journal by AMS"},{"id":"http://arxiv.org/abs/2403.15371v1","updated":"2024-03-22T17:50:43Z","published":"2024-03-22T17:50:43Z","title":"Can large language models explore in-context?","summary":"  We investigate the extent to which contemporary Large Language Models (LLMs)\ncan engage in exploration, a core capability in reinforcement learning and\ndecision making. We focus on native performance of existing LLMs, without\ntraining interventions. We deploy LLMs as agents in simple multi-armed bandit\nenvironments, specifying the environment description and interaction history\nentirely in-context, i.e., within the LLM prompt. We experiment with GPT-3.5,\nGPT-4, and Llama2, using a variety of prompt designs, and find that the models\ndo not robustly engage in exploration without substantial interventions: i)\nAcross all of our experiments, only one configuration resulted in satisfactory\nexploratory behavior: GPT-4 with chain-of-thought reasoning and an externally\nsummarized interaction history, presented as sufficient statistics; ii) All\nother configurations did not result in robust exploratory behavior, including\nthose with chain-of-thought reasoning but unsummarized history. Although these\nfindings can be interpreted positively, they suggest that external\nsummarization -- which may not be possible in more complex settings -- is\nimportant for obtaining desirable behavior from LLM agents. We conclude that\nnon-trivial algorithmic interventions, such as fine-tuning or dataset curation,\nmay be required to empower LLM-based decision making agents in complex\nsettings.\n","authors":["Akshay Krishnamurthy","Keegan Harris","Dylan J. Foster","Cyril Zhang","Aleksandrs Slivkins"],"pdf_url":"https://arxiv.org/pdf/2403.15371v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14617v2","updated":"2024-03-22T17:45:52Z","published":"2024-03-21T17:59:03Z","title":"Videoshop: Localized Semantic Video Editing with Noise-Extrapolated\n  Diffusion Inversion","summary":"  We introduce Videoshop, a training-free video editing algorithm for localized\nsemantic edits. Videoshop allows users to use any editing software, including\nPhotoshop and generative inpainting, to modify the first frame; it\nautomatically propagates those changes, with semantic, spatial, and temporally\nconsistent motion, to the remaining frames. Unlike existing methods that enable\nedits only through imprecise textual instructions, Videoshop allows users to\nadd or remove objects, semantically change objects, insert stock photos into\nvideos, etc. with fine-grained control over locations and appearance. We\nachieve this through image-based video editing by inverting latents with noise\nextrapolation, from which we generate videos conditioned on the edited image.\nVideoshop produces higher quality edits against 6 baselines on 2 editing\nbenchmarks using 10 evaluation metrics.\n","authors":["Xiang Fan","Anand Bhattad","Ranjay Krishna"],"pdf_url":"https://arxiv.org/pdf/2403.14617v2.pdf","comment":"Project page at https://videoshop-editing.github.io/"},{"id":"http://arxiv.org/abs/2312.00812v4","updated":"2024-03-22T17:29:01Z","published":"2023-11-28T03:13:09Z","title":"Empowering Autonomous Driving with Large Language Models: A Safety\n  Perspective","summary":"  Autonomous Driving (AD) encounters significant safety hurdles in long-tail\nunforeseen driving scenarios, largely stemming from the non-interpretability\nand poor generalization of the deep neural networks within the AD system,\nparticularly in out-of-distribution and uncertain data. To this end, this paper\nexplores the integration of Large Language Models (LLMs) into AD systems,\nleveraging their robust common-sense knowledge and reasoning abilities. The\nproposed methodologies employ LLMs as intelligent decision-makers in behavioral\nplanning, augmented with a safety verifier shield for contextual safety\nlearning, for enhancing driving performance and safety. We present two key\nstudies in a simulated environment: an adaptive LLM-conditioned Model\nPredictive Control (MPC) and an LLM-enabled interactive behavior planning\nscheme with a state machine. Demonstrating superior performance and safety\nmetrics compared to state-of-the-art approaches, our approach shows the\npromising potential for using LLMs for autonomous vehicles.\n","authors":["Yixuan Wang","Ruochen Jiao","Sinong Simon Zhan","Chengtian Lang","Chao Huang","Zhaoran Wang","Zhuoran Yang","Qi Zhu"],"pdf_url":"https://arxiv.org/pdf/2312.00812v4.pdf","comment":"Accepted to LLMAgent workshop @ICLR2024"},{"id":"http://arxiv.org/abs/2309.12276v3","updated":"2024-03-22T17:28:17Z","published":"2023-09-21T17:37:01Z","title":"LLMR: Real-time Prompting of Interactive Worlds using Large Language\n  Models","summary":"  We present Large Language Model for Mixed Reality (LLMR), a framework for the\nreal-time creation and modification of interactive Mixed Reality experiences\nusing LLMs. LLMR leverages novel strategies to tackle difficult cases where\nideal training data is scarce, or where the design goal requires the synthesis\nof internal dynamics, intuitive analysis, or advanced interactivity. Our\nframework relies on text interaction and the Unity game engine. By\nincorporating techniques for scene understanding, task planning,\nself-debugging, and memory management, LLMR outperforms the standard GPT-4 by\n4x in average error rate. We demonstrate LLMR's cross-platform interoperability\nwith several example worlds, and evaluate it on a variety of creation and\nmodification tasks to show that it can produce and edit diverse objects, tools,\nand scenes. Finally, we conducted a usability study (N=11) with a diverse set\nthat revealed participants had positive experiences with the system and would\nuse it again.\n","authors":["Fernanda De La Torre","Cathy Mengying Fang","Han Huang","Andrzej Banburski-Fahey","Judith Amores Fernandez","Jaron Lanier"],"pdf_url":"https://arxiv.org/pdf/2309.12276v3.pdf","comment":"46 pages, 18 figures; Matching version accepted at CHI 2024"},{"id":"http://arxiv.org/abs/2309.16512v4","updated":"2024-03-22T17:26:53Z","published":"2023-09-28T15:19:30Z","title":"From Complexity to Clarity: Analytical Expressions of Deep Neural\n  Network Weights via Clifford's Geometric Algebra and Convexity","summary":"  In this paper, we introduce a novel analysis of neural networks based on\ngeometric (Clifford) algebra and convex optimization. We show that optimal\nweights of deep ReLU neural networks are given by the wedge product of training\nsamples when trained with standard regularized loss. Furthermore, the training\nproblem reduces to convex optimization over wedge product features, which\nencode the geometric structure of the training dataset. This structure is given\nin terms of signed volumes of triangles and parallelotopes generated by data\nvectors. The convex problem finds a small subset of samples via $\\ell_1$\nregularization to discover only relevant wedge product features. Our analysis\nprovides a novel perspective on the inner workings of deep neural networks and\nsheds light on the role of the hidden layers.\n","authors":["Mert Pilanci"],"pdf_url":"https://arxiv.org/pdf/2309.16512v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15362v1","updated":"2024-03-22T17:26:05Z","published":"2024-03-22T17:26:05Z","title":"CoLLEGe: Concept Embedding Generation for Large Language Models","summary":"  Current language models are unable to quickly learn new concepts on the fly,\noften requiring a more involved finetuning process to learn robustly. Prompting\nin-context is not robust to context distractions, and often fails to confer\nmuch information about the new concepts. Classic methods for few-shot word\nlearning in NLP, relying on global word vectors, are less applicable to large\nlanguage models. In this paper, we introduce a novel approach named CoLLEGe\n(Concept Learning with Language Embedding Generation) to modernize few-shot\nconcept learning. CoLLEGe is a meta-learning framework capable of generating\nflexible embeddings for new concepts using a small number of example sentences\nor definitions. Our primary meta-learning objective is simply to facilitate a\nlanguage model to make next word predictions in forthcoming sentences, making\nit compatible with language model pretraining. We design a series of tasks to\ntest new concept learning in challenging real-world scenarios, including new\nword acquisition, definition inference, and verbal reasoning, and demonstrate\nthat our method succeeds in each setting without task-specific training.\n","authors":["Ryan Teehan","Brenden Lake","Mengye Ren"],"pdf_url":"https://arxiv.org/pdf/2403.15362v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.17543v2","updated":"2024-03-22T17:12:49Z","published":"2023-12-29T10:18:36Z","title":"Building Efficient Universal Classifiers with Natural Language Inference","summary":"  Generative Large Language Models (LLMs) have become the mainstream choice for\nfewshot and zeroshot learning thanks to the universality of text generation.\nMany users, however, do not need the broad capabilities of generative LLMs when\nthey only want to automate a classification task. Smaller BERT-like models can\nalso learn universal tasks, which allow them to do any text classification task\nwithout requiring fine-tuning (zeroshot classification) or to learn new tasks\nwith only a few examples (fewshot), while being significantly more efficient\nthan generative LLMs. This paper (1) explains how Natural Language Inference\n(NLI) can be used as a universal classification task that follows similar\nprinciples as instruction fine-tuning of generative LLMs, (2) provides a\nstep-by-step guide with reusable Jupyter notebooks for building a universal\nclassifier, and (3) shares the resulting universal classifier that is trained\non 33 datasets with 389 diverse classes. Parts of the code we share has been\nused to train our older zeroshot classifiers that have been downloaded more\nthan 55 million times via the Hugging Face Hub as of December 2023. Our new\nclassifier improves zeroshot performance by 9.4%.\n","authors":["Moritz Laurer","Wouter van Atteveldt","Andreu Casas","Kasper Welbers"],"pdf_url":"https://arxiv.org/pdf/2312.17543v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.14125v3","updated":"2024-03-22T17:06:53Z","published":"2023-12-21T18:46:41Z","title":"VideoPoet: A Large Language Model for Zero-Shot Video Generation","summary":"  We present VideoPoet, a language model capable of synthesizing high-quality\nvideo, with matching audio, from a large variety of conditioning signals.\nVideoPoet employs a decoder-only transformer architecture that processes\nmultimodal inputs -- including images, videos, text, and audio. The training\nprotocol follows that of Large Language Models (LLMs), consisting of two\nstages: pretraining and task-specific adaptation. During pretraining, VideoPoet\nincorporates a mixture of multimodal generative objectives within an\nautoregressive Transformer framework. The pretrained LLM serves as a foundation\nthat can be adapted for a range of video generation tasks. We present empirical\nresults demonstrating the model's state-of-the-art capabilities in zero-shot\nvideo generation, specifically highlighting VideoPoet's ability to generate\nhigh-fidelity motions. Project page: http://sites.research.google/videopoet/\n","authors":["Dan Kondratyuk","Lijun Yu","Xiuye Gu","José Lezama","Jonathan Huang","Grant Schindler","Rachel Hornung","Vighnesh Birodkar","Jimmy Yan","Ming-Chang Chiu","Krishna Somandepalli","Hassan Akbari","Yair Alon","Yong Cheng","Josh Dillon","Agrim Gupta","Meera Hahn","Anja Hauth","David Hendon","Alonso Martinez","David Minnen","Mikhail Sirotenko","Kihyuk Sohn","Xuan Yang","Hartwig Adam","Ming-Hsuan Yang","Irfan Essa","Huisheng Wang","David A. Ross","Bryan Seybold","Lu Jiang"],"pdf_url":"https://arxiv.org/pdf/2312.14125v3.pdf","comment":"Project page: http://sites.research.google/videopoet/"},{"id":"http://arxiv.org/abs/2403.15341v1","updated":"2024-03-22T16:50:56Z","published":"2024-03-22T16:50:56Z","title":"Collaborative AI Teaming in Unknown Environments via Active Goal\n  Deduction","summary":"  With the advancements of artificial intelligence (AI), we're seeing more\nscenarios that require AI to work closely with other agents, whose goals and\nstrategies might not be known beforehand. However, existing approaches for\ntraining collaborative agents often require defined and known reward signals\nand cannot address the problem of teaming with unknown agents that often have\nlatent objectives/rewards. In response to this challenge, we propose teaming\nwith unknown agents framework, which leverages kernel density Bayesian inverse\nlearning method for active goal deduction and utilizes pre-trained,\ngoal-conditioned policies to enable zero-shot policy adaptation. We prove that\nunbiased reward estimates in our framework are sufficient for optimal teaming\nwith unknown agents. We further evaluate the framework of redesigned\nmulti-agent particle and StarCraft II micromanagement environments with diverse\nunknown agents of different behaviors/rewards. Empirical results demonstrate\nthat our framework significantly advances the teaming performance of AI and\nunknown agents in a wide range of collaborative scenarios.\n","authors":["Zuyuan Zhang","Hanhan Zhou","Mahdi Imani","Taeyoung Lee","Tian Lan"],"pdf_url":"https://arxiv.org/pdf/2403.15341v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.00094v2","updated":"2024-03-22T16:38:34Z","published":"2023-11-30T13:07:19Z","title":"Fast ODE-based Sampling for Diffusion Models in Around 5 Steps","summary":"  Sampling from diffusion models can be treated as solving the corresponding\nordinary differential equations (ODEs), with the aim of obtaining an accurate\nsolution with as few number of function evaluations (NFE) as possible.\nRecently, various fast samplers utilizing higher-order ODE solvers have emerged\nand achieved better performance than the initial first-order one. However,\nthese numerical methods inherently result in certain approximation errors,\nwhich significantly degrades sample quality with extremely small NFE (e.g.,\naround 5). In contrast, based on the geometric observation that each sampling\ntrajectory almost lies in a two-dimensional subspace embedded in the ambient\nspace, we propose Approximate MEan-Direction Solver (AMED-Solver) that\neliminates truncation errors by directly learning the mean direction for fast\ndiffusion sampling. Besides, our method can be easily used as a plugin to\nfurther improve existing ODE-based samplers. Extensive experiments on image\nsynthesis with the resolution ranging from 32 to 512 demonstrate the\neffectiveness of our method. With only 5 NFE, we achieve 6.61 FID on CIFAR-10,\n10.74 FID on ImageNet 64$\\times$64, and 13.20 FID on LSUN Bedroom. Our code is\navailable at https://github.com/zju-pi/diff-sampler.\n","authors":["Zhenyu Zhou","Defang Chen","Can Wang","Chun Chen"],"pdf_url":"https://arxiv.org/pdf/2312.00094v2.pdf","comment":"Accepted by CVPR 2024"},{"id":"http://arxiv.org/abs/2403.15325v1","updated":"2024-03-22T16:30:58Z","published":"2024-03-22T16:30:58Z","title":"A Technological Perspective on Misuse of Available AI","summary":"  Potential malicious misuse of civilian artificial intelligence (AI) poses\nserious threats to security on a national and international level. Besides\ndefining autonomous systems from a technological viewpoint and explaining how\nAI development is characterized, we show how already existing and openly\navailable AI technology could be misused. To underline this, we developed three\nexemplary use cases of potentially misused AI that threaten political, digital\nand physical security. The use cases can be built from existing AI technologies\nand components from academia, the private sector and the developer-community.\nThis shows how freely available AI can be combined into autonomous weapon\nsystems. Based on the use cases, we deduce points of control and further\nmeasures to prevent the potential threat through misused AI. Further, we\npromote the consideration of malicious misuse of civilian AI systems in the\ndiscussion on autonomous weapon systems (AWS).\n","authors":["Lukas Pöhler","Valentin Schrader","Alexander Ladwein","Florian von Keller"],"pdf_url":"https://arxiv.org/pdf/2403.15325v1.pdf","comment":"Presented at the UN Meeting of the Group of Governmental Experts on\n  Lethal Autonomous Weapons Systems, 30 August 2018"},{"id":"http://arxiv.org/abs/2310.08731v2","updated":"2024-03-22T16:30:48Z","published":"2023-10-12T21:38:07Z","title":"Novelty Detection in Reinforcement Learning with World Models","summary":"  Reinforcement learning (RL) using world models has found significant recent\nsuccesses. However, when a sudden change to world mechanics or properties\noccurs then agent performance and reliability can dramatically decline. We\nrefer to the sudden change in visual properties or state transitions as\nnovelties. Implementing novelty detection within generated world model\nframeworks is a crucial task for protecting the agent when deployed. In this\npaper, we propose straightforward bounding approaches to incorporate novelty\ndetection into world model RL agents, by utilizing the misalignment of the\nworld model's hallucinated states and the true observed states as an anomaly\nscore. We provide effective approaches to detecting novelties in a distribution\nof transitions learned by an agent in a world model. Finally, we show the\nadvantage of our work in a novel environment compared to traditional machine\nlearning novelty detection methods as well as currently accepted RL focused\nnovelty detection algorithms.\n","authors":["Geigh Zollicoffer","Kenneth Eaton","Jonathan Balloch","Julia Kim","Mark O. Riedl","Robert Wright"],"pdf_url":"https://arxiv.org/pdf/2310.08731v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.04690v2","updated":"2024-03-22T16:26:40Z","published":"2024-03-07T17:35:58Z","title":"Faster Neighborhood Attention: Reducing the O(n^2) Cost of Self\n  Attention at the Threadblock Level","summary":"  Neighborhood attention reduces the cost of self attention by restricting each\ntoken's attention span to its nearest neighbors. This restriction,\nparameterized by a window size and dilation factor, draws a spectrum of\npossible attention patterns between linear projection and self attention.\nNeighborhood attention, and more generally sliding window attention patterns,\nhave long been bounded by infrastructure, particularly in higher-rank spaces\n(2-D and 3-D), calling for the development of custom kernels, which have been\nlimited in either functionality, or performance, if not both. In this work, we\nfirst show that neighborhood attention can be represented as a batched GEMM\nproblem, similar to standard attention, and implement it for 1-D and 2-D\nneighborhood attention. These kernels on average provide 895% and 272%\nimprovement in full precision latency compared to existing naive kernels for\n1-D and 2-D neighborhood attention respectively. We find certain inherent\ninefficiencies in all unfused neighborhood attention kernels that bound their\nperformance and lower-precision scalability. We also developed fused\nneighborhood attention; an adaptation of fused dot-product attention kernels\nthat allow fine-grained control over attention across different spatial axes.\nKnown for reducing the quadratic time complexity of self attention to a linear\ncomplexity, neighborhood attention can now enjoy a reduced and constant memory\nfootprint, and record-breaking half precision latency. We observe that our\nfused kernels successfully circumvent some of the unavoidable inefficiencies in\nunfused implementations. While our unfused GEMM-based kernels only improve half\nprecision performance compared to naive kernels by an average of 496% and 113%\nin 1-D and 2-D problems respectively, our fused kernels improve naive kernels\nby an average of 1607% and 581% in 1-D and 2-D problems respectively.\n","authors":["Ali Hassani","Wen-Mei Hwu","Humphrey Shi"],"pdf_url":"https://arxiv.org/pdf/2403.04690v2.pdf","comment":"Project page: https://github.com/SHI-Labs/NATTEN"},{"id":"http://arxiv.org/abs/2403.15317v1","updated":"2024-03-22T16:11:29Z","published":"2024-03-22T16:11:29Z","title":"Point-DETR3D: Leveraging Imagery Data with Spatial Point Prior for\n  Weakly Semi-supervised 3D Object Detection","summary":"  Training high-accuracy 3D detectors necessitates massive labeled 3D\nannotations with 7 degree-of-freedom, which is laborious and time-consuming.\nTherefore, the form of point annotations is proposed to offer significant\nprospects for practical applications in 3D detection, which is not only more\naccessible and less expensive but also provides strong spatial information for\nobject localization.In this paper, we empirically discover that it is\nnon-trivial to merely adapt Point-DETR to its 3D form, encountering two main\nbottlenecks: 1) it fails to encode strong 3D prior into the model, and 2) it\ngenerates low-quality pseudo labels in distant regions due to the extreme\nsparsity of LiDAR points. To overcome these challenges, we introduce\nPoint-DETR3D, a teacher-student framework for weakly semi-supervised 3D\ndetection, designed to fully capitalize on point-wise supervision within a\nconstrained instance-wise annotation budget.Different from Point-DETR which\nencodes 3D positional information solely through a point encoder, we propose an\nexplicit positional query initialization strategy to enhance the positional\nprior. Considering the low quality of pseudo labels at distant regions produced\nby the teacher model, we enhance the detector's perception by incorporating\ndense imagery data through a novel Cross-Modal Deformable RoI Fusion\n(D-RoI).Moreover, an innovative point-guided self-supervised learning technique\nis proposed to allow for fully exploiting point priors, even in student\nmodels.Extensive experiments on representative nuScenes dataset demonstrate our\nPoint-DETR3D obtains significant improvements compared to previous works.\nNotably, with only 5% of labeled data, Point-DETR3D achieves over 90%\nperformance of its fully supervised counterpart.\n","authors":["Hongzhi Gao","Zheng Chen","Zehui Chen","Lin Chen","Jiaming Liu","Shanghang Zhang","Feng Zhao"],"pdf_url":"https://arxiv.org/pdf/2403.15317v1.pdf","comment":"Accepted by AAAI2024"},{"id":"http://arxiv.org/abs/2403.15313v1","updated":"2024-03-22T16:06:05Z","published":"2024-03-22T16:06:05Z","title":"CR3DT: Camera-RADAR Fusion for 3D Detection and Tracking","summary":"  Accurate detection and tracking of surrounding objects is essential to enable\nself-driving vehicles. While Light Detection and Ranging (LiDAR) sensors have\nset the benchmark for high performance, the appeal of camera-only solutions\nlies in their cost-effectiveness. Notably, despite the prevalent use of Radio\nDetection and Ranging (RADAR) sensors in automotive systems, their potential in\n3D detection and tracking has been largely disregarded due to data sparsity and\nmeasurement noise. As a recent development, the combination of RADARs and\ncameras is emerging as a promising solution. This paper presents Camera-RADAR\n3D Detection and Tracking (CR3DT), a camera-RADAR fusion model for 3D object\ndetection, and Multi-Object Tracking (MOT). Building upon the foundations of\nthe State-of-the-Art (SotA) camera-only BEVDet architecture, CR3DT demonstrates\nsubstantial improvements in both detection and tracking capabilities, by\nincorporating the spatial and velocity information of the RADAR sensor.\nExperimental results demonstrate an absolute improvement in detection\nperformance of 5.3% in mean Average Precision (mAP) and a 14.9% increase in\nAverage Multi-Object Tracking Accuracy (AMOTA) on the nuScenes dataset when\nleveraging both modalities. CR3DT bridges the gap between high-performance and\ncost-effective perception systems in autonomous driving, by capitalizing on the\nubiquitous presence of RADAR in automotive applications.\n","authors":["Nicolas Baumann","Michael Baumgartner","Edoardo Ghignone","Jonas Kühne","Tobias Fischer","Yung-Hsu Yang","Marc Pollefeys","Michele Magno"],"pdf_url":"https://arxiv.org/pdf/2403.15313v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.10581v2","updated":"2024-03-22T16:00:24Z","published":"2024-03-15T13:25:09Z","title":"Large Language Model-informed ECG Dual Attention Network for Heart\n  Failure Risk Prediction","summary":"  Heart failure (HF) poses a significant public health challenge, with a rising\nglobal mortality rate. Early detection and prevention of HF could significantly\nreduce its impact. We introduce a novel methodology for predicting HF risk\nusing 12-lead electrocardiograms (ECGs). We present a novel, lightweight\ndual-attention ECG network designed to capture complex ECG features essential\nfor early HF risk prediction, despite the notable imbalance between low and\nhigh-risk groups. This network incorporates a cross-lead attention module and\ntwelve lead-specific temporal attention modules, focusing on cross-lead\ninteractions and each lead's local dynamics. To further alleviate model\noverfitting, we leverage a large language model (LLM) with a public ECG-Report\ndataset for pretraining on an ECG-report alignment task. The network is then\nfine-tuned for HF risk prediction using two specific cohorts from the UK\nBiobank study, focusing on patients with hypertension (UKB-HYP) and those who\nhave had a myocardial infarction (UKB-MI).The results reveal that LLM-informed\npre-training substantially enhances HF risk prediction in these cohorts. The\ndual-attention design not only improves interpretability but also predictive\naccuracy, outperforming existing competitive methods with C-index scores of\n0.6349 for UKB-HYP and 0.5805 for UKB-MI. This demonstrates our method's\npotential in advancing HF risk assessment with clinical complex ECG data.\n","authors":["Chen Chen","Lei Li","Marcel Beetz","Abhirup Banerjee","Ramneek Gupta","Vicente Grau"],"pdf_url":"https://arxiv.org/pdf/2403.10581v2.pdf","comment":"Under journal revision"},{"id":"http://arxiv.org/abs/2403.13969v2","updated":"2024-03-22T15:57:20Z","published":"2024-03-20T20:46:41Z","title":"\"This is not a data problem\": Algorithms and Power in Public Higher\n  Education in Canada","summary":"  Algorithmic decision-making is increasingly being adopted across public\nhigher education. The expansion of data-driven practices by post-secondary\ninstitutions has occurred in parallel with the adoption of New Public\nManagement approaches by neoliberal administrations. In this study, we conduct\na qualitative analysis of an in-depth ethnographic case study of data and\nalgorithms in use at a public college in Ontario, Canada. We identify the data,\nalgorithms, and outcomes in use at the college. We assess how the college's\nprocesses and relationships support those outcomes and the different\nstakeholders' perceptions of the college's data-driven systems. In addition, we\nfind that the growing reliance on algorithmic decisions leads to increased\nstudent surveillance, exacerbation of existing inequities, and the automation\nof the faculty-student relationship. Finally, we identify a cycle of increased\ninstitutional power perpetuated by algorithmic decision-making, and driven by a\npush towards financial sustainability.\n","authors":["Kelly McConvey","Shion Guha"],"pdf_url":"https://arxiv.org/pdf/2403.13969v2.pdf","comment":"In CHI '24 Proceedings of the CHI Conference on Human Factors in\n  Computing Systems Honolulu, HI, USA"},{"id":"http://arxiv.org/abs/2403.15304v1","updated":"2024-03-22T15:54:30Z","published":"2024-03-22T15:54:30Z","title":"KTbench: A Novel Data Leakage-Free Framework for Knowledge Tracing","summary":"  Knowledge Tracing (KT) is concerned with predicting students' future\nperformance on learning items in intelligent tutoring systems. Learning items\nare tagged with skill labels called knowledge concepts (KCs). Many KT models\nexpand the sequence of item-student interactions into KC-student interactions\nby replacing learning items with their constituting KCs. This often results in\na longer sequence length. This approach addresses the issue of sparse\nitem-student interactions and minimises model parameters. However, two problems\nhave been identified with such models.\n  The first problem is the model's ability to learn correlations between KCs\nbelonging to the same item, which can result in the leakage of ground truth\nlabels and hinder performance. This problem can lead to a significant decrease\nin performance on datasets with a higher number of KCs per item. The second\nproblem is that the available benchmark implementations ignore accounting for\nchanges in sequence length when expanding KCs, leading to different models\nbeing tested with varying sequence lengths but still compared against the same\nbenchmark.\n  To address these problems, we introduce a general masking framework that\nmitigates the first problem and enhances the performance of such KT models\nwhile preserving the original model architecture without significant\nalterations. Additionally, we introduce KTbench, an open-source benchmark\nlibrary designed to ensure the reproducibility of this work while mitigating\nthe second problem.\n","authors":["Yahya Badran","Christine Preisach"],"pdf_url":"https://arxiv.org/pdf/2403.15304v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2307.08309v3","updated":"2024-03-22T15:52:47Z","published":"2023-07-17T08:09:40Z","title":"LogPrécis: Unleashing Language Models for Automated Malicious Log\n  Analysis","summary":"  The collection of security-related logs holds the key to understanding attack\nbehaviors and diagnosing vulnerabilities. Still, their analysis remains a\ndaunting challenge. Recently, Language Models (LMs) have demonstrated unmatched\npotential in understanding natural and programming languages. The question\narises whether and how LMs could be also useful for security experts since\ntheir logs contain intrinsically confused and obfuscated information. In this\npaper, we systematically study how to benefit from the state-of-the-art in LM\nto automatically analyze text-like Unix shell attack logs. We present a\nthorough design methodology that leads to LogPr\\'ecis. It receives as input raw\nshell sessions and automatically identifies and assigns the attacker tactic to\neach portion of the session, i.e., unveiling the sequence of the attacker's\ngoals. We demonstrate LogPr\\'ecis capability to support the analysis of two\nlarge datasets containing about 400,000 unique Unix shell attacks. LogPr\\'ecis\nreduces them into about 3,000 fingerprints, each grouping sessions with the\nsame sequence of tactics. The abstraction it provides lets the analyst better\nunderstand attacks, identify fingerprints, detect novelty, link similar\nattacks, and track families and mutations. Overall, LogPr\\'ecis, released as\nopen source, paves the way for better and more responsive defense against\ncyberattacks.\n","authors":["Matteo Boffa","Rodolfo Vieira Valentim","Luca Vassio","Danilo Giordano","Idilio Drago","Marco Mellia","Zied Ben Houidi"],"pdf_url":"https://arxiv.org/pdf/2307.08309v3.pdf","comment":"18 pages, Computer&Security\n  (https://www.sciencedirect.com/science/article/pii/S0167404824001068), code\n  available at https://github.com/SmartData-Polito/logprecis, models available\n  at https://huggingface.co/SmartDataPolito"},{"id":"http://arxiv.org/abs/2403.15301v1","updated":"2024-03-22T15:51:39Z","published":"2024-03-22T15:51:39Z","title":"Planning with a Learned Policy Basis to Optimally Solve Complex Tasks","summary":"  Conventional reinforcement learning (RL) methods can successfully solve a\nwide range of sequential decision problems. However, learning policies that can\ngeneralize predictably across multiple tasks in a setting with non-Markovian\nreward specifications is a challenging problem. We propose to use successor\nfeatures to learn a policy basis so that each (sub)policy in it solves a\nwell-defined subproblem. In a task described by a finite state automaton (FSA)\nthat involves the same set of subproblems, the combination of these\n(sub)policies can then be used to generate an optimal solution without\nadditional learning. In contrast to other methods that combine (sub)policies\nvia planning, our method asymptotically attains global optimality, even in\nstochastic environments.\n","authors":["Guillermo Infante","David Kuric","Anders Jonsson","Vicenç Gómez","Herke van Hoof"],"pdf_url":"https://arxiv.org/pdf/2403.15301v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15297v1","updated":"2024-03-22T15:44:59Z","published":"2024-03-22T15:44:59Z","title":"Sphere Neural-Networks for Rational Reasoning","summary":"  The success of Large Language Models (LLMs), e.g., ChatGPT, is witnessed by\ntheir planetary popularity, their capability of human-like question-answering,\nand also by their steadily improved reasoning performance. However, it remains\nunclear whether LLMs reason. It is an open problem how traditional neural\nnetworks can be qualitatively extended to go beyond the statistic paradigm and\nachieve high-level cognition. Here, we present a minimalist qualitative\nextension by generalising computational building blocks from vectors to\nspheres. We propose Sphere Neural Networks (SphNNs) for human-like reasoning\nthrough model construction and inspection, and develop SphNN for syllogistic\nreasoning, a microcosm of human rationality. Instead of training data, SphNN\nuses a neuro-symbolic transition map of neighbourhood spatial relations to\nguide transformations from the current sphere configuration towards the target.\nSphNN is the first neural model that can determine the validity of long-chained\nsyllogistic reasoning in one epoch by constructing sphere configurations as\nEuler diagrams, with the worst computational complexity of O(N^2). SphNN can\nevolve into various types of reasoning, such as spatio-temporal reasoning,\nlogical reasoning with negation and disjunction, event reasoning,\nneuro-symbolic reasoning, and humour understanding (the highest level of\ncognition). All these suggest a new kind of Herbert A. Simon's scissors with\ntwo neural blades. SphNNs will tremendously enhance interdisciplinary\ncollaborations to develop the two neural blades and realise deterministic\nneural reasoning and human-bounded rationality and elevate LLMs to reliable\npsychological AI. This work suggests that the non-zero radii of spheres are the\nmissing components that prevent traditional deep-learning systems from reaching\nthe realm of rational reasoning and cause LLMs to be trapped in the swamp of\nhallucination.\n","authors":["Tiansi Dong","Mateja Jamnik","Pietro Liò"],"pdf_url":"https://arxiv.org/pdf/2403.15297v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.09530v2","updated":"2024-03-22T15:26:05Z","published":"2024-03-14T16:13:00Z","title":"VisionGPT-3D: A Generalized Multimodal Agent for Enhanced 3D Vision\n  Understanding","summary":"  The evolution of text to visual components facilitates people's daily lives,\nsuch as generating image, videos from text and identifying the desired elements\nwithin the images. Computer vision models involving the multimodal abilities in\nthe previous days are focused on image detection, classification based on\nwell-defined objects. Large language models (LLMs) introduces the\ntransformation from nature language to visual objects, which present the visual\nlayout for text contexts. OpenAI GPT-4 has emerged as the pinnacle in LLMs,\nwhile the computer vision (CV) domain boasts a plethora of state-of-the-art\n(SOTA) models and algorithms to convert 2D images to their 3D representations.\nHowever, the mismatching between the algorithms with the problem could lead to\nundesired results. In response to this challenge, we propose an unified\nVisionGPT-3D framework to consolidate the state-of-the-art vision models,\nthereby facilitating the development of vision-oriented AI. VisionGPT-3D\nprovides a versatile multimodal framework building upon the strengths of\nmultimodal foundation models. It seamlessly integrates various SOTA vision\nmodels and brings the automation in the selection of SOTA vision models,\nidentifies the suitable 3D mesh creation algorithms corresponding to 2D depth\nmaps analysis, generates optimal results based on diverse multimodal inputs\nsuch as text prompts.\n  Keywords: VisionGPT-3D, 3D vision understanding, Multimodal agent\n","authors":["Chris Kelly","Luhui Hu","Jiayin Hu","Yu Tian","Deshun Yang","Bang Yang","Cindy Yang","Zihao Li","Zaoshan Huang","Yuexian Zou"],"pdf_url":"https://arxiv.org/pdf/2403.09530v2.pdf","comment":"12 pages, 7 figures, pending conference"},{"id":"http://arxiv.org/abs/2403.15274v1","updated":"2024-03-22T15:16:23Z","published":"2024-03-22T15:16:23Z","title":"Bioinformatics and Biomedical Informatics with ChatGPT: Year One Review","summary":"  The year 2023 marked a significant surge in the exploration of applying large\nlanguage model (LLM) chatbots, notably ChatGPT, across various disciplines. We\nsurveyed the applications of ChatGPT in various sectors of bioinformatics and\nbiomedical informatics throughout the year, covering omics, genetics,\nbiomedical text mining, drug discovery, biomedical image understanding,\nbioinformatics programming, and bioinformatics education. Our survey delineates\nthe current strengths and limitations of this chatbot in bioinformatics and\noffers insights into potential avenues for future development.\n","authors":["Jinge Wang","Zien Cheng","Qiuming Yao","Li Liu","Dong Xu","Gangqing Hu"],"pdf_url":"https://arxiv.org/pdf/2403.15274v1.pdf","comment":"19 pages, 3 Figures, 1 Table"},{"id":"http://arxiv.org/abs/2403.15257v1","updated":"2024-03-22T14:57:27Z","published":"2024-03-22T14:57:27Z","title":"Hierarchical Information Enhancement Network for Cascade Prediction in\n  Social Networks","summary":"  Understanding information cascades in networks is a fundamental issue in\nnumerous applications. Current researches often sample cascade information into\nseveral independent paths or subgraphs to learn a simple cascade\nrepresentation. However, these approaches fail to exploit the hierarchical\nsemantic associations between different modalities, limiting their predictive\nperformance. In this work, we propose a novel Hierarchical Information\nEnhancement Network (HIENet) for cascade prediction. Our approach integrates\nfundamental cascade sequence, user social graphs, and sub-cascade graph into a\nunified framework. Specifically, HIENet utilizes DeepWalk to sample cascades\ninformation into a series of sequences. It then gathers path information\nbetween users to extract the social relationships of propagators. Additionally,\nwe employ a time-stamped graph convolutional network to aggregate sub-cascade\ngraph information effectively. Ultimately, we introduce a Multi-modal Cascade\nTransformer to powerfully fuse these clues, providing a comprehensive\nunderstanding of cascading process. Extensive experiments have demonstrated the\neffectiveness of the proposed method.\n","authors":["Fanrui Zhang","Jiawei Liu","Qiang Zhang","Xiaoling Zhu","Zheng-Jun Zha"],"pdf_url":"https://arxiv.org/pdf/2403.15257v1.pdf","comment":"7 pages, 2 figures"},{"id":"http://arxiv.org/abs/2403.15251v1","updated":"2024-03-22T14:49:49Z","published":"2024-03-22T14:49:49Z","title":"Safe Learning of PDDL Domains with Conditional Effects -- Extended\n  Version","summary":"  Powerful domain-independent planners have been developed to solve various\ntypes of planning problems. These planners often require a model of the acting\nagent's actions, given in some planning domain description language. Manually\ndesigning such an action model is a notoriously challenging task. An\nalternative is to automatically learn action models from observation. Such an\naction model is called safe if every plan created with it is consistent with\nthe real, unknown action model. Algorithms for learning such safe action models\nexist, yet they cannot handle domains with conditional or universal effects,\nwhich are common constructs in many planning problems. We prove that learning\nnon-trivial safe action models with conditional effects may require an\nexponential number of samples. Then, we identify reasonable assumptions under\nwhich such learning is tractable and propose SAM Learning of Conditional\nEffects (Conditional-SAM), the first algorithm capable of doing so. We analyze\nConditional-SAM theoretically and evaluate it experimentally. Our results show\nthat the action models learned by Conditional-SAM can be used to solve\nperfectly most of the test set problems in most of the experimented domains.\n","authors":["Argaman Mordoch","Enrico Scala","Roni Stern","Brendan Juba"],"pdf_url":"https://arxiv.org/pdf/2403.15251v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.04025v3","updated":"2024-03-22T14:49:31Z","published":"2023-08-08T03:43:24Z","title":"MSAC: Multiple Speech Attribute Control Method for Reliable Speech\n  Emotion Recognition","summary":"  Despite notable progress, speech emotion recognition (SER) remains\nchallenging due to the intricate and ambiguous nature of speech emotion,\nparticularly in wild world. While current studies primarily focus on\nrecognition and generalization abilities, our research pioneers an\ninvestigation into the reliability of SER methods in the presence of semantic\ndata shifts and explores how to exert fine-grained control over various\nattributes inherent in speech signals to enhance speech emotion modeling. In\nthis paper, we first introduce MSAC-SERNet, a novel unified SER framework\ncapable of simultaneously handling both single-corpus and cross-corpus SER.\nSpecifically, concentrating exclusively on the speech emotion attribute, a\nnovel CNN-based SER model is presented to extract discriminative emotional\nrepresentations, guided by additive margin softmax loss. Considering\ninformation overlap between various speech attributes, we propose a novel\nlearning paradigm based on correlations of different speech attributes, termed\nMultiple Speech Attribute Control (MSAC), which empowers the proposed SER model\nto simultaneously capture fine-grained emotion-related features while\nmitigating the negative impact of emotion-agnostic representations.\nFurthermore, we make a first attempt to examine the reliability of the\nMSAC-SERNet framework using out-of-distribution detection methods. Experiments\non both single-corpus and cross-corpus SER scenarios indicate that MSAC-SERNet\nnot only consistently outperforms the baseline in all aspects, but achieves\nsuperior performance compared to state-of-the-art SER approaches.\n","authors":["Yu Pan","Yuguang Yang","Yuheng Huang","Jixun Yao","Jingjing Yin","Yanni Hu","Heng Lu","Lei Ma","Jianjun Zhao"],"pdf_url":"https://arxiv.org/pdf/2308.04025v3.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2403.15250v1","updated":"2024-03-22T14:47:35Z","published":"2024-03-22T14:47:35Z","title":"Comprehensive Reassessment of Large-Scale Evaluation Outcomes in LLMs: A\n  Multifaceted Statistical Approach","summary":"  Amidst the rapid evolution of LLMs, the significance of evaluation in\ncomprehending and propelling these models forward is increasingly paramount.\nEvaluations have revealed that factors such as scaling, training types,\narchitectures and other factors profoundly impact the performance of LLMs.\nHowever, the extent and nature of these impacts continue to be subjects of\ndebate because most assessments have been restricted to a limited number of\nmodels and data points. Clarifying the effects of these factors on performance\nscores can be more effectively achieved through a statistical lens. Our study\nembarks on a thorough re-examination of these LLMs, targeting the inadequacies\nin current evaluation methods. With the advent of a uniform evaluation\nframework, our research leverages an expansive dataset of evaluation results,\nintroducing a comprehensive statistical methodology. This includes the\napplication of ANOVA, Tukey HSD tests, GAMM, and clustering technique, offering\na robust and transparent approach to deciphering LLM performance data. Contrary\nto prevailing findings, our results challenge assumptions about emergent\nabilities and the influence of given training types and architectures in LLMs.\nThese findings furnish new perspectives on the characteristics, intrinsic\nnature, and developmental trajectories of LLMs. By providing straightforward\nand reliable methods to scrutinize and reassess LLM performance data, this\nstudy contributes a nuanced perspective on LLM efficiency and potentials.\n","authors":["Kun Sun","Rong Wang","Haitao Liu","Anders Søgaard"],"pdf_url":"https://arxiv.org/pdf/2403.15250v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15249v1","updated":"2024-03-22T14:47:18Z","published":"2024-03-22T14:47:18Z","title":"Spectral Motion Alignment for Video Motion Transfer using Diffusion\n  Models","summary":"  The evolution of diffusion models has greatly impacted video generation and\nunderstanding. Particularly, text-to-video diffusion models (VDMs) have\nsignificantly facilitated the customization of input video with target\nappearance, motion, etc. Despite these advances, challenges persist in\naccurately distilling motion information from video frames. While existing\nworks leverage the consecutive frame residual as the target motion vector, they\ninherently lack global motion context and are vulnerable to frame-wise\ndistortions. To address this, we present Spectral Motion Alignment (SMA), a\nnovel framework that refines and aligns motion vectors using Fourier and\nwavelet transforms. SMA learns motion patterns by incorporating\nfrequency-domain regularization, facilitating the learning of whole-frame\nglobal motion dynamics, and mitigating spatial artifacts. Extensive experiments\ndemonstrate SMA's efficacy in improving motion transfer while maintaining\ncomputational efficiency and compatibility across various video customization\nframeworks.\n","authors":["Geon Yeong Park","Hyeonho Jeong","Sang Wan Lee","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2403.15249v1.pdf","comment":"Project page:\n  https://geonyeong-park.github.io/spectral-motion-alignment/"},{"id":"http://arxiv.org/abs/2403.15248v1","updated":"2024-03-22T14:46:51Z","published":"2024-03-22T14:46:51Z","title":"Self-Supervised Backbone Framework for Diverse Agricultural Vision Tasks","summary":"  Computer vision in agriculture is game-changing with its ability to transform\nfarming into a data-driven, precise, and sustainable industry. Deep learning\nhas empowered agriculture vision to analyze vast, complex visual data, but\nheavily rely on the availability of large annotated datasets. This remains a\nbottleneck as manual labeling is error-prone, time-consuming, and expensive.\nThe lack of efficient labeling approaches inspired us to consider\nself-supervised learning as a paradigm shift, learning meaningful feature\nrepresentations from raw agricultural image data. In this work, we explore how\nself-supervised representation learning unlocks the potential applicability to\ndiverse agriculture vision tasks by eliminating the need for large-scale\nannotated datasets. We propose a lightweight framework utilizing SimCLR, a\ncontrastive learning approach, to pre-train a ResNet-50 backbone on a large,\nunannotated dataset of real-world agriculture field images. Our experimental\nanalysis and results indicate that the model learns robust features applicable\nto a broad range of downstream agriculture tasks discussed in the paper.\nAdditionally, the reduced reliance on annotated data makes our approach more\ncost-effective and accessible, paving the way for broader adoption of computer\nvision in agriculture.\n","authors":["Sudhir Sornapudi","Rajhans Singh"],"pdf_url":"https://arxiv.org/pdf/2403.15248v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.05752v2","updated":"2024-03-22T14:44:17Z","published":"2024-03-09T01:17:26Z","title":"Task-Oriented GNNs Training on Large Knowledge Graphs for Accurate and\n  Efficient Modeling","summary":"  A Knowledge Graph (KG) is a heterogeneous graph encompassing a diverse range\nof node and edge types. Heterogeneous Graph Neural Networks (HGNNs) are popular\nfor training machine learning tasks like node classification and link\nprediction on KGs. However, HGNN methods exhibit excessive complexity\ninfluenced by the KG's size, density, and the number of node and edge types. AI\npractitioners handcraft a subgraph of a KG G relevant to a specific task. We\nrefer to this subgraph as a task-oriented subgraph (TOSG), which contains a\nsubset of task-related node and edge types in G. Training the task using TOSG\ninstead of G alleviates the excessive computation required for a large KG.\nCrafting the TOSG demands a deep understanding of the KG's structure and the\ntask's objectives. Hence, it is challenging and time-consuming. This paper\nproposes KG-TOSA, an approach to automate the TOSG extraction for task-oriented\nHGNN training on a large KG. In KG-TOSA, we define a generic graph pattern that\ncaptures the KG's local and global structure relevant to a specific task. We\nexplore different techniques to extract subgraphs matching our graph pattern:\nnamely (i) two techniques sampling around targeted nodes using biased random\nwalk or influence scores, and (ii) a SPARQL-based extraction method leveraging\nRDF engines' built-in indices. Hence, it achieves negligible preprocessing\noverhead compared to the sampling techniques. We develop a benchmark of real\nKGs of large sizes and various tasks for node classification and link\nprediction. Our experiments show that KG-TOSA helps state-of-the-art HGNN\nmethods reduce training time and memory usage by up to 70% while improving the\nmodel performance, e.g., accuracy and inference time.\n","authors":["Hussein Abdallah","Waleed Afandi","Panos Kalnis","Essam Mansour"],"pdf_url":"https://arxiv.org/pdf/2403.05752v2.pdf","comment":"12 pages,9 Figures, 3 Tables, ICDE:2024"},{"id":"http://arxiv.org/abs/2403.15245v1","updated":"2024-03-22T14:41:55Z","published":"2024-03-22T14:41:55Z","title":"Reasoning-Enhanced Object-Centric Learning for Videos","summary":"  Object-centric learning aims to break down complex visual scenes into more\nmanageable object representations, enhancing the understanding and reasoning\nabilities of machine learning systems toward the physical world. Recently,\nslot-based video models have demonstrated remarkable proficiency in segmenting\nand tracking objects, but they overlook the importance of the effective\nreasoning module. In the real world, reasoning and predictive abilities play a\ncrucial role in human perception and object tracking; in particular, these\nabilities are closely related to human intuitive physics. Inspired by this, we\ndesigned a novel reasoning module called the Slot-based Time-Space Transformer\nwith Memory buffer (STATM) to enhance the model's perception ability in complex\nscenes. The memory buffer primarily serves as storage for slot information from\nupstream modules, the Slot-based Time-Space Transformer makes predictions\nthrough slot-based spatiotemporal attention computations and fusion. Our\nexperiment results on various datasets show that STATM can significantly\nenhance object-centric learning capabilities of slot-based video models.\n","authors":["Jian Li","Pu Ren","Yang Liu","Hao Sun"],"pdf_url":"https://arxiv.org/pdf/2403.15245v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15235v1","updated":"2024-03-22T14:29:03Z","published":"2024-03-22T14:29:03Z","title":"Multi-perspective Memory Enhanced Network for Identifying Key Nodes in\n  Social Networks","summary":"  Identifying key nodes in social networks plays a crucial role in timely\nblocking false information. Existing key node identification methods usually\nconsider node influence only from the propagation structure perspective and\nhave insufficient generalization ability to unknown scenarios. In this paper,\nwe propose a novel Multi-perspective Memory Enhanced Network (MMEN) for\nidentifying key nodes in social networks, which mines key nodes from multiple\nperspectives and utilizes memory networks to store historical information.\nSpecifically, MMEN first constructs two propagation networks from the\nperspectives of user attributes and propagation structure and updates node\nfeature representations using graph attention networks. Meanwhile, the memory\nnetwork is employed to store information of similar subgraphs, enhancing the\nmodel's generalization performance in unknown scenarios. Finally, MMEN applies\nadaptive weights to combine the node influence of the two propagation networks\nto select the ultimate key nodes. Extensive experiments demonstrate that our\nmethod significantly outperforms previous methods.\n","authors":["Qiang Zhang","Jiawei Liu","Fanrui Zhang","Xiaoling Zhu","Zheng-Jun Zha"],"pdf_url":"https://arxiv.org/pdf/2403.15235v1.pdf","comment":"7 pages, 1 figures"},{"id":"http://arxiv.org/abs/2206.00759v3","updated":"2024-03-22T14:13:56Z","published":"2022-06-01T20:48:24Z","title":"Interpretability Guarantees with Merlin-Arthur Classifiers","summary":"  We propose an interactive multi-agent classifier that provides provable\ninterpretability guarantees even for complex agents such as neural networks.\nThese guarantees consist of lower bounds on the mutual information between\nselected features and the classification decision. Our results are inspired by\nthe Merlin-Arthur protocol from Interactive Proof Systems and express these\nbounds in terms of measurable metrics such as soundness and completeness.\nCompared to existing interactive setups, we rely neither on optimal agents nor\non the assumption that features are distributed independently. Instead, we use\nthe relative strength of the agents as well as the new concept of Asymmetric\nFeature Correlation which captures the precise kind of correlations that make\ninterpretability guarantees difficult. We evaluate our results on two\nsmall-scale datasets where high mutual information can be verified explicitly.\n","authors":["Stephan Wäldchen","Kartikey Sharma","Berkant Turan","Max Zimmer","Sebastian Pokutta"],"pdf_url":"https://arxiv.org/pdf/2206.00759v3.pdf","comment":"AISTATS24 Camera-Ready Version, 34 pages total (9 pages main part, 3\n  pages references, 22 pages appendix), 17 figures, 3 tables"},{"id":"http://arxiv.org/abs/2403.15218v1","updated":"2024-03-22T14:07:07Z","published":"2024-03-22T14:07:07Z","title":"Anytime, Anywhere, Anyone: Investigating the Feasibility of Segment\n  Anything Model for Crowd-Sourcing Medical Image Annotations","summary":"  Curating annotations for medical image segmentation is a labor-intensive and\ntime-consuming task that requires domain expertise, resulting in \"narrowly\"\nfocused deep learning (DL) models with limited translational utility. Recently,\nfoundation models like the Segment Anything Model (SAM) have revolutionized\nsemantic segmentation with exceptional zero-shot generalizability across\nvarious domains, including medical imaging, and hold a lot of promise for\nstreamlining the annotation process. However, SAM has yet to be evaluated in a\ncrowd-sourced setting to curate annotations for training 3D DL segmentation\nmodels. In this work, we explore the potential of SAM for crowd-sourcing\n\"sparse\" annotations from non-experts to generate \"dense\" segmentation masks\nfor training 3D nnU-Net models, a state-of-the-art DL segmentation model. Our\nresults indicate that while SAM-generated annotations exhibit high mean Dice\nscores compared to ground-truth annotations, nnU-Net models trained on\nSAM-generated annotations perform significantly worse than nnU-Net models\ntrained on ground-truth annotations ($p<0.001$, all).\n","authors":["Pranav Kulkarni","Adway Kanhere","Dharmam Savani","Andrew Chan","Devina Chatterjee","Paul H. Yi","Vishwa S. Parekh"],"pdf_url":"https://arxiv.org/pdf/2403.15218v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15216v1","updated":"2024-03-22T14:03:37Z","published":"2024-03-22T14:03:37Z","title":"(Un)making AI Magic: a Design Taxonomy","summary":"  This paper examines the role that enchantment plays in the design of AI\nthings by constructing a taxonomy of design approaches that increase or\ndecrease the perception of magic and enchantment. We start from the design\ndiscourse surrounding recent developments in AI technologies, highlighting\nspecific interaction qualities such as algorithmic uncertainties and errors and\narticulating relations to the rhetoric of magic and supernatural thinking.\nThrough analyzing and reflecting upon 52 students' design projects from two\neditions of a Master course in design and AI, we identify seven design\nprinciples and unpack the effects of each in terms of enchantment and\ndisenchantment. We conclude by articulating ways in which this taxonomy can be\napproached and appropriated by design/HCI practitioners, especially to support\nexploration and reflexivity.\n","authors":["Maria Luce Lupetti","Dave Murray-Rust"],"pdf_url":"https://arxiv.org/pdf/2403.15216v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.10482v2","updated":"2024-03-22T13:59:34Z","published":"2024-03-15T17:12:57Z","title":"Can a GPT4-Powered AI Agent Be a Good Enough Performance Attribution\n  Analyst?","summary":"  Performance attribution analysis, defined as the process of explaining the\ndrivers of the excess performance of an investment portfolio against a\nbenchmark, stands as a significant feature of portfolio management and plays a\ncrucial role in the investment decision-making process, particularly within the\nfund management industry. Rooted in a solid financial and mathematical\nframework, the importance and methodologies of this analytical technique are\nextensively documented across numerous academic research papers and books. The\nintegration of large language models (LLMs) and AI agents marks a\ngroundbreaking development in this field. These agents are designed to automate\nand enhance the performance attribution analysis by accurately calculating and\nanalyzing portfolio performances against benchmarks. In this study, we\nintroduce the application of an AI Agent for a variety of essential performance\nattribution tasks, including the analysis of performance drivers and utilizing\nLLMs as calculation engine for multi-level attribution analysis and\nquestion-answering (QA) tasks. Leveraging advanced prompt engineering\ntechniques such as Chain-of-Thought (CoT) and Plan and Solve (PS), and\nemploying a standard agent framework from LangChain, the research achieves\npromising results: it achieves accuracy rates exceeding 93% in analyzing\nperformance drivers, attains 100% in multi-level attribution calculations, and\nsurpasses 84% accuracy in QA exercises that simulate official examination\nstandards. These findings affirm the impactful role of AI agents, prompt\nengineering and evaluation in advancing portfolio management processes,\nhighlighting a significant development in the practical application and\nevaluation of Generative AI technologies within the domain.\n","authors":["Bruno de Melo","Jamiel Sheikh"],"pdf_url":"https://arxiv.org/pdf/2403.10482v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15195v1","updated":"2024-03-22T13:31:24Z","published":"2024-03-22T13:31:24Z","title":"FSD-Inference: Fully Serverless Distributed Inference with Scalable\n  Cloud Communication","summary":"  Serverless computing offers attractive scalability, elasticity and\ncost-effectiveness. However, constraints on memory, CPU and function runtime\nhave hindered its adoption for data-intensive applications and machine learning\n(ML) workloads. Traditional 'server-ful' platforms enable distributed\ncomputation via fast networks and well-established inter-process communication\n(IPC) mechanisms such as MPI and shared memory. In the absence of such\nsolutions in the serverless domain, parallel computation with significant IPC\nrequirements is challenging. We present FSD-Inference, the first fully\nserverless and highly scalable system for distributed ML inference. We explore\npotential communication channels, in conjunction with Function-as-a-Service\n(FaaS) compute, to design a state-of-the-art solution for distributed ML within\nthe context of serverless data-intensive computing. We introduce novel fully\nserverless communication schemes for ML inference workloads, leveraging both\ncloud-based publish-subscribe/queueing and object storage offerings. We\ndemonstrate how publish-subscribe/queueing services can be adapted for FaaS IPC\nwith comparable performance to object storage, while offering significantly\nreduced cost at high parallelism levels. We conduct in-depth experiments on\nbenchmark DNNs of various sizes. The results show that when compared to\nserver-based alternatives, FSD-Inference is significantly more cost-effective\nand scalable, and can even achieve competitive performance against optimized\nHPC solutions. Experiments also confirm that our serverless solution can handle\nlarge distributed workloads and leverage high degrees of FaaS parallelism.\n","authors":["Joe Oakley","Hakan Ferhatosmanoglu"],"pdf_url":"https://arxiv.org/pdf/2403.15195v1.pdf","comment":"In Proceedings of 2024 IEEE 40th International Conference on Data\n  Engineering (ICDE) (to appear)"},{"id":"http://arxiv.org/abs/2312.13964v2","updated":"2024-03-22T13:25:53Z","published":"2023-12-21T15:51:12Z","title":"PIA: Your Personalized Image Animator via Plug-and-Play Modules in\n  Text-to-Image Models","summary":"  Recent advancements in personalized text-to-image (T2I) models have\nrevolutionized content creation, empowering non-experts to generate stunning\nimages with unique styles. While promising, adding realistic motions into these\npersonalized images by text poses significant challenges in preserving distinct\nstyles, high-fidelity details, and achieving motion controllability by text. In\nthis paper, we present PIA, a Personalized Image Animator that excels in\naligning with condition images, achieving motion controllability by text, and\nthe compatibility with various personalized T2I models without specific tuning.\nTo achieve these goals, PIA builds upon a base T2I model with well-trained\ntemporal alignment layers, allowing for the seamless transformation of any\npersonalized T2I model into an image animation model. A key component of PIA is\nthe introduction of the condition module, which utilizes the condition frame\nand inter-frame affinity as input to transfer appearance information guided by\nthe affinity hint for individual frame synthesis in the latent space. This\ndesign mitigates the challenges of appearance-related image alignment within\nand allows for a stronger focus on aligning with motion-related guidance.\n","authors":["Yiming Zhang","Zhening Xing","Yanhong Zeng","Youqing Fang","Kai Chen"],"pdf_url":"https://arxiv.org/pdf/2312.13964v2.pdf","comment":"Project page: https://pi-animator.github.io/"},{"id":"http://arxiv.org/abs/2403.15192v1","updated":"2024-03-22T13:24:50Z","published":"2024-03-22T13:24:50Z","title":"SFOD: Spiking Fusion Object Detector","summary":"  Event cameras, characterized by high temporal resolution, high dynamic range,\nlow power consumption, and high pixel bandwidth, offer unique capabilities for\nobject detection in specialized contexts. Despite these advantages, the\ninherent sparsity and asynchrony of event data pose challenges to existing\nobject detection algorithms. Spiking Neural Networks (SNNs), inspired by the\nway the human brain codes and processes information, offer a potential solution\nto these difficulties. However, their performance in object detection using\nevent cameras is limited in current implementations. In this paper, we propose\nthe Spiking Fusion Object Detector (SFOD), a simple and efficient approach to\nSNN-based object detection. Specifically, we design a Spiking Fusion Module,\nachieving the first-time fusion of feature maps from different scales in SNNs\napplied to event cameras. Additionally, through integrating our analysis and\nexperiments conducted during the pretraining of the backbone network on the\nNCAR dataset, we delve deeply into the impact of spiking decoding strategies\nand loss functions on model performance. Thereby, we establish state-of-the-art\nclassification results based on SNNs, achieving 93.7\\% accuracy on the NCAR\ndataset. Experimental results on the GEN1 detection dataset demonstrate that\nthe SFOD achieves a state-of-the-art mAP of 32.1\\%, outperforming existing\nSNN-based approaches. Our research not only underscores the potential of SNNs\nin object detection with event cameras but also propels the advancement of\nSNNs. Code is available at https://github.com/yimeng-fan/SFOD.\n","authors":["Yimeng Fan","Wei Zhang","Changsong Liu","Mingyang Li","Wenrui Lu"],"pdf_url":"https://arxiv.org/pdf/2403.15192v1.pdf","comment":"Accepted by CVPR2024"},{"id":"http://arxiv.org/abs/2306.14899v2","updated":"2024-03-22T13:24:35Z","published":"2023-06-26T17:59:55Z","title":"FunQA: Towards Surprising Video Comprehension","summary":"  Surprising videos, such as funny clips, creative performances, or visual\nillusions, attract significant attention. Enjoyment of these videos is not\nsimply a response to visual stimuli; rather, it hinges on the human capacity to\nunderstand (and appreciate) commonsense violations depicted in these videos. We\nintroduce FunQA, a challenging video question-answering (QA) dataset\nspecifically designed to evaluate and enhance the depth of video reasoning\nbased on counter-intuitive and fun videos. Unlike most video QA benchmarks\nwhich focus on less surprising contexts, e.g., cooking or instructional videos,\nFunQA covers three previously unexplored types of surprising videos: 1)\nHumorQA, 2) CreativeQA, and 3) MagicQA. For each subset, we establish rigorous\nQA tasks designed to assess the model's capability in counter-intuitive\ntimestamp localization, detailed video description, and reasoning around\ncounter-intuitiveness. We also pose higher-level tasks, such as attributing a\nfitting and vivid title to the video and scoring the video creativity. In\ntotal, the FunQA benchmark consists of 312K free-text QA pairs derived from\n4.3K video clips, spanning a total of 24 video hours. Moreover, we propose\nFunMentor, an agent designed for Vision-Language Models (VLMs) that uses\nmulti-turn dialogues to enhance models' understanding of counter-intuitiveness.\nExtensive experiments with existing VLMs demonstrate the effectiveness of\nFunMentor and reveal significant performance gaps for the FunQA videos across\nspatial-temporal reasoning, visual-centered reasoning, and free-text\ngeneration.\n","authors":["Binzhu Xie","Sicheng Zhang","Zitang Zhou","Bo Li","Yuanhan Zhang","Jack Hessel","Jingkang Yang","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2306.14899v2.pdf","comment":"Project Page: https://funqa-benchmark.github.io/ Codebase:\n  https://github.com/Jingkang50/FunQA"},{"id":"http://arxiv.org/abs/2403.15176v1","updated":"2024-03-22T13:01:10Z","published":"2024-03-22T13:01:10Z","title":"Brain-grounding of semantic vectors improves neural decoding of visual\n  stimuli","summary":"  Developing algorithms for accurate and comprehensive neural decoding of\nmental contents is one of the long-cherished goals in the field of neuroscience\nand brain-machine interfaces. Previous studies have demonstrated the\nfeasibility of neural decoding by training machine learning models to map brain\nactivity patterns into a semantic vector representation of stimuli. These\nvectors, hereafter referred as pretrained feature vectors, are usually derived\nfrom semantic spaces based solely on image and/or text features and therefore\nthey might have a totally different characteristics than how visual stimuli is\nrepresented in the human brain, resulting in limiting the capability of brain\ndecoders to learn this mapping. To address this issue, we propose a\nrepresentation learning framework, termed brain-grounding of semantic vectors,\nwhich fine-tunes pretrained feature vectors to better align with the neural\nrepresentation of visual stimuli in the human brain. We trained this model this\nmodel with functional magnetic resonance imaging (fMRI) of 150 different visual\nstimuli categories, and then performed zero-shot brain decoding and\nidentification analyses on 1) fMRI and 2) magnetoencephalography (MEG).\nInterestingly, we observed that by using the brain-grounded vectors, the brain\ndecoding and identification accuracy on brain data from different neuroimaging\nmodalities increases. These findings underscore the potential of incorporating\na richer array of brain-derived features to enhance performance of brain\ndecoding algorithms.\n","authors":["Shirin Vafaei","Ryohei Fukuma","Huixiang Yang","Haruhiko Kishima","Takufumi Yanagisawa"],"pdf_url":"https://arxiv.org/pdf/2403.15176v1.pdf","comment":"16 pages, 4 figures"},{"id":"http://arxiv.org/abs/2403.15170v1","updated":"2024-03-22T12:46:58Z","published":"2024-03-22T12:46:58Z","title":"Exploring the Task-agnostic Trait of Self-supervised Learning in the\n  Context of Detecting Mental Disorders","summary":"  Self-supervised learning (SSL) has been investigated to generate\ntask-agnostic representations across various domains. However, such\ninvestigation has not been conducted for detecting multiple mental disorders.\nThe rationale behind the existence of a task-agnostic representation lies in\nthe overlapping symptoms among multiple mental disorders. Consequently, the\nbehavioural data collected for mental health assessment may carry a mixed bag\nof attributes related to multiple disorders. Motivated by that, in this study,\nwe explore a task-agnostic representation derived through SSL in the context of\ndetecting major depressive disorder (MDD) and post-traumatic stress disorder\n(PTSD) using audio and video data collected during interactive sessions. This\nstudy employs SSL models trained by predicting multiple fixed targets or masked\nframes. We propose a list of fixed targets to make the generated representation\nmore efficient for detecting MDD and PTSD. Furthermore, we modify the\nhyper-parameters of the SSL encoder predicting fixed targets to generate global\nrepresentations that capture varying temporal contexts. Both these innovations\nare noted to yield improved detection performances for considered mental\ndisorders and exhibit task-agnostic traits. In the context of the SSL model\npredicting masked frames, the generated global representations are also noted\nto exhibit task-agnostic traits.\n","authors":["Rohan Kumar Gupta","Rohit Sinha"],"pdf_url":"https://arxiv.org/pdf/2403.15170v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15167v1","updated":"2024-03-22T12:37:14Z","published":"2024-03-22T12:37:14Z","title":"Transition Graph Properties of Target Class Classification","summary":"  Target class classification is a mixed classification and transition model\nwhose integrated goal is to assign objects to a certain, so called target or\nnormal class. The classification process is iterative, and in each step an\nobject in a certain class undergoes an action attached to that class,\ninitiating the transition of the object to one of the classes. The sequence of\ntransitions, which we call class transitions, must be designed to provide the\nfinal assignment of objects to the target class. The transition process can be\ndescribed in the form of a directed graph, and the success of the final\nclassification is mainly due to the properties of this graph. In our previous\nresearch we showed that the desirable structure of the transition graph is an\noriented rooted tree with orientation towards the root vertex, which\ncorresponds to the normal class. It is clear that the transition graph of an\narbitrary algorithm (policy) may not have this property. In this paper we study\nthe structure of realistic transition graphs, which makes it possible to find\nclassification inconsistencies, helping to transfer it into the desired form.\nThe medical interpretation of dynamic treatment regime considered in the\narticle further clarifies the investigated framework.\n","authors":["Levon Aslanyan","Hasmik Sahakyan"],"pdf_url":"https://arxiv.org/pdf/2403.15167v1.pdf","comment":"14pages, 4 figures"},{"id":"http://arxiv.org/abs/2312.16427v3","updated":"2024-03-22T12:05:02Z","published":"2023-12-27T06:23:29Z","title":"Learning to Embed Time Series Patches Independently","summary":"  Masked time series modeling has recently gained much attention as a\nself-supervised representation learning strategy for time series. Inspired by\nmasked image modeling in computer vision, recent works first patchify and\npartially mask out time series, and then train Transformers to capture the\ndependencies between patches by predicting masked patches from unmasked\npatches. However, we argue that capturing such patch dependencies might not be\nan optimal strategy for time series representation learning; rather, learning\nto embed patches independently results in better time series representations.\nSpecifically, we propose to use 1) the simple patch reconstruction task, which\nautoencode each patch without looking at other patches, and 2) the simple\npatch-wise MLP that embeds each patch independently. In addition, we introduce\ncomplementary contrastive learning to hierarchically capture adjacent time\nseries information efficiently. Our proposed method improves time series\nforecasting and classification performance compared to state-of-the-art\nTransformer-based models, while it is more efficient in terms of the number of\nparameters and training/inference time. Code is available at this repository:\nhttps://github.com/seunghan96/pits.\n","authors":["Seunghan Lee","Taeyoung Park","Kibok Lee"],"pdf_url":"https://arxiv.org/pdf/2312.16427v3.pdf","comment":"ICLR 2024"},{"id":"http://arxiv.org/abs/2312.16424v3","updated":"2024-03-22T12:02:42Z","published":"2023-12-27T06:15:00Z","title":"Soft Contrastive Learning for Time Series","summary":"  Contrastive learning has shown to be effective to learn representations from\ntime series in a self-supervised way. However, contrasting similar time series\ninstances or values from adjacent timestamps within a time series leads to\nignore their inherent correlations, which results in deteriorating the quality\nof learned representations. To address this issue, we propose SoftCLT, a simple\nyet effective soft contrastive learning strategy for time series. This is\nachieved by introducing instance-wise and temporal contrastive loss with soft\nassignments ranging from zero to one. Specifically, we define soft assignments\nfor 1) instance-wise contrastive loss by the distance between time series on\nthe data space, and 2) temporal contrastive loss by the difference of\ntimestamps. SoftCLT is a plug-and-play method for time series contrastive\nlearning that improves the quality of learned representations without bells and\nwhistles. In experiments, we demonstrate that SoftCLT consistently improves the\nperformance in various downstream tasks including classification,\nsemi-supervised learning, transfer learning, and anomaly detection, showing\nstate-of-the-art performance. Code is available at this repository:\nhttps://github.com/seunghan96/softclt.\n","authors":["Seunghan Lee","Taeyoung Park","Kibok Lee"],"pdf_url":"https://arxiv.org/pdf/2312.16424v3.pdf","comment":"ICLR 2024 Spotlight"},{"id":"http://arxiv.org/abs/2403.15143v1","updated":"2024-03-22T11:53:03Z","published":"2024-03-22T11:53:03Z","title":"Modular Deep Active Learning Framework for Image Annotation: A Technical\n  Report for the Ophthalmo-AI Project","summary":"  Image annotation is one of the most essential tasks for guaranteeing proper\ntreatment for patients and tracking progress over the course of therapy in the\nfield of medical imaging and disease diagnosis. However, manually annotating a\nlot of 2D and 3D imaging data can be extremely tedious. Deep Learning (DL)\nbased segmentation algorithms have completely transformed this process and made\nit possible to automate image segmentation. By accurately segmenting medical\nimages, these algorithms can greatly minimize the time and effort necessary for\nmanual annotation. Additionally, by incorporating Active Learning (AL) methods,\nthese segmentation algorithms can perform far more effectively with a smaller\namount of ground truth data. We introduce MedDeepCyleAL, an end-to-end\nframework implementing the complete AL cycle. It provides researchers with the\nflexibility to choose the type of deep learning model they wish to employ and\nincludes an annotation tool that supports the classification and segmentation\nof medical images. The user-friendly interface allows for easy alteration of\nthe AL and DL model settings through a configuration file, requiring no prior\nprogramming experience. While MedDeepCyleAL can be applied to any kind of image\ndata, we have specifically applied it to ophthalmology data in this project.\n","authors":["Md Abdul Kadir","Hasan Md Tusfiqur Alam","Pascale Maul","Hans-Jürgen Profitlich","Moritz Wolf","Daniel Sonntag"],"pdf_url":"https://arxiv.org/pdf/2403.15143v1.pdf","comment":"DFKI Technical Report"},{"id":"http://arxiv.org/abs/2403.15137v1","updated":"2024-03-22T11:42:47Z","published":"2024-03-22T11:42:47Z","title":"CACA Agent: Capability Collaboration based AI Agent","summary":"  As AI Agents based on Large Language Models (LLMs) have shown potential in\npractical applications across various fields, how to quickly deploy an AI agent\nand how to conveniently expand the application scenario of AI agents has become\na challenge. Previous studies mainly focused on implementing all the reasoning\ncapabilities of AI agents within a single LLM, which often makes the model more\ncomplex and also reduces the extensibility of AI agent functionality. In this\npaper, we propose CACA Agent (Capability Collaboration based AI Agent), using\nan open architecture inspired by service computing. CACA Agent integrates a set\nof collaborative capabilities to implement AI Agents, not only reducing the\ndependence on a single LLM, but also enhancing the extensibility of both the\nplanning abilities and the tools available to AI agents. Utilizing the proposed\nsystem, we present a demo to illustrate the operation and the application\nscenario extension of CACA Agent.\n","authors":["Peng Xu","Haoran Wang","Chuang Wang","Xu Liu"],"pdf_url":"https://arxiv.org/pdf/2403.15137v1.pdf","comment":"4 pages,5 figures"},{"id":"http://arxiv.org/abs/2403.11220v3","updated":"2024-03-22T11:42:40Z","published":"2024-03-17T13:43:10Z","title":"CPA-Enhancer: Chain-of-Thought Prompted Adaptive Enhancer for Object\n  Detection under Unknown Degradations","summary":"  Object detection methods under known single degradations have been\nextensively investigated. However, existing approaches require prior knowledge\nof the degradation type and train a separate model for each, limiting their\npractical applications in unpredictable environments. To address this\nchallenge, we propose a chain-of-thought (CoT) prompted adaptive enhancer,\nCPA-Enhancer, for object detection under unknown degradations. Specifically,\nCPA-Enhancer progressively adapts its enhancement strategy under the\nstep-by-step guidance of CoT prompts, that encode degradation-related\ninformation. To the best of our knowledge, it's the first work that exploits\nCoT prompting for object detection tasks. Overall, CPA-Enhancer is a\nplug-and-play enhancement model that can be integrated into any generic\ndetectors to achieve substantial gains on degraded images, without knowing the\ndegradation type priorly. Experimental results demonstrate that CPA-Enhancer\nnot only sets the new state of the art for object detection but also boosts the\nperformance of other downstream vision tasks under unknown degradations.\n","authors":["Yuwei Zhang","Yan Wu","Yanming Liu","Xinyue Peng"],"pdf_url":"https://arxiv.org/pdf/2403.11220v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13408v2","updated":"2024-03-22T11:41:38Z","published":"2024-03-20T08:50:15Z","title":"S2DM: Sector-Shaped Diffusion Models for Video Generation","summary":"  Diffusion models have achieved great success in image generation. However,\nwhen leveraging this idea for video generation, we face significant challenges\nin maintaining the consistency and continuity across video frames. This is\nmainly caused by the lack of an effective framework to align frames of videos\nwith desired temporal features while preserving consistent semantic and\nstochastic features. In this work, we propose a novel Sector-Shaped Diffusion\nModel (S2DM) whose sector-shaped diffusion region is formed by a set of\nray-shaped reverse diffusion processes starting at the same noise point. S2DM\ncan generate a group of intrinsically related data sharing the same semantic\nand stochastic features while varying on temporal features with appropriate\nguided conditions. We apply S2DM to video generation tasks, and explore the use\nof optical flow as temporal conditions. Our experimental results show that S2DM\noutperforms many existing methods in the task of video generation without any\ntemporal-feature modelling modules. For text-to-video generation tasks where\ntemporal conditions are not explicitly given, we propose a two-stage generation\nstrategy which can decouple the generation of temporal features from\nsemantic-content features. We show that, without additional training, our model\nintegrated with another temporal conditions generative model can still achieve\ncomparable performance with existing works. Our results can be viewd at\nhttps://s2dm.github.io/S2DM/.\n","authors":["Haoran Lang","Yuxuan Ge","Zheng Tian"],"pdf_url":"https://arxiv.org/pdf/2403.13408v2.pdf","comment":"17 pages, 6 figures"},{"id":"http://arxiv.org/abs/2403.15115v1","updated":"2024-03-22T11:16:43Z","published":"2024-03-22T11:16:43Z","title":"Language Models in Dialogue: Conversational Maxims for Human-AI\n  Interactions","summary":"  Modern language models, while sophisticated, exhibit some inherent\nshortcomings, particularly in conversational settings. We claim that many of\nthe observed shortcomings can be attributed to violation of one or more\nconversational principles. By drawing upon extensive research from both the\nsocial science and AI communities, we propose a set of maxims -- quantity,\nquality, relevance, manner, benevolence, and transparency -- for describing\neffective human-AI conversation. We first justify the applicability of the\nfirst four maxims (from Grice) in the context of human-AI interactions. We then\nargue that two new maxims, benevolence (concerning the generation of, and\nengagement with, harmful content) and transparency (concerning recognition of\none's knowledge boundaries, operational constraints, and intents), are\nnecessary for addressing behavior unique to modern human-AI interactions. The\nproposed maxims offer prescriptive guidance on how to assess conversational\nquality between humans and LLM-driven conversational agents, informing both\ntheir evaluation and improved design.\n","authors":["Erik Miehling","Manish Nagireddy","Prasanna Sattigeri","Elizabeth M. Daly","David Piorkowski","John T. Richards"],"pdf_url":"https://arxiv.org/pdf/2403.15115v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15114v1","updated":"2024-03-22T11:16:11Z","published":"2024-03-22T11:16:11Z","title":"Solving a Real-World Package Delivery Routing Problem Using Quantum\n  Annealers","summary":"  Research focused on the conjunction between quantum computing and routing\nproblems has been very prolific in recent years. Most of the works revolve\naround classical problems such as the Traveling Salesman Problem or the Vehicle\nRouting Problem. Even though working on these problems is valuable, it is also\nundeniable that their academic-oriented nature falls short of real-world\nrequirements. The main objective of this research is to present a solving\nmethod for realistic instances, avoiding problem relaxations or technical\nshortcuts. Instead, a quantum-classical hybrid solver has been developed,\ncoined Q4RPD, that considers a set of real constraints such as a heterogeneous\nfleet of vehicles, priority deliveries, and capacities characterized by two\nvalues: weight and dimensions of the packages. Q4RPD resorts to the Leap\nConstrained Quadratic Model Hybrid Solver of D-Wave. To demonstrate the\napplication of Q4RPD, an experimentation composed of six different instances\nhas been conducted, aiming to serve as illustrative examples.\n","authors":["Eneko Osaba","Esther Villar-Rodriguez","Antón Asla"],"pdf_url":"https://arxiv.org/pdf/2403.15114v1.pdf","comment":"15 pages, 11 figures and 4 tables. Paper submitted for review in\n  Scientific Reports"},{"id":"http://arxiv.org/abs/2403.15112v1","updated":"2024-03-22T11:08:48Z","published":"2024-03-22T11:08:48Z","title":"Text clustering with LLM embeddings","summary":"  Text clustering is an important approach for organising the growing amount of\ndigital content, helping to structure and find hidden patterns in uncategorised\ndata. In this research, we investigated how different textual embeddings -\nparticularly those used in large language models (LLMs) - and clustering\nalgorithms affect how text datasets are clustered. A series of experiments were\nconducted to assess how embeddings influence clustering results, the role\nplayed by dimensionality reduction through summarisation, and embedding size\nadjustment. Results reveal that LLM embeddings excel at capturing the nuances\nof structured language, while BERT leads the lightweight options in\nperformance. In addition, we find that increasing embedding dimensionality and\nsummarisation techniques do not uniformly improve clustering efficiency,\nsuggesting that these strategies require careful analysis to use in real-life\nmodels. These results highlight a complex balance between the need for nuanced\ntext representation and computational feasibility in text clustering\napplications. This study extends traditional text clustering frameworks by\nincorporating embeddings from LLMs, thereby paving the way for improved\nmethodologies and opening new avenues for future research in various types of\ntextual analysis.\n","authors":["Alina Petukhova","Joao P. Matos-Carvalho","Nuno Fachada"],"pdf_url":"https://arxiv.org/pdf/2403.15112v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13869v2","updated":"2024-03-22T10:59:56Z","published":"2024-03-20T14:00:29Z","title":"Accurately Predicting Probabilities of Safety-Critical Rare Events for\n  Intelligent Systems","summary":"  Intelligent systems are increasingly integral to our daily lives, yet rare\nsafety-critical events present significant latent threats to their practical\ndeployment. Addressing this challenge hinges on accurately predicting the\nprobability of safety-critical events occurring within a given time step from\nthe current state, a metric we define as 'criticality'. The complexity of\npredicting criticality arises from the extreme data imbalance caused by rare\nevents in high dimensional variables associated with the rare events, a\nchallenge we refer to as the curse of rarity. Existing methods tend to be\neither overly conservative or prone to overlooking safety-critical events, thus\nstruggling to achieve both high precision and recall rates, which severely\nlimits their applicability. This study endeavors to develop a criticality\nprediction model that excels in both precision and recall rates for evaluating\nthe criticality of safety-critical autonomous systems. We propose a multi-stage\nlearning framework designed to progressively densify the dataset, mitigating\nthe curse of rarity across stages. To validate our approach, we evaluate it in\ntwo cases: lunar lander and bipedal walker scenarios. The results demonstrate\nthat our method surpasses traditional approaches, providing a more accurate and\ndependable assessment of criticality in intelligent systems.\n","authors":["Ruoxuan Bai","Jingxuan Yang","Weiduo Gong","Yi Zhang","Qiujing Lu","Shuo Feng"],"pdf_url":"https://arxiv.org/pdf/2403.13869v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15100v1","updated":"2024-03-22T10:39:22Z","published":"2024-03-22T10:39:22Z","title":"Subequivariant Reinforcement Learning Framework for Coordinated Motion\n  Control","summary":"  Effective coordination is crucial for motion control with reinforcement\nlearning, especially as the complexity of agents and their motions increases.\nHowever, many existing methods struggle to account for the intricate\ndependencies between joints. We introduce CoordiGraph, a novel architecture\nthat leverages subequivariant principles from physics to enhance coordination\nof motion control with reinforcement learning. This method embeds the\nprinciples of equivariance as inherent patterns in the learning process under\ngravity influence, which aids in modeling the nuanced relationships between\njoints vital for motion control. Through extensive experimentation with\nsophisticated agents in diverse environments, we highlight the merits of our\napproach. Compared to current leading methods, CoordiGraph notably enhances\ngeneralization and sample efficiency.\n","authors":["Haoyu Wang","Xiaoyu Tan","Xihe Qiu","Chao Qu"],"pdf_url":"https://arxiv.org/pdf/2403.15100v1.pdf","comment":"7 pages, 7 figures, 2024 IEEE International Conference on Robotics\n  and Automation"},{"id":"http://arxiv.org/abs/2310.00354v3","updated":"2024-03-22T10:36:47Z","published":"2023-09-30T12:17:36Z","title":"AI-Dentify: Deep learning for proximal caries detection on bitewing\n  x-ray -- HUNT4 Oral Health Study","summary":"  Background: Dental caries diagnosis requires the manual inspection of\ndiagnostic bitewing images of the patient, followed by a visual inspection and\nprobing of the identified dental pieces with potential lesions. Yet the use of\nartificial intelligence, and in particular deep-learning, has the potential to\naid in the diagnosis by providing a quick and informative analysis of the\nbitewing images.\n  Methods: A dataset of 13,887 bitewings from the HUNT4 Oral Health Study were\nannotated individually by six different experts, and used to train three\ndifferent object detection deep-learning architectures: RetinaNet (ResNet50),\nYOLOv5 (M size), and EfficientDet (D0 and D1 sizes). A consensus dataset of 197\nimages, annotated jointly by the same six dentist, was used for evaluation. A\nfive-fold cross validation scheme was used to evaluate the performance of the\nAI models.\n  Results: he trained models show an increase in average precision and\nF1-score, and decrease of false negative rate, with respect to the dental\nclinicians. When compared against the dental clinicians, the YOLOv5 model shows\nthe largest improvement, reporting 0.647 mean average precision, 0.548 mean\nF1-score, and 0.149 mean false negative rate. Whereas the best annotators on\neach of these metrics reported 0.299, 0.495, and 0.164 respectively.\n  Conclusion: Deep-learning models have shown the potential to assist dental\nprofessionals in the diagnosis of caries. Yet, the task remains challenging due\nto the artifacts natural to the bitewing images.\n","authors":["Javier Pérez de Frutos","Ragnhild Holden Helland","Shreya Desai","Line Cathrine Nymoen","Thomas Langø","Theodor Remman","Abhijit Sen"],"pdf_url":"https://arxiv.org/pdf/2310.00354v3.pdf","comment":"24 pages, 5 figure, 7 tables"},{"id":"http://arxiv.org/abs/2403.15097v1","updated":"2024-03-22T10:32:43Z","published":"2024-03-22T10:32:43Z","title":"Argument-Aware Approach To Event Linking","summary":"  Event linking connects event mentions in text with relevant nodes in a\nknowledge base (KB). Prior research in event linking has mainly borrowed\nmethods from entity linking, overlooking the distinct features of events.\nCompared to the extensively explored entity linking task, events have more\ncomplex structures and can be more effectively distinguished by examining their\nassociated arguments. Moreover, the information-rich nature of events leads to\nthe scarcity of event KBs. This emphasizes the need for event linking models to\nidentify and classify event mentions not in the KB as ``out-of-KB,'' an area\nthat has received limited attention. In this work, we tackle these challenges\nby introducing an argument-aware approach. First, we improve event linking\nmodels by augmenting input text with tagged event argument information,\nfacilitating the recognition of key information about event mentions.\nSubsequently, to help the model handle ``out-of-KB'' scenarios, we synthesize\nout-of-KB training examples from in-KB instances through controlled\nmanipulation of event arguments. Our experiment across two test datasets showed\nsignificant enhancements in both in-KB and out-of-KB scenarios, with a notable\n22% improvement in out-of-KB evaluations.\n","authors":["I-Hung Hsu","Zihan Xue","Nilay Pochh","Sahil Bansal","Premkumar Natarajan","Jayanth Srinivasa","Nanyun Peng"],"pdf_url":"https://arxiv.org/pdf/2403.15097v1.pdf","comment":"Work In Progress"},{"id":"http://arxiv.org/abs/2403.15091v1","updated":"2024-03-22T10:20:09Z","published":"2024-03-22T10:20:09Z","title":"Improved Long Short-Term Memory-based Wastewater Treatment Simulators\n  for Deep Reinforcement Learning","summary":"  Even though Deep Reinforcement Learning (DRL) showed outstanding results in\nthe fields of Robotics and Games, it is still challenging to implement it in\nthe optimization of industrial processes like wastewater treatment. One of the\nchallenges is the lack of a simulation environment that will represent the\nactual plant as accurately as possible to train DRL policies. Stochasticity and\nnon-linearity of wastewater treatment data lead to unstable and incorrect\npredictions of models over long time horizons. One possible reason for the\nmodels' incorrect simulation behavior can be related to the issue of\ncompounding error, which is the accumulation of errors throughout the\nsimulation. The compounding error occurs because the model utilizes its\npredictions as inputs at each time step. The error between the actual data and\nthe prediction accumulates as the simulation continues. We implemented two\nmethods to improve the trained models for wastewater treatment data, which\nresulted in more accurate simulators: 1- Using the model's prediction data as\ninput in the training step as a tool of correction, and 2- Change in the loss\nfunction to consider the long-term predicted shape (dynamics). The experimental\nresults showed that implementing these methods can improve the behavior of\nsimulators in terms of Dynamic Time Warping throughout a year up to 98%\ncompared to the base model. These improvements demonstrate significant promise\nin creating simulators for biological processes that do not need pre-existing\nknowledge of the process but instead depend exclusively on time series data\nobtained from the system.\n","authors":["Esmaeel Mohammadi","Daniel Ortiz-Arroyo","Mikkel Stokholm-Bjerregaard","Aviaja Anna Hansen","Petar Durdevic"],"pdf_url":"https://arxiv.org/pdf/2403.15091v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11879v3","updated":"2024-03-22T10:08:51Z","published":"2024-03-18T15:32:02Z","title":"Unimodal Multi-Task Fusion for Emotional Mimicry Prediction","summary":"  In this study, we propose a methodology for the Emotional Mimicry Intensity\n(EMI) Estimation task within the context of the 6th Workshop and Competition on\nAffective Behavior Analysis in-the-wild. Our approach leverages the Wav2Vec 2.0\nframework, pre-trained on a comprehensive podcast dataset, to extract a broad\nrange of audio features encompassing both linguistic and paralinguistic\nelements. We enhance feature representation through a fusion technique that\nintegrates individual features with a global mean vector, introducing global\ncontextual insights into our analysis. Additionally, we incorporate a\npre-trained valence-arousal-dominance (VAD) module from the Wav2Vec 2.0 model.\nOur fusion employs a Long Short-Term Memory (LSTM) architecture for efficient\ntemporal analysis of audio data. Utilizing only the provided audio data, our\napproach demonstrates significant improvements over the established baseline.\n","authors":["Tobias Hallmen","Fabian Deuser","Norbert Oswald","Elisabeth André"],"pdf_url":"https://arxiv.org/pdf/2403.11879v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15076v1","updated":"2024-03-22T10:00:52Z","published":"2024-03-22T10:00:52Z","title":"Comprehensive Lipidomic Automation Workflow using Large Language Models","summary":"  Lipidomics generates large data that makes manual annotation and\ninterpretation challenging. Lipid chemical and structural diversity with\nstructural isomers further complicates annotation. Although, several commercial\nand open-source software for targeted lipid identification exists, it lacks\nautomated method generation workflows and integration with statistical and\nbioinformatics tools. We have developed the Comprehensive Lipidomic Automated\nWorkflow (CLAW) platform with integrated workflow for parsing, detailed\nstatistical analysis and lipid annotations based on custom multiple reaction\nmonitoring (MRM) precursor and product ion pair transitions. CLAW contains\nseveral modules including identification of carbon-carbon double bond\nposition(s) in unsaturated lipids when combined with ozone electrospray\nionization (OzESI)-MRM methodology. To demonstrate the utility of the automated\nworkflow in CLAW, large-scale lipidomics data was collected with traditional\nand OzESI-MRM profiling on biological and non-biological samples. Specifically,\na total of 1497 transitions organized into 10 MRM-based mass spectrometry\nmethods were used to profile lipid droplets isolated from different brain\nregions of 18-24 month-old Alzheimer's disease mice and age-matched wild-type\ncontrols. Additionally, triacyclglycerols (TGs) profiles with carbon-carbon\ndouble bond specificity were generated from canola oil samples using OzESI-MRM\nprofiling. We also developed an integrated language user interface with large\nlanguage models using artificially intelligent (AI) agents that permits users\nto interact with the CLAW platform using a chatbot terminal to perform\nstatistical and bioinformatic analyses. We envision CLAW pipeline to be used in\nhigh-throughput lipid structural identification tasks aiding users to generate\nautomated lipidomics workflows ranging from data acquisition to AI agent-based\nbioinformatic analysis.\n","authors":["Connor Beveridge","Sanjay Iyer","Caitlin E. Randolph","Matthew Muhoberac","Palak Manchanda","Amy C. Clingenpeel","Shane Tichy","Gaurav Chopra"],"pdf_url":"https://arxiv.org/pdf/2403.15076v1.pdf","comment":"53 pages, 4 main figures, 23 Supporting figures, 10 Supporting Tables"},{"id":"http://arxiv.org/abs/2403.15075v1","updated":"2024-03-22T09:58:33Z","published":"2024-03-22T09:58:33Z","title":"Bilateral Unsymmetrical Graph Contrastive Learning for Recommendation","summary":"  Recent methods utilize graph contrastive Learning within graph-structured\nuser-item interaction data for collaborative filtering and have demonstrated\ntheir efficacy in recommendation tasks. However, they ignore that the\ndifference relation density of nodes between the user- and item-side causes the\nadaptability of graphs on bilateral nodes to be different after multi-hop graph\ninteraction calculation, which limits existing models to achieve ideal results.\nTo solve this issue, we propose a novel framework for recommendation tasks\ncalled Bilateral Unsymmetrical Graph Contrastive Learning (BusGCL) that\nconsider the bilateral unsymmetry on user-item node relation density for sliced\nuser and item graph reasoning better with bilateral slicing contrastive\ntraining. Especially, taking into account the aggregation ability of\nhypergraph-based graph convolutional network (GCN) in digging implicit\nsimilarities is more suitable for user nodes, embeddings generated from three\ndifferent modules: hypergraph-based GCN, GCN and perturbed GCN, are sliced into\ntwo subviews by the user- and item-side respectively, and selectively combined\ninto subview pairs bilaterally based on the characteristics of inter-node\nrelation structure. Furthermore, to align the distribution of user and item\nembeddings after aggregation, a dispersing loss is leveraged to adjust the\nmutual distance between all embeddings for maintaining learning ability.\nComprehensive experiments on two public datasets have proved the superiority of\nBusGCL in comparison to various recommendation methods. Other models can simply\nutilize our bilateral slicing contrastive learning to enhance recommending\nperformance without incurring extra expenses.\n","authors":["Jiaheng Yu","Jing Li","Yue He","Kai Zhu","Shuyi Zhang","Wen Hu"],"pdf_url":"https://arxiv.org/pdf/2403.15075v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.05222v2","updated":"2024-03-22T09:38:29Z","published":"2022-03-10T08:02:03Z","title":"Similarity-based Label Inference Attack against Training and Inference\n  of Split Learning","summary":"  Split learning is a promising paradigm for privacy-preserving distributed\nlearning. The learning model can be cut into multiple portions to be\ncollaboratively trained at the participants by exchanging only the intermediate\nresults at the cut layer. Understanding the security performance of split\nlearning is critical for many privacy-sensitive applications. This paper shows\nthat the exchanged intermediate results, including the smashed data (i.e.,\nextracted features from the raw data) and gradients during training and\ninference of split learning, can already reveal the private labels. We\nmathematically analyze the potential label leakages and propose the cosine and\nEuclidean similarity measurements for gradients and smashed data, respectively.\nThen, the two similarity measurements are shown to be unified in Euclidean\nspace. Based on the similarity metric, we design three label inference attacks\nto efficiently recover the private labels during both the training and\ninference phases. Experimental results validate that the proposed approaches\ncan achieve close to 100% accuracy of label attacks. The proposed attack can\nstill achieve accurate predictions against various state-of-the-art defense\nmechanisms, including DP-SGD, label differential privacy, gradient compression,\nand Marvell.\n","authors":["Junlin Liu","Xinchen Lyu","Qimei Cui","Xiaofeng Tao"],"pdf_url":"https://arxiv.org/pdf/2203.05222v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.05614v3","updated":"2024-03-22T09:34:11Z","published":"2023-02-11T06:32:28Z","title":"Cross-domain Random Pre-training with Prototypes for Reinforcement\n  Learning","summary":"  This work has been submitted to the IEEE for possible publication. Copyright\nmay be transferred without notice, after which this version may no longer be\naccessible. Unsupervised cross-domain Reinforcement Learning (RL) pre-training\nshows great potential for challenging continuous visual control but poses a big\nchallenge. In this paper, we propose \\textbf{C}ross-domain \\textbf{R}andom\n\\textbf{P}re-\\textbf{T}raining with \\textbf{pro}totypes (CRPTpro), a novel,\nefficient, and effective self-supervised cross-domain RL pre-training\nframework. CRPTpro decouples data sampling from encoder pre-training, proposing\ndecoupled random collection to easily and quickly generate a qualified\ncross-domain pre-training dataset. Moreover, a novel prototypical\nself-supervised algorithm is proposed to pre-train an effective visual encoder\nthat is generic across different domains. Without finetuning, the cross-domain\nencoder can be implemented for challenging downstream tasks defined in\ndifferent domains, either seen or unseen. Compared with recent advanced\nmethods, CRPTpro achieves better performance on downstream policy learning\nwithout extra training on exploration agents for data collection, greatly\nreducing the burden of pre-training. We conduct extensive experiments across\neight challenging continuous visual-control domains, including balance control,\nrobot locomotion, and manipulation. CRPTpro significantly outperforms the next\nbest Proto-RL(C) on 11/12 cross-domain downstream tasks with only 54\\%\nwall-clock pre-training time, exhibiting state-of-the-art pre-training\nperformance with greatly improved pre-training efficiency. The complete code is\navailable at https://github.com/liuxin0824/CRPTpro.\n","authors":["Xin Liu","Yaran Chen","Haoran Li","Boyu Li","Dongbin Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.05614v3.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2403.15059v1","updated":"2024-03-22T09:32:31Z","published":"2024-03-22T09:32:31Z","title":"MM-Diff: High-Fidelity Image Personalization via Multi-Modal Condition\n  Integration","summary":"  Recent advances in tuning-free personalized image generation based on\ndiffusion models are impressive. However, to improve subject fidelity, existing\nmethods either retrain the diffusion model or infuse it with dense visual\nembeddings, both of which suffer from poor generalization and efficiency. Also,\nthese methods falter in multi-subject image generation due to the unconstrained\ncross-attention mechanism. In this paper, we propose MM-Diff, a unified and\ntuning-free image personalization framework capable of generating high-fidelity\nimages of both single and multiple subjects in seconds. Specifically, to\nsimultaneously enhance text consistency and subject fidelity, MM-Diff employs a\nvision encoder to transform the input image into CLS and patch embeddings. CLS\nembeddings are used on the one hand to augment the text embeddings, and on the\nother hand together with patch embeddings to derive a small number of\ndetail-rich subject embeddings, both of which are efficiently integrated into\nthe diffusion model through the well-designed multimodal cross-attention\nmechanism. Additionally, MM-Diff introduces cross-attention map constraints\nduring the training phase, ensuring flexible multi-subject image sampling\nduring inference without any predefined inputs (e.g., layout). Extensive\nexperiments demonstrate the superior performance of MM-Diff over other leading\nmethods.\n","authors":["Zhichao Wei","Qingkun Su","Long Qin","Weizhi Wang"],"pdf_url":"https://arxiv.org/pdf/2403.15059v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.15929v2","updated":"2024-03-22T09:18:24Z","published":"2023-10-24T15:27:15Z","title":"E-Sparse: Boosting the Large Language Model Inference through\n  Entropy-based N:M Sparsity","summary":"  Traditional pruning methods are known to be challenging to work in Large\nLanguage Models (LLMs) for Generative AI because of their unaffordable training\nprocess and large computational demands. For the first time, we introduce the\ninformation entropy of hidden state features into a pruning metric design,\nnamely E-Sparse, to improve the accuracy of N:M sparsity on LLM. E-Sparse\nemploys the information richness to leverage the channel importance, and\nfurther incorporates several novel techniques to put it into effect: (1) it\nintroduces information entropy to enhance the significance of parameter weights\nand input feature norms as a novel pruning metric, and performs N:M sparsity\nwithout modifying the remaining weights. (2) it designs global naive shuffle\nand local block shuffle to quickly optimize the information distribution and\nadequately cope with the impact of N:M sparsity on LLMs' accuracy. E-Sparse is\nimplemented as a Sparse-GEMM on FasterTransformer and runs on NVIDIA Ampere\nGPUs. Extensive experiments on the LLaMA family and OPT models show that\nE-Sparse can significantly speed up the model inference over the dense model\n(up to 1.53X) and obtain significant memory saving (up to 43.52%), with\nacceptable accuracy loss.\n","authors":["Yun Li","Lin Niu","Xipeng Zhang","Kai Liu","Jianchen Zhu","Zhanhui Kang"],"pdf_url":"https://arxiv.org/pdf/2310.15929v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.02733v3","updated":"2024-03-22T09:17:24Z","published":"2024-02-05T05:25:33Z","title":"ToonAging: Face Re-Aging upon Artistic Portrait Style Transfer","summary":"  Face re-aging is a prominent field in computer vision and graphics, with\nsignificant applications in photorealistic domains such as movies, advertising,\nand live streaming. Recently, the need to apply face re-aging to\nnon-photorealistic images, like comics, illustrations, and animations, has\nemerged as an extension in various entertainment sectors. However, the lack of\na network that can seamlessly edit the apparent age in NPR images has limited\nthese tasks to a naive, sequential approach. This often results in unpleasant\nartifacts and a loss of facial attributes due to domain discrepancies. In this\npaper, we introduce a novel one-stage method for face re-aging combined with\nportrait style transfer, executed in a single generative step. We leverage\nexisting face re-aging and style transfer networks, both trained within the\nsame PR domain. Our method uniquely fuses distinct latent vectors, each\nresponsible for managing aging-related attributes and NPR appearance. By\nadopting an exemplar-based approach, our method offers greater flexibility\ncompared to domain-level fine-tuning approaches, which typically require\nseparate training or fine-tuning for each domain. This effectively addresses\nthe limitation of requiring paired datasets for re-aging and domain-level,\ndata-driven approaches for stylization. Our experiments show that our model can\neffortlessly generate re-aged images while simultaneously transferring the\nstyle of examples, maintaining both natural appearance and controllability.\n","authors":["Bumsoo Kim","Abdul Muqeet","Kyuchul Lee","Sanghyun Seo"],"pdf_url":"https://arxiv.org/pdf/2402.02733v3.pdf","comment":"14 pages, 15 figures, 1 table"},{"id":"http://arxiv.org/abs/2403.15049v1","updated":"2024-03-22T09:15:36Z","published":"2024-03-22T09:15:36Z","title":"Continual Vision-and-Language Navigation","summary":"  Vision-and-Language Navigation (VLN) agents navigate to a destination using\nnatural language instructions and the visual information they observe. Existing\nmethods for training VLN agents presuppose fixed datasets, leading to a\nsignificant limitation: the introduction of new environments necessitates\nretraining with previously encountered environments to preserve their\nknowledge. This makes it difficult to train VLN agents that operate in the\never-changing real world. To address this limitation, we present the Continual\nVision-and-Language Navigation (CVLN) paradigm, designed to evaluate agents\ntrained through a continual learning process. For the training and evaluation\nof CVLN agents, we re-arrange existing VLN datasets to propose two datasets:\nCVLN-I, focused on navigation via initial-instruction interpretation, and\nCVLN-D, aimed at navigation through dialogue with other agents. Furthermore, we\npropose two novel rehearsal-based methods for CVLN, Perplexity Replay (PerpR)\nand Episodic Self-Replay (ESR). PerpR prioritizes replaying challenging\nepisodes based on action perplexity, while ESR replays previously predicted\naction logits to preserve learned behaviors. We demonstrate the effectiveness\nof the proposed methods on CVLN through extensive experiments.\n","authors":["Seongjun Jeong","Gi-Cheon Kang","Seongho Choi","Joochan Kim","Byoung-Tak Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.15049v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.01479v2","updated":"2024-03-22T09:14:48Z","published":"2024-03-03T11:13:44Z","title":"Align-to-Distill: Trainable Attention Alignment for Knowledge\n  Distillation in Neural Machine Translation","summary":"  The advent of scalable deep models and large datasets has improved the\nperformance of Neural Machine Translation. Knowledge Distillation (KD) enhances\nefficiency by transferring knowledge from a teacher model to a more compact\nstudent model. However, KD approaches to Transformer architecture often rely on\nheuristics, particularly when deciding which teacher layers to distill from. In\nthis paper, we introduce the 'Align-to-Distill' (A2D) strategy, designed to\naddress the feature mapping problem by adaptively aligning student attention\nheads with their teacher counterparts during training. The Attention Alignment\nModule in A2D performs a dense head-by-head comparison between student and\nteacher attention heads across layers, turning the combinatorial mapping\nheuristics into a learning problem. Our experiments show the efficacy of A2D,\ndemonstrating gains of up to +3.61 and +0.63 BLEU points for WMT-2022 De->Dsb\nand WMT-2014 En->De, respectively, compared to Transformer baselines.\n","authors":["Heegon Jin","Seonil Son","Jemin Park","Youngseok Kim","Hyungjong Noh","Yeonsoo Lee"],"pdf_url":"https://arxiv.org/pdf/2403.01479v2.pdf","comment":"Accepted to LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2403.15048v1","updated":"2024-03-22T09:13:09Z","published":"2024-03-22T09:13:09Z","title":"Cartoon Hallucinations Detection: Pose-aware In Context Visual Learning","summary":"  Large-scale Text-to-Image (TTI) models have become a common approach for\ngenerating training data in various generative fields. However, visual\nhallucinations, which contain perceptually critical defects, remain a concern,\nespecially in non-photorealistic styles like cartoon characters. We propose a\nnovel visual hallucination detection system for cartoon character images\ngenerated by TTI models. Our approach leverages pose-aware in-context visual\nlearning (PA-ICVL) with Vision-Language Models (VLMs), utilizing both RGB\nimages and pose information. By incorporating pose guidance from a fine-tuned\npose estimator, we enable VLMs to make more accurate decisions. Experimental\nresults demonstrate significant improvements in identifying visual\nhallucinations compared to baseline methods relying solely on RGB images. This\nresearch advances TTI models by mitigating visual hallucinations, expanding\ntheir potential in non-photorealistic domains.\n","authors":["Bumsoo Kim","Wonseop Shin","Kyuchul Lee","Sanghyun Seo"],"pdf_url":"https://arxiv.org/pdf/2403.15048v1.pdf","comment":"11 pages, 12 figures, 1 table, Project page:\n  https://gh-bumsookim.github.io/Cartoon-Hallucinations-Detection/"},{"id":"http://arxiv.org/abs/2403.15044v1","updated":"2024-03-22T09:00:24Z","published":"2024-03-22T09:00:24Z","title":"Multimodal Fusion with Pre-Trained Model Features in Affective Behaviour\n  Analysis In-the-wild","summary":"  Multimodal fusion is a significant method for most multimodal tasks. With the\nrecent surge in the number of large pre-trained models, combining both\nmultimodal fusion methods and pre-trained model features can achieve\noutstanding performance in many multimodal tasks. In this paper, we present our\napproach, which leverages both advantages for addressing the task of Expression\n(Expr) Recognition and Valence-Arousal (VA) Estimation. We evaluate the\nAff-Wild2 database using pre-trained models, then extract the final hidden\nlayers of the models as features. Following preprocessing and interpolation or\nconvolution to align the extracted features, different models are employed for\nmodal fusion. Our code is available at GitHub - FulgenceWen/ABAW6th.\n","authors":["Zhuofan Wen","Fengyu Zhang","Siyuan Zhang","Haiyang Sun","Mingyu Xu","Licai Sun","Zheng Lian","Bin Liu","Jianhua Tao"],"pdf_url":"https://arxiv.org/pdf/2403.15044v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.11838v6","updated":"2024-03-22T08:42:14Z","published":"2023-08-23T00:10:29Z","title":"A Benchmark Study on Calibration","summary":"  Deep neural networks are increasingly utilized in various machine learning\ntasks. However, as these models grow in complexity, they often face calibration\nissues, despite enhanced prediction accuracy. Many studies have endeavored to\nimprove calibration performance through the use of specific loss functions,\ndata preprocessing and training frameworks. Yet, investigations into\ncalibration properties have been somewhat overlooked. Our study leverages the\nNeural Architecture Search (NAS) search space, offering an exhaustive model\narchitecture space for thorough calibration properties exploration. We\nspecifically create a model calibration dataset. This dataset evaluates 90\nbin-based and 12 additional calibration measurements across 117,702 unique\nneural networks within the widely employed NATS-Bench search space. Our\nanalysis aims to answer several longstanding questions in the field, using our\nproposed dataset: (i) Can model calibration be generalized across different\ndatasets? (ii) Can robustness be used as a calibration measurement? (iii) How\nreliable are calibration metrics? (iv) Does a post-hoc calibration method\naffect all models uniformly? (v) How does calibration interact with accuracy?\n(vi) What is the impact of bin size on calibration measurement? (vii) Which\narchitectural designs are beneficial for calibration? Additionally, our study\nbridges an existing gap by exploring calibration within NAS. By providing this\ndataset, we enable further research into NAS calibration. As far as we are\naware, our research represents the first large-scale investigation into\ncalibration properties and the premier study of calibration issues within NAS.\nThe project page can be found at https://www.taolinwei.com/calibration-study\n","authors":["Linwei Tao","Younan Zhu","Haolan Guo","Minjing Dong","Chang Xu"],"pdf_url":"https://arxiv.org/pdf/2308.11838v6.pdf","comment":"ICLR 2024 poster"},{"id":"http://arxiv.org/abs/2311.18598v2","updated":"2024-03-22T08:26:20Z","published":"2023-11-30T14:45:51Z","title":"Generalisable Agents for Neural Network Optimisation","summary":"  Optimising deep neural networks is a challenging task due to complex training\ndynamics, high computational requirements, and long training times. To address\nthis difficulty, we propose the framework of Generalisable Agents for Neural\nNetwork Optimisation (GANNO) -- a multi-agent reinforcement learning (MARL)\napproach that learns to improve neural network optimisation by dynamically and\nresponsively scheduling hyperparameters during training. GANNO utilises an\nagent per layer that observes localised network dynamics and accordingly takes\nactions to adjust these dynamics at a layerwise level to collectively improve\nglobal performance. In this paper, we use GANNO to control the layerwise\nlearning rate and show that the framework can yield useful and responsive\nschedules that are competitive with handcrafted heuristics. Furthermore, GANNO\nis shown to perform robustly across a wide variety of unseen initial\nconditions, and can successfully generalise to harder problems than it was\ntrained on. Our work presents an overview of the opportunities that this\nparadigm offers for training neural networks, along with key challenges that\nremain to be overcome.\n","authors":["Kale-ab Tessera","Callum Rhys Tilbury","Sasha Abramowitz","Ruan de Kock","Omayma Mahjoub","Benjamin Rosman","Sara Hooker","Arnu Pretorius"],"pdf_url":"https://arxiv.org/pdf/2311.18598v2.pdf","comment":"Accepted at the Workshop on Advanced Neural Network Training (WANT)\n  and Optimization for Machine Learning (OPT) at NeurIPS 2023"},{"id":"http://arxiv.org/abs/2403.15027v1","updated":"2024-03-22T08:17:00Z","published":"2024-03-22T08:17:00Z","title":"Grey-informed neural network for time-series forecasting","summary":"  Neural network models have shown outstanding performance and successful\nresolutions to complex problems in various fields. However, the majority of\nthese models are viewed as black-box, requiring a significant amount of data\nfor development. Consequently, in situations with limited data, constructing\nappropriate models becomes challenging due to the lack of transparency and\nscarcity of data. To tackle these challenges, this study suggests the\nimplementation of a grey-informed neural network (GINN). The GINN ensures that\nthe output of the neural network follows the differential equation model of the\ngrey system, improving interpretability. Moreover, incorporating prior\nknowledge from grey system theory enables traditional neural networks to\neffectively handle small data samples. Our proposed model has been observed to\nuncover underlying patterns in the real world and produce reliable forecasts\nbased on empirical data.\n","authors":["Wanli Xie","Ruibin Zhao","Zhenguo Xu","Tingting Liang"],"pdf_url":"https://arxiv.org/pdf/2403.15027v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.02893v2","updated":"2024-03-22T07:44:32Z","published":"2024-03-05T11:57:21Z","title":"Zero-Shot Cross-Lingual Document-Level Event Causality Identification\n  with Heterogeneous Graph Contrastive Transfer Learning","summary":"  Event Causality Identification (ECI) refers to the detection of causal\nrelations between events in texts. However, most existing studies focus on\nsentence-level ECI with high-resource languages, leaving more challenging\ndocument-level ECI (DECI) with low-resource languages under-explored. In this\npaper, we propose a Heterogeneous Graph Interaction Model with\nMulti-granularity Contrastive Transfer Learning (GIMC) for zero-shot\ncross-lingual document-level ECI. Specifically, we introduce a heterogeneous\ngraph interaction network to model the long-distance dependencies between\nevents that are scattered over a document. Then, to improve cross-lingual\ntransferability of causal knowledge learned from the source language, we\npropose a multi-granularity contrastive transfer learning module to align the\ncausal representations across languages. Extensive experiments show our\nframework outperforms the previous state-of-the-art model by 9.4% and 8.2% of\naverage F1 score on monolingual and multilingual scenarios respectively.\nNotably, in the multilingual scenario, our zero-shot framework even exceeds\nGPT-3.5 with few-shot learning by 24.3% in overall performance.\n","authors":["Zhitao He","Pengfei Cao","Zhuoran Jin","Yubo Chen","Kang Liu","Zhiqiang Zhang","Mengshu Sun","Jun Zhao"],"pdf_url":"https://arxiv.org/pdf/2403.02893v2.pdf","comment":"Accepted at LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2403.05574v2","updated":"2024-03-22T07:34:38Z","published":"2024-02-26T09:10:34Z","title":"HealMe: Harnessing Cognitive Reframing in Large Language Models for\n  Psychotherapy","summary":"  Large Language Models (LLMs) can play a vital role in psychotherapy by\nadeptly handling the crucial task of cognitive reframing and overcoming\nchallenges such as shame, distrust, therapist skill variability, and resource\nscarcity. Previous LLMs in cognitive reframing mainly converted negative\nemotions to positive ones, but these approaches have limited efficacy, often\nnot promoting clients' self-discovery of alternative perspectives. In this\npaper, we unveil the Helping and Empowering through Adaptive Language in Mental\nEnhancement (HealMe) model. This novel cognitive reframing therapy method\neffectively addresses deep-rooted negative thoughts and fosters rational,\nbalanced perspectives. Diverging from traditional LLM methods, HealMe employs\nempathetic dialogue based on psychotherapeutic frameworks. It systematically\nguides clients through distinguishing circumstances from feelings,\nbrainstorming alternative viewpoints, and developing empathetic, actionable\nsuggestions. Moreover, we adopt the first comprehensive and expertly crafted\npsychological evaluation metrics, specifically designed to rigorously assess\nthe performance of cognitive reframing, in both AI-simulated dialogues and\nreal-world therapeutic conversations. Experimental results show that our model\noutperforms others in terms of empathy, guidance, and logical coherence,\ndemonstrating its effectiveness and potential positive impact on psychotherapy.\n","authors":["Mengxi Xiao","Qianqian Xie","Ziyan Kuang","Zhicheng Liu","Kailai Yang","Min Peng","Weiguang Han","Jimin Huang"],"pdf_url":"https://arxiv.org/pdf/2403.05574v2.pdf","comment":"17 pages, 4 figures"},{"id":"http://arxiv.org/abs/2401.00248v2","updated":"2024-03-22T07:25:03Z","published":"2023-12-30T14:24:33Z","title":"Promoting Segment Anything Model towards Highly Accurate Dichotomous\n  Image Segmentation","summary":"  The Segment Anything Model (SAM) represents a significant breakthrough into\nfoundation models for computer vision, providing a large-scale image\nsegmentation model. However, despite SAM's zero-shot performance, its\nsegmentation masks lack fine-grained details, particularly in accurately\ndelineating object boundaries. We have high expectations regarding whether SAM,\nas a foundation model, can be improved towards highly accurate object\nsegmentation, which is known as dichotomous image segmentation (DIS). To\naddress this issue, we propose DIS-SAM, which advances SAM towards DIS with\nextremely accurate details. DIS-SAM is a framework specifically tailored for\nhighly accurate segmentation, maintaining SAM's promptable design. DIS-SAM\nemploys a two-stage approach, integrating SAM with a modified IS-Net dedicated\nto DIS. Despite its simplicity, DIS-SAM demonstrates significantly enhanced\nsegmentation accuracy compared to SAM and HQ-SAM.\n","authors":["Xianjie Liu","Keren Fu","Qijun Zhao"],"pdf_url":"https://arxiv.org/pdf/2401.00248v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14999v1","updated":"2024-03-22T07:21:09Z","published":"2024-03-22T07:21:09Z","title":"Magic for the Age of Quantized DNNs","summary":"  Recently, the number of parameters in DNNs has explosively increased, as\nexemplified by LLMs (Large Language Models), making inference on small-scale\ncomputers more difficult. Model compression technology is, therefore, essential\nfor integration into products. In this paper, we propose a method of\nquantization-aware training. We introduce a novel normalization (Layer-Batch\nNormalization) that is independent of the mini-batch size and does not require\nany additional computation cost during inference. Then, we quantize the weights\nby the scaled round-clip function with the weight standardization. We also\nquantize activation functions using the same function and apply surrogate\ngradients to train the model with both quantized weights and the quantized\nactivation functions. We call this method Magic for the age of Quantised DNNs\n(MaQD). Experimental results show that our quantization method can be achieved\nwith minimal accuracy degradation.\n","authors":["Yoshihide Sawada","Ryuji Saiin","Kazuma Suetake"],"pdf_url":"https://arxiv.org/pdf/2403.14999v1.pdf","comment":"14 pages, 5 figures, 4 tables"},{"id":"http://arxiv.org/abs/2311.15243v3","updated":"2024-03-22T07:05:58Z","published":"2023-11-26T09:06:40Z","title":"ID-like Prompt Learning for Few-Shot Out-of-Distribution Detection","summary":"  Out-of-distribution (OOD) detection methods often exploit auxiliary outliers\nto train model identifying OOD samples, especially discovering challenging\noutliers from auxiliary outliers dataset to improve OOD detection. However,\nthey may still face limitations in effectively distinguishing between the most\nchallenging OOD samples that are much like in-distribution (ID) data, i.e.,\n\\idlike samples. To this end, we propose a novel OOD detection framework that\ndiscovers \\idlike outliers using CLIP \\cite{DBLP:conf/icml/RadfordKHRGASAM21}\nfrom the vicinity space of the ID samples, thus helping to identify these most\nchallenging OOD samples. Then a prompt learning framework is proposed that\nutilizes the identified \\idlike outliers to further leverage the capabilities\nof CLIP for OOD detection. Benefiting from the powerful CLIP, we only need a\nsmall number of ID samples to learn the prompts of the model without exposing\nother auxiliary outlier datasets. By focusing on the most challenging \\idlike\nOOD samples and elegantly exploiting the capabilities of CLIP, our method\nachieves superior few-shot learning performance on various real-world image\ndatasets (e.g., in 4-shot OOD detection on the ImageNet-1k dataset, our method\nreduces the average FPR95 by 12.16\\% and improves the average AUROC by 2.76\\%,\ncompared to state-of-the-art methods). Code is available at\nhttps://github.com/ycfate/ID-like.\n","authors":["Yichen Bai","Zongbo Han","Changqing Zhang","Bing Cao","Xiaoheng Jiang","Qinghua Hu"],"pdf_url":"https://arxiv.org/pdf/2311.15243v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.14428v2","updated":"2024-03-22T06:29:26Z","published":"2024-02-22T10:17:57Z","title":"KoCoSa: Korean Context-aware Sarcasm Detection Dataset","summary":"  Sarcasm is a way of verbal irony where someone says the opposite of what they\nmean, often to ridicule a person, situation, or idea. It is often difficult to\ndetect sarcasm in the dialogue since detecting sarcasm should reflect the\ncontext (i.e., dialogue history). In this paper, we introduce a new dataset for\nthe Korean dialogue sarcasm detection task, KoCoSa (Korean Context-aware\nSarcasm Detection Dataset), which consists of 12.8K daily Korean dialogues and\nthe labels for this task on the last response. To build the dataset, we propose\nan efficient sarcasm detection dataset generation pipeline: 1) generating new\nsarcastic dialogues from source dialogues with large language models, 2)\nautomatic and manual filtering of abnormal and toxic dialogues, and 3) human\nannotation for the sarcasm detection task. We also provide a simple but\neffective baseline for the Korean sarcasm detection task trained on our\ndataset. Experimental results on the dataset show that our baseline system\noutperforms strong baselines like large language models, such as GPT-3.5, in\nthe Korean sarcasm detection task. We show that the sarcasm detection task\nrelies deeply on the existence of sufficient context. We will release the\ndataset at https://github.com/Yu-billie/KoCoSa_sarcasm_detection.\n","authors":["Yumin Kim","Heejae Suh","Mingi Kim","Dongyeon Won","Hwanhee Lee"],"pdf_url":"https://arxiv.org/pdf/2402.14428v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14977v1","updated":"2024-03-22T06:22:20Z","published":"2024-03-22T06:22:20Z","title":"Piecewise-Linear Manifolds for Deep Metric Learning","summary":"  Unsupervised deep metric learning (UDML) focuses on learning a semantic\nrepresentation space using only unlabeled data. This challenging problem\nrequires accurately estimating the similarity between data points, which is\nused to supervise a deep network. For this purpose, we propose to model the\nhigh-dimensional data manifold using a piecewise-linear approximation, with\neach low-dimensional linear piece approximating the data manifold in a small\nneighborhood of a point. These neighborhoods are used to estimate similarity\nbetween data points. We empirically show that this similarity estimate\ncorrelates better with the ground truth than the similarity estimates of\ncurrent state-of-the-art techniques. We also show that proxies, commonly used\nin supervised metric learning, can be used to model the piecewise-linear\nmanifold in an unsupervised setting, helping improve performance. Our method\noutperforms existing unsupervised metric learning approaches on standard\nzero-shot image retrieval benchmarks.\n","authors":["Shubhang Bhatnagar","Narendra Ahuja"],"pdf_url":"https://arxiv.org/pdf/2403.14977v1.pdf","comment":"Accepted at CPAL 2024 (Oral)"},{"id":"http://arxiv.org/abs/2403.14972v1","updated":"2024-03-22T06:03:07Z","published":"2024-03-22T06:03:07Z","title":"A Picture Is Worth a Graph: Blueprint Debate on Graph for Multimodal\n  Reasoning","summary":"  This paper presents a pilot study aimed at introducing multi-agent debate\ninto multimodal reasoning. The study addresses two key challenges: the\ntrivialization of opinions resulting from excessive summarization and the\ndiversion of focus caused by distractor concepts introduced from images. These\nchallenges stem from the inductive (bottom-up) nature of existing debating\nschemes. To address the issue, we propose a deductive (top-down) debating\napproach called Blueprint Debate on Graphs (BDoG). In BDoG, debates are\nconfined to a blueprint graph to prevent opinion trivialization through\nworld-level summarization. Moreover, by storing evidence in branches within the\ngraph, BDoG mitigates distractions caused by frequent but irrelevant concepts.\nExtensive experiments validate BDoG, achieving state-of-the-art results in\nScience QA and MMBench with significant improvements over previous methods.\n","authors":["Changmeng Zheng","Dayong Liang","Wengyu Zhang","Xiao-Yong Wei","Tat-Seng Chua","Qing Li"],"pdf_url":"https://arxiv.org/pdf/2403.14972v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2403.14965v1","updated":"2024-03-22T05:37:52Z","published":"2024-03-22T05:37:52Z","title":"Comprehensive Evaluation and Insights into the Use of Large Language\n  Models in the Automation of Behavior-Driven Development Acceptance Test\n  Formulation","summary":"  Behavior-driven development (BDD) is an Agile testing methodology fostering\ncollaboration among developers, QA analysts, and stakeholders. In this\nmanuscript, we propose a novel approach to enhance BDD practices using large\nlanguage models (LLMs) to automate acceptance test generation. Our study uses\nzero and few-shot prompts to evaluate LLMs such as GPT-3.5, GPT-4, Llama-2-13B,\nand PaLM-2. The paper presents a detailed methodology that includes the\ndataset, prompt techniques, LLMs, and the evaluation process. The results\ndemonstrate that GPT-3.5 and GPT-4 generate error-free BDD acceptance tests\nwith better performance. The few-shot prompt technique highlights its ability\nto provide higher accuracy by incorporating examples for in-context learning.\nFurthermore, the study examines syntax errors, validation accuracy, and\ncomparative analysis of LLMs, revealing their effectiveness in enhancing BDD\npractices. However, our study acknowledges that there are limitations to the\nproposed approach. We emphasize that this approach can support collaborative\nBDD processes and create opportunities for future research into automated BDD\nacceptance test generation using LLMs.\n","authors":["Shanthi Karpurapu","Sravanthy Myneni","Unnati Nettur","Likhit Sagar Gajja","Dave Burke","Tom Stiehm","Jeffery Payne"],"pdf_url":"https://arxiv.org/pdf/2403.14965v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14952v1","updated":"2024-03-22T05:05:45Z","published":"2024-03-22T05:05:45Z","title":"Evidence-Driven Retrieval Augmented Response Generation for Online\n  Misinformation","summary":"  The proliferation of online misinformation has posed significant threats to\npublic interest. While numerous online users actively participate in the combat\nagainst misinformation, many of such responses can be characterized by the lack\nof politeness and supporting facts. As a solution, text generation approaches\nare proposed to automatically produce counter-misinformation responses.\nNevertheless, existing methods are often trained end-to-end without leveraging\nexternal knowledge, resulting in subpar text quality and excessively repetitive\nresponses. In this paper, we propose retrieval augmented response generation\nfor online misinformation (RARG), which collects supporting evidence from\nscientific sources and generates counter-misinformation responses based on the\nevidences. In particular, our RARG consists of two stages: (1) evidence\ncollection, where we design a retrieval pipeline to retrieve and rerank\nevidence documents using a database comprising over 1M academic articles; (2)\nresponse generation, in which we align large language models (LLMs) to generate\nevidence-based responses via reinforcement learning from human feedback (RLHF).\nWe propose a reward function to maximize the utilization of the retrieved\nevidence while maintaining the quality of the generated text, which yields\npolite and factual responses that clearly refutes misinformation. To\ndemonstrate the effectiveness of our method, we study the case of COVID-19 and\nperform extensive experiments with both in- and cross-domain datasets, where\nRARG consistently outperforms baselines by generating high-quality\ncounter-misinformation responses.\n","authors":["Zhenrui Yue","Huimin Zeng","Yimeng Lu","Lanyu Shang","Yang Zhang","Dong Wang"],"pdf_url":"https://arxiv.org/pdf/2403.14952v1.pdf","comment":"Accepted to NAACL 2024"},{"id":"http://arxiv.org/abs/2403.14951v1","updated":"2024-03-22T05:04:48Z","published":"2024-03-22T05:04:48Z","title":"Simple Graph Condensation","summary":"  The burdensome training costs on large-scale graphs have aroused significant\ninterest in graph condensation, which involves tuning Graph Neural Networks\n(GNNs) on a small condensed graph for use on the large-scale original graph.\nExisting methods primarily focus on aligning key metrics between the condensed\nand original graphs, such as gradients, distribution and trajectory of GNNs,\nyielding satisfactory performance on downstream tasks. However, these complex\nmetrics necessitate intricate computations and can potentially disrupt the\noptimization process of the condensation graph, making the condensation process\nhighly demanding and unstable. Motivated by the recent success of simplified\nmodels in various fields, we propose a simplified approach to metric alignment\nin graph condensation, aiming to reduce unnecessary complexity inherited from\nGNNs. In our approach, we eliminate external parameters and exclusively retain\nthe target condensed graph during the condensation process. Following the\nhierarchical aggregation principles of GNNs, we introduce the Simple Graph\nCondensation (SimGC) framework, which aligns the condensed graph with the\noriginal graph from the input layer to the prediction layer, guided by a\npre-trained Simple Graph Convolution (SGC) model on the original graph. As a\nresult, both graphs possess the similar capability to train GNNs. This\nstraightforward yet effective strategy achieves a significant speedup of up to\n10 times compared to existing graph condensation methods while performing on\npar with state-of-the-art baselines. Comprehensive experiments conducted on\nseven benchmark datasets demonstrate the effectiveness of SimGC in prediction\naccuracy, condensation time, and generalization capability. Our code will be\nmade publicly available.\n","authors":["Zhenbang Xiao","Yu Wang","Shunyu Liu","Huiqiong Wang","Mingli Song","Tongya Zheng"],"pdf_url":"https://arxiv.org/pdf/2403.14951v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2403.09920v3","updated":"2024-03-22T04:53:29Z","published":"2024-03-14T23:41:00Z","title":"Predicting Generalization of AI Colonoscopy Models to Unseen Data","summary":"  $\\textbf{Background}$: Generalizability of AI colonoscopy algorithms is\nimportant for wider adoption in clinical practice. However, current techniques\nfor evaluating performance on unseen data require expensive and time-intensive\nlabels.\n  $\\textbf{Methods}$: We use a \"Masked Siamese Network\" (MSN) to identify novel\nphenomena in unseen data and predict polyp detector performance. MSN is trained\nto predict masked out regions of polyp images, without any labels. We test\nMSN's ability to be trained on data only from Israel and detect unseen\ntechniques, narrow-band imaging (NBI) and chromendoscoy (CE), on colonoscopes\nfrom Japan (354 videos, 128 hours). We also test MSN's ability to predict\nperformance of Computer Aided Detection (CADe) of polyps on colonoscopies from\nboth countries, even though MSN is not trained on data from Japan.\n  $\\textbf{Results}$: MSN correctly identifies NBI and CE as less similar to\nIsrael whitelight than Japan whitelight (bootstrapped z-test, |z| > 496, p <\n10^-8 for both) using the label-free Frechet distance. MSN detects NBI with 99%\naccuracy, predicts CE better than our heuristic (90% vs 79% accuracy) despite\nbeing trained only on whitelight, and is the only method that is robust to\nnoisy labels. MSN predicts CADe polyp detector performance on in-domain Israel\nand out-of-domain Japan colonoscopies (r=0.79, 0.37 respectively). With few\nexamples of Japan detector performance to train on, MSN prediction of Japan\nperformance improves (r=0.56).\n  $\\textbf{Conclusion}$: Our technique can identify distribution shifts in\nclinical data and can predict CADe detector performance on unseen data, without\nlabels. Our self-supervised approach can aid in detecting when data in practice\nis different from training, such as between hospitals or data has meaningfully\nshifted from training. MSN has potential for application to medical image\ndomains beyond colonoscopy.\n","authors":["Joel Shor","Carson McNeil","Yotam Intrator","Joseph R Ledsam","Hiro-o Yamano","Daisuke Tsurumaru","Hiroki Kayama","Atsushi Hamabe","Koji Ando","Mitsuhiko Ota","Haruei Ogino","Hiroshi Nakase","Kaho Kobayashi","Masaaki Miyo","Eiji Oki","Ichiro Takemasa","Ehud Rivlin","Roman Goldenberg"],"pdf_url":"https://arxiv.org/pdf/2403.09920v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.11940v3","updated":"2024-03-22T04:40:11Z","published":"2022-11-22T01:29:47Z","title":"Decision-making with Speculative Opponent Models","summary":"  Opponent modelling has proven effective in enhancing the decision-making of\nthe controlled agent by constructing models of opponent agents. However,\nexisting methods often rely on access to the observations and actions of\nopponents, a requirement that is infeasible when such information is either\nunobservable or challenging to obtain. To address this issue, we introduce\nDistributional Opponent-aided Multi-agent Actor-Critic (DOMAC), the first\nspeculative opponent modelling algorithm that relies solely on local\ninformation (i.e., the controlled agent's observations, actions, and rewards).\nSpecifically, the actor maintains a speculated belief about the opponents using\nthe tailored speculative opponent models that predict the opponents' actions\nusing only local information. Moreover, DOMAC features distributional critic\nmodels that estimate the return distribution of the actor's policy, yielding a\nmore fine-grained assessment of the actor's quality. This thus more effectively\nguides the training of the speculative opponent models that the actor depends\nupon. Furthermore, we formally derive a policy gradient theorem with the\nproposed opponent models. Extensive experiments under eight different\nchallenging multi-agent benchmark tasks within the MPE, Pommerman and StarCraft\nMultiagent Challenge (SMAC) demonstrate that our DOMAC successfully models\nopponents' behaviours and delivers superior performance against\nstate-of-the-art methods with a faster convergence speed.\n","authors":["Jing Sun","Shuo Chen","Cong Zhang","Yining Ma","Jie Zhang"],"pdf_url":"https://arxiv.org/pdf/2211.11940v3.pdf","comment":"13 pages, 27 figures"},{"id":"http://arxiv.org/abs/2403.14946v1","updated":"2024-03-22T04:38:42Z","published":"2024-03-22T04:38:42Z","title":"A Single Linear Layer Yields Task-Adapted Low-Rank Matrices","summary":"  Low-Rank Adaptation (LoRA) is a widely used Parameter-Efficient Fine-Tuning\n(PEFT) method that updates an initial weight matrix $W_0$ with a delta matrix\n$\\Delta W$ consisted by two low-rank matrices $A$ and $B$. A previous study\nsuggested that there is correlation between $W_0$ and $\\Delta W$. In this\nstudy, we aim to delve deeper into relationships between $W_0$ and low-rank\nmatrices $A$ and $B$ to further comprehend the behavior of LoRA. In particular,\nwe analyze a conversion matrix that transform $W_0$ into low-rank matrices,\nwhich encapsulates information about the relationships. Our analysis reveals\nthat the conversion matrices are similar across each layer. Inspired by these\nfindings, we hypothesize that a single linear layer, which takes each layer's\n$W_0$ as input, can yield task-adapted low-rank matrices. To confirm this\nhypothesis, we devise a method named Conditionally Parameterized LoRA\n(CondLoRA) that updates initial weight matrices with low-rank matrices derived\nfrom a single linear layer. Our empirical results show that CondLoRA maintains\na performance on par with LoRA, despite the fact that the trainable parameters\nof CondLoRA are fewer than those of LoRA. Therefore, we conclude that \"a single\nlinear layer yields task-adapted low-rank matrices.\"\n","authors":["Hwichan Kim","Shota Sasaki","Sho Hoshino","Ukyo Honda"],"pdf_url":"https://arxiv.org/pdf/2403.14946v1.pdf","comment":"Accepted at LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2403.14941v1","updated":"2024-03-22T04:21:40Z","published":"2024-03-22T04:21:40Z","title":"Unifying Lane-Level Traffic Prediction from a Graph Structural\n  Perspective: Benchmark and Baseline","summary":"  Traffic prediction has long been a focal and pivotal area in research,\nwitnessing both significant strides from city-level to road-level predictions\nin recent years. With the advancement of Vehicle-to-Everything (V2X)\ntechnologies, autonomous driving, and large-scale models in the traffic domain,\nlane-level traffic prediction has emerged as an indispensable direction.\nHowever, further progress in this field is hindered by the absence of\ncomprehensive and unified evaluation standards, coupled with limited public\navailability of data and code. This paper extensively analyzes and categorizes\nexisting research in lane-level traffic prediction, establishes a unified\nspatial topology structure and prediction tasks, and introduces a simple\nbaseline model, GraphMLP, based on graph structure and MLP networks. We have\nreplicated codes not publicly available in existing studies and, based on this,\nthoroughly and fairly assessed various models in terms of effectiveness,\nefficiency, and applicability, providing insights for practical applications.\nAdditionally, we have released three new datasets and corresponding codes to\naccelerate progress in this field, all of which can be found on\nhttps://github.com/ShuhaoLii/TITS24LaneLevel-Traffic-Benchmark.\n","authors":["Shuhao Li","Yue Cui","Jingyi Xu","Libin Li","Lingkai Meng","Weidong Yang","Fan Zhang","Xiaofang Zhou"],"pdf_url":"https://arxiv.org/pdf/2403.14941v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.08699v3","updated":"2024-03-22T03:31:22Z","published":"2024-01-14T12:38:49Z","title":"On Image Search in Histopathology","summary":"  Pathology images of histopathology can be acquired from camera-mounted\nmicroscopes or whole slide scanners. Utilizing similarity calculations to match\npatients based on these images holds significant potential in research and\nclinical contexts. Recent advancements in search technologies allow for\nimplicit quantification of tissue morphology across diverse primary sites,\nfacilitating comparisons and enabling inferences about diagnosis, and\npotentially prognosis, and predictions for new patients when compared against a\ncurated database of diagnosed and treated cases. In this paper, we\ncomprehensively review the latest developments in image search technologies for\nhistopathology, offering a concise overview tailored for computational\npathology researchers seeking effective, fast and efficient image search\nmethods in their work.\n","authors":["H. R. Tizhoosh","Liron Pantanowitz"],"pdf_url":"https://arxiv.org/pdf/2401.08699v3.pdf","comment":"A chapter in the Book \"Artificial INtelligence in Digital Pathology\"\n  by Cohen and Chauhan, 2024"},{"id":"http://arxiv.org/abs/2403.14932v1","updated":"2024-03-22T03:23:58Z","published":"2024-03-22T03:23:58Z","title":"Attention-Driven Reasoning: Unlocking the Potential of Large Language\n  Models","summary":"  Large Language Models (LLMs) have shown remarkable capabilities, but their\nreasoning abilities and underlying mechanisms remain poorly understood. We\npresent a novel approach to enhance LLMs' reasoning through attention mechanism\noptimization, without additional training data. We identify inefficiencies in\nthe attention distribution caused by non-semantic tokens and propose an\nalgorithm to re-balance the skewed distribution, enabling the model to abstract\nmore nuanced knowledge. Our experiments demonstrate significantly improved\nreasoning capabilities, particularly for non-STEM questions. We provide\ninsights into the role of attention patterns in LLMs' reasoning and propose a\nmethod to enhance these abilities, paving the way for more powerful and\nversatile language models.\n","authors":["Bingli Liao","Danilo Vasconcellos Vargas"],"pdf_url":"https://arxiv.org/pdf/2403.14932v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10278v2","updated":"2024-03-22T03:09:25Z","published":"2023-11-17T01:55:15Z","title":"Physics-Enhanced Multi-fidelity Learning for Optical Surface Imprint","summary":"  Human fingerprints serve as one unique and powerful characteristic for each\nperson, from which policemen can recognize the identity. Similar to humans,\nmany natural bodies and intrinsic mechanical qualities can also be uniquely\nidentified from surface characteristics. To measure the elasto-plastic\nproperties of one material, one formally sharp indenter is pushed into the\nmeasured body under constant force and retracted, leaving a unique residual\nimprint of the minute size from several micrometers to nanometers. However, one\ngreat challenge is how to map the optical image of this residual imprint into\nthe real wanted mechanical properties, \\ie, the tensile force curve. In this\npaper, we propose a novel method to use multi-fidelity neural networks (MFNN)\nto solve this inverse problem. We first build up the NN model via pure\nsimulation data, and then bridge the sim-to-real gap via transfer learning.\nConsidering the difficulty of collecting real experimental data, we use NN to\ndig out the unknown physics and also implant the known physics into the\ntransfer learning framework, thus highly improving the model stability and\ndecreasing the data requirement. The final constructed model only needs\nthree-shot calibration of real materials. We tested the final model across 20\nreal materials and achieved satisfying accuracy. This work serves as one great\nexample of applying machine learning into scientific research, especially under\nthe constraints of data limitation and fidelity variance.\n","authors":["Yongchao Chen"],"pdf_url":"https://arxiv.org/pdf/2311.10278v2.pdf","comment":"15 pages, 11 figure"},{"id":"http://arxiv.org/abs/2312.01697v4","updated":"2024-03-22T02:47:00Z","published":"2023-12-04T07:36:04Z","title":"Hulk: A Universal Knowledge Translator for Human-Centric Tasks","summary":"  Human-centric perception tasks, e.g., pedestrian detection, skeleton-based\naction recognition, and pose estimation, have wide industrial applications,\nsuch as metaverse and sports analysis. There is a recent surge to develop\nhuman-centric foundation models that can benefit a broad range of human-centric\nperception tasks. While many human-centric foundation models have achieved\nsuccess, they did not explore 3D and vision-language tasks for human-centric\nand required task-specific finetuning. These limitations restrict their\napplication to more downstream tasks and situations. To tackle these problems,\nwe present Hulk, the first multimodal human-centric generalist model, capable\nof addressing 2D vision, 3D vision, skeleton-based, and vision-language tasks\nwithout task-specific finetuning. The key to achieving this is condensing\nvarious task-specific heads into two general heads, one for discrete\nrepresentations, e.g., languages, and the other for continuous representations,\ne.g., location coordinates. The outputs of two heads can be further stacked\ninto four distinct input and output modalities. This uniform representation\nenables Hulk to treat diverse human-centric tasks as modality translation,\nintegrating knowledge across a wide range of tasks. Comprehensive evaluations\nof Hulk on 12 benchmarks covering 8 human-centric tasks demonstrate the\nsuperiority of our proposed method, achieving state-of-the-art performance in\n11 benchmarks. The code is available on https://github.com/OpenGVLab/Hulk.\n","authors":["Yizhou Wang","Yixuan Wu","Shixiang Tang","Weizhen He","Xun Guo","Feng Zhu","Lei Bai","Rui Zhao","Jian Wu","Tong He","Wanli Ouyang"],"pdf_url":"https://arxiv.org/pdf/2312.01697v4.pdf","comment":"24 pages, 5 figures"},{"id":"http://arxiv.org/abs/2403.14919v1","updated":"2024-03-22T02:44:05Z","published":"2024-03-22T02:44:05Z","title":"Hierarchical Skip Decoding for Efficient Autoregressive Text Generation","summary":"  Autoregressive decoding strategy is a commonly used method for text\ngeneration tasks with pre-trained language models, while early-exiting is an\neffective approach to speedup the inference stage. In this work, we propose a\nnovel decoding strategy named Hierarchical Skip Decoding (HSD) for efficient\nautoregressive text generation. Different from existing methods that require\nadditional trainable components, HSD is a plug-and-play method applicable to\nautoregressive text generation models, it adaptively skips decoding layers in a\nhierarchical manner based on the current sequence length, thereby reducing\ncomputational workload and allocating computation resources. Comprehensive\nexperiments on five text generation datasets with pre-trained language models\ndemonstrate HSD's advantages in balancing efficiency and text quality. With\nalmost half of the layers skipped, HSD can sustain 90% of the text quality\ncompared to vanilla autoregressive decoding, outperforming the competitive\napproaches.\n","authors":["Yunqi Zhu","Xuebing Yang","Yuanyuan Wu","Wensheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.14919v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14468v2","updated":"2024-03-22T02:16:40Z","published":"2024-03-21T15:15:00Z","title":"AnyV2V: A Plug-and-Play Framework For Any Video-to-Video Editing Tasks","summary":"  Video-to-video editing involves editing a source video along with additional\ncontrol (such as text prompts, subjects, or styles) to generate a new video\nthat aligns with the source video and the provided control. Traditional methods\nhave been constrained to certain editing types, limiting their ability to meet\nthe wide range of user demands. In this paper, we introduce AnyV2V, a novel\ntraining-free framework designed to simplify video editing into two primary\nsteps: (1) employing an off-the-shelf image editing model (e.g.\nInstructPix2Pix, InstantID, etc) to modify the first frame, (2) utilizing an\nexisting image-to-video generation model (e.g. I2VGen-XL) for DDIM inversion\nand feature injection. In the first stage, AnyV2V can plug in any existing\nimage editing tools to support an extensive array of video editing tasks.\nBeyond the traditional prompt-based editing methods, AnyV2V also can support\nnovel video editing tasks, including reference-based style transfer,\nsubject-driven editing, and identity manipulation, which were unattainable by\nprevious methods. In the second stage, AnyV2V can plug in any existing\nimage-to-video models to perform DDIM inversion and intermediate feature\ninjection to maintain the appearance and motion consistency with the source\nvideo. On the prompt-based editing, we show that AnyV2V can outperform the\nprevious best approach by 35\\% on prompt alignment, and 25\\% on human\npreference. On the three novel tasks, we show that AnyV2V also achieves a high\nsuccess rate. We believe AnyV2V will continue to thrive due to its ability to\nseamlessly integrate the fast-evolving image editing methods. Such\ncompatibility can help AnyV2V to increase its versatility to cater to diverse\nuser demands.\n","authors":["Max Ku","Cong Wei","Weiming Ren","Harry Yang","Wenhu Chen"],"pdf_url":"https://arxiv.org/pdf/2403.14468v2.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2306.04366v4","updated":"2024-03-22T02:14:07Z","published":"2023-06-07T11:59:45Z","title":"Enhancing Worker Recruitment in Collaborative Mobile Crowdsourcing: A\n  Graph Neural Network Trust Evaluation Approach","summary":"  Collaborative Mobile Crowdsourcing (CMCS) allows platforms to recruit worker\nteams to collaboratively execute complex sensing tasks. The efficiency of such\ncollaborations could be influenced by trust relationships among workers. To\nobtain the asymmetric trust values among all workers in the social network, the\nTrust Reinforcement Evaluation Framework (TREF) based on Graph Convolutional\nNeural Networks (GCNs) is proposed in this paper. The task completion effect is\ncomprehensively calculated by considering the workers' ability benefits,\ndistance benefits, and trust benefits in this paper. The worker recruitment\nproblem is modeled as an Undirected Complete Recruitment Graph (UCRG), for\nwhich a specific Tabu Search Recruitment (TSR) algorithm solution is proposed.\nAn optimal execution team is recruited for each task by the TSR algorithm, and\nthe collaboration team for the task is obtained under the constraint of privacy\nloss. To enhance the efficiency of the recruitment algorithm on a large scale\nand scope, the Mini-Batch K-Means clustering algorithm and edge computing\ntechnology are introduced, enabling distributed worker recruitment. Lastly,\nextensive experiments conducted on five real datasets validate that the\nrecruitment algorithm proposed in this paper outperforms other baselines.\nAdditionally, TREF proposed herein surpasses the performance of\nstate-of-the-art trust evaluation methods in the literature.\n","authors":["Zhongwei Zhan","Yingjie Wang","Peiyong Duan","Akshita Maradapu Vera Venkata Sai","Zhaowei Liu","Chaocan Xiang","Xiangrong Tong","Weilong Wang","Zhipeng Cai"],"pdf_url":"https://arxiv.org/pdf/2306.04366v4.pdf","comment":"The article has been accepted by IEEE TMC, and its DOI is\n  10.1109/TMC.2024.3373469"},{"id":"http://arxiv.org/abs/2305.05080v2","updated":"2024-03-22T01:17:08Z","published":"2023-05-08T22:43:16Z","title":"Scalable Optimal Transport Methods in Machine Learning: A Contemporary\n  Survey","summary":"  Optimal Transport (OT) is a mathematical framework that first emerged in the\neighteenth century and has led to a plethora of methods for answering many\ntheoretical and applied questions. The last decade has been a witness to the\nremarkable contributions of this classical optimization problem to machine\nlearning. This paper is about where and how optimal transport is used in\nmachine learning with a focus on the question of scalable optimal transport. We\nprovide a comprehensive survey of optimal transport while ensuring an\naccessible presentation as permitted by the nature of the topic and the\ncontext. First, we explain the optimal transport background and introduce\ndifferent flavors (i.e., mathematical formulations), properties, and notable\napplications. We then address the fundamental question of how to scale optimal\ntransport to cope with the current demands of big and high dimensional data. We\nconduct a systematic analysis of the methods used in the literature for scaling\nOT and present the findings in a unified taxonomy. We conclude with presenting\nsome open challenges and discussing potential future research directions. A\nlive repository of related OT research papers is maintained in\nhttps://github.com/abdelwahed/OT_for_big_data.git\n","authors":["Abdelwahed Khamis","Russell Tsuchida","Mohamed Tarek","Vivien Rolland","Lars Petersson"],"pdf_url":"https://arxiv.org/pdf/2305.05080v2.pdf","comment":"Accepted @ TPAMI 24"},{"id":"http://arxiv.org/abs/2403.09738v3","updated":"2024-03-22T01:08:42Z","published":"2024-03-13T18:16:21Z","title":"Evaluating Large Language Models as Generative User Simulators for\n  Conversational Recommendation","summary":"  Synthetic users are cost-effective proxies for real users in the evaluation\nof conversational recommender systems. Large language models show promise in\nsimulating human-like behavior, raising the question of their ability to\nrepresent a diverse population of users. We introduce a new protocol to measure\nthe degree to which language models can accurately emulate human behavior in\nconversational recommendation. This protocol is comprised of five tasks, each\ndesigned to evaluate a key property that a synthetic user should exhibit:\nchoosing which items to talk about, expressing binary preferences, expressing\nopen-ended preferences, requesting recommendations, and giving feedback.\nThrough evaluation of baseline simulators, we demonstrate these tasks\neffectively reveal deviations of language models from human behavior, and offer\ninsights on how to reduce the deviations with model selection and prompting\nstrategies.\n","authors":["Se-eun Yoon","Zhankui He","Jessica Maria Echterhoff","Julian McAuley"],"pdf_url":"https://arxiv.org/pdf/2403.09738v3.pdf","comment":"NAACL 2024"},{"id":"http://arxiv.org/abs/2403.14895v1","updated":"2024-03-22T00:58:28Z","published":"2024-03-22T00:58:28Z","title":"Stance Reasoner: Zero-Shot Stance Detection on Social Media with\n  Explicit Reasoning","summary":"  Social media platforms are rich sources of opinionated content. Stance\ndetection allows the automatic extraction of users' opinions on various topics\nfrom such content. We focus on zero-shot stance detection, where the model's\nsuccess relies on (a) having knowledge about the target topic; and (b) learning\ngeneral reasoning strategies that can be employed for new topics. We present\nStance Reasoner, an approach to zero-shot stance detection on social media that\nleverages explicit reasoning over background knowledge to guide the model's\ninference about the document's stance on a target. Specifically, our method\nuses a pre-trained language model as a source of world knowledge, with the\nchain-of-thought in-context learning approach to generate intermediate\nreasoning steps. Stance Reasoner outperforms the current state-of-the-art\nmodels on 3 Twitter datasets, including fully supervised models. It can better\ngeneralize across targets, while at the same time providing explicit and\ninterpretable explanations for its predictions.\n","authors":["Maksym Taranukhin","Vered Shwartz","Evangelos Milios"],"pdf_url":"https://arxiv.org/pdf/2403.14895v1.pdf","comment":"Accepted to COLING 2024"},{"id":"http://arxiv.org/abs/2403.12211v2","updated":"2024-03-22T00:17:11Z","published":"2024-03-18T19:51:55Z","title":"A Unified Model for Longitudinal Multi-Modal Multi-View Prediction with\n  Missingness","summary":"  Medical records often consist of different modalities, such as images, text,\nand tabular information. Integrating all modalities offers a holistic view of a\npatient's condition, while analyzing them longitudinally provides a better\nunderstanding of disease progression. However, real-world longitudinal medical\nrecords present challenges: 1) patients may lack some or all of the data for a\nspecific timepoint, and 2) certain modalities or views might be absent for all\npatients during a particular period. In this work, we introduce a unified model\nfor longitudinal multi-modal multi-view prediction with missingness. Our method\nallows as many timepoints as desired for input, and aims to leverage all\navailable data, regardless of their availability. We conduct extensive\nexperiments on the knee osteoarthritis dataset from the Osteoarthritis\nInitiative for pain and Kellgren-Lawrence grade prediction at a future\ntimepoint. We demonstrate the effectiveness of our method by comparing results\nfrom our unified model to specific models that use the same modality and view\ncombinations during training and evaluation. We also show the benefit of having\nextended temporal data and provide post-hoc analysis for a deeper understanding\nof each modality/view's importance for different tasks.\n","authors":["Boqi Chen","Junier Oliva","Marc Niethammer"],"pdf_url":"https://arxiv.org/pdf/2403.12211v2.pdf","comment":null}],"Optimization and Control":[{"id":"http://arxiv.org/abs/2309.16512v4","updated":"2024-03-22T17:26:53Z","published":"2023-09-28T15:19:30Z","title":"From Complexity to Clarity: Analytical Expressions of Deep Neural\n  Network Weights via Clifford's Geometric Algebra and Convexity","summary":"  In this paper, we introduce a novel analysis of neural networks based on\ngeometric (Clifford) algebra and convex optimization. We show that optimal\nweights of deep ReLU neural networks are given by the wedge product of training\nsamples when trained with standard regularized loss. Furthermore, the training\nproblem reduces to convex optimization over wedge product features, which\nencode the geometric structure of the training dataset. This structure is given\nin terms of signed volumes of triangles and parallelotopes generated by data\nvectors. The convex problem finds a small subset of samples via $\\ell_1$\nregularization to discover only relevant wedge product features. Our analysis\nprovides a novel perspective on the inner workings of deep neural networks and\nsheds light on the role of the hidden layers.\n","authors":["Mert Pilanci"],"pdf_url":"https://arxiv.org/pdf/2309.16512v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15344v1","updated":"2024-03-22T16:55:01Z","published":"2024-03-22T16:55:01Z","title":"Optimal Exploration Strategy for Regret Minimization in Unconstrained\n  Scalar Optimization Problems","summary":"  We study the problem of determining the optimal exploration strategy in an\nunconstrained scalar optimization problem depending on an unknown parameter to\nbe learned from online collected noisy data. An optimal trade-off between\nexploration and exploitation is crucial for effective optimization under\nuncertainties, and to achieve this we consider a cumulative regret minimization\napproach over a finite horizon, with each time instant in the horizon\ncharacterized by a stochastic exploration signal, whose variance has to be\ndesigned. In this setting, under an idealized assumption on an appropriately\ndefined information function associated with the excitation, we are able to\nshow that the optimal exploration strategy is either to use no exploration at\nall (called lazy exploration) or adding an exploration excitation only at the\nfirst time instant of the horizon (called immediate exploration). A quadratic\nnumerical example is used to illustrate the results.\n","authors":["Ying Wang","Mirko Pasquini","Kévin Colin","Håkan Hjalmarsson"],"pdf_url":"https://arxiv.org/pdf/2403.15344v1.pdf","comment":"Preprint submitted to IEEE Conference on Decision and Control (CDC\n  2024)"},{"id":"http://arxiv.org/abs/2112.05645v3","updated":"2024-03-22T16:22:32Z","published":"2021-12-10T16:17:49Z","title":"Graph-structured tensor optimization for nonlinear density control and\n  mean field games","summary":"  In this work we develop a numerical method for solving a type of convex\ngraph-structured tensor optimization problems. This type of problems, which can\nbe seen as a generalization of multi-marginal optimal transport problems with\ngraph-structured costs, appear in many applications. Examples are unbalanced\noptimal transport and multi-species potential mean field games, where the\nlatter is a class of nonlinear density control problems. The method we develop\nis based on coordinate ascent in a Lagrangian dual, and under mild assumptions\nwe prove that the algorithm converges globally. Moreover, under a set of\nstricter assumptions, the algorithm converges R-linearly. To perform the\ncoordinate ascent steps one has to compute projections of the tensor, and doing\nso by brute force is in general not computationally feasible. Nevertheless, for\ncertain graph structures it is possible to derive efficient methods for\ncomputing these projections, and here we specifically consider the graph\nstructure that occurs in multi-species potential mean field games. We also\nillustrate the methodology on a numerical example from this problem class.\n","authors":["Axel Ringh","Isabel Haasler","Yongxin Chen","Johan Karlsson"],"pdf_url":"https://arxiv.org/pdf/2112.05645v3.pdf","comment":"27 pages. Revision: among other things, the section on Convex dynamic\n  network flow problems has been removed, and the section on Multi-species\n  potential mean field games has been expanded"},{"id":"http://arxiv.org/abs/1909.06689v5","updated":"2024-03-22T16:17:02Z","published":"2019-09-14T22:36:59Z","title":"Reducing non-negativity over general semialgebraic sets to\n  non-negativity over simple sets","summary":"  A non-negativity certificate (NNC) is a way to write a polynomial so that its\nnon-negativity on a semialgebraic set becomes evident. Positivstellens\\\"atze\n(Ps\\\"atze) guarantee the existence of NNCs. Both, NNCs and Ps\\\"atze underlie\npowerful algorithmic techniques for optimization. This paper proposes a\nuniversal approach to derive new Ps\\\"atze for general semialgebraic sets from\nones developed for simpler sets, such as a box, a simplex, or the non-negative\northant. We provide several results illustrating the approach. First, by\nconsidering Handelman's Positivstellensatz (Psatz) over a box, we construct\nnon-SOS Schm\\\"{u}dgen-type Ps\\\"atze over any compact semialgebraic set. That\nis, a family of Ps\\\"atze that follow the structure of the fundamental\nSchm\\\"{u}dgen's Psatz, but where instead of SOS polynomials, any class of\npolynomials containing the non-negative constants can be used, such as SONC,\nDSOS/SDSOS, hyperbolic or sums of AM/GM polynomials. Secondly, by considering\nthe simplex as the simple set, we derive a sparse Psatz over general compact\nsets, which does not require any structural assumptions of the set. Finally, by\nconsidering P\\'olya's Psatz over the non-negative orthant, we derive a new\nnon-SOS Psatz over unbounded sets which satisfy some generic conditions. All\nthese results contribute to the literature regarding the use of non-SOS\npolynomials and sparse NNCs to derive Ps\\\"atze over compact and unbounded sets.\nThroughout the article, we illustrate our results with relevant examples and\nnumerical experiments.\n","authors":["Olga Kuryatnikova","Juan C. Vera","Luis F. Zuluaga"],"pdf_url":"https://arxiv.org/pdf/1909.06689v5.pdf","comment":"33 pages, 4 tables, 2 figures"},{"id":"http://arxiv.org/abs/2403.15299v1","updated":"2024-03-22T15:50:13Z","published":"2024-03-22T15:50:13Z","title":"Quantitative propagation of smallness and spectral estimates for the\n  Schrödinger operator","summary":"  In this paper, we investigate quantitative propagation of smallness\nproperties for the Schr\\\"odinger operator on a bounded domain in $\\mathbb R^d$.\nWe extend Logunov, Malinnikova's results concerning propagation of smallness\nfor $A$-harmonic functions to solutions of divergence elliptic equations\nperturbed by a bounded zero order term. We also prove similar results for\ngradient of solutions to some particular equations. This latter result enables\nus to follow the recent strategy of Burq, Moyano for the obtaining of spectral\nestimates on rough sets for the Schr\\\"odinger operator. Applications to\nobservability estimates and to the null-controllability of associated parabolic\nequations posed on compact manifolds or the whole euclidean space are then\nconsidered.\n","authors":["Kévin Le Balc'h","Jérémy Martin"],"pdf_url":"https://arxiv.org/pdf/2403.15299v1.pdf","comment":"Comments welcome"},{"id":"http://arxiv.org/abs/2403.15294v1","updated":"2024-03-22T15:40:26Z","published":"2024-03-22T15:40:26Z","title":"Nonlinear Reachable Set Computation and Model Predictive Control for\n  Safe Hypersonic Re-entry of Atmospheric Vehicles","summary":"  This paper investigates the application of reachability analysis to the\nre-entry problem faced by vehicles entering Earth's atmosphere. The study\ndelves into the time evolution of reachable sets for the system, particularly\nwhen subject to nonlinear implicit controls, given the potential damage from\nthe intense heat generated during hypersonic re-entry. Our proposed methodology\nleverages zonotopes and constrained zonotopes to ensure compliance with safety\nspecifications. Furthermore, we utilize Model Predictive Control for detailed\ntrajectory planning. To substantiate our methodology, we provide detailed\nsimulations that not only tackle nonlinear re-entry scenarios but also\nillustrate trajectory planning using MPC.\n","authors":["Jinaykumar Patel","Kamesh Subbarao"],"pdf_url":"https://arxiv.org/pdf/2403.15294v1.pdf","comment":"2023 AAS/AIAA Astrodynamics Specialist Conference, Big Sky, MT"},{"id":"http://arxiv.org/abs/2403.15292v1","updated":"2024-03-22T15:40:09Z","published":"2024-03-22T15:40:09Z","title":"A data-driven approach to PDE-constrained optimization in inverse\n  problems","summary":"  Inverse problems are ubiquitous in science and engineering. Many of these are\nnaturally formulated as a PDE-constrained optimization problem. These\nnon-linear, large-scale, constrained optimization problems know many\nchallenges, of which the inherent non-linearity of the problem is an important\none. As an alternative to this physics-driven approach, data-driven methods\nhave been proposed. These methods come with their own set of challenges, and it\nappears that, ideally, one would devise hybrid methods that combine the best of\nboth worlds. In this paper, we propose one way of combining PDE-constrained\noptimization with recently proposed data-driven reduced-order models. Starting\nfrom an infinite-dimensional formulation of the inverse problem with discrete\ndata, we propose a general framework for the analysis and discretisation of\nsuch problems. The proposed approach is based on a relaxed formulation of the\nPDE-constrained optimization problem, which reduces to a weighted non-linear\nleast-squares problem. The weight matrix turns out to be the Gram matrix of\nsolutions of the PDE, and it can be estimated directly from the measurements.\nWe provide a number of representative case studies and numerical examples.\n","authors":["Tristan van Leeuwen","Yunan Yang"],"pdf_url":"https://arxiv.org/pdf/2403.15292v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.00488v2","updated":"2024-03-22T15:14:59Z","published":"2024-03-01T12:15:46Z","title":"Inferring solar differential rotation and viscosity via passive imaging\n  with inertial waves","summary":"  The recent discovery of inertial waves on the surface of the Sun offers new\npossibilities to learn about the solar interior. These waves are long-lived\nwith a period on the order of the Sun rotation period ($\\sim$27 days) and are\nsensitive to parameters deep inside the Sun. They are excited by turbulent\nconvection, leading to a passive imaging problem. In this work, we present the\nforward and inverse problem of reconstructing viscosity and differential\nrotation on the Sun from cross-covariance observations of these inertial waves.\n","authors":["Tram Thi Ngoc Nguyen","Thorsten Hohage","Damien Fournier","Laurent Gizon"],"pdf_url":"https://arxiv.org/pdf/2403.00488v2.pdf","comment":"proceedings paper"},{"id":"http://arxiv.org/abs/2305.01317v3","updated":"2024-03-22T14:49:02Z","published":"2023-05-02T10:57:59Z","title":"The role of individual compensation and acceptance decisions in\n  crowdsourced delivery","summary":"  One of the recent innovations in urban distribution is crowdsourced delivery,\nwhere deliveries are made by occasional drivers who wish to utilize their\nsurplus resources (unused transport capacity) by making deliveries in exchange\nfor some compensation. The potential benefits of crowdsourced delivery include\nreduced delivery costs and increased flexibility (by scaling delivery capacity\nup and down as needed). The use of occasional drivers poses new challenges\nbecause (unlike traditional couriers) neither their availability nor their\nbehavior in accepting delivery offers is certain. The relationship between the\ncompensation offered to occasional drivers and the probability that they will\naccept a task has been largely neglected in the scientific literature.\nTherefore, we consider a setting in which compensation-dependent acceptance\nprobabilities are explicitly considered in the process of assigning delivery\ntasks to occasional drivers. We propose a mixed-integer nonlinear model that\nminimizes the expected delivery costs while identifying optimal assignments of\ntasks to a mix of professional and occasional drivers and their compensation.\nWe propose an exact two-stage solution algorithm that allows to decompose\ncompensation and assignment decisions for generic acceptance probability\nfunctions and show that the runtime of this algorithm is polynomial under mild\nconditions. Finally, we also study a more general case of the considered\nproblem setting, show that it is NP-hard and propose an approximate\nlinearization scheme of our mixed-integer nonlinear model. The results of our\ncomputational study show clear advantages of our new approach over existing\nones. They also indicate that these advantages remain in dynamic settings when\ntasks and drivers are revealed over time and in which case our method\nconstitutes a fast, yet powerful heuristic.\n","authors":["Alim Buğra Çınar","Wout Dullaert","Markus Leitner","Rosario Paradiso","Stefan Waldherr"],"pdf_url":"https://arxiv.org/pdf/2305.01317v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15244v1","updated":"2024-03-22T14:40:29Z","published":"2024-03-22T14:40:29Z","title":"A Stochastic Quasi-Newton Method for Non-convex Optimization with\n  Non-uniform Smoothness","summary":"  Classical convergence analyses for optimization algorithms rely on the\nwidely-adopted uniform smoothness assumption. However, recent experimental\nstudies have demonstrated that many machine learning problems exhibit\nnon-uniform smoothness, meaning the smoothness factor is a function of the\nmodel parameter instead of a universal constant. In particular, it has been\nobserved that the smoothness grows with respect to the gradient norm along the\ntraining trajectory. Motivated by this phenomenon, the recently introduced\n$(L_0, L_1)$-smoothness is a more general notion, compared to traditional\n$L$-smoothness, that captures such positive relationship between smoothness and\ngradient norm. Under this type of non-uniform smoothness, existing literature\nhas designed stochastic first-order algorithms by utilizing gradient clipping\ntechniques to obtain the optimal $\\mathcal{O}(\\epsilon^{-3})$ sample complexity\nfor finding an $\\epsilon$-approximate first-order stationary solution.\nNevertheless, the studies of quasi-Newton methods are still lacking.\nConsidering higher accuracy and more robustness for quasi-Newton methods, in\nthis paper we propose a fast stochastic quasi-Newton method when there exists\nnon-uniformity in smoothness. Leveraging gradient clipping and variance\nreduction, our algorithm can achieve the best-known\n$\\mathcal{O}(\\epsilon^{-3})$ sample complexity and enjoys convergence speedup\nwith simple hyperparameter tuning. Our numerical experiments show that our\nproposed algorithm outperforms the state-of-the-art approaches.\n","authors":["Zhenyu Sun","Ermin Wei"],"pdf_url":"https://arxiv.org/pdf/2403.15244v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.12764v3","updated":"2024-03-22T14:29:14Z","published":"2024-01-23T13:44:15Z","title":"Fast Nonlinear Two-Time-Scale Stochastic Approximation: Achieving\n  $O(1/k)$ Finite-Sample Complexity","summary":"  This paper proposes to develop a new variant of the two-time-scale stochastic\napproximation to find the roots of two coupled nonlinear operators, assuming\nonly noisy samples of these operators can be observed. Our key idea is to\nleverage the classic Ruppert-Polyak averaging technique to dynamically estimate\nthe operators through their samples. The estimated values of these averaging\nsteps will then be used in the two-time-scale stochastic approximation updates\nto find the desired solution. Our main theoretical result is to show that under\nthe strongly monotone condition of the underlying nonlinear operators the\nmean-squared errors of the iterates generated by the proposed method converge\nto zero at an optimal rate $O(1/k)$, where $k$ is the number of iterations. Our\nresult significantly improves the existing result of two-time-scale stochastic\napproximation, where the best known finite-time convergence rate is\n$O(1/k^{2/3})$. We illustrate this result by applying the proposed method to\ndevelop new reinforcement learning algorithms with improved performance.\n","authors":["Thinh T. Doan"],"pdf_url":"https://arxiv.org/pdf/2401.12764v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15228v1","updated":"2024-03-22T14:21:14Z","published":"2024-03-22T14:21:14Z","title":"On moment relaxations for linear state feedback controller synthesis\n  with non-convex quadratic costs and constraints","summary":"  We present a simple and effective way to account for non-convex costs and\nconstraints~in~state feedback synthesis, and an interpretation for the\nvariables in which state feedback synthesis is typically convex. We achieve\nthis by deriving the controller design using moment matrices of state and\ninput. It turns out that this approach allows the consideration of non-convex\nconstraints by relaxing them as expectation constraints, and that the variables\nin which state feedback synthesis is typically convexified can be identified\nwith blocks of these moment matrices.\n","authors":["Dennis Gramlich","Sheng Gao","Hao Zhang","Carsten W. Scherer","Christian Ebenbauer"],"pdf_url":"https://arxiv.org/pdf/2403.15228v1.pdf","comment":"Preprent to be submitted to IEEE Conference on Decision and Control"},{"id":"http://arxiv.org/abs/2403.15219v1","updated":"2024-03-22T14:08:36Z","published":"2024-03-22T14:08:36Z","title":"Robust Microgrid Dispatch with Real-Time Energy Sharing and Endogenous\n  Uncertainty","summary":"  With the rising adoption of distributed energy resources (DERs), microgrid\ndispatch is facing new challenges: DER owners are independent stakeholders\nseeking to maximize their individual profits rather than being controlled\ncentrally; and the dispatch of renewable generators may affect the microgrid's\nexposure to uncertainty. To address these challenges, this paper proposes a\ntwo-stage robust microgrid dispatch model with real-time energy sharing and\nendogenous uncertainty. In the day-ahead stage, the connection/disconnection of\nrenewable generators is optimized, which influences the size and dimension of\nthe uncertainty set. As a result, the uncertainty set is endogenously given. In\naddition, non-anticipative operational bounds for energy storage (ES) are\nderived to enable the online operation of ES in real-time. In the real-time\nstage, DER owners (consumers and prosumers) share energy with each other via a\nproposed energy sharing mechanism, which forms a generalized Nash game. To\nsolve the robust microgrid dispatch model, we develop an equivalent\noptimization model to compute the real-time energy sharing equilibrium. Based\non this, a projection-based column-and-constraint generation (C&CG) method is\nproposed to handle the endogenous uncertainty. Numerical experiments show the\neffectiveness and advantages of the proposed model and method.\n","authors":["Meng Yang","Rui Xie","Yongjun Zhang","Yue Chen"],"pdf_url":"https://arxiv.org/pdf/2403.15219v1.pdf","comment":"11 pages, 11 figures"},{"id":"http://arxiv.org/abs/2311.18438v2","updated":"2024-03-22T13:26:52Z","published":"2023-11-30T10:39:47Z","title":"Solution-Set Geometry and Regularization Path of a Nonconvexly\n  Regularized Convex Sparse Model","summary":"  The generalized minimax concave (GMC) penalty is a nonconvex sparse\nregularizer which can preserve the overall-convexity of the regularized\nleast-squares problem. In this paper, we focus on a significant instance of the\nGMC model termed scaled GMC (sGMC), and present various notable findings on its\nsolution-set geometry and regularization path. Our investigation indicates that\nwhile the sGMC penalty is a nonconvex extension of the LASSO penalty (i.e., the\n$\\ell_1$-norm), the sGMC model preserves many celebrated properties of the\nLASSO model, hence can serve as a less biased surrogate of LASSO without losing\nits advantages. Specifically, for a fixed regularization parameter $\\lambda$,\nwe show that the solution-set geometry, solution uniqueness and sparseness of\nthe sGMC model can be characterized in a similar elegant way to the LASSO model\n(see, e.g., Osborne et al. 2000, R. J. Tibshirani 2013). For a varying\n$\\lambda$, we prove that the sGMC solution set is a continuous polytope-valued\nmapping of $\\lambda$. Most noticeably, our study indicates that similar to\nLASSO, the minimum $\\ell_2$-norm regularization path of the sGMC model is\ncontinuous and piecewise linear in $\\lambda$. Based on these theoretical\nresults, an efficient regularization path algorithm is proposed for the sGMC\nmodel, extending the well-known least angle regression (LARS) algorithm for\nLASSO. We prove the correctness and finite termination of the proposed\nalgorithm under a mild assumption, and confirm its\ncorrectness-in-general-situation, efficiency, and practical utility through\nnumerical experiments. Many results in this study also contribute to the\ntheoretical research of LASSO.\n","authors":["Yi Zhang","Isao Yamada"],"pdf_url":"https://arxiv.org/pdf/2311.18438v2.pdf","comment":"53 pages, 10 figures. Submitted to journal"},{"id":"http://arxiv.org/abs/2403.15188v1","updated":"2024-03-22T13:16:47Z","published":"2024-03-22T13:16:47Z","title":"Pursuit-Evasion on a Sphere and When It Can Be Considered Flat","summary":"  In classical works on a planar differential pursuit-evasion game with a\nfaster pursuer, the intercept point resulting from the equilibrium strategies\nlies on the Apollonius circle. This property was exploited for the construction\nof the equilibrium strategies for two faster pursuers against one evader.\nExtensions for planar multiple-pursuer single-evader scenarios have been\nconsidered. We study a pursuit-evasion game on a sphere and the relation of the\nequilibrium intercept point to the Apollonius domain on the sphere. The domain\nis a generalization of the planar Apollonius circle set. We find a condition\nresulting in the intercept point belonging to the Apollonius domain, which is\nthe characteristic of the planar game solution. Finally, we use this\ncharacteristic to discuss pursuit and evasion strategies in the context of two\npursuers and a single slower evader on the sphere and illustrate it using\nnumerical simulations.\n","authors":["Dejan Milutinovic","Alexander Von Moll","Satyanarayana G. Manyam","David W. Casbeer","Isaac E. Weintraub","Meir Pachter"],"pdf_url":"https://arxiv.org/pdf/2403.15188v1.pdf","comment":"8 Pages, 5 figures, To be submitted to 2024 Conference on Decision\n  and Control in Milan, Italy"},{"id":"http://arxiv.org/abs/2309.05422v2","updated":"2024-03-22T12:50:02Z","published":"2023-09-11T12:49:27Z","title":"Turnpike and dissipativity in generalized discrete-time stochastic\n  linear-quadratic optimal control","summary":"  We investigate different turnpike phenomena of generalized discrete-time\nstochastic linear-quadratic optimal control problems. Our analysis is based on\na novel strict dissipativity notion for such problems, in which a stationary\nstochastic process replaces the optimal steady state of the deterministic\nsetting. We show that from this time-varying dissipativity notion, we can\nconclude turnpike behaviors concerning different objects like distributions,\nmoments, or sample paths of the stochastic system and that the distributions of\nthe stationary pair can be characterized by a stationary optimization problem.\nThe analytical findings are illustrated by numerical simulations.\n","authors":["Jonas Schießl","Ruchuan Ou","Timm Faulwasser","Michael Heinrich Baumann","Lars Grüne"],"pdf_url":"https://arxiv.org/pdf/2309.05422v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.03821v3","updated":"2024-03-22T12:39:11Z","published":"2023-11-07T09:12:39Z","title":"Positive Competitive Networks for Sparse Reconstruction","summary":"  We propose and analyze a continuous-time firing-rate neural network, the\npositive firing-rate competitive network (\\pfcn), to tackle sparse\nreconstruction problems with non-negativity constraints. These problems, which\ninvolve approximating a given input stimulus from a dictionary using a set of\nsparse (active) neurons, play a key role in a wide range of domains, including\nfor example neuroscience, signal processing, and machine learning. First, by\nleveraging the theory of proximal operators, we relate the equilibria of a\nfamily of continuous-time firing-rate neural networks to the optimal solutions\nof sparse reconstruction problems. Then, we prove that the \\pfcn is a positive\nsystem and give rigorous conditions for the convergence to the equilibrium.\nSpecifically, we show that the convergence: (i) only depends on a property of\nthe dictionary; (ii) is linear-exponential, in the sense that initially the\nconvergence rate is at worst linear and then, after a transient, it becomes\nexponential. We also prove a number of technical results to assess the\ncontractivity properties of the neural dynamics of interest. Our analysis\nleverages contraction theory to characterize the behavior of a family of\nfiring-rate competitive networks for sparse reconstruction with and without\nnon-negativity constraints. Finally, we validate the effectiveness of our\napproach via a numerical example.\n","authors":["Veronica Centorrino","Anand Gokhale","Alexander Davydov","Giovanni Russo","Francesco Bullo"],"pdf_url":"https://arxiv.org/pdf/2311.03821v3.pdf","comment":"26 pages, 9 Figure, 1 Table"},{"id":"http://arxiv.org/abs/2204.05382v4","updated":"2024-03-22T12:25:53Z","published":"2022-04-11T19:43:10Z","title":"Modeling and Contractivity of Neural-Synaptic Networks with Hebbian\n  Learning","summary":"  This paper is concerned with the modeling and analysis of two of the most\ncommonly used recurrent neural network models (i.e., Hopfield neural network\nand firing-rate neural network) with dynamic recurrent connections undergoing\nHebbian learning rules. To capture the synaptic sparsity of neural circuits we\npropose a low dimensional formulation. We then characterize certain key\ndynamical properties. First, we give biologically-inspired forward invariance\nresults. Then, we give sufficient conditions for the non-Euclidean\ncontractivity of the models. Our contraction analysis leads to stability and\nrobustness of time-varying trajectories -- for networks with both excitatory\nand inhibitory synapses governed by both Hebbian and anti-Hebbian rules. For\neach model, we propose a contractivity test based upon biologically meaningful\nquantities, e.g., neural and synaptic decay rate, maximum in-degree, and the\nmaximum synaptic strength. Then, we show that the models satisfy Dale's\nPrinciple. Finally, we illustrate the effectiveness of our results via a\nnumerical example.\n","authors":["Veronica Centorrino","Francesco Bullo","Giovanni Russo"],"pdf_url":"https://arxiv.org/pdf/2204.05382v4.pdf","comment":"24 pages, 4 figures"},{"id":"http://arxiv.org/abs/2403.15159v1","updated":"2024-03-22T12:15:22Z","published":"2024-03-22T12:15:22Z","title":"Near-optimal performance of stochastic economic MPC","summary":"  This paper presents first results for near optimality in expectation of the\nclosed-loop solutions for stochastic economic MPC. The approach relies on a\nrecently developed turnpike property for stochastic optimal control problems at\nan optimal stationary process, combined with techniques for analyzing\ntime-varying economic MPC schemes. We obtain near optimality in finite time as\nwell as overtaking and average near optimality on infinite time horizons.\n","authors":["Jonas Schießl","Ruchuan Ou","Timm Faulwasser","Michael H. Baumann","Lars Grüne"],"pdf_url":"https://arxiv.org/pdf/2403.15159v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15146v1","updated":"2024-03-22T11:57:51Z","published":"2024-03-22T11:57:51Z","title":"On the Convergence of Adam under Non-uniform Smoothness: Separability\n  from SGDM and Beyond","summary":"  This paper aims to clearly distinguish between Stochastic Gradient Descent\nwith Momentum (SGDM) and Adam in terms of their convergence rates. We\ndemonstrate that Adam achieves a faster convergence compared to SGDM under the\ncondition of non-uniformly bounded smoothness. Our findings reveal that: (1) in\ndeterministic environments, Adam can attain the known lower bound for the\nconvergence rate of deterministic first-order optimizers, whereas the\nconvergence rate of Gradient Descent with Momentum (GDM) has higher order\ndependence on the initial function value; (2) in stochastic setting, Adam's\nconvergence rate upper bound matches the lower bounds of stochastic first-order\noptimizers, considering both the initial function value and the final error,\nwhereas there are instances where SGDM fails to converge with any learning\nrate. These insights distinctly differentiate Adam and SGDM regarding their\nconvergence rates. Additionally, by introducing a novel stopping-time based\ntechnique, we further prove that if we consider the minimum gradient norm\nduring iterations, the corresponding convergence rate can match the lower\nbounds across all problem hyperparameters. The technique can also help proving\nthat Adam with a specific hyperparameter scheduler is parameter-agnostic, which\nhence can be of independent interest.\n","authors":["Bohan Wang","Huishuai Zhang","Qi Meng","Ruoyu Sun","Zhi-Ming Ma","Wei Chen"],"pdf_url":"https://arxiv.org/pdf/2403.15146v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15140v1","updated":"2024-03-22T11:51:47Z","published":"2024-03-22T11:51:47Z","title":"Hybrid integrator-gain system based integral resonant controllers for\n  negative imaginary systems","summary":"  We introduce a hybrid control system called a hybrid integrator-gain system\n(HIGS) based integral resonant controller (IRC) to stabilize negative imaginary\n(NI) systems. A HIGS-based IRC has a similar structure to an IRC, with the\nintegrator replaced by a HIGS. We show that a HIGS-based IRC is an NI system.\nAlso, for a SISO NI system with a minimal realization, we show there exists a\nHIGS-based IRC such that their closed-loop interconnection is asymptotically\nstable. Also, we propose a proportional-integral-double-integral resonant\ncontroller and a HIGS-based proportional-integral-double-integral resonant\ncontroller and show that both of them can be applied to asymptotically\nstabilize an NI system. An example is provided to illustrate the proposed\nresults.\n","authors":["Kanghong Shi","Ian R. Petersen"],"pdf_url":"https://arxiv.org/pdf/2403.15140v1.pdf","comment":"9 pages, 9 figures"},{"id":"http://arxiv.org/abs/2403.15101v1","updated":"2024-03-22T10:39:58Z","published":"2024-03-22T10:39:58Z","title":"Paddy: Evolutionary Optimization Algorithm for Chemical Systems and\n  Spaces","summary":"  Optimization of chemical systems and processes have been enhanced and enabled\nby the guidance of algorithms and analytical approaches. While many methods\nwill systematically investigate how underlying variables govern a given\noutcome, there is often a substantial number of experiments needed to\naccurately model these relations. As chemical systems increase in complexity,\ninexhaustive processes must propose experiments that efficiently optimize the\nunderlying objective, while ideally avoiding convergence on unsatisfactory\nlocal minima. We have developed the Paddy software package around the Paddy\nField Algorithm, a biologically inspired evolutionary optimization algorithm\nthat propagates parameters without direct inference of the underlying objective\nfunction. Benchmarked against the Tree of Parzen Estimator, a Bayesian\nalgorithm implemented in the Hyperopt software Library, Paddy displays\nefficient optimization with lower runtime, and avoidance of early convergence.\nHerein we report these findings for the cases of: global optimization of a\ntwo-dimensional bimodal distribution, interpolation of an irregular sinusoidal\nfunction, hyperparameter optimization of an artificial neural network tasked\nwith classification of solvent for reaction components, and targeted molecule\ngeneration via optimization of input vectors for a decoder network. We\nanticipate that the facile nature of Paddy will serve to aid in automated\nexperimentation, where minimization of investigative trials and or diversity of\nsuitable solutions is of high priority.\n","authors":["Armen Beck","Jonathan Fine","Gaurav Chopra"],"pdf_url":"https://arxiv.org/pdf/2403.15101v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15099v1","updated":"2024-03-22T10:38:46Z","published":"2024-03-22T10:38:46Z","title":"Optimal Contract Design for End-of-Life Care Payments","summary":"  A large fraction of total healthcare expenditure occurs due to end-of-life\n(EOL) care, which means it is important to study the problem of more carefully\nincentivizing necessary versus unnecessary EOL care because this has the\npotential to reduce overall healthcare spending. This paper introduces a\nprincipal-agent model that integrates a mixed payment system of fee-for-service\nand pay-for-performance in order to analyze whether it is possible to better\nalign healthcare provider incentives with patient outcomes and cost-efficiency\nin EOL care. The primary contributions are to derive optimal contracts for EOL\ncare payments using a principal-agent framework under three separate models for\nthe healthcare provider, where each model considers a different level of risk\ntolerance for the provider. We derive these optimal contracts by converting the\nunderlying principal-agent models from a bilevel optimization problem into a\nsingle-level optimization problem that can be analytically solved. Our results\nare demonstrated using a simulation where an optimal contract is used to price\nintracranial pressure monitoring for traumatic brain injuries.\n","authors":["Muyan Jiang","Ying Chen","Xin Chen","Javad Lavaei","Anil Aswani"],"pdf_url":"https://arxiv.org/pdf/2403.15099v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15056v1","updated":"2024-03-22T09:28:14Z","published":"2024-03-22T09:28:14Z","title":"Perturbations in PDE-constrained optimal control decay exponentially in\n  space","summary":"  For linear-quadratic optimal control problems (OCPs) governed by elliptic and\nparabolic partial differential equations (PDEs), we investigate the impact of\nperturbations on optimal solutions. Local perturbations may occur, e.g., due to\ndiscretization of the optimality system or disturbed problem data. Whereas\nthese perturbations may exhibit global effects in the uncontrolled case, we\nprove that the ramifications are exponentially damped in space under\nstabilizability- and detectability-like conditions. To this end, we prove a\nbound on the optimality condition's solution operator that is uniform in the\ndomain size. Then, this uniformity is used in a scaling argument to show the\nexponential decay of perturbations in space. We numerically validate and\nillustrate our results by solving OCPs involving Helmholtz, Poisson, and\nadvection-diffusion-reaction equations.\n","authors":["Simone Göttlich","Manuel Schaller","Karl Worthmann"],"pdf_url":"https://arxiv.org/pdf/2403.15056v1.pdf","comment":"26 pages, 9 figures"},{"id":"http://arxiv.org/abs/2311.15587v2","updated":"2024-03-22T09:28:02Z","published":"2023-11-27T07:25:47Z","title":"Quantum Langevin Dynamics for Optimization","summary":"  We initiate the study of utilizing Quantum Langevin Dynamics (QLD) to solve\noptimization problems, particularly those non-convex objective functions that\npresent substantial obstacles for traditional gradient descent algorithms.\nSpecifically, we examine the dynamics of a system coupled with an infinite heat\nbath. This interaction induces both random quantum noise and a deterministic\ndamping effect to the system, which nudge the system towards a steady state\nthat hovers near the global minimum of objective functions. We theoretically\nprove the convergence of QLD in convex landscapes, demonstrating that the\naverage energy of the system can approach zero in the low temperature limit\nwith an exponential decay rate correlated with the evolution time. Numerically,\nwe first show the energy dissipation capability of QLD by retracing its origins\nto spontaneous emission. Furthermore, we conduct detailed discussion of the\nimpact of each parameter. Finally, based on the observations when comparing QLD\nwith classical Fokker-Plank-Smoluchowski equation, we propose a time-dependent\nQLD by making temperature and $\\hbar$ time-dependent parameters, which can be\ntheoretically proven to converge better than the time-independent case and also\noutperforms a series of state-of-the-art quantum and classical optimization\nalgorithms in many non-convex landscapes.\n","authors":["Zherui Chen","Yuchen Lu","Hao Wang","Yizhou Liu","Tongyang Li"],"pdf_url":"https://arxiv.org/pdf/2311.15587v2.pdf","comment":"52 pages, 1 table, 25 figures"},{"id":"http://arxiv.org/abs/2403.15055v1","updated":"2024-03-22T09:27:34Z","published":"2024-03-22T09:27:34Z","title":"Optimal control of gradient flows via the Weighted Energy-Dissipation\n  method","summary":"  We consider a general optimal control problem in the setting of gradient\nflows. Two approximations of the problem are presented, both relying on the\nvariational reformulation of gradient-flow dynamics via the\nWeighted-Energy-Dissipation variational approach. This consists in the\nminimization of global-in-time functionals over trajectories, combined with a\nlimit passage. We show that the original nonpenalized problem and the two\nsuccessive approximations admits solutions. Moreover, resorting to a\n$\\Gamma$-convergence analysis we show that penalised optimal controls converge\nto nonpenalized one as the approximation is removed.\n","authors":["Takeshi Fukao","Ulisse Stefanelli","Riccardo Voso"],"pdf_url":"https://arxiv.org/pdf/2403.15055v1.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2403.15024v1","updated":"2024-03-22T08:13:09Z","published":"2024-03-22T08:13:09Z","title":"Riemannian Optimization and the Hartree-Fock Method","summary":"  In the present work we studied a subfield of Applied Mathematics called\nRiemannian Optimization. The main goal of this subfield is to generalize\nalgorithms, theorems and tools from Mathematical Optimization to the case in\nwhich the optimization problem is defined on a Riemannian manifold. As a case\nstudy, we implemented some of the main algorithms described in the literature\n(Gradient Descent, Newton-Raphson and Conjugate Gradient) to solve an\noptimization problem known as Hartree-Fock. This method is extremely important\nin the field of Computational Quantum Chemistry and it is a good case study\nbecause it is a problem somewhat hard to solve and, as a consequence of this,\nit requires many tools from Riemannian Optimization. Besides, it is also a good\nexample to see how these algorithms perform in practice.\n","authors":["Caio O. da Silva"],"pdf_url":"https://arxiv.org/pdf/2403.15024v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14981v1","updated":"2024-03-22T06:30:13Z","published":"2024-03-22T06:30:13Z","title":"Extragradient Sliding for Composite Non-Monotone Variational\n  Inequalities","summary":"  Variational inequalities offer a versatile and straightforward approach to\nanalyzing a broad range of equilibrium problems in both theoretical and\npractical fields. In this paper, we consider a composite generally non-monotone\nvariational inequality represented as a sum of $L_q$-Lipschitz monotone and\n$L_p$-Lipschitz generally non-monotone operators. We applied a special sliding\nversion of the classical Extragradient method to this problem and obtain better\nconvergence results. In particular, to achieve $\\varepsilon$-accuracy of the\nsolution, the oracle complexity of the non-monotone operator $Q$ for our\nalgorithm is $O\\left(L_p^2/\\varepsilon^2\\right)$ in contrast to the basic\nExtragradient algorithm with $O\\left((L_p+L_q)^2/\\varepsilon^2\\right)$. The\nresults of numerical experiments confirm the theoretical findings and show the\nsuperiority of the proposed method.\n","authors":["Roman Emelyanov","Andrey Tikhomirov","Aleksandr Beznosikov","Alexander Gasnikov"],"pdf_url":"https://arxiv.org/pdf/2403.14981v1.pdf","comment":"12 pages, 1 algorithm, 3 figures"},{"id":"http://arxiv.org/abs/2403.14960v1","updated":"2024-03-22T05:28:21Z","published":"2024-03-22T05:28:21Z","title":"Model Construction for Convex-Constrained Derivative-Free Optimization","summary":"  We develop a new approximation theory for linear and quadratic interpolation\nmodels, suitable for use in convex-constrained derivative-free optimization\n(DFO). Most existing model-based DFO methods for constrained problems assume\nthe ability to construct sufficiently accurate approximations via\ninterpolation, but the standard notions of accuracy (designed for unconstrained\nproblems) may not be achievable by only sampling feasible points, and so may\nnot give practical algorithms. This work extends the theory of\nconvex-constrained linear interpolation developed in [Hough & Roberts, SIAM J.\nOptim, 32:4 (2022), pp. 2552-2579] to the case of linear regression models and\nunderdetermined quadratic interpolation models.\n","authors":["Lindon Roberts"],"pdf_url":"https://arxiv.org/pdf/2403.14960v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14958v1","updated":"2024-03-22T05:23:31Z","published":"2024-03-22T05:23:31Z","title":"Adapprox: Adaptive Approximation in Adam Optimization via Randomized\n  Low-Rank Matrices","summary":"  As deep learning models exponentially increase in size, optimizers such as\nAdam encounter significant memory consumption challenges due to the storage of\nfirst and second moment data. Current memory-efficient methods like Adafactor\nand CAME often compromise accuracy with their matrix factorization techniques.\nAddressing this, we introduce Adapprox, a novel approach that employs\nrandomized low-rank matrix approximation for a more effective and accurate\napproximation of Adam's second moment. Adapprox features an adaptive rank\nselection mechanism, finely balancing accuracy and memory efficiency, and\nincludes an optional cosine similarity guidance strategy to enhance stability\nand expedite convergence. In GPT-2 training and downstream tasks, Adapprox\nsurpasses AdamW by achieving 34.5% to 49.9% and 33.8% to 49.9% memory savings\nfor the 117M and 345M models, respectively, with the first moment enabled, and\nfurther increases these savings without the first moment. Besides, it enhances\nconvergence speed and improves downstream task performance relative to its\ncounterparts.\n","authors":["Pengxiang Zhao","Ping Li","Yingjie Gu","Yi Zheng","Stephan Ludger Kölker","Zhefeng Wang","Xiaoming Yuan"],"pdf_url":"https://arxiv.org/pdf/2403.14958v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14935v1","updated":"2024-03-22T03:37:53Z","published":"2024-03-22T03:37:53Z","title":"Data-Driven Predictive Control with Adaptive Disturbance Attenuation for\n  Constrained Systems","summary":"  In this paper, we propose a novel data-driven predictive control approach for\nsystems subject to time-domain constraints. The approach combines the strengths\nof H-infinity control for rejecting disturbances and MPC for handling\nconstraints. In particular, the approach can dynamically adapt H-infinity\ndisturbance attenuation performance depending on measured system state and\nforecasted disturbance level to satisfy constraints. We establish theoretical\nproperties of the approach including robust guarantees of closed-loop\nstability, disturbance attenuation, constraint satisfaction under noisy data,\nas well as sufficient conditions for recursive feasibility, and illustrate the\napproach with a numerical example.\n","authors":["Nan Li","Ilya Kolmanovsky","Hong Chen"],"pdf_url":"https://arxiv.org/pdf/2403.14935v1.pdf","comment":"11 pages, 2 figures"},{"id":"http://arxiv.org/abs/2403.14934v1","updated":"2024-03-22T03:31:11Z","published":"2024-03-22T03:31:11Z","title":"A Stochastic Model-Based Control Methodology for Glycemic Management in\n  the Intensive Care Unit","summary":"  Intensive care unit (ICU) patients exhibit erratic blood glucose (BG)\nfluctuations, including hypoglycemic and hyperglycemic episodes, and require\nexogenous insulin delivery to keep their BG in healthy ranges. Glycemic control\nvia glycemic management (GM) is associated with reduced mortality and morbidity\nin the ICU, but GM increases the cognitive load on clinicians. The availability\nof robust, accurate, and actionable clinical decision support (CDS) tools\nreduces this burden and assists in the decision-making process to improve\nhealth outcomes. Clinicians currently follow GM protocol flow charts for\npatient intravenous insulin delivery rate computations. We present a\nmechanistic model-based control algorithm that predicts the optimal intravenous\ninsulin rate to keep BG within a target range; the goal is to develop this\napproach for eventual use within CDS systems. In this control framework, we\nemployed a stochastic model representing BG dynamics in the ICU setting and\nused the linear quadratic Gaussian control methodology to develop a controller.\nWe designed two experiments, one using virtual (simulated) patients and one\nusing a real-world retrospective dataset. Using these, we evaluate the safety\nand efficacy of this model-based glycemic control methodology. The presented\ncontroller avoids hypoglycemia and hyperglycemia in virtual patients,\nmaintaining BG levels in the target range more consistently than two existing\nGM protocols. Moreover, this methodology could theoretically prevent a large\nproportion of hypoglycemic and hyperglycemic events recorded in a real-world\nretrospective dataset.\n","authors":["Melike Sirlanci","George Hripcsak","Cecilia C. Low Wang","J. N. Stroh","Yanran Wang","Tellen D. Bennett","Andrew M. Stuart","David J. Albers"],"pdf_url":"https://arxiv.org/pdf/2403.14934v1.pdf","comment":"14 pages, 4 figures, 5 tables"},{"id":"http://arxiv.org/abs/2403.14924v1","updated":"2024-03-22T02:58:00Z","published":"2024-03-22T02:58:00Z","title":"Anderson acceleration of derivative-free projection methods for\n  constrained monotone nonlinear equations","summary":"  The derivative-free projection method (DFPM) is an efficient algorithm for\nsolving monotone nonlinear equations. As problems grow larger, there is a\nstrong demand for speeding up the convergence of DFPM. This paper considers the\napplication of Anderson acceleration (AA) to DFPM for constrained monotone\nnonlinear equations. By employing a nonstationary relaxation parameter and\ninterleaving with slight modifications in each iteration, a globally convergent\nvariant of AA for DFPM named as AA-DFPM is proposed. Further, the linear\nconvergence rate is proved under some mild assumptions. Experiments on both\nmathematical examples and a real-world application show encouraging results of\nAA-DFPM and confirm the suitability of AA for accelerating DFPM in solving\noptimization problems.\n","authors":["Jiachen Jin","Hongxia Wang","Kangkang Deng"],"pdf_url":"https://arxiv.org/pdf/2403.14924v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14915v1","updated":"2024-03-22T02:37:44Z","published":"2024-03-22T02:37:44Z","title":"Network Learning with Directional Sign Patterns","summary":"  Complex systems can be effectively modeled via graphs that encode networked\ninteractions, where relations between entities or nodes are often quantified by\nsigned edge weights, e.g., promotion/inhibition in gene regulatory networks, or\nencoding political of friendship differences in social networks. However, it is\noften the case that only an aggregate consequence of such edge weights that\ncharacterize relations may be directly observable, as in protein expression of\nin gene regulatory networks. Thus, learning edge weights poses a significant\nchallenge that is further exacerbated for intricate and large-scale networks.\nIn this article, we address a model problem to determine the strength of\nsign-indefinite relations that explain marginal distributions that constitute\nour data. To this end, we develop a paradigm akin to that of the Schr\\\"odinger\nbridge problem and an efficient Sinkhorn type algorithm (more properly,\nSchr\\\"odinger-Fortet-Sinkhorn algorithm) that allows fast convergence to\nparameters that minimize a relative entropy/likelihood criterion between the\nsought signed adjacency matrix and a prior. The formalism that we present\nrepresents a novel generalization of the earlier Schr\\\"odinger formalism in\nthat marginal computations may incorporate weights that model directionality in\nunderlying relations, and further, that it can be extended to high-order\nnetworks -- the Schr\\\"odinger-Fortet-Sinkhorn algorithm that we derive is\napplicable all the same and allows geometric convergence to a sought\nsign-indefinite adjacency matrix or tensor, for high-order networks. We\ndemonstrate our framework with synthetic and real-world examples.\n","authors":["Anqi Dong","Can Chen","Tryphon T. Georgiou"],"pdf_url":"https://arxiv.org/pdf/2403.14915v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.02485v2","updated":"2024-03-22T00:45:54Z","published":"2023-10-03T23:23:41Z","title":"Computationally Efficient Chance Constrained Covariance Control with\n  Output Feedback","summary":"  This paper studies the problem of developing computationally efficient\nsolutions for steering the distribution of the state of a stochastic, linear\ndynamical system between two boundary Gaussian distributions in the presence of\nchance-constraints on the state and control input. It is assumed that the state\nis only partially available through a measurement model corrupted with noise.\nThe filtered state is reconstructed with a Kalman filter, the chance\nconstraints are reformulated as difference of convex (DC) constraints, and the\nresulting covariance control problem is reformulated as a DC program, which is\nsolved using successive convexification. The efficiency of the proposed method\nis illustrated on a double integrator example with varying time horizons, and\nis compared to other state-of-the-art chance constrained covariance control\nmethods.\n","authors":["Joshua Pilipovsky","Panagiotis Tsiotras"],"pdf_url":"https://arxiv.org/pdf/2310.02485v2.pdf","comment":"v2, submitted to CDC '24"},{"id":"http://arxiv.org/abs/2211.06003v2","updated":"2024-03-22T00:08:32Z","published":"2022-11-11T05:06:33Z","title":"Coherent Equalization of Linear Quantum Systems","summary":"  This paper introduces a $H_\\infty$-like methodology of coherent filtering for\nequalization of passive linear quantum systems to help mitigate degrading\neffects of quantum communication channels. For such systems, which include a\nwide range of linear quantum optical devices and signals, we seek to find a\nnear optimal equalizing filter which is itself a passive quantum system. The\nproblem amounts to solving an optimization problem subject to constraints\ndictated by the requirement for the equalizer to be physically realizable. By\nformulating these constraints in the frequency domain, we show that the problem\nadmits a convex $H_\\infty$-like formulation. This allows us to derive a set of\nsuboptimal coherent equalizers using $J$-spectral factorization. An additional\nsemidefinite relaxation combined with the Nevanlinna-Pick interpolation is\nshown to lead to a tractable algorithm for the design of a near optimal\ncoherent equalizer.\n","authors":["V. Ugrinovskii","M. R. James"],"pdf_url":"https://arxiv.org/pdf/2211.06003v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15642v1","updated":"2024-03-22T22:43:03Z","published":"2024-03-22T22:43:03Z","title":"Fourier Galerkin approximation of mean field control problems","summary":"  The purpose of this work is to provide a finite dimensional approximation of\nthe solution to a mean field optimal control problem set on the $d$-dimensional\ntorus. The approximation is obtained by means of a Fourier-Galerkin method, the\nmain principle of which is to convolve probability measures on the torus by the\nDirichlet kernel or, equivalently, to truncate the Fourier expansion of\nprobability measures on the torus. However, this operation has the main feature\nnot to leave the space of probability measures invariant, which drawback is\nknow as \\textit{Gibbs}' phenomenon. In spite of this, we manage to prove that,\nfor initial conditions in the `interior' of the space of probability measures\nand for sufficiently large levels of truncation, the Fourier-Galerkin method\ninduces a new finite dimensional control problem whose trajectories take values\nin the space of probability measures with a finite number of Fourier\ncoefficients. Our main result asserts that, whenever the cost functionals are\nsmooth and convex, the distance between the optimal trajectories of the\noriginal and approximating control problems decreases at a polynomial rate as\nthe index of truncation in the Fourier-Galerkin method tends to $\\infty$. A\nsimilar result holds for the distance between the corresponding value\nfunctions. From a practical point of view, our approach provides an efficient\nstrategy to approximate mean field control optimizers by finite dimensional\nparameters and opens new perspectives for the numerical analysis of mean field\ncontrol problems. It may be also applied to discretize more general mean field\ngame systems.\n","authors":["François Delarue","Mattia Martini"],"pdf_url":"https://arxiv.org/pdf/2403.15642v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15630v1","updated":"2024-03-22T21:54:11Z","published":"2024-03-22T21:54:11Z","title":"Data-Driven Approximation of Stationary Nonlinear Filters with Optimal\n  Transport Maps","summary":"  The nonlinear filtering problem is concerned with finding the conditional\nprobability distribution (posterior) of the state of a stochastic dynamical\nsystem, given a history of partial and noisy observations. This paper presents\na data-driven nonlinear filtering algorithm for the case when the state and\nobservation processes are stationary. The posterior is approximated as the\npush-forward of an optimal transport (OT) map from a given distribution, that\nis easy to sample from, to the posterior conditioned on a truncated observation\nwindow. The OT map is obtained as the solution to a stochastic optimization\nproblem that is solved offline using recorded trajectory data from the state\nand observations. An error analysis of the algorithm is presented under the\nstationarity and filter stability assumptions, which decomposes the error into\ntwo parts related to the truncation window during training and the error due to\nthe optimization procedure. The performance of the proposed method, referred to\nas optimal transport data-driven filter (OT-DDF), is evaluated for several\nnumerical examples, highlighting its significant computational efficiency\nduring the online stage while maintaining the flexibility and accuracy of OT\nmethods in nonlinear filtering.\n","authors":["Mohammad Al-Jarrah","Bamdad Hosseini","Amirhossein Taghvaei"],"pdf_url":"https://arxiv.org/pdf/2403.15630v1.pdf","comment":"7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2309.07139v2","updated":"2024-03-22T20:49:54Z","published":"2023-09-01T16:19:27Z","title":"A Traffic Management Framework for On-Demand Urban Air Mobility Systems","summary":"  Urban Air Mobility (UAM) offers a solution to current traffic congestion by\nproviding on-demand air mobility in urban areas. Effective traffic management\nis crucial for efficient operation of UAM systems, especially for high-demand\nscenarios. In this paper, we present a centralized traffic management framework\nfor on-demand UAM systems. Specifically, we provide a scheduling policy, called\nVertiSync, which schedules the aircraft for either servicing trip requests or\nrebalancing in the system subject to aircraft safety margins and energy\nrequirements. We characterize the system-level throughput of VertiSync, which\ndetermines the demand threshold at which passenger waiting times transition\nfrom being stabilized to being increasing over time. We show that the proposed\npolicy is able to maximize throughput for sufficiently large fleet sizes. We\ndemonstrate the performance of VertiSync through a case study for the city of\nLos Angeles, and show that it significantly reduces passenger waiting times\ncompared to a first-come first-serve scheduling policy.\n","authors":["Milad Pooladsanj","Ketan Savla","Petros A. Ioannou"],"pdf_url":"https://arxiv.org/pdf/2309.07139v2.pdf","comment":"9 pages, 6 figures"},{"id":"http://arxiv.org/abs/2403.15610v1","updated":"2024-03-22T20:40:57Z","published":"2024-03-22T20:40:57Z","title":"Optimal Control of Reduced Left-Invariant Hybrid Control Systems","summary":"  Optimal control is ubiquitous in many fields of engineering. A common\ntechnique to find candidate solutions is via Pontryagin's maximum principle. An\nunfortunate aspect of this method is that the dimension of system doubles. When\nthe system evolves on a Lie group and the system is invariant under left (or\nright) translations, Lie-Poisson reduction can be applied to eliminate half of\nthe dimensions (and returning the dimension of the problem to the back to the\noriginal number).\n  Hybrid control systems are an extension of (continuous) control systems by\nallowing for sudden changes to the state. Examples of such systems include the\nbouncing ball - the velocity instantaneously jumps during a bounce, the\nthermostat - controls switch to on or off, and a sailboat undergoing tacking.\nThe goal of this work is to extend the idea of Lie-Poisson reduction to the\noptimal control of these systems. If $n$ is the dimension of the original\nsystem, $2n$ is the dimension of the system produced by the maximum principle.\nIn the case of classical Lie-Poisson reduction, the dimension drops back down\nto $n$. This, unfortunately, is impossible in hybrid systems as there must be\nan auxiliary variable encoding whether or not an event occurs. As such, the\nanalogous hybrid Lie-Poisson reduction results in a $n+1$ dimensional system.\nThe purpose of this work is to develop and present this technique.\n","authors":["William Clark","Maria Oprea"],"pdf_url":"https://arxiv.org/pdf/2403.15610v1.pdf","comment":"Submitted for a conference. 6 pages"},{"id":"http://arxiv.org/abs/2403.15592v1","updated":"2024-03-22T19:40:49Z","published":"2024-03-22T19:40:49Z","title":"A Triangular Normal Form for x-Flat Control-Affine Two-Input Systems","summary":"  This paper is devoted to normal forms for x-flat control-affine systems with\ntwo inputs. We propose a general triangular normal form which contains several\nother normal forms discussed in the literature as special cases. We derive\nconditions under which a system with given x-flat output can be transformed\ninto the proposed triangular form. Based on the triangular form we motivate a\nsimple algorithm for identifying candidates for flat outputs.\n","authors":["Conrad Gstöttner","Bernd Kolar","Markus Schöberl"],"pdf_url":"https://arxiv.org/pdf/2403.15592v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15563v1","updated":"2024-03-22T18:33:46Z","published":"2024-03-22T18:33:46Z","title":"Sparse additive function decompositions facing basis transforms","summary":"  High-dimensional real-world systems can often be well characterized by a\nsmall number of simultaneous low-complexity interactions. The analysis of\nvariance (ANOVA) decomposition and the anchored decomposition are typical\ntechniques to find sparse additive decompositions of functions. In this paper,\nwe are interested in a setting, where these decompositions are not directly\nspare, but become so after an appropriate basis transform. Noting that the\nsparsity of those additive function decompositions is equivalent to the fact\nthat most of its mixed partial derivatives vanish, we can exploit a connection\nto the underlying function graphs to determine an orthogonal transform that\nrealizes the appropriate basis change. This is done in three steps: we apply\nsingular value decomposition to minimize the number of vertices of the function\ngraph, and joint block diagonalization techniques of families of matrices\nfollowed by sparse minimization based on relaxations of the zero ''norm'' for\nminimizing the number of edges. For the latter one, we propose and analyze\nminimization techniques over the manifold of special orthogonal matrices.\nVarious numerical examples illustrate the reliability of our approach for\nfunctions having, after a basis transform, a sparse additive decomposition into\nsummands with at most two variables.\n","authors":["Fatima Antarou Ba","Oleh Melnyk","Christian Wald","Gabriele Steidl"],"pdf_url":"https://arxiv.org/pdf/2403.15563v1.pdf","comment":"46 pages, 10 figures, 8 tables"}],"Systems and Control":[{"id":"http://arxiv.org/abs/2403.15380v1","updated":"2024-03-22T17:58:45Z","published":"2024-03-22T17:58:45Z","title":"Control Designs for Critical-Continegency Responsible Grid-Following\n  Inverters and Seamless Transitions To and From Grid-Forming Modes","summary":"  This article introduces two control frameworks: one for Grid-Following (GFL)\ninverters aiding Grid-Forming (GFM) inverters in voltage regulation during\nlarge contingency events and optimizing power transactions under normal\nconditions; and another for seamless transitions between grid-tied and\ngrid-isolated setups, managing voltage transient characteristics. In\nmicrogrids, GFM inverters regulate voltage, while GFL inverters handle power\ntransactions. The proposed GFL control detects abrupt load/generation changes,\nadjusting power transactions using local storage to support GFM inverters\nduring contingencies. Additionally, a transition control ensures smooth GFL-GFM\nshifts, reducing power and voltage fluctuations. Simulation results validate\nimproved voltage regulation during contingencies and enhanced power tracking\nduring slow changes, alongside minimized transient overshoot.\n","authors":["Jaesang Park","Alireza Askarian","Srinivasa Salapaka"],"pdf_url":"https://arxiv.org/pdf/2403.15380v1.pdf","comment":"6 pages, 6 figures, submitted and accepted for 2024 American Control\n  Conference (ACC)"},{"id":"http://arxiv.org/abs/2403.15363v1","updated":"2024-03-22T17:31:21Z","published":"2024-03-22T17:31:21Z","title":"Cascading Blackout Severity Prediction with Statistically-Augmented\n  Graph Neural Networks","summary":"  Higher variability in grid conditions, resulting from growing renewable\npenetration and increased incidence of extreme weather events, has increased\nthe difficulty of screening for scenarios that may lead to catastrophic\ncascading failures. Traditional power-flow-based tools for assessing cascading\nblackout risk are too slow to properly explore the space of possible failures\nand load/generation patterns. We add to the growing literature of faster\ngraph-neural-network (GNN)-based techniques, developing two novel techniques\nfor the estimation of blackout magnitude from initial grid conditions. First we\npropose several methods for employing an initial classification step to filter\nout safe \"non blackout\" scenarios prior to magnitude estimation. Second, using\ninsights from the statistical properties of cascading blackouts, we propose a\nmethod for facilitating non-local message passing in our GNN models. We\nvalidate these two approaches on a large simulated dataset, and show the\npotential of both to increase blackout size estimation performance.\n","authors":["Joe Gorka","Tim Hsu","Wenting Li","Yury Maximov","Line Roald"],"pdf_url":"https://arxiv.org/pdf/2403.15363v1.pdf","comment":"Accepted to Power Systems Computation Conference (PSCC) 2024"},{"id":"http://arxiv.org/abs/2312.00812v4","updated":"2024-03-22T17:29:01Z","published":"2023-11-28T03:13:09Z","title":"Empowering Autonomous Driving with Large Language Models: A Safety\n  Perspective","summary":"  Autonomous Driving (AD) encounters significant safety hurdles in long-tail\nunforeseen driving scenarios, largely stemming from the non-interpretability\nand poor generalization of the deep neural networks within the AD system,\nparticularly in out-of-distribution and uncertain data. To this end, this paper\nexplores the integration of Large Language Models (LLMs) into AD systems,\nleveraging their robust common-sense knowledge and reasoning abilities. The\nproposed methodologies employ LLMs as intelligent decision-makers in behavioral\nplanning, augmented with a safety verifier shield for contextual safety\nlearning, for enhancing driving performance and safety. We present two key\nstudies in a simulated environment: an adaptive LLM-conditioned Model\nPredictive Control (MPC) and an LLM-enabled interactive behavior planning\nscheme with a state machine. Demonstrating superior performance and safety\nmetrics compared to state-of-the-art approaches, our approach shows the\npromising potential for using LLMs for autonomous vehicles.\n","authors":["Yixuan Wang","Ruochen Jiao","Sinong Simon Zhan","Chengtian Lang","Chao Huang","Zhaoran Wang","Zhuoran Yang","Qi Zhu"],"pdf_url":"https://arxiv.org/pdf/2312.00812v4.pdf","comment":"Accepted to LLMAgent workshop @ICLR2024"},{"id":"http://arxiv.org/abs/2403.15360v1","updated":"2024-03-22T17:22:56Z","published":"2024-03-22T17:22:56Z","title":"SiMBA: Simplified Mamba-Based Architecture for Vision and Multivariate\n  Time series","summary":"  Transformers have widely adopted attention networks for sequence mixing and\nMLPs for channel mixing, playing a pivotal role in achieving breakthroughs\nacross domains. However, recent literature highlights issues with attention\nnetworks, including low inductive bias and quadratic complexity concerning\ninput sequence length. State Space Models (SSMs) like S4 and others (Hippo,\nGlobal Convolutions, liquid S4, LRU, Mega, and Mamba), have emerged to address\nthe above issues to help handle longer sequence lengths. Mamba, while being the\nstate-of-the-art SSM, has a stability issue when scaled to large networks for\ncomputer vision datasets. We propose SiMBA, a new architecture that introduces\nEinstein FFT (EinFFT) for channel modeling by specific eigenvalue computations\nand uses the Mamba block for sequence modeling. Extensive performance studies\nacross image and time-series benchmarks demonstrate that SiMBA outperforms\nexisting SSMs, bridging the performance gap with state-of-the-art transformers.\nNotably, SiMBA establishes itself as the new state-of-the-art SSM on ImageNet\nand transfer learning benchmarks such as Stanford Car and Flower as well as\ntask learning benchmarks as well as seven time series benchmark datasets. The\nproject page is available on this website\n~\\url{https://github.com/badripatro/Simba}.\n","authors":["Badri N. Patro","Vijay S. Agneeswaran"],"pdf_url":"https://arxiv.org/pdf/2403.15360v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14372v2","updated":"2024-03-22T17:03:09Z","published":"2024-03-21T13:02:14Z","title":"A Benchmark for the Application of Distributed Control Techniques to the\n  Electricity Network of the European Economic Area","summary":"  The European Economic Area Electricity Network Benchmark (EEA-ENB) is a\nmulti-area power system representing the European network of transmission\nsystems for electricity to facilitate the application of distributed control\ntechniques. In the EEA-ENB we consider the Load Frequency Control (LFC) problem\nin the presence of renewable energy sources (RESs), and energy storage systems\n(ESSs). RESs are known to cause instability in power networks due to their\ninertia-less and intermittent characteristics, while ESSs are introduced as a\nresource to mitigate the problem. In the EEA-ENB, particular attention is\ndedicated to Distributed Model Predictive Control (DMPC), whose application is\noften limited to small and homogeneous test cases due to the lack of\nstandardized large-scale scenarios for testing, and due to the large\ncomputation time required to obtain a centralized MPC action for performance\ncomparison with DMPC strategies under consideration. The second problem is\nexacerbated when the scale of the system grows. To address these challenges and\nto provide a real-world-based and control-independent benchmark, the EEA-ENB\nhas been developed. The benchmark includes a centralized MPC strategy providing\nperformance and computation time metrics to compare distributed control within\na repeatable and realistic simulation environment.\n","authors":["A. Riccardi","L. Laurenti","B. De Schutter"],"pdf_url":"https://arxiv.org/pdf/2403.14372v2.pdf","comment":"Updated reference list with reference and DOI to software sources to\n  run the benchmark"},{"id":"http://arxiv.org/abs/2403.15344v1","updated":"2024-03-22T16:55:01Z","published":"2024-03-22T16:55:01Z","title":"Optimal Exploration Strategy for Regret Minimization in Unconstrained\n  Scalar Optimization Problems","summary":"  We study the problem of determining the optimal exploration strategy in an\nunconstrained scalar optimization problem depending on an unknown parameter to\nbe learned from online collected noisy data. An optimal trade-off between\nexploration and exploitation is crucial for effective optimization under\nuncertainties, and to achieve this we consider a cumulative regret minimization\napproach over a finite horizon, with each time instant in the horizon\ncharacterized by a stochastic exploration signal, whose variance has to be\ndesigned. In this setting, under an idealized assumption on an appropriately\ndefined information function associated with the excitation, we are able to\nshow that the optimal exploration strategy is either to use no exploration at\nall (called lazy exploration) or adding an exploration excitation only at the\nfirst time instant of the horizon (called immediate exploration). A quadratic\nnumerical example is used to illustrate the results.\n","authors":["Ying Wang","Mirko Pasquini","Kévin Colin","Håkan Hjalmarsson"],"pdf_url":"https://arxiv.org/pdf/2403.15344v1.pdf","comment":"Preprint submitted to IEEE Conference on Decision and Control (CDC\n  2024)"},{"id":"http://arxiv.org/abs/2403.15329v1","updated":"2024-03-22T16:35:24Z","published":"2024-03-22T16:35:24Z","title":"Optimal Data-Driven Prediction and Predictive Control using Signal\n  Matrix Models","summary":"  Data-driven control uses a past signal trajectory to characterise the\ninput-output behaviour of a system. Willems' lemma provides a data-based\nprediction model allowing a control designer to bypass the step of identifying\na state-space or transfer function model. This paper provides a more\nparsimonious formulation of Willems' lemma that separates the model into\ninitial condition matching and predictive control design parts. This avoids the\nneed for regularisers in the predictive control problem that are found in other\ndata-driven predictive control methods. It also gives a closed form expression\nfor the optimal (minimum variance) unbiased predictor of the future output\ntrajectory and applies it for predictive control. Simulation comparisons\nillustrate very good control performance.\n","authors":["Roy S. Smith","Mohamed Abdalmoaty","Mingzhou Yin"],"pdf_url":"https://arxiv.org/pdf/2403.15329v1.pdf","comment":"7 pages, 3 figures. Submitted to IEEE Control Systems Society Letters\n  and the 2024 Conference on Decision and Control"},{"id":"http://arxiv.org/abs/2310.08731v2","updated":"2024-03-22T16:30:48Z","published":"2023-10-12T21:38:07Z","title":"Novelty Detection in Reinforcement Learning with World Models","summary":"  Reinforcement learning (RL) using world models has found significant recent\nsuccesses. However, when a sudden change to world mechanics or properties\noccurs then agent performance and reliability can dramatically decline. We\nrefer to the sudden change in visual properties or state transitions as\nnovelties. Implementing novelty detection within generated world model\nframeworks is a crucial task for protecting the agent when deployed. In this\npaper, we propose straightforward bounding approaches to incorporate novelty\ndetection into world model RL agents, by utilizing the misalignment of the\nworld model's hallucinated states and the true observed states as an anomaly\nscore. We provide effective approaches to detecting novelties in a distribution\nof transitions learned by an agent in a world model. Finally, we show the\nadvantage of our work in a novel environment compared to traditional machine\nlearning novelty detection methods as well as currently accepted RL focused\nnovelty detection algorithms.\n","authors":["Geigh Zollicoffer","Kenneth Eaton","Jonathan Balloch","Julia Kim","Mark O. Riedl","Robert Wright"],"pdf_url":"https://arxiv.org/pdf/2310.08731v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.05645v3","updated":"2024-03-22T16:22:32Z","published":"2021-12-10T16:17:49Z","title":"Graph-structured tensor optimization for nonlinear density control and\n  mean field games","summary":"  In this work we develop a numerical method for solving a type of convex\ngraph-structured tensor optimization problems. This type of problems, which can\nbe seen as a generalization of multi-marginal optimal transport problems with\ngraph-structured costs, appear in many applications. Examples are unbalanced\noptimal transport and multi-species potential mean field games, where the\nlatter is a class of nonlinear density control problems. The method we develop\nis based on coordinate ascent in a Lagrangian dual, and under mild assumptions\nwe prove that the algorithm converges globally. Moreover, under a set of\nstricter assumptions, the algorithm converges R-linearly. To perform the\ncoordinate ascent steps one has to compute projections of the tensor, and doing\nso by brute force is in general not computationally feasible. Nevertheless, for\ncertain graph structures it is possible to derive efficient methods for\ncomputing these projections, and here we specifically consider the graph\nstructure that occurs in multi-species potential mean field games. We also\nillustrate the methodology on a numerical example from this problem class.\n","authors":["Axel Ringh","Isabel Haasler","Yongxin Chen","Johan Karlsson"],"pdf_url":"https://arxiv.org/pdf/2112.05645v3.pdf","comment":"27 pages. Revision: among other things, the section on Convex dynamic\n  network flow problems has been removed, and the section on Multi-species\n  potential mean field games has been expanded"},{"id":"http://arxiv.org/abs/2403.15289v1","updated":"2024-03-22T15:37:33Z","published":"2024-03-22T15:37:33Z","title":"Event-Triggered State Estimation Through Confidence Level","summary":"  This paper considers the state estimation problem for discrete-time linear\nsystems under event-triggered scheme. In order to improve performance, a novel\nevent-triggered scheme based on confidence level is proposed using the\nchi-square distribution and mild regularity assumption. In terms of the novel\nevent-triggered scheme, a minimum mean squared error (MMSE) state estimator is\nproposed using some results presented in this paper. Two algorithms for\ncommunication rate estimation of the proposed MMSE state estimator are\ndeveloped where the first algorithm is based on information with one-step\ndelay, and the second algorithm is based on information with two-step delay.\nThe performance and effectiveness of the proposed MMSE state estimator and the\ntwo communication rate estimation algorithms are illustrated using a target\ntracking scenario.\n","authors":["Wei Liu"],"pdf_url":"https://arxiv.org/pdf/2403.15289v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.09217v2","updated":"2024-03-22T15:35:48Z","published":"2024-02-14T14:54:36Z","title":"Inferentialist Resource Semantics","summary":"  In systems modelling, a system typically comprises located resources relative\nto which processes execute. One important use of logic in informatics is in\nmodelling such systems for the purpose of reasoning (perhaps automated) about\ntheir behaviour and properties. To this end, one requires an interpretation of\nlogical formulae in terms of the resources and states of the system; such an\ninterpretation is called a resource semantics of the logic. This paper shows\nhow inferentialism -- the view that meaning is given in terms of inferential\nbehaviour -- enables a versatile and expressive framework for resource\nsemantics. Specifically, how inferentialism seamlessly incorporates the\nassertion-based approach of the logic of Bunched Implications, foundational in\nprogram verification (e.g., as the basis of Separation Logic), and the renowned\nnumber-of-uses reading of Linear Logic. This integration enables reasoning\nabout shared and separated resources in intuitive and familiar ways, as well as\nabout the composition and interfacing of system components.\n","authors":["Alexander V. Gheorghiu","Tao Gu","David J. Pym"],"pdf_url":"https://arxiv.org/pdf/2402.09217v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15264v1","updated":"2024-03-22T15:02:31Z","published":"2024-03-22T15:02:31Z","title":"Control contraction metrics on Lie groups","summary":"  In this paper, we extend the control contraction metrics (CCM) approach,\nwhich was originally proposed for the universal tracking control of nonlinear\nsystems, to those that evolves on Lie groups. Our idea is to view the manifold\nas a constrained set that is embedded in Euclidean space, and then propose the\nsufficient conditions for the existence of a CCM and the associated controller\ndesign. Notably, we demonstrate that the search for CCM on Lie groups can be\nreformulated as convex conditions. The results extend the applicability of the\nCCM approach and provide a framework for analyzing the behavior of control\nsystems with Lie group structures.\n","authors":["Dongjun Wu","Bowen Yi","Ian R. Manchester"],"pdf_url":"https://arxiv.org/pdf/2403.15264v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.12973v2","updated":"2024-03-22T15:00:47Z","published":"2023-12-20T12:31:28Z","title":"Sparse Mean Field Load Balancing in Large Localized Queueing Systems","summary":"  Scalable load balancing algorithms are of great interest in cloud networks\nand data centers, necessitating the use of tractable techniques to compute\noptimal load balancing policies for good performance. However, most existing\nscalable techniques, especially asymptotically scaling methods based on mean\nfield theory, have not been able to model large queueing networks with strong\nlocality. Meanwhile, general multi-agent reinforcement learning techniques can\nbe hard to scale and usually lack a theoretical foundation. In this work, we\naddress this challenge by leveraging recent advances in sparse mean field\ntheory to learn a near-optimal load balancing policy in sparsely connected\nqueueing networks in a tractable manner, which may be preferable to global\napproaches in terms of wireless communication overhead. Importantly, we obtain\na general load balancing framework for a large class of sparse bounded-degree\nwireless topologies. By formulating a novel mean field control problem in the\ncontext of graphs with bounded degree, we reduce the otherwise difficult\nmulti-agent problem to a single-agent problem. Theoretically, the approach is\njustified by approximation guarantees. Empirically, the proposed methodology\nperforms well on several realistic and scalable wireless network topologies as\ncompared to a number of well-known load balancing heuristics and existing\nscalable multi-agent reinforcement learning methods.\n","authors":["Anam Tahir","Kai Cui","Heinz Koeppl"],"pdf_url":"https://arxiv.org/pdf/2312.12973v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13346v2","updated":"2024-03-22T14:39:26Z","published":"2024-03-20T07:10:22Z","title":"A Control-Recoverable Added-Noise-based Privacy Scheme for LQ Control in\n  Networked Control Systems","summary":"  As networked control systems continue to evolve, ensuring the privacy of\nsensitive data becomes an increasingly pressing concern, especially in\nsituations where the controller is physically separated from the plant. In this\npaper, we propose a secure control scheme for computing linear quadratic\ncontrol in a networked control system utilizing two networked controllers, a\nprivacy encoder and a control restorer. Specifically, the encoder generates two\nstate signals blurred with random noise and sends them to the controllers,\nwhile the restorer reconstructs the correct control signal. The proposed design\neffectively preserves the privacy of the control system's state without\nsacrificing the control performance. We theoretically quantify the\nprivacy-preserving performance in terms of the state estimation error of the\ncontrollers and the disclosure probability. Additionally, the proposed\nprivacy-preserving scheme is also proven to satisfy differential privacy.\nMoreover, we extend the proposed privacy-preserving scheme and evaluation\nmethod to cases where collusion between two controllers occurs. Finally, we\nverify the validity of our proposed scheme through simulations.\n","authors":["Xuening Tang","Xianghui Cao","Wei Xing Zheng"],"pdf_url":"https://arxiv.org/pdf/2403.13346v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15228v1","updated":"2024-03-22T14:21:14Z","published":"2024-03-22T14:21:14Z","title":"On moment relaxations for linear state feedback controller synthesis\n  with non-convex quadratic costs and constraints","summary":"  We present a simple and effective way to account for non-convex costs and\nconstraints~in~state feedback synthesis, and an interpretation for the\nvariables in which state feedback synthesis is typically convex. We achieve\nthis by deriving the controller design using moment matrices of state and\ninput. It turns out that this approach allows the consideration of non-convex\nconstraints by relaxing them as expectation constraints, and that the variables\nin which state feedback synthesis is typically convexified can be identified\nwith blocks of these moment matrices.\n","authors":["Dennis Gramlich","Sheng Gao","Hao Zhang","Carsten W. Scherer","Christian Ebenbauer"],"pdf_url":"https://arxiv.org/pdf/2403.15228v1.pdf","comment":"Preprent to be submitted to IEEE Conference on Decision and Control"},{"id":"http://arxiv.org/abs/2308.01674v3","updated":"2024-03-22T13:51:19Z","published":"2023-08-03T10:21:53Z","title":"End-to-End Reinforcement Learning of Koopman Models for Economic\n  Nonlinear Model Predictive Control","summary":"  (Economic) nonlinear model predictive control ((e)NMPC) requires dynamic\nmodels that are sufficiently accurate and computationally tractable.\nData-driven surrogate models for mechanistic models can reduce the\ncomputational burden of (e)NMPC; however, such models are typically trained by\nsystem identification for maximum prediction accuracy on simulation samples and\nperform suboptimally in (e)NMPC. We present a method for end-to-end\nreinforcement learning of Koopman surrogate models for optimal performance as\npart of (e)NMPC. We apply our method to two applications derived from an\nestablished nonlinear continuous stirred-tank reactor model. The controller\nperformance is compared to that of (e)NMPCs utilizing models trained using\nsystem identification, and model-free neural network controllers trained using\nreinforcement learning. We show that the end-to-end trained models outperform\nthose trained using system identification in (e)NMPC, and that, in contrast to\nthe neural network controllers, the (e)NMPC controllers can react to changes in\nthe control setting without retraining.\n","authors":["Daniel Mayfrank","Alexander Mitsos","Manuel Dahmen"],"pdf_url":"https://arxiv.org/pdf/2308.01674v3.pdf","comment":"manuscript (18 pages, 7 figures, 5 tables), supplementary materials\n  (3 pages, 2 tables)"},{"id":"http://arxiv.org/abs/2403.15207v1","updated":"2024-03-22T13:49:53Z","published":"2024-03-22T13:49:53Z","title":"Robust optimization for adversarial learning with finite sample\n  complexity guarantees","summary":"  Decision making and learning in the presence of uncertainty has attracted\nsignificant attention in view of the increasing need to achieve robust and\nreliable operations. In the case where uncertainty stems from the presence of\nadversarial attacks this need is becoming more prominent. In this paper we\nfocus on linear and nonlinear classification problems and propose a novel\nadversarial training method for robust classifiers, inspired by Support Vector\nMachine (SVM) margins. We view robustness under a data driven lens, and derive\nfinite sample complexity bounds for both linear and non-linear classifiers in\nbinary and multi-class scenarios. Notably, our bounds match natural\nclassifiers' complexity. Our algorithm minimizes a worst-case surrogate loss\nusing Linear Programming (LP) and Second Order Cone Programming (SOCP) for\nlinear and non-linear models. Numerical experiments on the benchmark MNIST and\nCIFAR10 datasets show our approach's comparable performance to state-of-the-art\nmethods, without needing adversarial examples during training. Our work offers\na comprehensive framework for enhancing binary linear and non-linear classifier\nrobustness, embedding robustness in learning under the presence of adversaries.\n","authors":["André Bertolace","Konstatinos Gatsis","Kostas Margellos"],"pdf_url":"https://arxiv.org/pdf/2403.15207v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15189v1","updated":"2024-03-22T13:18:45Z","published":"2024-03-22T13:18:45Z","title":"Forecasting the load of Parcel Pickup Points using a Markov Jump Process","summary":"  The growth of e-commerce has resulted in a surge in parcel deliveries,\nincreasing transportation costs and pollution issues. Alternatives to home\ndelivery have emerged, such as the delivery to so-called parcel pick-up points\n(PUPs), which eliminates delivery failure due to customers not being at home.\nNevertheless, parcels reaching overloaded PUPs may need to be redirected to\nalternative PUPs, sometimes far from the chosen ones, which may generate\ncustomer dissatisfaction. Consequently, predicting the PUP load is critical for\na PUP management company to infer the availability of PUPs for future orders\nand better balance parcel flows between PUPs.\n  This paper proposes a new approach to forecasting the PUP load evolution\nusing a Markov jump process that models the parcel life cycle. The latest known\nstatus of each parcel is considered to estimate its contribution to the future\nload of its target PUP. This approach can account for the variability of\nactivity, the various parcel preparation delays by sellers, and the diversity\nof parcel carriers that may result in different delivery delays. Here, results\nare provided for predicting the load associated with parcels ordered from\nonline retailers by customers (Business-to-Customer, B2C). The proposed\napproach is generic and can also be applied to other parcel flows to PUPs, such\nas second-hand products (Customer-to-Customer, C2C) sent via a PUP network.\n","authors":["Thi-Thu-Tam Nguyen","Adnane Cabani","Iyadh Cabani","Koen De Turck","Michel Kieffer"],"pdf_url":"https://arxiv.org/pdf/2403.15189v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15188v1","updated":"2024-03-22T13:16:47Z","published":"2024-03-22T13:16:47Z","title":"Pursuit-Evasion on a Sphere and When It Can Be Considered Flat","summary":"  In classical works on a planar differential pursuit-evasion game with a\nfaster pursuer, the intercept point resulting from the equilibrium strategies\nlies on the Apollonius circle. This property was exploited for the construction\nof the equilibrium strategies for two faster pursuers against one evader.\nExtensions for planar multiple-pursuer single-evader scenarios have been\nconsidered. We study a pursuit-evasion game on a sphere and the relation of the\nequilibrium intercept point to the Apollonius domain on the sphere. The domain\nis a generalization of the planar Apollonius circle set. We find a condition\nresulting in the intercept point belonging to the Apollonius domain, which is\nthe characteristic of the planar game solution. Finally, we use this\ncharacteristic to discuss pursuit and evasion strategies in the context of two\npursuers and a single slower evader on the sphere and illustrate it using\nnumerical simulations.\n","authors":["Dejan Milutinovic","Alexander Von Moll","Satyanarayana G. Manyam","David W. Casbeer","Isaac E. Weintraub","Meir Pachter"],"pdf_url":"https://arxiv.org/pdf/2403.15188v1.pdf","comment":"8 Pages, 5 figures, To be submitted to 2024 Conference on Decision\n  and Control in Milan, Italy"},{"id":"http://arxiv.org/abs/2311.03821v3","updated":"2024-03-22T12:39:11Z","published":"2023-11-07T09:12:39Z","title":"Positive Competitive Networks for Sparse Reconstruction","summary":"  We propose and analyze a continuous-time firing-rate neural network, the\npositive firing-rate competitive network (\\pfcn), to tackle sparse\nreconstruction problems with non-negativity constraints. These problems, which\ninvolve approximating a given input stimulus from a dictionary using a set of\nsparse (active) neurons, play a key role in a wide range of domains, including\nfor example neuroscience, signal processing, and machine learning. First, by\nleveraging the theory of proximal operators, we relate the equilibria of a\nfamily of continuous-time firing-rate neural networks to the optimal solutions\nof sparse reconstruction problems. Then, we prove that the \\pfcn is a positive\nsystem and give rigorous conditions for the convergence to the equilibrium.\nSpecifically, we show that the convergence: (i) only depends on a property of\nthe dictionary; (ii) is linear-exponential, in the sense that initially the\nconvergence rate is at worst linear and then, after a transient, it becomes\nexponential. We also prove a number of technical results to assess the\ncontractivity properties of the neural dynamics of interest. Our analysis\nleverages contraction theory to characterize the behavior of a family of\nfiring-rate competitive networks for sparse reconstruction with and without\nnon-negativity constraints. Finally, we validate the effectiveness of our\napproach via a numerical example.\n","authors":["Veronica Centorrino","Anand Gokhale","Alexander Davydov","Giovanni Russo","Francesco Bullo"],"pdf_url":"https://arxiv.org/pdf/2311.03821v3.pdf","comment":"26 pages, 9 Figure, 1 Table"},{"id":"http://arxiv.org/abs/2403.15156v1","updated":"2024-03-22T12:11:06Z","published":"2024-03-22T12:11:06Z","title":"Infrastructure-Assisted Collaborative Perception in Automated Valet\n  Parking: A Safety Perspective","summary":"  Environmental perception in Automated Valet Parking (AVP) has been a\nchallenging task due to severe occlusions in parking garages. Although\nCollaborative Perception (CP) can be applied to broaden the field of view of\nconnected vehicles, the limited bandwidth of vehicular communications restricts\nits application. In this work, we propose a BEV feature-based CP network\narchitecture for infrastructure-assisted AVP systems. The model takes the\nroadside camera and LiDAR as optional inputs and adaptively fuses them with\nonboard sensors in a unified BEV representation. Autoencoder and downsampling\nare applied for channel-wise and spatial-wise dimension reduction, while\nsparsification and quantization further compress the feature map with little\nloss in data precision. Combining these techniques, the size of a BEV feature\nmap is effectively compressed to fit in the feasible data rate of the NR-V2X\nnetwork. With the synthetic AVP dataset, we observe that CP can effectively\nincrease perception performance, especially for pedestrians. Moreover, the\nadvantage of infrastructure-assisted CP is demonstrated in two typical\nsafety-critical scenarios in the AVP setting, increasing the maximum safe\ncruising speed by up to 3m/s in both scenarios.\n","authors":["Yukuan Jia","Jiawen Zhang","Shimeng Lu","Baokang Fan","Ruiqing Mao","Sheng Zhou","Zhisheng Niu"],"pdf_url":"https://arxiv.org/pdf/2403.15156v1.pdf","comment":"7 pages, 7 figures, 4 tables, accepted by IEEE VTC2024-Spring"},{"id":"http://arxiv.org/abs/2403.15140v1","updated":"2024-03-22T11:51:47Z","published":"2024-03-22T11:51:47Z","title":"Hybrid integrator-gain system based integral resonant controllers for\n  negative imaginary systems","summary":"  We introduce a hybrid control system called a hybrid integrator-gain system\n(HIGS) based integral resonant controller (IRC) to stabilize negative imaginary\n(NI) systems. A HIGS-based IRC has a similar structure to an IRC, with the\nintegrator replaced by a HIGS. We show that a HIGS-based IRC is an NI system.\nAlso, for a SISO NI system with a minimal realization, we show there exists a\nHIGS-based IRC such that their closed-loop interconnection is asymptotically\nstable. Also, we propose a proportional-integral-double-integral resonant\ncontroller and a HIGS-based proportional-integral-double-integral resonant\ncontroller and show that both of them can be applied to asymptotically\nstabilize an NI system. An example is provided to illustrate the proposed\nresults.\n","authors":["Kanghong Shi","Ian R. Petersen"],"pdf_url":"https://arxiv.org/pdf/2403.15140v1.pdf","comment":"9 pages, 9 figures"},{"id":"http://arxiv.org/abs/2403.15116v1","updated":"2024-03-22T11:20:30Z","published":"2024-03-22T11:20:30Z","title":"Collision Avoidance Safety Filter for an Autonomous E-Scooter using\n  Ultrasonic Sensors","summary":"  In this paper, we propose a collision avoidance safety filter for autonomous\nelectric scooters to enable safe operation of such vehicles in pedestrian\nareas. In particular, we employ multiple low-cost ultrasonic sensors to detect\na wide range of possible obstacles in front of the e-scooter. Based on possibly\nfaulty distance measurements, we design a filter to mitigate measurement noise\nand missing values as well as a gain-scheduled controller to limit the velocity\ncommanded to the e-scooter when required due to imminent collisions. The\nproposed controller structure is able to prevent collisions with unknown\nobstacles by deploying a reduced safe velocity ensuring a sufficiently large\nsafety distance. The collision avoidance approach is designed such that it may\nbe easily deployed in similar applications of general micromobility vehicles.\nThe effectiveness of our proposed safety filter is demonstrated in real-world\nexperiments.\n","authors":["Robin Strässer","Marc Seidel","Felix Brändle","David Meister","Raffaele Soloperto","David Hambach Ferrer","Frank Allgöwer"],"pdf_url":"https://arxiv.org/pdf/2403.15116v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15113v1","updated":"2024-03-22T11:08:56Z","published":"2024-03-22T11:08:56Z","title":"Set-membership target search and tracking within an unknown cluttered\n  area using cooperating UAVs equipped with vision systems","summary":"  This paper addresses the problem of target search and tracking using a fleet\nof cooperating UAVs evolving in some unknown region of interest containing an a\npriori unknown number of moving ground targets. Each drone is equipped with an\nembedded Computer Vision System (CVS), providing an image with labeled pixels\nand a depth map of the observed part of its environment. Moreover, a box\ncontaining the corresponding pixels in the image frame is available when a UAV\nidentifies a target. Hypotheses regarding information provided by the pixel\nclassification, depth map construction, and target identification algorithms\nare proposed to allow its exploitation by set-membership approaches. A\nset-membership target location estimator is developed using the information\nprovided by the CVS. Each UAV evaluates sets guaranteed to contain the location\nof the identified targets and a set possibly containing the locations of\ntargets still to be identified. Then, each UAV uses these sets to search and\ntrack targets cooperatively.\n","authors":["Maxime Zagar","Luc Meyer","Michel Kieffer","Hélène Piet-Lahanier"],"pdf_url":"https://arxiv.org/pdf/2403.15113v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.16973v2","updated":"2024-03-22T10:27:53Z","published":"2023-06-29T14:28:22Z","title":"Robust Direct Data-Driven Control for Probabilistic Systems","summary":"  We propose a data-driven control method for systems with aleatoric\nuncertainty, for example, robot fleets with variations between agents. Our\nmethod leverages shared trajectory data to increase the robustness of the\ndesigned controller and thus facilitate transfer to new variations without the\nneed for prior parameter and uncertainty estimations. In contrast to existing\nwork on experience transfer for performance, our approach focuses on robustness\nand uses data collected from multiple realizations to guarantee generalization\nto unseen ones. Our method is based on scenario optimization combined with\nrecent formulations for direct data-driven control. We derive lower bounds on\nthe amount of data required to achieve quadratic stability for probabilistic\nsystems with aleatoric uncertainty and demonstrate the benefits of our\ndata-driven method through a numerical example. We find that the learned\ncontrollers generalize well to high variations in the dynamics even when based\non only a few short open-loop trajectories. Robust experience transfer enables\nthe design of safe and robust controllers that work out of the box without any\nadditional learning during deployment.\n","authors":["Alexander von Rohr","Dmitrii Likhachev","Sebastian Trimpe"],"pdf_url":"https://arxiv.org/pdf/2306.16973v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15091v1","updated":"2024-03-22T10:20:09Z","published":"2024-03-22T10:20:09Z","title":"Improved Long Short-Term Memory-based Wastewater Treatment Simulators\n  for Deep Reinforcement Learning","summary":"  Even though Deep Reinforcement Learning (DRL) showed outstanding results in\nthe fields of Robotics and Games, it is still challenging to implement it in\nthe optimization of industrial processes like wastewater treatment. One of the\nchallenges is the lack of a simulation environment that will represent the\nactual plant as accurately as possible to train DRL policies. Stochasticity and\nnon-linearity of wastewater treatment data lead to unstable and incorrect\npredictions of models over long time horizons. One possible reason for the\nmodels' incorrect simulation behavior can be related to the issue of\ncompounding error, which is the accumulation of errors throughout the\nsimulation. The compounding error occurs because the model utilizes its\npredictions as inputs at each time step. The error between the actual data and\nthe prediction accumulates as the simulation continues. We implemented two\nmethods to improve the trained models for wastewater treatment data, which\nresulted in more accurate simulators: 1- Using the model's prediction data as\ninput in the training step as a tool of correction, and 2- Change in the loss\nfunction to consider the long-term predicted shape (dynamics). The experimental\nresults showed that implementing these methods can improve the behavior of\nsimulators in terms of Dynamic Time Warping throughout a year up to 98%\ncompared to the base model. These improvements demonstrate significant promise\nin creating simulators for biological processes that do not need pre-existing\nknowledge of the process but instead depend exclusively on time series data\nobtained from the system.\n","authors":["Esmaeel Mohammadi","Daniel Ortiz-Arroyo","Mikkel Stokholm-Bjerregaard","Aviaja Anna Hansen","Petar Durdevic"],"pdf_url":"https://arxiv.org/pdf/2403.15091v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15072v1","updated":"2024-03-22T09:52:18Z","published":"2024-03-22T09:52:18Z","title":"Direct and Indirect Hydrogen Storage: Dynamics and Interactions in the\n  Transition to a Renewable Energy Based System for Europe","summary":"  To move towards a low-carbon society by 2050, understanding the intricate\ndynamics of energy systems is critical. Our study examines these interactions\nthrough the lens of hydrogen storage, dividing it into 'direct' and 'indirect'\nhydrogen storage. Direct hydrogen storage involves electrolysis-produced\nhydrogen being stored before use, while indirect storage first transforms\nhydrogen into gas via the Sabatier process for later energy distribution.\nFirstly, we utilize the PyPSA-Eur-Sec-30-path model to capture the interactions\nwithin the energy system. The model is an hour-level, one node per country\nsystem that encompasses a range of energy transformation technologies,\noutlining a pathway for Europe to reduce carbon emissions by 95 percent by 2050\ncompared to 1990, with updates every 5 years. Subsequently, we employ both\nquantitative and qualitative approaches to thoroughly analyze these complex\nrelationships. Our research indicates that during the European green\ntransition, cross-country flow of electricity will play an important role in\nEurope's rapid decarbonization stage before the large-scale introduction of\nenergy storage. Under the paper cost assumptions, fuel cells are not considered\na viable option. This research further identifies the significant impact of\nnatural resource variability on the local energy mix, highlighting indirect\nhydrogen storage as a common solution due to the better economic performance\nand actively fluctuation pattern. Specifically, indirect hydrogen storage will\ncontribute at least 60 percent of hydrogen storage benefits, reaching 100\npercent in Italy. Moreover, its fluctuation pattern will change with the local\nenergy structure, which is a distinct difference with the unchanged pattern of\ndirect hydrogen storage and battery storage.\n","authors":["Zhiyuan Xie","Gorm Bruun Andresen"],"pdf_url":"https://arxiv.org/pdf/2403.15072v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15067v1","updated":"2024-03-22T09:48:40Z","published":"2024-03-22T09:48:40Z","title":"A Twin Delayed Deep Deterministic Policy Gradient Algorithm for\n  Autonomous Ground Vehicle Navigation via Digital Twin Perception Awareness","summary":"  Autonomous ground vehicle (UGV) navigation has the potential to revolutionize\nthe transportation system by increasing accessibility to disabled people,\nensure safety and convenience of use. However, UGV requires extensive and\nefficient testing and evaluation to ensure its acceptance for public use. This\ntesting are mostly done in a simulator which result to sim2real transfer gap.\nIn this paper, we propose a digital twin perception awareness approach for the\ncontrol of robot navigation without prior creation of the virtual environment\n(VT) environment state. To achieve this, we develop a twin delayed deep\ndeterministic policy gradient (TD3) algorithm that ensures collision avoidance\nand goal-based path planning. We demonstrate the performance of our approach on\ndifferent environment dynamics. We show that our approach is capable of\nefficiently avoiding collision with obstacles and navigating to its desired\ndestination, while at the same time safely avoids obstacles using the\ninformation received from the LIDAR sensor mounted on the robot. Our approach\nbridges the gap between sim-to-real transfer and contributes to the adoption of\nUGVs in real world. We validate our approach in simulation and a real-world\napplication in an office space.\n","authors":["Kabirat Olayemi","Mien Van","Sean McLoone","Yuzhu Sun","Jack Close","Nguyen Minh Nhat","Stephen McIlvanna"],"pdf_url":"https://arxiv.org/pdf/2403.15067v1.pdf","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2310.11760v4","updated":"2024-03-22T09:14:22Z","published":"2023-10-18T07:34:40Z","title":"Performance Investigation of an Optimal Control Strategy for\n  Zero-Emission Operations of Shipboard Microgrids","summary":"  This work introduces an efficient power management approach for shipboard\nmicrogrids that integrates diesel generators, a fuel cell, and battery energy\nstorage system. This strategy addresses both unit commitment and power\ndispatch, considering the zero-emission capability of the ship, as well as\noptimizing the ship's speed. The optimization is done through mixed integer\nlinear programming with the objective of minimizing the operational cost of all\nthe power resources. Evaluations are conducted on a notional all-electric ship,\nwith electrical load simulated using a Markov chain based on actual measurement\ndata. The findings underscore the effectiveness of the proposed strategy in\noptimizing fuel consumption while ensuring protection against blackout\noccurrences.\n","authors":["Fabio D'Agostino","Marco Gallo","Matteo Saviozzi","Federico Silvestro"],"pdf_url":"https://arxiv.org/pdf/2310.11760v4.pdf","comment":"Submitted to SPEEDAM 2024"},{"id":"http://arxiv.org/abs/2401.10519v2","updated":"2024-03-22T09:09:45Z","published":"2024-01-19T06:32:54Z","title":"A Wind-Aware Path Planning Method for UAV-Asisted Bridge Inspection","summary":"  In response to the gap in considering wind conditions in the bridge\ninspection using unmanned aerial vehicle (UAV) , this paper proposes a path\nplanning method for UAVs that takes into account the influence of wind, based\non the simulated annealing algorithm. The algorithm considers the wind factors,\nincluding the influence of different wind speeds and directions at the same\ntime on the path planning of the UAV. Firstly, An environment model is\nconstructed specifically for UAV bridge inspection, taking into account the\nvarious objective functions and constraint conditions of UAVs. A more\nsophisticated and precise mathematical model is then developed based on this\nenvironmental model to enable efficient and effective UAV path planning.\nSecondly, the bridge separation planning model is applied in a novel way, and a\nseries of parameters are simulated, including the adjustment of the initial\ntemperature value. The experimental results demonstrate that, compared with\ntraditional local search algorithms, the proposed method achieves a cost\nreduction of 30.05\\% and significantly improves effectiveness. Compared to path\nplanning methods that do not consider wind factors, the proposed approach\nyields more realistic and practical results for UAV applications, as\ndemonstrated by its improved effectiveness in simulations. These findings\nhighlight the value of our method in facilitating more accurate and efficient\nUAV path planning in wind-prone environments.\n","authors":["Jian Xu","Hua Dai"],"pdf_url":"https://arxiv.org/pdf/2401.10519v2.pdf","comment":"After carefully analysis, there is a bit design flaws in Algorithm 1.\n  The experimental work of the paper is not comprehensive,which lacks an\n  evaluation of the algorithm's running time"},{"id":"http://arxiv.org/abs/2403.15037v1","updated":"2024-03-22T08:42:27Z","published":"2024-03-22T08:42:27Z","title":"Implementation of Firm-Dispatchable Generation in South Africa","summary":"  South Africa is currently facing a critical situation in its power generation\nlandscape, which is plagued by frequent power outages and the need to move from\nfossil fuels to renewable energy sources. This period emphasizes the importance\nof having firm-dispatchable power to balance out the intermittent nature of\nwind and solar energy sources. The paper proposes to repurpose old coal-fired\npower plants to generate firm-dispatchable energy in line with the principles\nof a Just Transition. Eskom's coal plants are approaching the end of their\neconomic life, and their declining energy availability factor is becoming a\nchallenge in meeting the country's energy needs. The study suggests that a\ncomprehensive strategy that integrates wind, solar, and firm-dispatchable power\ncan be cost-effective and reliable compared to the traditional coal-based\napproach or the nuclear alternative. The study emphasizes the necessity of a\n25-year plan that would invest in flexible and modular dispatchable generation.\nIt also highlights the strategic location of this generating capacity,\nincluding repurposing decommissioned coal plant sites. The proposed model\nintegrates private investment, adheres to established best practices, and\nemphasizes adaptability to changing demand dynamics. The study provides a\nroadmap for enabling firm-dispatchable capacity for South Africa's energy\ntransition, emphasizing economic prudence, environmental sustainability, and\nalignment with the principles of the Just Transition program.\n","authors":["Stephen R. Clark","Craig McGregor"],"pdf_url":"https://arxiv.org/pdf/2403.15037v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15029v1","updated":"2024-03-22T08:21:35Z","published":"2024-03-22T08:21:35Z","title":"On the Solution Uniqueness of Data-Driven Modeling of Flexible Loads","summary":"  This letter first explores the solution uniqueness of the data-driven\nmodeling of price-responsive flexible loads (PFL). The PFL on the demand side\nis critical in modern power systems. An accurate PFL model is fundamental for\nsystem operations. Yet, whether the PFL model can be uniquely and correctly\nidentified from operational data remains unclear. To address this, we analyze\nthe structural and practical identifiability of the PFL model, deriving the\ncondition for the solution uniqueness. Based on this, we point out the\nimplications for selecting physical models of PFL to enhance the identification\nresults. Numerical results validate this work.\n","authors":["Shuai Lu","Jiayi Ding","Wei Gu","Junpeng Zhu","Yijun Xu","Zhaoyang Dong","Zezheng Sun"],"pdf_url":"https://arxiv.org/pdf/2403.15029v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14997v1","updated":"2024-03-22T07:17:56Z","published":"2024-03-22T07:17:56Z","title":"Linear Quadratic Guidance Law for Joint Motion Planning of a\n  Pursuer-Turret Assembly","summary":"  This paper presents joint motion planning of a vehicle with an attached\nrotating turret. The turret has a limited range as well as the field of view.\nThe objective is capture a maneuvering target such that at the terminal time it\nis withing the field-of-view and range limits. Catering to it, we present a\nminimum effort guidance law that commensurate for the turn rate abilities of\nthe vehicle and the turret. The guidance law is obtained using linearization\nabout the collision triangle and admits an analytical solution. Simulation\nresults are presented to exemplify the cooperation between the turret and the\nvehicle.\n","authors":["Bhargav Jha","Shaunak Bopardikar","Alexander Von Moll","David Casbeer"],"pdf_url":"https://arxiv.org/pdf/2403.14997v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.05279v2","updated":"2024-03-22T06:38:58Z","published":"2023-07-11T14:16:38Z","title":"DRAMS: Double-RIS Assisted Multihop Routing Scheme for Device-to-Device\n  Communication","summary":"  Reconfigurable intelligent surfaces (RISs) is a promising solution for\nenhancing the performance of multihop wireless communication networks. In this\npaper, we propose a double-RIS assisted multihop routing scheme for a\ndevice-to-device (D2D) communication network. Specifically, the scheme is\ndependent on the already deployed RISs and users in the surroundings. Besides\nthe RISs, the emphasis of this work is to make more use of the existing\nintermediate users (IUs), which can act as relays. Hence, the density of RIS\ndeployment in the surroundings can be reduced, which leads to the avoidance of\nresource wastage. However, we cannot solely depend on the IUs because this\nimplies complete dependence on their availability for relaying and as a result,\nthe aspect of reliability in terms of delay-constrained information transfer\ncannot be guaranteed. Moreover, the IUs are considered capable of energy\nharvesting and as a result, they do not waste their own energy in the process\nof volunteering to act as a relay for other users. Numerical results\ndemonstrate the advantage of the proposed scheme over some existing approaches\nand lastly, useful insights related to the scheme design are also drawn, where\nwe characterize the maximum acceptable delay at each hop under different\nset-ups.\n","authors":["Lakshmikanta Sau","Priyadarshi Mukherjee","Sasthi C. Ghosh"],"pdf_url":"https://arxiv.org/pdf/2307.05279v2.pdf","comment":"To appear in Elsevier Computer Communications"},{"id":"http://arxiv.org/abs/2309.13456v2","updated":"2024-03-22T05:55:16Z","published":"2023-09-23T18:51:44Z","title":"An Optimal Control Framework for Influencing Human Driving Behavior in\n  Mixed-Autonomy Traffic","summary":"  As autonomous vehicles (AVs) become increasingly prevalent, their interaction\nwith human drivers presents a critical challenge. Current AVs lack social\nawareness, causing behavior that is often awkward or unsafe. To combat this,\nsocial AVs, which are proactive rather than reactive in their behavior, have\nbeen explored in recent years. With knowledge of robot-human interaction\ndynamics, a social AV can influence a human driver to exhibit desired behaviors\nby strategically altering its own behaviors. In this paper, we present a novel\nframework for achieving human influence. The foundation of our framework lies\nin an innovative use of control barrier functions to formulate the desired\nobjectives of influence as constraints in an optimal control problem. The\ncomputed controls gradually push the system state toward satisfaction of the\nobjectives, e.g. slowing the human down to some desired speed. We demonstrate\nthe proposed framework's feasibility in a variety of scenarios related to\ncar-following and lane changes, including multi-robot and multi-human\nconfigurations. In two case studies, we validate the framework's effectiveness\nwhen applied to the problems of traffic flow optimization and aggressive\nbehavior mitigation. Given these results, the main contribution of our\nframework is its versatility in a wide spectrum of influence objectives and\nmixed-autonomy configurations.\n","authors":["Anirudh Chari","Rui Chen","Jaskaran Grover","Changliu Liu"],"pdf_url":"https://arxiv.org/pdf/2309.13456v2.pdf","comment":"Accepted to American Control Conference (ACC) 2024"},{"id":"http://arxiv.org/abs/2403.14968v1","updated":"2024-03-22T05:49:52Z","published":"2024-03-22T05:49:52Z","title":"Real-time Safety Index Adaptation for Parameter-varying Systems via\n  Determinant Gradient Ascend","summary":"  Safety Index Synthesis (SIS) is critical for deriving safe control laws.\nRecent works propose to synthesize a safety index (SI) via nonlinear\nprogramming and derive a safe control law such that the system 1) achieves\nforward invariant (FI) with some safe set and 2) guarantees finite time\nconvergence (FTC) to that safe set. However, real-world system dynamics can\nvary during run-time, making the control law infeasible and invalidating the\ninitial SI. Since the full SIS nonlinear programming is computationally\nexpensive, it is infeasible to re-synthesize the SI each time the dynamics are\nperturbed. To address that, this paper proposes an efficient approach to\nadapting the SI to varying system dynamics and maintaining the feasibility of\nthe safe control law. The proposed method leverages determinant gradient ascend\nand derives a closed-form update to safety index parameters, enabling real-time\nadaptation performance. A numerical study validates the effectiveness of our\napproach.\n","authors":["Rui Chen","Weiye Zhao","Ruixuan Liu","Weiyang Zhang","Changliu Liu"],"pdf_url":"https://arxiv.org/pdf/2403.14968v1.pdf","comment":"Accepted to American Control Conference (ACC) 2024"},{"id":"http://arxiv.org/abs/2403.14935v1","updated":"2024-03-22T03:37:53Z","published":"2024-03-22T03:37:53Z","title":"Data-Driven Predictive Control with Adaptive Disturbance Attenuation for\n  Constrained Systems","summary":"  In this paper, we propose a novel data-driven predictive control approach for\nsystems subject to time-domain constraints. The approach combines the strengths\nof H-infinity control for rejecting disturbances and MPC for handling\nconstraints. In particular, the approach can dynamically adapt H-infinity\ndisturbance attenuation performance depending on measured system state and\nforecasted disturbance level to satisfy constraints. We establish theoretical\nproperties of the approach including robust guarantees of closed-loop\nstability, disturbance attenuation, constraint satisfaction under noisy data,\nas well as sufficient conditions for recursive feasibility, and illustrate the\napproach with a numerical example.\n","authors":["Nan Li","Ilya Kolmanovsky","Hong Chen"],"pdf_url":"https://arxiv.org/pdf/2403.14935v1.pdf","comment":"11 pages, 2 figures"},{"id":"http://arxiv.org/abs/2403.14545v2","updated":"2024-03-22T03:19:50Z","published":"2024-03-21T16:44:49Z","title":"Learning Hierarchical Control For Multi-Agent Capacity-Constrained\n  Systems","summary":"  This paper introduces a novel data-driven hierarchical control scheme for\nmanaging a fleet of nonlinear, capacity-constrained autonomous agents in an\niterative environment. We propose a control framework consisting of a\nhigh-level dynamic task assignment and routing layer and low-level motion\nplanning and tracking layer. Each layer of the control hierarchy uses a\ndata-driven Model Predictive Control (MPC) policy, maintaining bounded\ncomputational complexity at each calculation of a new task assignment or\nactuation input. We utilize collected data to iteratively refine estimates of\nagent capacity usage, and update MPC policy parameters accordingly. Our\napproach leverages tools from iterative learning control to integrate learning\nat both levels of the hierarchy, and coordinates learning between levels in\norder to maintain closed-loop feasibility and performance improvement of the\nconnected architecture.\n","authors":["Charlott Vallon","Alessandro Pinto","Bartolomeo Stellato","Francesco Borrelli"],"pdf_url":"https://arxiv.org/pdf/2403.14545v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14931v1","updated":"2024-03-22T03:18:40Z","published":"2024-03-22T03:18:40Z","title":"Structured stability analysis of networked systems with uncertain links","summary":"  An input-output approach to stability analysis is explored for networked\nsystems with uncertain link dynamics. The main result consists of a collection\nof integral quadratic constraints, which together imply robust stability of the\nuncertain networked system, under the assumption that stability is achieved\nwith ideal links. The conditions are decentralized inasmuch as each involves\nonly agent and uncertainty model parameters that are local to a corresponding\nlink. This makes the main result, which imposes no restriction on network\nstructure, suitable for the study of large-scale systems.\n","authors":["Simone Mariano","Michael Cantoni"],"pdf_url":"https://arxiv.org/pdf/2403.14931v1.pdf","comment":null},{"id":"http://arxiv.org/abs/1912.07383v2","updated":"2024-03-22T03:02:39Z","published":"2019-12-12T20:11:51Z","title":"A Survey of Predictive Maintenance: Systems, Purposes and Approaches","summary":"  This paper highlights the importance of maintenance techniques in the coming\nindustrial revolution, reviews the evolution of maintenance techniques, and\npresents a comprehensive literature review on the latest advancement of\nmaintenance techniques, i.e., Predictive Maintenance (PdM), with emphasis on\nsystem architectures, optimization objectives, and optimization methods. In\nindustry, any outages and unplanned downtime of machines or systems would\ndegrade or interrupt a company's core business, potentially resulting in\nsignificant penalties and immeasurable reputation and economic loss. Existing\ntraditional maintenance approaches, such as Reactive Maintenance (RM) and\nPreventive Maintenance (PM), suffer from high prevent and repair costs,\ninadequate or inaccurate mathematical degradation processes, and manual feature\nextraction. The incoming fourth industrial revolution is also demanding for a\nnew maintenance paradigm to reduce the maintenance cost and downtime, and\nincrease system availability and reliability. Predictive Maintenance (PdM) is\nenvisioned the solution. In this survey, we first provide a high-level view of\nthe PdM system architectures including PdM 4.0, Open System Architecture for\nCondition Based Monitoring (OSA-CBM), and cloud-enhanced PdM system. Then, we\nreview the specific optimization objectives, which mainly comprise cost\nminimization, availability/reliability maximization, and multi-objective\noptimization. Furthermore, we present the optimization methods to achieve the\naforementioned objectives, which include traditional Machine Learning (ML)\nbased and Deep Learning (DL) based approaches. Finally, we highlight the future\nresearch directions that are critical to promote the application of DL\ntechniques in the context of PdM.\n","authors":["Tianwen Zhu","Yongyi Ran","Xin Zhou","Yonggang Wen"],"pdf_url":"https://arxiv.org/pdf/1912.07383v2.pdf","comment":"38 pages, 23 figures"},{"id":"http://arxiv.org/abs/2403.14915v1","updated":"2024-03-22T02:37:44Z","published":"2024-03-22T02:37:44Z","title":"Network Learning with Directional Sign Patterns","summary":"  Complex systems can be effectively modeled via graphs that encode networked\ninteractions, where relations between entities or nodes are often quantified by\nsigned edge weights, e.g., promotion/inhibition in gene regulatory networks, or\nencoding political of friendship differences in social networks. However, it is\noften the case that only an aggregate consequence of such edge weights that\ncharacterize relations may be directly observable, as in protein expression of\nin gene regulatory networks. Thus, learning edge weights poses a significant\nchallenge that is further exacerbated for intricate and large-scale networks.\nIn this article, we address a model problem to determine the strength of\nsign-indefinite relations that explain marginal distributions that constitute\nour data. To this end, we develop a paradigm akin to that of the Schr\\\"odinger\nbridge problem and an efficient Sinkhorn type algorithm (more properly,\nSchr\\\"odinger-Fortet-Sinkhorn algorithm) that allows fast convergence to\nparameters that minimize a relative entropy/likelihood criterion between the\nsought signed adjacency matrix and a prior. The formalism that we present\nrepresents a novel generalization of the earlier Schr\\\"odinger formalism in\nthat marginal computations may incorporate weights that model directionality in\nunderlying relations, and further, that it can be extended to high-order\nnetworks -- the Schr\\\"odinger-Fortet-Sinkhorn algorithm that we derive is\napplicable all the same and allows geometric convergence to a sought\nsign-indefinite adjacency matrix or tensor, for high-order networks. We\ndemonstrate our framework with synthetic and real-world examples.\n","authors":["Anqi Dong","Can Chen","Tryphon T. Georgiou"],"pdf_url":"https://arxiv.org/pdf/2403.14915v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14913v1","updated":"2024-03-22T02:22:03Z","published":"2024-03-22T02:22:03Z","title":"Optimisation of photodetectors design: comparison between Montecarlo and\n  Genetic Algorithms","summary":"  We present Montecarlo and Genetic Algorithm optimisations applied to the\ndesign of photodetectors based on a transimpedance amplifier and a photodiode.\nThe circuit performance is evaluated with a merit function and the systematic\nsearch method is used as a reference. The design parameters are the feedback\nnetwork components and the photodiode bias voltage. To evaluate the\noptimisations, we define the relative difference between its merit and the\noptimum merit obtained by the systematic search. In both algorithms, the\nrelative difference decreases with the number of evaluations, following a power\nlaw. The power-law exponent for the Genetic Algorithm is larger than that of\nMontecarlo (0.74 vs. 0.50). We conclude that both algorithms are advantageous\ncompared to the systematic search method, and that the Genetic Algorithm shows\na better performance than Montecarlo.\n","authors":["Patricia M. E. Vázquez","Ligia Ciocci Brazzano","Francisco E. Veiras","Patricio A. Sorichetti"],"pdf_url":"https://arxiv.org/pdf/2403.14913v1.pdf","comment":"10 pages, 14 figures"},{"id":"http://arxiv.org/abs/2310.02485v2","updated":"2024-03-22T00:45:54Z","published":"2023-10-03T23:23:41Z","title":"Computationally Efficient Chance Constrained Covariance Control with\n  Output Feedback","summary":"  This paper studies the problem of developing computationally efficient\nsolutions for steering the distribution of the state of a stochastic, linear\ndynamical system between two boundary Gaussian distributions in the presence of\nchance-constraints on the state and control input. It is assumed that the state\nis only partially available through a measurement model corrupted with noise.\nThe filtered state is reconstructed with a Kalman filter, the chance\nconstraints are reformulated as difference of convex (DC) constraints, and the\nresulting covariance control problem is reformulated as a DC program, which is\nsolved using successive convexification. The efficiency of the proposed method\nis illustrated on a double integrator example with varying time horizons, and\nis compared to other state-of-the-art chance constrained covariance control\nmethods.\n","authors":["Joshua Pilipovsky","Panagiotis Tsiotras"],"pdf_url":"https://arxiv.org/pdf/2310.02485v2.pdf","comment":"v2, submitted to CDC '24"},{"id":"http://arxiv.org/abs/2211.06003v2","updated":"2024-03-22T00:08:32Z","published":"2022-11-11T05:06:33Z","title":"Coherent Equalization of Linear Quantum Systems","summary":"  This paper introduces a $H_\\infty$-like methodology of coherent filtering for\nequalization of passive linear quantum systems to help mitigate degrading\neffects of quantum communication channels. For such systems, which include a\nwide range of linear quantum optical devices and signals, we seek to find a\nnear optimal equalizing filter which is itself a passive quantum system. The\nproblem amounts to solving an optimization problem subject to constraints\ndictated by the requirement for the equalizer to be physically realizable. By\nformulating these constraints in the frequency domain, we show that the problem\nadmits a convex $H_\\infty$-like formulation. This allows us to derive a set of\nsuboptimal coherent equalizers using $J$-spectral factorization. An additional\nsemidefinite relaxation combined with the Nevanlinna-Pick interpolation is\nshown to lead to a tractable algorithm for the design of a near optimal\ncoherent equalizer.\n","authors":["V. Ugrinovskii","M. R. James"],"pdf_url":"https://arxiv.org/pdf/2211.06003v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.00458v2","updated":"2024-03-22T23:47:18Z","published":"2023-09-30T18:33:01Z","title":"Forced oscillation source localization from generator measurements","summary":"  Malfunctioning equipment, erroneous operating conditions or periodic load\nvariations can cause periodic disturbances that would persist over time,\ncreating an undesirable transfer of energy across the system -- an effect\nreferred to as forced oscillations. Wide-area oscillations may damage assets,\ntrigger inadvertent tripping or control actions, and be the cause of equipment\nfailure. Unfortunately, for wide-area oscillations, the location, frequency,\nand amplitude of these forced oscillations may be hard to determine. Recently,\na data-driven maximum-likelihood-based method was proposed to perform source\nlocalization in transmission grids under wide-area response scenarios. However,\nthis method relies on full PMU coverage and all buses having inertia and\ndamping. Here, we extend this method to realistic scenarios which includes\nbuses without inertia or dumping, such as passive loads and inverter-based\ngenerators. Incorporating Kron reduction directly into the maximum likelihood\nestimator, we are able to identify the location and frequency of forcing\napplied at both traditional generators and loads.\n","authors":["Melvyn Tyloo","Marc Vuffray","Andrey Y. Lokhov"],"pdf_url":"https://arxiv.org/pdf/2310.00458v2.pdf","comment":"7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2403.15636v1","updated":"2024-03-22T22:27:28Z","published":"2024-03-22T22:27:28Z","title":"On the Variational Interpretation of Mirror Play in Monotone Games","summary":"  Mirror play (MP) is a well-accepted primal-dual multi-agent learning\nalgorithm where all agents simultaneously implement mirror descent in a\ndistributed fashion. The advantage of MP over vanilla gradient play lies in its\nusage of mirror maps that better exploit the geometry of decision domains.\nDespite extensive literature dedicated to the asymptotic convergence of MP to\nequilibrium, the understanding of the finite-time behavior of MP before\nreaching equilibrium is still rudimentary. To facilitate the study of MP's\nnon-equilibrium performance, this work establishes an equivalence between MP's\nfinite-time primal-dual path (mirror path) in monotone games and the\nclosed-loop Nash equilibrium path of a finite-horizon differential game,\nreferred to as mirror differential game (MDG). Our construction of MDG rests on\nthe Brezis-Ekeland variational principle, and the stage cost functional for MDG\nis Fenchel coupling between MP's iterates and associated gradient updates. The\nvariational interpretation of mirror path in static games as the equilibrium\npath in MDG holds in deterministic and stochastic cases. Such a variational\ninterpretation translates the non-equilibrium studies of learning dynamics into\na more tractable equilibrium analysis of dynamic games, as demonstrated in a\ncase study on the Cournot game, where MP dynamics corresponds to a linear\nquadratic game.\n","authors":["Yunian Pan","Tao Li","Quanyan Zhu"],"pdf_url":"https://arxiv.org/pdf/2403.15636v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.00186v3","updated":"2024-03-22T22:06:29Z","published":"2023-07-31T22:50:14Z","title":"Learning Complex Motion Plans using Neural ODEs with Safety and\n  Stability Guarantees","summary":"  We propose a Dynamical System (DS) approach to learn complex, possibly\nperiodic motion plans from kinesthetic demonstrations using Neural Ordinary\nDifferential Equations (NODE). To ensure reactivity and robustness to\ndisturbances, we propose a novel approach that selects a target point at each\ntime step for the robot to follow, by combining tools from control theory and\nthe target trajectory generated by the learned NODE. A correction term to the\nNODE model is computed online by solving a quadratic program that guarantees\nstability and safety using control Lyapunov functions and control barrier\nfunctions, respectively. Our approach outperforms baseline DS learning\ntechniques on the LASA handwriting dataset and complex periodic trajectories.\nIt is also validated on the Franka Emika robot arm to produce stable motions\nfor wiping and stirring tasks that do not have a single attractor, while being\nrobust to perturbations and safe around humans and obstacles.\n","authors":["Farhad Nawaz","Tianyu Li","Nikolai Matni","Nadia Figueroa"],"pdf_url":"https://arxiv.org/pdf/2308.00186v3.pdf","comment":"accepted to ICRA 2024"},{"id":"http://arxiv.org/abs/2403.15626v1","updated":"2024-03-22T21:36:46Z","published":"2024-03-22T21:36:46Z","title":"Uncertainty Propagation in Stochastic Systems via Mixture Models with\n  Error Quantification","summary":"  Uncertainty propagation in non-linear dynamical systems has become a key\nproblem in various fields including control theory and machine learning. In\nthis work we focus on discrete-time non-linear stochastic dynamical systems. We\npresent a novel approach to approximate the distribution of the system over a\ngiven finite time horizon with a mixture of distributions. The key novelty of\nour approach is that it not only provides tractable approximations for the\ndistribution of a non-linear stochastic system, but also comes with formal\nguarantees of correctness. In particular, we consider the total variation (TV)\ndistance to quantify the distance between two distributions and derive an upper\nbound on the TV between the distribution of the original system and the\napproximating mixture distribution derived with our framework. We show that in\nvarious cases of interest, including in the case of Gaussian noise, the\nresulting bound can be efficiently computed in closed form. This allows us to\nquantify the correctness of the approximation and to optimize the parameters of\nthe resulting mixture distribution to minimize such distance. The effectiveness\nof our approach is illustrated on several benchmarks from the control\ncommunity.\n","authors":["Eduardo Figueiredo","Andrea Patane","Morteza Lahijanian","Luca Laurenti"],"pdf_url":"https://arxiv.org/pdf/2403.15626v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15617v1","updated":"2024-03-22T21:07:43Z","published":"2024-03-22T21:07:43Z","title":"Transactive Local Energy Markets Enable Community-Level Resource\n  Coordination Using Individual Rewards","summary":"  ALEX (Autonomous Local Energy eXchange) is an economy-driven, transactive\nlocal energy market where each participating building is represented by a\nrational agent. Relying solely on building-level information, this agent\nminimizes its electricity bill by automating distributed energy resource\nutilization and trading. This study examines ALEX's capabilities to align\nparticipant and grid-stakeholder interests and assesses ALEX's impact on short-\nand long-term intermittence using a set of community net-load metrics, such as\nramping rate, load factor, and peak load. The policies for ALEX's rational\nagents are generated using dynamic programming through value iteration in\nconjunction with iterative best response. This facilitates comparing ALEX and a\nbenchmark energy management system, which optimizes building-level\nself-consumption, ramping rate, and peak net load. Simulations are performed\nusing the open-source CityLearn2022 dataset to provide a pathway for\nbenchmarking by future studies. The experiments demonstrate that ALEX enables\nthe coordination of distributed energy resources across the community.\nRemarkably, this community-level coordination occurs even though the system is\npopulated by agents who only access building-level information and selfishly\nmaximize their own relative profit. Compared to the benchmark energy management\nsystem, ALEX improves across all metrics.\n","authors":["Daniel C. May","Petr Musilek"],"pdf_url":"https://arxiv.org/pdf/2403.15617v1.pdf","comment":"Preprint, submitted to IEEE Access"},{"id":"http://arxiv.org/abs/2403.15616v1","updated":"2024-03-22T21:06:48Z","published":"2024-03-22T21:06:48Z","title":"Balancing Fairness and Efficiency in Energy Resource Allocations","summary":"  Bringing fairness to energy resource allocation remains a challenge, due to\nthe complexity of system structures and economic interdependencies among users\nand system operators' decision-making. The rise of distributed energy resources\nhas introduced more diverse heterogeneous user groups, surpassing the\ncapabilities of traditional efficiency-oriented allocation schemes. Without\nexplicitly bringing fairness to user-system interaction, this disparity often\nleads to disproportionate payments for certain user groups due to their utility\nformats or group sizes.\n  Our paper addresses this challenge by formalizing the problem of fair energy\nresource allocation and introducing the framework for aggregators. This\nframework enables optimal fairness-efficiency trade-offs by selecting\nappropriate objectives in a principled way. By jointly optimizing over the\ntotal resources to allocate and individual allocations, our approach reveals\noptimized allocation schemes that lie on the Pareto front, balancing fairness\nand efficiency in resource allocation strategies.\n","authors":["Jiayi Li","Matthew Motoki","Baosen Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.15616v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.07139v2","updated":"2024-03-22T20:49:54Z","published":"2023-09-01T16:19:27Z","title":"A Traffic Management Framework for On-Demand Urban Air Mobility Systems","summary":"  Urban Air Mobility (UAM) offers a solution to current traffic congestion by\nproviding on-demand air mobility in urban areas. Effective traffic management\nis crucial for efficient operation of UAM systems, especially for high-demand\nscenarios. In this paper, we present a centralized traffic management framework\nfor on-demand UAM systems. Specifically, we provide a scheduling policy, called\nVertiSync, which schedules the aircraft for either servicing trip requests or\nrebalancing in the system subject to aircraft safety margins and energy\nrequirements. We characterize the system-level throughput of VertiSync, which\ndetermines the demand threshold at which passenger waiting times transition\nfrom being stabilized to being increasing over time. We show that the proposed\npolicy is able to maximize throughput for sufficiently large fleet sizes. We\ndemonstrate the performance of VertiSync through a case study for the city of\nLos Angeles, and show that it significantly reduces passenger waiting times\ncompared to a first-come first-serve scheduling policy.\n","authors":["Milad Pooladsanj","Ketan Savla","Petros A. Ioannou"],"pdf_url":"https://arxiv.org/pdf/2309.07139v2.pdf","comment":"9 pages, 6 figures"},{"id":"http://arxiv.org/abs/2403.15590v1","updated":"2024-03-22T19:32:15Z","published":"2024-03-22T19:32:15Z","title":"Adaptive Dual Covariance Steering with Active Parameter Estimation","summary":"  This work examines the optimal covariance steering problem for systems\nsubject to unknown parameters that enter multiplicatively with the state and\ncontrol, in addition to additive disturbances. In contrast to existing works,\nthe unknown parameters are modeled as random variables and are estimated\nonline. This work proposes the utilization of recursive least squares\nestimation for efficient parameter identification. A dual control problem is\nformulated in which the effect of the planned control policy on the parameter\nestimates is modeled and optimized for. The parameter estimates are then used\nto modify the pre-computed control policy online in an adaptive control\nfashion. Finally, the proposed approach is demonstrated in a vehicle control\nexample with closed-loop parameter identification.\n","authors":["Jacob W. Knaup","Panagiotis Tsiotras"],"pdf_url":"https://arxiv.org/pdf/2403.15590v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15577v1","updated":"2024-03-22T19:04:58Z","published":"2024-03-22T19:04:58Z","title":"Autonomous Driving With Perception Uncertainties: Deep-Ensemble Based\n  Adaptive Cruise Control","summary":"  Autonomous driving depends on perception systems to understand the\nenvironment and to inform downstream decision-making. While advanced perception\nsystems utilizing black-box Deep Neural Networks (DNNs) demonstrate human-like\ncomprehension, their unpredictable behavior and lack of interpretability may\nhinder their deployment in safety critical scenarios. In this paper, we develop\nan Ensemble of DNN regressors (Deep Ensemble) that generates predictions with\nquantification of prediction uncertainties. In the scenario of Adaptive Cruise\nControl (ACC), we employ the Deep Ensemble to estimate distance headway to the\nlead vehicle from RGB images and enable the downstream controller to account\nfor the estimation uncertainty. We develop an adaptive cruise controller that\nutilizes Stochastic Model Predictive Control (MPC) with chance constraints to\nprovide a probabilistic safety guarantee. We evaluate our ACC algorithm using a\nhigh-fidelity traffic simulator and a real-world traffic dataset and\ndemonstrate the ability of the proposed approach to effect speed tracking and\ncar following while maintaining a safe distance headway. The\nout-of-distribution scenarios are also examined.\n","authors":["Xiao Li","H. Eric Tseng","Anouck Girard","Ilya Kolmanovsky"],"pdf_url":"https://arxiv.org/pdf/2403.15577v1.pdf","comment":null}]},"2024-03-25T00:00:00Z":{"Robotics":[{"id":"http://arxiv.org/abs/2403.16730v1","updated":"2024-03-25T13:04:20Z","published":"2024-03-25T13:04:20Z","title":"A Robotic Skill Learning System Built Upon Diffusion Policies and\n  Foundation Models","summary":"  In this paper, we build upon two major recent developments in the field,\nDiffusion Policies for visuomotor manipulation and large pre-trained multimodal\nfoundational models to obtain a robotic skill learning system. The system can\nobtain new skills via the behavioral cloning approach of visuomotor diffusion\npolicies given teleoperated demonstrations. Foundational models are being used\nto perform skill selection given the user's prompt in natural language. Before\nexecuting a skill the foundational model performs a precondition check given an\nobservation of the workspace. We compare the performance of different\nfoundational models to this end as well as give a detailed experimental\nevaluation of the skills taught by the user in simulation and the real world.\nFinally, we showcase the combined system on a challenging food serving scenario\nin the real world. Videos of all experimental executions, as well as the\nprocess of teaching new skills in simulation and the real world, are available\non the project's website.\n","authors":["Nils Ingelhag","Jesper Munkeby","Jonne van Haastregt","Anastasia Varava","Michael C. Welle","Danica Kragic"],"pdf_url":"https://arxiv.org/pdf/2403.16730v1.pdf","comment":"https://roboskillframework.github.io"},{"id":"http://arxiv.org/abs/2403.16696v1","updated":"2024-03-25T12:27:24Z","published":"2024-03-25T12:27:24Z","title":"BatDeck: Advancing Nano-drone Navigation with Low-power Ultrasound-based\n  Obstacle Avoidance","summary":"  Nano-drones, distinguished by their agility, minimal weight, and\ncost-effectiveness, are particularly well-suited for exploration in confined,\ncluttered and narrow spaces. Recognizing transparent, highly reflective or\nabsorbing materials, such as glass and metallic surfaces is challenging, as\nclassical sensors, such as cameras or laser rangers, often do not detect them.\nInspired by bats, which can fly at high speeds in complete darkness with the\nhelp of ultrasound, this paper introduces \\textit{BatDeck}, a pioneering\nsensor-deck employing a lightweight and low-power ultrasonic sensor for\nnano-drone autonomous navigation. This paper first provides insights about\nsensor characteristics, highlighting the influence of motor noise on the\nultrasound readings, then it introduces the results of extensive experimental\ntests for obstacle avoidance (OA) in a diverse environment. Results show that\n\\textit{BatDeck} allows exploration for a flight time of 8 minutes while\ncovering 136m on average before crash in a challenging environment with\ntransparent and reflective obstacles, proving the effectiveness of ultrasonic\nsensors for OA on nano-drones.\n","authors":["Hanna Müller","Victor Kartsch","Michele Magno","Luca Benini"],"pdf_url":"https://arxiv.org/pdf/2403.16696v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2403.16689v1","updated":"2024-03-25T12:23:39Z","published":"2024-03-25T12:23:39Z","title":"Synapse: Learning Preferential Concepts from Visual Demonstrations","summary":"  This paper addresses the problem of preference learning, which aims to learn\nuser-specific preferences (e.g., \"good parking spot\", \"convenient drop-off\nlocation\") from visual input. Despite its similarity to learning factual\nconcepts (e.g., \"red cube\"), preference learning is a fundamentally harder\nproblem due to its subjective nature and the paucity of person-specific\ntraining data. We address this problem using a new framework called Synapse,\nwhich is a neuro-symbolic approach designed to efficiently learn preferential\nconcepts from limited demonstrations. Synapse represents preferences as\nneuro-symbolic programs in a domain-specific language (DSL) that operates over\nimages, and leverages a novel combination of visual parsing, large language\nmodels, and program synthesis to learn programs representing individual\npreferences. We evaluate Synapse through extensive experimentation including a\nuser case study focusing on mobility-related concepts in mobile robotics and\nautonomous driving. Our evaluation demonstrates that Synapse significantly\noutperforms existing baselines as well as its own ablations. The code and other\ndetails can be found on the project website https://amrl.cs.utexas.edu/synapse .\n","authors":["Sadanand Modak","Noah Patton","Isil Dillig","Joydeep Biswas"],"pdf_url":"https://arxiv.org/pdf/2403.16689v1.pdf","comment":"23 pages, 7 figures; Preprint"},{"id":"http://arxiv.org/abs/2403.16669v1","updated":"2024-03-25T12:07:24Z","published":"2024-03-25T12:07:24Z","title":"Domain Adaptive Detection of MAVs: A Benchmark and Noise Suppression\n  Network","summary":"  Visual detection of Micro Air Vehicles (MAVs) has attracted increasing\nattention in recent years due to its important application in various tasks.\nThe existing methods for MAV detection assume that the training set and testing\nset have the same distribution. As a result, when deployed in new domains, the\ndetectors would have a significant performance degradation due to domain\ndiscrepancy. In this paper, we study the problem of cross-domain MAV detection.\nThe contributions of this paper are threefold. 1) We propose a\nMulti-MAV-Multi-Domain (M3D) dataset consisting of both simulation and\nrealistic images. Compared to other existing datasets, the proposed one is more\ncomprehensive in the sense that it covers rich scenes, diverse MAV types, and\nvarious viewing angles. A new benchmark for cross-domain MAV detection is\nproposed based on the proposed dataset. 2) We propose a Noise Suppression\nNetwork (NSN) based on the framework of pseudo-labeling and a large-to-small\ntraining procedure. To reduce the challenging pseudo-label noises, two novel\nmodules are designed in this network. The first is a prior-based curriculum\nlearning module for allocating adaptive thresholds for pseudo labels with\ndifferent difficulties. The second is a masked copy-paste augmentation module\nfor pasting truly-labeled MAVs on unlabeled target images and thus decreasing\npseudo-label noises. 3) Extensive experimental results verify the superior\nperformance of the proposed method compared to the state-of-the-art ones. In\nparticular, it achieves mAP of 46.9%(+5.8%), 50.5%(+3.7%), and 61.5%(+11.3%) on\nthe tasks of simulation-to-real adaptation, cross-scene adaptation, and\ncross-camera adaptation, respectively.\n","authors":["Yin Zhang","Jinhong Deng","Peidong Liu","Wen Li","Shiyu Zhao"],"pdf_url":"https://arxiv.org/pdf/2403.16669v1.pdf","comment":"17 pages, 11 figures. Accepted by IEEE Transactions on Automation\n  Science and Engineering"},{"id":"http://arxiv.org/abs/2311.00390v3","updated":"2024-03-25T12:02:27Z","published":"2023-11-01T09:33:11Z","title":"A Modular Pneumatic Soft Gripper Design for Aerial Grasping and Landing","summary":"  Aerial robots have garnered significant attention due to their potential\napplications in various industries, such as inspection, search and rescue, and\ndrone delivery. Successful missions often depend on the ability of these robots\nto grasp and land effectively. This paper presents a novel modular soft gripper\ndesign tailored explicitly for aerial grasping and landing operations. The\nproposed modular pneumatic soft gripper incorporates a feed-forward\nproportional controller to regulate pressure, enabling compliant gripping\ncapabilities. The modular connectors of the soft fingers offer two\nconfigurations for the 4-tip soft gripper, H-base (cylindrical) and X-base\n(spherical), allowing adaptability to different target objects. Additionally,\nthe gripper can serve as a soft landing gear when deflated, eliminating the\nneed for an extra landing gear. This design reduces weight, simplifies aerial\nmanipulation control, and enhances flight efficiency. We demonstrate the\nefficacy of indoor aerial grasping and achieve a maximum payload of 217 g using\nthe proposed soft aerial vehicle and its H-base pneumatic soft gripper (808 g).\n","authors":["Hiu Ching Cheung","Ching-Wei Chang","Bailun Jiang","Chih-Yung Wen","Henry K. Chu"],"pdf_url":"https://arxiv.org/pdf/2311.00390v3.pdf","comment":"7 pages, 13 figures, accepted by IEEE RoboSoft 2024"},{"id":"http://arxiv.org/abs/2403.16664v1","updated":"2024-03-25T11:57:30Z","published":"2024-03-25T11:57:30Z","title":"Skill Q-Network: Learning Adaptive Skill Ensemble for Mapless Navigation\n  in Unknown Environments","summary":"  This paper focuses on the acquisition of mapless navigation skills within\nunknown environments. We introduce the Skill Q-Network (SQN), a novel\nreinforcement learning method featuring an adaptive skill ensemble mechanism.\nUnlike existing methods, our model concurrently learns a high-level skill\ndecision process alongside multiple low-level navigation skills, all without\nthe need for prior knowledge. Leveraging a tailored reward function for mapless\nnavigation, the SQN is capable of learning adaptive maneuvers that incorporate\nboth exploration and goal-directed skills, enabling effective navigation in new\nenvironments. Our experiments demonstrate that our SQN can effectively navigate\ncomplex environments, exhibiting a 40% higher performance compared to baseline\nmodels. Without explicit guidance, SQN discovers how to combine low-level skill\npolicies, showcasing both goal-directed navigations to reach destinations and\nexploration maneuvers to escape from local minimum regions in challenging\nscenarios. Remarkably, our adaptive skill ensemble method enables zero-shot\ntransfer to out-of-distribution domains, characterized by unseen observations\nfrom non-convex obstacles or uneven, subterranean-like environments.\n","authors":["Hyunki Seong","David Hyunchul Shim"],"pdf_url":"https://arxiv.org/pdf/2403.16664v1.pdf","comment":"8 pages, 8 figures"},{"id":"http://arxiv.org/abs/2403.16652v1","updated":"2024-03-25T11:40:32Z","published":"2024-03-25T11:40:32Z","title":"Trajectory Planning of Robotic Manipulator in Dynamic Environment\n  Exploiting DRL","summary":"  This study is about the implementation of a reinforcement learning algorithm\nin the trajectory planning of manipulators. We have a 7-DOF robotic arm to pick\nand place the randomly placed block at a random target point in an unknown\nenvironment. The obstacle is randomly moving which creates a hurdle in picking\nthe object. The objective of the robot is to avoid the obstacle and pick the\nblock with constraints to a fixed timestamp. In this literature, we have\napplied a deep deterministic policy gradient (DDPG) algorithm and compared the\nmodel's efficiency with dense and sparse rewards.\n","authors":["Osama Ahmad","Zawar Hussain","Hammad Naeem"],"pdf_url":"https://arxiv.org/pdf/2403.16652v1.pdf","comment":"Accepted in ICIESTR-2024"},{"id":"http://arxiv.org/abs/2403.16644v1","updated":"2024-03-25T11:29:32Z","published":"2024-03-25T11:29:32Z","title":"Bridging the Sim-to-Real Gap with Bayesian Inference","summary":"  We present SIM-FSVGD for learning robot dynamics from data. As opposed to\ntraditional methods, SIM-FSVGD leverages low-fidelity physical priors, e.g., in\nthe form of simulators, to regularize the training of neural network models.\nWhile learning accurate dynamics already in the low data regime, SIM-FSVGD\nscales and excels also when more data is available. We empirically show that\nlearning with implicit physical priors results in accurate mean model\nestimation as well as precise uncertainty quantification. We demonstrate the\neffectiveness of SIM-FSVGD in bridging the sim-to-real gap on a\nhigh-performance RC racecar system. Using model-based RL, we demonstrate a\nhighly dynamic parking maneuver with drifting, using less than half the data\ncompared to the state of the art.\n","authors":["Jonas Rothfuss","Bhavya Sukhija","Lenart Treven","Florian Dörfler","Stelian Coros","Andreas Krause"],"pdf_url":"https://arxiv.org/pdf/2403.16644v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16634v1","updated":"2024-03-25T11:22:38Z","published":"2024-03-25T11:22:38Z","title":"Symbolic and User-friendly Geometric Algebra Routines (SUGAR) for\n  Computations in Matlab","summary":"  Geometric algebra (GA) is a mathematical tool for geometric computing,\nproviding a framework that allows a unified and compact approach to geometric\nrelations which in other mathematical systems are typically described using\ndifferent more complicated elements. This fact has led to an increasing\nadoption of GA in applied mathematics and engineering problems. However, the\nscarcity of symbolic implementations of GA and its inherent complexity,\nrequiring a specific mathematical background, make it challenging and less\nintuitive for engineers to work with. This prevents wider adoption among more\napplied professionals. To address this challenge, this paper introduces SUGAR\n(Symbolic and User-friendly Geometric Algebra Routines), an open-source toolbox\ndesigned for Matlab and licensed under the MIT License. SUGAR facilitates the\ntranslation of GA concepts into Matlab and provides a collection of\nuser-friendly functions tailored for GA computations, including support for\nsymbolic operations. It supports both numeric and symbolic computations in\nhigh-dimensional GAs. Specifically tailored for applied mathematics and\nengineering applications, SUGAR has been meticulously engineered to represent\ngeometric elements and transformations within two and three-dimensional\nprojective and conformal geometric algebras, aligning with established\ncomputational methodologies in the literature. Furthermore, SUGAR efficiently\nhandles functions of multivectors, such as exponential, logarithmic,\nsinusoidal, and cosine functions, enhancing its applicability across various\nengineering domains, including robotics, control systems, and power\nelectronics. Finally, this work includes four distinct validation examples,\ndemonstrating SUGAR's capabilities across the above-mentioned fields and its\npractical utility in addressing real-world applied mathematics and engineering\nproblems.\n","authors":["Manel Velasco","Isiah Zaplana","Arnau Dória-Cerezo","Pau Martí"],"pdf_url":"https://arxiv.org/pdf/2403.16634v1.pdf","comment":"33 pages, 6 figures, journal paper submitted to ACM TOMS"},{"id":"http://arxiv.org/abs/2310.00262v2","updated":"2024-03-25T10:45:50Z","published":"2023-09-30T05:26:42Z","title":"Robust Integral Consensus Control of Multi-Agent Networks Perturbed by\n  Matched and Unmatched Disturbances: The Case of Directed Graphs","summary":"  This work presents a new method to design consensus controllers for perturbed\ndouble integrator systems whose interconnection is described by a directed\ngraph containing a rooted spanning tree. We propose new robust controllers to\nsolve the consensus and synchronization problems when the systems are under the\neffects of matched and unmatched disturbances. In both problems, we present\nsimple continuous controllers, whose integral actions allow us to handle the\ndisturbances. A rigorous stability analysis based on Lyapunov's direct method\nfor unperturbed networked systems is presented. To assess the performance of\nour result, a representative simulation study is presented.\n","authors":["Jose Guadalupe Romero","David Navarro-Alarcon"],"pdf_url":"https://arxiv.org/pdf/2310.00262v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16613v1","updated":"2024-03-25T10:43:47Z","published":"2024-03-25T10:43:47Z","title":"Technical Development of a Semi-Autonomous Robotic Partition","summary":"  This technical description details the design and engineering process of a\nsemi-autonomous robotic partition. This robotic partition prototype was\nsubsequently employed in a longer-term evaluation in-the-wild study conducted\nby the authors in a real-world office setting.\n","authors":["Binh Vinh Duc Nguyen","Andrew Vande Moere"],"pdf_url":"https://arxiv.org/pdf/2403.16613v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16606v1","updated":"2024-03-25T10:33:20Z","published":"2024-03-25T10:33:20Z","title":"ROXIE: Defining a Robotic eXplanation and Interpretability Engine","summary":"  In an era where autonomous robots increasingly inhabit public spaces, the\nimperative for transparency and interpretability in their decision-making\nprocesses becomes paramount. This paper presents the overview of a Robotic\neXplanation and Interpretability Engine (ROXIE), which addresses this critical\nneed, aiming to demystify the opaque nature of complex robotic behaviors. This\npaper elucidates the key features and requirements needed for providing\ninformation and explanations about robot decision-making processes. It also\noverviews the suite of software components and libraries available for\ndeployment with ROS 2, empowering users to provide comprehensive explanations\nand interpretations of robot processes and behaviors, thereby fostering trust\nand collaboration in human-robot interactions.\n","authors":["Francisco J. Rodríguez-Lera","Miguel A. González-Santamarta","Alejandro González-Cantón","Laura Fernández-Becerra","David Sobrín-Hidalgo","Angel Manuel Guerrero-Higueras"],"pdf_url":"https://arxiv.org/pdf/2403.16606v1.pdf","comment":"7 pages, 3 figures, 1 tables, Submitted to IROS 2024"},{"id":"http://arxiv.org/abs/2403.16600v1","updated":"2024-03-25T10:20:50Z","published":"2024-03-25T10:20:50Z","title":"Research Challenges for Adaptive Architecture: Empowering Occupants of\n  Multi-Occupancy Buildings","summary":"  This positional paper outlines our vision of 'adaptive architecture', which\ninvolves the integration of robotic technology to physically change an\narchitectural space in supporting the changing needs of its occupants, in\nresponse to the CHI'24 workshop \"HabiTech - Inhabiting Buildings, Data &\nTechnology\" call on \"How do new technologies enable and empower the inhabitants\nof multi-occupancy buildings?\". Specifically, while adaptive architecture holds\npromise for enhancing occupant satisfaction, comfort, and overall health and\nwell-being, there remains a range of research challenges of (1) how it can\neffectively support individual occupants, while (2) mediating the conflicting\nneeds of collocated others, and (3) integrating meaningfully into the\nsociocultural characteristics of their building community.\n","authors":["Binh Vinh Duc Nguyen","Andrew Vande Moere"],"pdf_url":"https://arxiv.org/pdf/2403.16600v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16595v1","updated":"2024-03-25T10:16:51Z","published":"2024-03-25T10:16:51Z","title":"The Adaptive Workplace: Orchestrating Architectural Services around the\n  Wellbeing of Individual Occupants","summary":"  As the academic consortia members of the EU Horizon project SONATA\n(\"Situation-aware OrchestratioN of AdapTive Architecture\"), we respond to the\nworkshop call for \"Office Wellbeing by Design: Don't Stand for Anything Less\"\nby proposing the \"Adaptive Workplace\" concept. In essence, our vision aims to\nadapt a workplace to the ever-changing needs of individual occupants, instead\nof that occupants are expected to adapt to their workplace.\n","authors":["Andrew Vande Moere","Sara Arko","Alena Safrova Drasilova","Tomáš Ondráček","Ilaria Pigliautile","Benedetta Pioppi","Anna Laura Pisello","Jakub Prochazka","Paula Acuna Roncancio","Davide Schaumann","Marcel Schweiker","Binh Vinh Duc Nguyen"],"pdf_url":"https://arxiv.org/pdf/2403.16595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16593v1","updated":"2024-03-25T10:09:42Z","published":"2024-03-25T10:09:42Z","title":"Counter-example guided Imitation Learning of Feedback Controllers from\n  Temporal Logic Specifications","summary":"  We present a novel method for imitation learning for control requirements\nexpressed using Signal Temporal Logic (STL). More concretely we focus on the\nproblem of training a neural network to imitate a complex controller. The\nlearning process is guided by efficient data aggregation based on\ncounter-examples and a coverage measure. Moreover, we introduce a method to\nevaluate the performance of the learned controller via parameterization and\nparameter estimation of the STL requirements. We demonstrate our approach with\na flying robot case study.\n","authors":["Thao Dang","Alexandre Donzé","Inzemamul Haque","Nikolaos Kekatos","Indranil Saha"],"pdf_url":"https://arxiv.org/pdf/2403.16593v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16560v1","updated":"2024-03-25T09:18:48Z","published":"2024-03-25T09:18:48Z","title":"Active Admittance Control with Iterative Learning for General-Purpose\n  Contact-Rich Manipulation","summary":"  Force interaction is inevitable when robots face multiple operation\nscenarios. How to make the robot competent in force control for generalized\noperations such as multi-tasks still remains a challenging problem. Aiming at\nthe reproducibility of interaction tasks and the lack of a generalized force\ncontrol framework for multi-task scenarios, this paper proposes a novel hybrid\ncontrol framework based on active admittance control with iterative learning\nparameters-tunning mechanism. The method adopts admittance control as the\nunderlying algorithm to ensure flexibility, and iterative learning as the\nhigh-level algorithm to regulate the parameters of the admittance model. The\nwhole algorithm has flexibility and learning ability, which is capable of\nachieving the goal of excellent versatility. Four representative interactive\nrobot manipulation tasks are chosen to investigate the consistency and\ngeneralisability of the proposed method. Experiments are designed to verify the\neffectiveness of the whole framework, and an average of 98.21% and 91.52%\nimprovement of RMSE is obtained relative to the traditional admittance control\nas well as the model-free adaptive control, respectively.\n","authors":["Bo Zhou","Yuyao Sun","Wenbo Liu","Ruixuan Jiao","Fang Fang","Shihua Li"],"pdf_url":"https://arxiv.org/pdf/2403.16560v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16535v1","updated":"2024-03-25T08:26:20Z","published":"2024-03-25T08:26:20Z","title":"Arm-Constrained Curriculum Learning for Loco-Manipulation of the\n  Wheel-Legged Robot","summary":"  Incorporating a robotic manipulator into a wheel-legged robot enhances its\nagility and expands its potential for practical applications. However, the\npresence of potential instability and uncertainties presents additional\nchallenges for control objectives. In this paper, we introduce an\narm-constrained curriculum learning architecture to tackle the issues\nintroduced by adding the manipulator. Firstly, we develop an arm-constrained\nreinforcement learning algorithm to ensure safety and stability in control\nperformance. Additionally, to address discrepancies in reward settings between\nthe arm and the base, we propose a reward-aware curriculum learning method. The\npolicy is first trained in Isaac gym and transferred to the physical robot to\ndo dynamic grasping tasks, including the door-opening task, fan-twitching task\nand the relay-baton-picking and following task. The results demonstrate that\nour proposed approach effectively controls the arm-equipped wheel-legged robot\nto master dynamic grasping skills, allowing it to chase and catch a moving\nobject while in motion. The code can be found at\nhttps://github.com/aCodeDog/legged-robots-manipulation. To view the\nsupplemental video, please visit https://youtu.be/sNXT-rwPNMM.\n","authors":["Zifan Wang","Yufei Jia","Lu Shi","Haoyu Wang","Haizhou Zhao","Xueyang Li","Jinni Zhou","Jun Ma","Guyue Zhou"],"pdf_url":"https://arxiv.org/pdf/2403.16535v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16527v1","updated":"2024-03-25T08:11:02Z","published":"2024-03-25T08:11:02Z","title":"Hallucination Detection in Foundation Models for Decision-Making: A\n  Flexible Definition and Review of the State of the Art","summary":"  Autonomous systems are soon to be ubiquitous, from manufacturing autonomy to\nagricultural field robots, and from health care assistants to the entertainment\nindustry. The majority of these systems are developed with modular\nsub-components for decision-making, planning, and control that may be\nhand-engineered or learning-based. While these existing approaches have been\nshown to perform well under the situations they were specifically designed for,\nthey can perform especially poorly in rare, out-of-distribution scenarios that\nwill undoubtedly arise at test-time. The rise of foundation models trained on\nmultiple tasks with impressively large datasets from a variety of fields has\nled researchers to believe that these models may provide common sense reasoning\nthat existing planners are missing. Researchers posit that this common sense\nreasoning will bridge the gap between algorithm development and deployment to\nout-of-distribution tasks, like how humans adapt to unexpected scenarios. Large\nlanguage models have already penetrated the robotics and autonomous systems\ndomains as researchers are scrambling to showcase their potential use cases in\ndeployment. While this application direction is very promising empirically,\nfoundation models are known to hallucinate and generate decisions that may\nsound reasonable, but are in fact poor. We argue there is a need to step back\nand simultaneously design systems that can quantify the certainty of a model's\ndecision, and detect when it may be hallucinating. In this work, we discuss the\ncurrent use cases of foundation models for decision-making tasks, provide a\ngeneral definition for hallucinations with examples, discuss existing\napproaches to hallucination detection and mitigation with a focus on decision\nproblems, and explore areas for further research in this exciting field.\n","authors":["Neeloy Chakraborty","Melkior Ornik","Katherine Driggs-Campbell"],"pdf_url":"https://arxiv.org/pdf/2403.16527v1.pdf","comment":"31 pages, 2 tables"},{"id":"http://arxiv.org/abs/2403.16489v1","updated":"2024-03-25T07:17:44Z","published":"2024-03-25T07:17:44Z","title":"Spatially temporally distributed informative path planning for\n  multi-robot systems","summary":"  This paper investigates the problem of informative path planning for a mobile\nrobotic sensor network in spatially temporally distributed mapping. The robots\nare able to gather noisy measurements from an area of interest during their\nmovements to build a Gaussian Process (GP) model of a spatio-temporal field.\nThe model is then utilized to predict the spatio-temporal phenomenon at\ndifferent points of interest. To spatially and temporally navigate the group of\nrobots so that they can optimally acquire maximal information gains while their\nconnectivity is preserved, we propose a novel multistep prediction informative\npath planning optimization strategy employing our newly defined local cost\nfunctions. By using the dual decomposition method, it is feasible and practical\nto effectively solve the optimization problem in a distributed manner. The\nproposed method was validated through synthetic experiments utilizing\nreal-world data sets.\n","authors":["Binh Nguyen","Linh Nguyen","Truong X. Nghiem","Hung La","Jose Baca","Pablo Rangel","Miguel Cid Montoya","Thang Nguyen"],"pdf_url":"https://arxiv.org/pdf/2403.16489v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16485v1","updated":"2024-03-25T07:12:51Z","published":"2024-03-25T07:12:51Z","title":"Real-time Model Predictive Control with Zonotope-Based Neural Networks\n  for Bipedal Social Navigation","summary":"  This study addresses the challenge of bipedal navigation in a dynamic\nhuman-crowded environment, a research area that remains largely underexplored\nin the field of legged navigation. We propose two cascaded zonotope-based\nneural networks: a Pedestrian Prediction Network (PPN) for pedestrians' future\ntrajectory prediction and an Ego-agent Social Network (ESN) for ego-agent\nsocial path planning. Representing future paths as zonotopes allows for\nefficient reachability-based planning and collision checking. The ESN is then\nintegrated with a Model Predictive Controller (ESN-MPC) for footstep planning\nfor our bipedal robot Digit designed by Agility Robotics. ESN-MPC solves for a\ncollision-free optimal trajectory by optimizing through the gradients of ESN.\nESN-MPC optimal trajectory is sent to the low-level controller for full-order\nsimulation of Digit. The overall proposed framework is validated with extensive\nsimulations on randomly generated initial settings with varying human crowd\ndensities.\n","authors":["Abdulaziz Shamsah","Krishanu Agarwal","Shreyas Kousik","Ye Zhao"],"pdf_url":"https://arxiv.org/pdf/2403.16485v1.pdf","comment":"8 pages, 9 figures"},{"id":"http://arxiv.org/abs/2403.16478v1","updated":"2024-03-25T07:04:24Z","published":"2024-03-25T07:04:24Z","title":"Towards Cooperative Maneuver Planning in Mixed Traffic at Urban\n  Intersections","summary":"  Connected automated driving promises a significant improvement of traffic\nefficiency and safety on highways and in urban areas. Apart from sharing of\nawareness and perception information over wireless communication links,\ncooperative maneuver planning may facilitate active guidance of connected\nautomated vehicles at urban intersections. Research in automatic intersection\nmanagement put forth a large body of works that mostly employ rule-based or\noptimization-based approaches primarily in fully automated simulated\nenvironments. In this work, we present two cooperative planning approaches that\nare capable of handling mixed traffic, i.e., the road being shared by automated\nvehicles and regular vehicles driven by humans. Firstly, we propose an\noptimization-based planner trained on real driving data that cyclically selects\nthe most efficient out of multiple predicted coordinated maneuvers.\nAdditionally, we present a cooperative planning approach based on graph-based\nreinforcement learning, which conquers the lack of ground truth data for\ncooperative maneuvers. We present evaluation results of both cooperative\nplanners in high-fidelity simulation and real-world traffic. Simulative\nexperiments in fully automated traffic and mixed traffic show that cooperative\nmaneuver planning leads to less delay due to interaction and a reduced number\nof stops. In real-world experiments with three prototype connected automated\nvehicles in public traffic, both planners demonstrate their ability to perform\nefficient cooperative maneuvers.\n","authors":["Marvin Klimke","Max Bastian Mertens","Benjamin Völz","Michael Buchholz"],"pdf_url":"https://arxiv.org/pdf/2403.16478v1.pdf","comment":"M. Klimke and M. Mertens are both first authors with equal\n  contribution. 11 pages, 10 figures, 2 tables, submitted to IEEE Transactions\n  on Intelligent Vehicles"},{"id":"http://arxiv.org/abs/2403.16439v1","updated":"2024-03-25T05:58:33Z","published":"2024-03-25T05:58:33Z","title":"Producing and Leveraging Online Map Uncertainty in Trajectory Prediction","summary":"  High-definition (HD) maps have played an integral role in the development of\nmodern autonomous vehicle (AV) stacks, albeit with high associated labeling and\nmaintenance costs. As a result, many recent works have proposed methods for\nestimating HD maps online from sensor data, enabling AVs to operate outside of\npreviously-mapped regions. However, current online map estimation approaches\nare developed in isolation of their downstream tasks, complicating their\nintegration in AV stacks. In particular, they do not produce uncertainty or\nconfidence estimates. In this work, we extend multiple state-of-the-art online\nmap estimation methods to additionally estimate uncertainty and show how this\nenables more tightly integrating online mapping with trajectory forecasting. In\ndoing so, we find that incorporating uncertainty yields up to 50% faster\ntraining convergence and up to 15% better prediction performance on the\nreal-world nuScenes driving dataset.\n","authors":["Xunjiang Gu","Guanyu Song","Igor Gilitschenski","Marco Pavone","Boris Ivanovic"],"pdf_url":"https://arxiv.org/pdf/2403.16439v1.pdf","comment":"14 pages, 14 figures, 6 tables. CVPR 2024"},{"id":"http://arxiv.org/abs/2403.16430v1","updated":"2024-03-25T05:21:19Z","published":"2024-03-25T05:21:19Z","title":"AeroBridge: Autonomous Drone Handoff System for Emergency Battery\n  Service","summary":"  This paper proposes an Emergency Battery Service (EBS) for drones in which an\nEBS drone flies to a drone in the field with a depleted battery and transfers a\nfresh battery to the exhausted drone. The authors present a unique battery\ntransfer mechanism and drone localization that uses the Cross Marker Position\n(CMP) method. The main challenges include a stable and balanced transfer that\nprecisely localizes the receiver drone. The proposed EBS drone mitigates the\neffects of downwash due to the vertical proximity between the drones by\nimplementing diagonal alignment with the receiver, reducing the distance to 0.5\nm between the two drones. CFD analysis shows that diagonal instead of\nperpendicular alignment minimizes turbulence, and the authors verify the actual\nsystem for change in output airflow and thrust measurements. The CMP\nmarker-based localization method enables position lock for the EBS drone with\nup to 0.9 cm accuracy. The performance of the transfer mechanism is validated\nexperimentally by successful mid-air transfer in 5 seconds, where the EBS drone\nis within 0.5 m vertical distance from the receiver drone, wherein 4m/s\nturbulence does not affect the transfer process.\n","authors":["Avishkar Seth","Alice James","Endrowednes Kuantama","Richard Han","Subhas Mukhopadhyay"],"pdf_url":"https://arxiv.org/pdf/2403.16430v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.17463v2","updated":"2024-03-25T05:16:38Z","published":"2024-01-30T21:51:57Z","title":"A Group Theoretic Metric for Robot State Estimation Leveraging Chebyshev\n  Interpolation","summary":"  We propose a new metric for robot state estimation based on the recently\nintroduced $\\text{SE}_2(3)$ Lie group definition. Our metric is related to\nprior metrics for SLAM but explicitly takes into account the linear velocity of\nthe state estimate, improving over current pose-based trajectory analysis. This\nhas the benefit of providing a single, quantitative metric to evaluate state\nestimation algorithms against, while being compatible with existing tools and\nlibraries. Since ground truth data generally consists of pose data from motion\ncapture systems, we also propose an approach to compute the ground truth linear\nvelocity based on polynomial interpolation. Using Chebyshev interpolation and a\npseudospectral parameterization, we can accurately estimate the ground truth\nlinear velocity of the trajectory in an optimal fashion with best approximation\nerror. We demonstrate how this approach performs on multiple robotic platforms\nwhere accurate state estimation is vital, and compare it to alternative\napproaches such as finite differences. The pseudospectral parameterization also\nprovides a means of trajectory data compression as an additional benefit.\nExperimental results show our method provides a valid and accurate means of\ncomparing state estimation systems, which is also easy to interpret and report.\n","authors":["Varun Agrawal","Frank Dellaert"],"pdf_url":"https://arxiv.org/pdf/2401.17463v2.pdf","comment":"Accepted to ICRA 2024"},{"id":"http://arxiv.org/abs/2403.16425v1","updated":"2024-03-25T05:10:34Z","published":"2024-03-25T05:10:34Z","title":"Enhancing Visual Place Recognition via Fast and Slow Adaptive Biasing in\n  Event Cameras","summary":"  Event cameras are increasingly popular in robotics due to their beneficial\nfeatures, such as low latency, energy efficiency, and high dynamic range.\nNevertheless, their downstream task performance is greatly influenced by the\noptimization of bias parameters. These parameters, for instance, regulate the\nnecessary change in light intensity to trigger an event, which in turn depends\non factors such as the environment lighting and camera motion. This paper\nintroduces feedback control algorithms that automatically tune the bias\nparameters through two interacting methods: 1) An immediate, on-the-fly fast\nadaptation of the refractory period, which sets the minimum interval between\nconsecutive events, and 2) if the event rate exceeds the specified bounds even\nafter changing the refractory period repeatedly, the controller adapts the\npixel bandwidth and event thresholds, which stabilizes after a short period of\nnoise events across all pixels (slow adaptation). Our evaluation focuses on the\nvisual place recognition task, where incoming query images are compared to a\ngiven reference database. We conducted comprehensive evaluations of our\nalgorithms' adaptive feedback control in real-time. To do so, we collected the\nQCR-Fast-and-Slow dataset that contains DAVIS346 event camera streams from 366\nrepeated traversals of a Scout Mini robot navigating through a 100 meter long\nindoor lab setting (totaling over 35km distance traveled) in varying brightness\nconditions with ground truth location information. Our proposed feedback\ncontrollers result in superior performance when compared to the standard bias\nsettings and prior feedback control methods. Our findings also detail the\nimpact of bias adjustments on task performance and feature ablation studies on\nthe fast and slow adaptation mechanisms.\n","authors":["Gokul B. Nair","Michael Milford","Tobias Fischer"],"pdf_url":"https://arxiv.org/pdf/2403.16425v1.pdf","comment":"8 pages, 9 figures, paper under review"},{"id":"http://arxiv.org/abs/2312.03009v2","updated":"2024-03-25T05:04:04Z","published":"2023-12-04T19:01:19Z","title":"I-PHYRE: Interactive Physical Reasoning","summary":"  Current evaluation protocols predominantly assess physical reasoning in\nstationary scenes, creating a gap in evaluating agents' abilities to interact\nwith dynamic events. While contemporary methods allow agents to modify initial\nscene configurations and observe consequences, they lack the capability to\ninteract with events in real time. To address this, we introduce I-PHYRE, a\nframework that challenges agents to simultaneously exhibit intuitive physical\nreasoning, multi-step planning, and in-situ intervention. Here, intuitive\nphysical reasoning refers to a quick, approximate understanding of physics to\naddress complex problems; multi-step denotes the need for extensive sequence\nplanning in I-PHYRE, considering each intervention can significantly alter\nsubsequent choices; and in-situ implies the necessity for timely object\nmanipulation within a scene, where minor timing deviations can result in task\nfailure. We formulate four game splits to scrutinize agents' learning and\ngeneralization of essential principles of interactive physical reasoning,\nfostering learning through interaction with representative scenarios. Our\nexploration involves three planning strategies and examines several supervised\nand reinforcement agents' zero-shot generalization proficiency on I-PHYRE. The\noutcomes highlight a notable gap between existing learning algorithms and human\nperformance, emphasizing the imperative for more research in enhancing agents\nwith interactive physical reasoning capabilities. The environment and baselines\nwill be made publicly available.\n","authors":["Shiqian Li","Kewen Wu","Chi Zhang","Yixin Zhu"],"pdf_url":"https://arxiv.org/pdf/2312.03009v2.pdf","comment":"21 pages, ICLR 2024"},{"id":"http://arxiv.org/abs/2403.16419v1","updated":"2024-03-25T04:45:16Z","published":"2024-03-25T04:45:16Z","title":"Terrain-Attentive Learning for Efficient 6-DoF Kinodynamic Modeling on\n  Vertically Challenging Terrain","summary":"  Wheeled robots have recently demonstrated superior mechanical capability to\ntraverse vertically challenging terrain (e.g., extremely rugged boulders\ncomparable in size to the vehicles themselves). Negotiating such terrain\nintroduces significant variations of vehicle pose in all six Degrees-of-Freedom\n(DoFs), leading to imbalanced contact forces, varying momentum, and chassis\ndeformation due to non-rigid tires and suspensions. To autonomously navigate on\nvertically challenging terrain, all these factors need to be efficiently\nreasoned within limited onboard computation and strict real-time constraints.\nIn this paper, we propose a 6-DoF kinodynamics learning approach that is\nattentive only to the specific underlying terrain critical to the current\nvehicle-terrain interaction, so that it can be efficiently queried in real-time\nmotion planners onboard small robots. Physical experiment results show our\nTerrain-Attentive Learning demonstrates on average 51.1% reduction in model\nprediction error among all 6 DoFs compared to a state-of-the-art model for\nvertically challenging terrain.\n","authors":["Aniket Datar","Chenhui Pan","Mohammad Nazeri","Anuj Pokhrel","Xuesu Xiao"],"pdf_url":"https://arxiv.org/pdf/2403.16419v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16400v1","updated":"2024-03-25T03:30:37Z","published":"2024-03-25T03:30:37Z","title":"ASDF: Assembly State Detection Utilizing Late Fusion by Integrating 6D\n  Pose Estimation","summary":"  In medical and industrial domains, providing guidance for assembly processes\nis critical to ensure efficiency and safety. Errors in assembly can lead to\nsignificant consequences such as extended surgery times, and prolonged\nmanufacturing or maintenance times in industry. Assembly scenarios can benefit\nfrom in-situ AR visualization to provide guidance, reduce assembly times and\nminimize errors. To enable in-situ visualization 6D pose estimation can be\nleveraged. Existing 6D pose estimation techniques primarily focus on individual\nobjects and static captures. However, assembly scenarios have various dynamics\nincluding occlusion during assembly and dynamics in the assembly objects\nappearance. Existing work, combining object detection/6D pose estimation and\nassembly state detection focuses either on pure deep learning-based approaches,\nor limit the assembly state detection to building blocks. To address the\nchallenges of 6D pose estimation in combination with assembly state detection,\nour approach ASDF builds upon the strengths of YOLOv8, a real-time capable\nobject detection framework. We extend this framework, refine the object pose\nand fuse pose knowledge with network-detected pose information. Utilizing our\nlate fusion in our Pose2State module results in refined 6D pose estimation and\nassembly state detection. By combining both pose and state information, our\nPose2State module predicts the final assembly state with precision. Our\nevaluation on our ASDF dataset shows that our Pose2State module leads to an\nimproved assembly state detection and that the improvement of the assembly\nstate further leads to a more robust 6D pose estimation. Moreover, on the GBOT\ndataset, we outperform the pure deep learning-based network, and even\noutperform the hybrid and pure tracking-based approaches.\n","authors":["Hannah Schieber","Shiyu Li","Niklas Corell","Philipp Beckerle","Julian Kreimeier","Daniel Roth"],"pdf_url":"https://arxiv.org/pdf/2403.16400v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.10670v2","updated":"2024-03-25T02:52:43Z","published":"2024-02-16T13:21:33Z","title":"OpenFMNav: Towards Open-Set Zero-Shot Object Navigation via\n  Vision-Language Foundation Models","summary":"  Object navigation (ObjectNav) requires an agent to navigate through unseen\nenvironments to find queried objects. Many previous methods attempted to solve\nthis task by relying on supervised or reinforcement learning, where they are\ntrained on limited household datasets with close-set objects. However, two key\nchallenges are unsolved: understanding free-form natural language instructions\nthat demand open-set objects, and generalizing to new environments in a\nzero-shot manner. Aiming to solve the two challenges, in this paper, we propose\nOpenFMNav, an Open-set Foundation Model based framework for zero-shot object\nNavigation. We first unleash the reasoning abilities of large language models\n(LLMs) to extract proposed objects from natural language instructions that meet\nthe user's demand. We then leverage the generalizability of large vision\nlanguage models (VLMs) to actively discover and detect candidate objects from\nthe scene, building a Versatile Semantic Score Map (VSSM). Then, by conducting\ncommon sense reasoning on VSSM, our method can perform effective\nlanguage-guided exploration and exploitation of the scene and finally reach the\ngoal. By leveraging the reasoning and generalizing abilities of foundation\nmodels, our method can understand free-form human instructions and perform\neffective open-set zero-shot navigation in diverse environments. Extensive\nexperiments on the HM3D ObjectNav benchmark show that our method surpasses all\nthe strong baselines on all metrics, proving our method's effectiveness.\nFurthermore, we perform real robot demonstrations to validate our method's\nopen-set-ness and generalizability to real-world environments.\n","authors":["Yuxuan Kuang","Hai Lin","Meng Jiang"],"pdf_url":"https://arxiv.org/pdf/2402.10670v2.pdf","comment":"NAACL 2024 Findings"},{"id":"http://arxiv.org/abs/2403.11384v2","updated":"2024-03-25T02:10:23Z","published":"2024-03-18T00:22:30Z","title":"Towards Massive Interaction with Generalist Robotics: A Systematic\n  Review of XR-enabled Remote Human-Robot Interaction Systems","summary":"  This survey provides an exhaustive review of the applications of extended\nreality (XR) technologies in the field of remote human-computer interaction\n(HRI). We developed a systematic search strategy based on the PRISMA\nmethodology. From the initial 2,561 articles selected, 100 research papers that\nmet our inclusion criteria were included. We categorized and summarized the\ndomain in detail, delving into XR technologies, including augmented reality\n(AR), virtual reality (VR), and mixed reality (MR), and their applications in\nfacilitating intuitive and effective remote control and interaction with\nrobotic systems.The survey highlights existing articles on the application of\nXR technologies, user experience enhancement, and various interaction designs\nfor XR in remote HRI, providing insights into current trends and future\ndirections. We also identified potential gaps and opportunities for future\nresearch to improve remote HRI systems through XR technology to guide and\ninform future XR and robotics research.\n","authors":["Xian Wang","Luyao Shen","Lik-Hang Lee"],"pdf_url":"https://arxiv.org/pdf/2403.11384v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16366v1","updated":"2024-03-25T02:04:06Z","published":"2024-03-25T02:04:06Z","title":"SE(3) Linear Parameter Varying Dynamical Systems for Globally\n  Asymptotically Stable End-Effector Control","summary":"  Linear Parameter Varying Dynamical Systems (LPV-DS) encode trajectories into\nan autonomous first-order DS that enables reactive responses to perturbations,\nwhile ensuring globally asymptotic stability at the target. However, the\ncurrent LPV-DS framework is established on Euclidean data only and has not been\napplicable to broader robotic applications requiring pose control. In this\npaper we present an extension to the current LPV-DS framework, named\nQuaternion-DS, which efficiently learns a DS-based motion policy for\norientation. Leveraging techniques from differential geometry and Riemannian\nstatistics, our approach properly handles the non-Euclidean orientation data in\nquaternion space, enabling the integration with positional control, namely\nSE(3) LPV-DS, so that the synergistic behaviour within the full SE(3) pose is\npreserved. Through simulation and real robot experiments, we validate our\nmethod, demonstrating its ability to efficiently and accurately reproduce the\noriginal SE(3) trajectory while exhibiting strong robustness to perturbations\nin task space.\n","authors":["Sunan Sun","Nadia Figueroa"],"pdf_url":"https://arxiv.org/pdf/2403.16366v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.02609v3","updated":"2024-03-25T01:50:40Z","published":"2023-09-05T22:53:37Z","title":"Directionality-Aware Mixture Model Parallel Sampling for Efficient\n  Linear Parameter Varying Dynamical System Learning","summary":"  The Linear Parameter Varying Dynamical System (LPV-DS) is an effective\napproach that learns stable, time-invariant motion policies using statistical\nmodeling and semi-definite optimization to encode complex motions for reactive\nrobot control. Despite its strengths, the LPV-DS learning approach faces\nchallenges in achieving a high model accuracy without compromising the\ncomputational efficiency. To address this, we introduce the\nDirectionality-Aware Mixture Model (DAMM), a novel statistical model that\napplies the Riemannian metric on the n-sphere $\\mathbb{S}^n$ to efficiently\nblend non-Euclidean directional data with $\\mathbb{R}^m$ Euclidean states.\nAdditionally, we develop a hybrid Markov chain Monte Carlo technique that\ncombines Gibbs Sampling with Split/Merge Proposal, allowing for parallel\ncomputation to drastically speed up inference. Our extensive empirical tests\ndemonstrate that LPV-DS integrated with DAMM achieves higher reproduction\naccuracy, better model efficiency, and near real-time/online learning compared\nto standard estimation methods on various datasets. Lastly, we demonstrate its\nsuitability for incrementally learning multi-behavior policies in real-world\nrobot experiments.\n","authors":["Sunan Sun","Haihui Gao","Tianyu Li","Nadia Figueroa"],"pdf_url":"https://arxiv.org/pdf/2309.02609v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16356v1","updated":"2024-03-25T01:33:03Z","published":"2024-03-25T01:33:03Z","title":"Bipedal Safe Navigation over Uncertain Rough Terrain: Unifying Terrain\n  Mapping and Locomotion Stability","summary":"  We study the problem of bipedal robot navigation in complex environments with\nuncertain and rough terrain. In particular, we consider a scenario in which the\nrobot is expected to reach a desired goal location by traversing an environment\nwith uncertain terrain elevation. Such terrain uncertainties induce not only\nuntraversable regions but also robot motion perturbations. Thus, the problems\nof terrain mapping and locomotion stability are intertwined. We evaluate three\ndifferent kernels for Gaussian process (GP) regression to learn the terrain\nelevation. We also learn the motion deviation resulting from both the terrain\nas well as the discrepancy between the reduced-order Prismatic Inverted\nPendulum Model used for planning and the full-order locomotion dynamics. We\npropose a hierarchical locomotion-dynamics-aware sampling-based navigation\nplanner. The global navigation planner plans a series of local waypoints to\nreach the desired goal locations while respecting locomotion stability\nconstraints. Then, a local navigation planner is used to generate a sequence of\ndynamically feasible footsteps to reach local waypoints. We develop a novel\ntrajectory evaluation metric to minimize motion deviation and maximize\ninformation gain of the terrain elevation map. We evaluate the efficacy of our\nplanning framework on Digit bipedal robot simulation in MuJoCo.\n","authors":["Kasidit Muenprasitivej","Jesse Jiang","Abdulaziz Shamsah","Samuel Coogan","Ye Zhao"],"pdf_url":"https://arxiv.org/pdf/2403.16356v1.pdf","comment":"9 pages, 7 figures"},{"id":"http://arxiv.org/abs/2403.09900v2","updated":"2024-03-25T01:29:27Z","published":"2024-03-14T22:22:22Z","title":"DTG : Diffusion-based Trajectory Generation for Mapless Global\n  Navigation","summary":"  We present a novel end-to-end diffusion-based trajectory generation method,\nDTG, for mapless global navigation in challenging outdoor scenarios with\nocclusions and unstructured off-road features like grass, buildings, bushes,\netc. Given a distant goal, our approach computes a trajectory that satisfies\nthe following goals: (1) minimize the travel distance to the goal; (2) maximize\nthe traversability by choosing paths that do not lie in undesirable areas.\nSpecifically, we present a novel Conditional RNN(CRNN) for diffusion models to\nefficiently generate trajectories. Furthermore, we propose an adaptive training\nmethod that ensures that the diffusion model generates more traversable\ntrajectories. We evaluate our methods in various outdoor scenes and compare the\nperformance with other global navigation algorithms on a Husky robot. In\npractice, we observe at least a 15% improvement in traveling distance and\naround a 7% improvement in traversability.\n","authors":["Jing Liang","Amirreza Payandeh","Daeun Song","Xuesu Xiao","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2403.09900v2.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2403.17270v1","updated":"2024-03-25T23:28:57Z","published":"2024-03-25T23:28:57Z","title":"Human Stress Response and Perceived Safety during Encounters with\n  Quadruped Robots","summary":"  Despite the rise of mobile robot deployments in home and work settings,\nperceived safety of users and bystanders is understudied in the human-robot\ninteraction (HRI) literature. To address this, we present a study designed to\nidentify elements of a human-robot encounter that correlate with observed\nstress response. Stress is a key component of perceived safety and is strongly\nassociated with human physiological response. In this study a Boston Dynamics\nSpot and a Unitree Go1 navigate autonomously through a shared environment\noccupied by human participants wearing multimodal physiological sensors to\ntrack their electrocardiography (ECG) and electrodermal activity (EDA). The\nencounters are varied through several trials and participants self-rate their\nstress levels after each encounter. The study resulted in a multidimensional\ndataset archiving various objective and subjective aspects of a human-robot\nencounter, containing insights for understanding perceived safety in such\nencounters. To this end, acute stress responses were decoded from the human\nparticipants' ECG and EDA and compared across different human-robot encounter\nconditions. Statistical analysis of data indicate that on average (1)\nparticipants feel more stress during encounters compared to baselines, (2)\nparticipants feel more stress encountering multiple robots compared to a single\nrobot and (3) participants stress increases during navigation behavior compared\nwith search behavior.\n","authors":["Ryan Gupta","Hyonyoung Shin","Emily Norman","Keri K. Stephens","Nanshu Lu","Luis Sentis"],"pdf_url":"https://arxiv.org/pdf/2403.17270v1.pdf","comment":"7 pages, 7 figs, 5 tables"},{"id":"http://arxiv.org/abs/2309.14150v8","updated":"2024-03-25T23:25:17Z","published":"2023-09-25T14:04:31Z","title":"Fast LiDAR Informed Visual Search in Unseen Indoor Environments","summary":"  This paper explores the problem of planning for visual search without prior\nmap information. We leverage the pixel-wise environment perception problem\nwhere one is given wide Field of View 2D scan data and must perform LiDAR\nsegmentation to contextually label points in the surroundings. These pixel\nclassifications provide an informed prior on which to plan next best viewpoints\nduring visual search tasks. We present LIVES: LiDAR Informed Visual Search, a\nmethod aimed at finding objects of interest in unknown indoor environments. A\nrobust map-free classifier is trained from expert data collected using a simple\ncart platform equipped with a map-based classifier. An autonomous exploration\nplanner takes the contextual data from scans and uses that prior to plan\nviewpoints more likely to yield detection of the search target. We propose a\nutility function that accounts for traditional metrics like information gain\nand path cost and for the contextual information. LIVES is baselined against\nseveral existing exploration methods in simulation to verify its performance.\nIt is validated in real-world experiments with single and multiple search\nobjects with a Spot robot in two unseen environments. Videos of experiments,\nimplementation details and open source code can be found at\nhttps://sites.google.com/view/lives-2024/home.\n","authors":["Ryan Gupta","Kyle Morgenstein","Steven Ortega","Luis Sentis"],"pdf_url":"https://arxiv.org/pdf/2309.14150v8.pdf","comment":"6 pages + references. 6 figures. 1 algorithm. 1 table"},{"id":"http://arxiv.org/abs/2403.17266v1","updated":"2024-03-25T23:19:19Z","published":"2024-03-25T23:19:19Z","title":"Exploring CausalWorld: Enhancing robotic manipulation via knowledge\n  transfer and curriculum learning","summary":"  This study explores a learning-based tri-finger robotic arm manipulating\ntask, which requires complex movements and coordination among the fingers. By\nemploying reinforcement learning, we train an agent to acquire the necessary\nskills for proficient manipulation. To enhance the efficiency and effectiveness\nof the learning process, two knowledge transfer strategies, fine-tuning and\ncurriculum learning, were utilized within the soft actor-critic architecture.\nFine-tuning allows the agent to leverage pre-trained knowledge and adapt it to\nnew tasks. Several variations like model transfer, policy transfer, and\nacross-task transfer were implemented and evaluated. To eliminate the need for\npretraining, curriculum learning decomposes the advanced task into simpler,\nprogressive stages, mirroring how humans learn. The number of learning stages,\nthe context of the sub-tasks, and the transition timing were found to be the\ncritical design parameters. The key factors of two learning strategies and\ncorresponding effects were explored in context-aware and context-unaware\nscenarios, enabling us to identify the scenarios where the methods demonstrate\noptimal performance, derive conclusive insights, and contribute to a broader\nrange of learning-based engineering applications.\n","authors":["Xinrui Wang","Yan Jin"],"pdf_url":"https://arxiv.org/pdf/2403.17266v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.12465v2","updated":"2024-03-25T22:57:28Z","published":"2024-03-19T05:46:20Z","title":"Diagrammatic Instructions to Specify Spatial Objectives and Constraints\n  with Applications to Mobile Base Placement","summary":"  This paper introduces Spatial Diagrammatic Instructions (SDIs), an approach\nfor human operators to specify objectives and constraints that are related to\nspatial regions in the working environment. Human operators are enabled to\nsketch out regions directly on camera images that correspond to the objectives\nand constraints. These sketches are projected to 3D spatial coordinates, and\ncontinuous Spatial Instruction Maps (SIMs) are learned upon them. These maps\ncan then be integrated into optimization problems for tasks of robots. In\nparticular, we demonstrate how Spatial Diagrammatic Instructions can be applied\nto solve the Base Placement Problem of mobile manipulators, which concerns the\nbest place to put the manipulator to facilitate a certain task. Human operators\ncan specify, via sketch, spatial regions of interest for a manipulation task\nand permissible regions for the mobile manipulator to be at. Then, an\noptimization problem that maximizes the manipulator's reachability, or\ncoverage, over the designated regions of interest while remaining in the\npermissible regions is solved. We provide extensive empirical evaluations, and\nshow that our formulation of Spatial Instruction Maps provides accurate\nrepresentations of user-specified diagrammatic instructions. Furthermore, we\ndemonstrate that our diagrammatic approach to the Mobile Base Placement Problem\nenables higher quality solutions and faster run-time.\n","authors":["Qilin Sun","Weiming Zhi","Tianyi Zhang","Matthew Johnson-Roberson"],"pdf_url":"https://arxiv.org/pdf/2403.12465v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17249v1","updated":"2024-03-25T22:51:27Z","published":"2024-03-25T22:51:27Z","title":"Impact-Aware Bimanual Catching of Large-Momentum Objects","summary":"  This paper investigates one of the most challenging tasks in dynamic\nmanipulation -- catching large-momentum moving objects. Beyond the realm of\nquasi-static manipulation, dealing with highly dynamic objects can\nsignificantly improve the robot's capability of interacting with its\nsurrounding environment. Yet, the inevitable motion mismatch between the fast\nmoving object and the approaching robot will result in large impulsive forces,\nwhich lead to the unstable contacts and irreversible damage to both the object\nand the robot. To address the above problems, we propose an online optimization\nframework to: 1) estimate and predict the linear and angular motion of the\nobject; 2) search and select the optimal contact locations across every surface\nof the object to mitigate impact through sequential quadratic programming\n(SQP); 3) simultaneously optimize the end-effector motion, stiffness, and\ncontact force for both robots using multi-mode trajectory optimization (MMTO);\nand 4) realise the impact-aware catching motion on the compliant robotic system\nbased on indirect force controller. We validate the impulse distribution,\ncontact selection, and impact-aware MMTO algorithms in simulation and\ndemonstrate the benefits of the proposed framework in real-world experiments\nincluding catching large-momentum moving objects with well-defined motion,\nconstrained motion and free-flying motion.\n","authors":["Lei Yan","Theodoros Stouraitis","João Moura","Wenfu Xu","Michael Gienger","Sethu Vijayakumar"],"pdf_url":"https://arxiv.org/pdf/2403.17249v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17247v1","updated":"2024-03-25T22:49:56Z","published":"2024-03-25T22:49:56Z","title":"DASA: Delay-Adaptive Multi-Agent Stochastic Approximation","summary":"  We consider a setting in which $N$ agents aim to speedup a common Stochastic\nApproximation (SA) problem by acting in parallel and communicating with a\ncentral server. We assume that the up-link transmissions to the server are\nsubject to asynchronous and potentially unbounded time-varying delays. To\nmitigate the effect of delays and stragglers while reaping the benefits of\ndistributed computation, we propose \\texttt{DASA}, a Delay-Adaptive algorithm\nfor multi-agent Stochastic Approximation. We provide a finite-time analysis of\n\\texttt{DASA} assuming that the agents' stochastic observation processes are\nindependent Markov chains. Significantly advancing existing results,\n\\texttt{DASA} is the first algorithm whose convergence rate depends only on the\nmixing time $\\tmix$ and on the average delay $\\tau_{avg}$ while jointly\nachieving an $N$-fold convergence speedup under Markovian sampling. Our work is\nrelevant for various SA applications, including multi-agent and distributed\ntemporal difference (TD) learning, Q-learning and stochastic optimization with\ncorrelated data.\n","authors":["Nicolo Dal Fabbro","Arman Adibi","H. Vincent Poor","Sanjeev R. Kulkarni","Aritra Mitra","George J. Pappas"],"pdf_url":"https://arxiv.org/pdf/2403.17247v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17246v1","updated":"2024-03-25T22:47:13Z","published":"2024-03-25T22:47:13Z","title":"TwoStep: Multi-agent Task Planning using Classical Planners and Large\n  Language Models","summary":"  Classical planning formulations like the Planning Domain Definition Language\n(PDDL) admit action sequences guaranteed to achieve a goal state given an\ninitial state if any are possible. However, reasoning problems defined in PDDL\ndo not capture temporal aspects of action taking, for example that two agents\nin the domain can execute an action simultaneously if postconditions of each do\nnot interfere with preconditions of the other. A human expert can decompose a\ngoal into largely independent constituent parts and assign each agent to one of\nthese subgoals to take advantage of simultaneous actions for faster execution\nof plan steps, each using only single agent planning. By contrast, large\nlanguage models (LLMs) used for directly inferring plan steps do not guarantee\nexecution success, but do leverage commonsense reasoning to assemble action\nsequences. We combine the strengths of classical planning and LLMs by\napproximating human intuitions for two-agent planning goal decomposition. We\ndemonstrate that LLM-based goal decomposition leads to faster planning times\nthan solving multi-agent PDDL problems directly while simultaneously achieving\nfewer plan execution steps than a single agent plan alone and preserving\nexecution success. Additionally, we find that LLM-based approximations of\nsubgoals can achieve similar multi-agent execution steps than those specified\nby human experts. Website and resources at https://glamor-usc.github.io/twostep\n","authors":["Ishika Singh","David Traum","Jesse Thomason"],"pdf_url":"https://arxiv.org/pdf/2403.17246v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2403.17238v1","updated":"2024-03-25T22:39:20Z","published":"2024-03-25T22:39:20Z","title":"Temporal and Semantic Evaluation Metrics for Foundation Models in\n  Post-Hoc Analysis of Robotic Sub-tasks","summary":"  Recent works in Task and Motion Planning (TAMP) show that training control\npolicies on language-supervised robot trajectories with quality labeled data\nmarkedly improves agent task success rates. However, the scarcity of such data\npresents a significant hurdle to extending these methods to general use cases.\nTo address this concern, we present an automated framework to decompose\ntrajectory data into temporally bounded and natural language-based descriptive\nsub-tasks by leveraging recent prompting strategies for Foundation Models (FMs)\nincluding both Large Language Models (LLMs) and Vision Language Models (VLMs).\nOur framework provides both time-based and language-based descriptions for\nlower-level sub-tasks that comprise full trajectories. To rigorously evaluate\nthe quality of our automatic labeling framework, we contribute an algorithm\nSIMILARITY to produce two novel metrics, temporal similarity and semantic\nsimilarity. The metrics measure the temporal alignment and semantic fidelity of\nlanguage descriptions between two sub-task decompositions, namely an FM\nsub-task decomposition prediction and a ground-truth sub-task decomposition. We\npresent scores for temporal similarity and semantic similarity above 90%,\ncompared to 30% of a randomized baseline, for multiple robotic environments,\ndemonstrating the effectiveness of our proposed framework. Our results enable\nbuilding diverse, large-scale, language-supervised datasets for improved\nrobotic TAMP.\n","authors":["Jonathan Salfity","Selma Wanna","Minkyu Choi","Mitch Pryor"],"pdf_url":"https://arxiv.org/pdf/2403.17238v1.pdf","comment":"8 pages, 3 figures. IROS 2024 Submission"},{"id":"http://arxiv.org/abs/2403.17234v1","updated":"2024-03-25T22:21:23Z","published":"2024-03-25T22:21:23Z","title":"Speeding Up Path Planning via Reinforcement Learning in MCTS for\n  Automated Parking","summary":"  In this paper, we address a method that integrates reinforcement learning\ninto the Monte Carlo tree search to boost online path planning under fully\nobservable environments for automated parking tasks. Sampling-based planning\nmethods under high-dimensional space can be computationally expensive and\ntime-consuming. State evaluation methods are useful by leveraging the prior\nknowledge into the search steps, making the process faster in a real-time\nsystem. Given the fact that automated parking tasks are often executed under\ncomplex environments, a solid but lightweight heuristic guidance is challenging\nto compose in a traditional analytical way. To overcome this limitation, we\npropose a reinforcement learning pipeline with a Monte Carlo tree search under\nthe path planning framework. By iteratively learning the value of a state and\nthe best action among samples from its previous cycle's outcomes, we are able\nto model a value estimator and a policy generator for given states. By doing\nthat, we build up a balancing mechanism between exploration and exploitation,\nspeeding up the path planning process while maintaining its quality without\nusing human expert driver data.\n","authors":["Xinlong Zheng","Xiaozhou Zhang","Donghao Xu"],"pdf_url":"https://arxiv.org/pdf/2403.17234v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17232v1","updated":"2024-03-25T22:19:58Z","published":"2024-03-25T22:19:58Z","title":"PROSPECT: Precision Robot Spectroscopy Exploration and Characterization\n  Tool","summary":"  Near Infrared (NIR) spectroscopy is widely used in industrial quality control\nand automation to test the purity and material quality of items. In this\nresearch, we propose a novel sensorized end effector and acquisition strategy\nto capture spectral signatures from objects and register them with a 3D point\ncloud. Our methodology first takes a 3D scan of an object generated by a\ntime-of-flight depth camera and decomposes the object into a series of planned\nviewpoints covering the surface. We generate motion plans for a robot\nmanipulator and end-effector to visit these viewpoints while maintaining a\nfixed distance and surface normal to ensure maximal spectral signal quality\nenabled by the spherical motion of the end-effector. By continuously acquiring\nsurface reflectance values as the end-effector scans the target object, the\nautonomous system develops a four-dimensional model of the target object:\nposition in an R^3 coordinate frame, and a wavelength vector denoting the\nassociated spectral signature. We demonstrate this system in building\nspectral-spatial object profiles of increasingly complex geometries. As a point\nof comparison, we show our proposed system and spectral acquisition planning\nyields more consistent signal signals than naive point scanning strategies for\ncapturing spectral information over complex surface geometries. Our work\nrepresents a significant step towards high-resolution spectral-spatial sensor\nfusion for automated quality assessment.\n","authors":["Nathaniel Hanson","Gary Lvov","Vedant Rautela","Samuel Hibbard","Ethan Holand","Charles DiMarzio","Taşkın Padır"],"pdf_url":"https://arxiv.org/pdf/2403.17232v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17231v1","updated":"2024-03-25T22:17:51Z","published":"2024-03-25T22:17:51Z","title":"Dyna-LfLH: Learning Agile Navigation in Dynamic Environments from\n  Learned Hallucination","summary":"  This paper presents a self-supervised learning method to safely learn a\nmotion planner for ground robots to navigate environments with dense and\ndynamic obstacles. When facing highly-cluttered, fast-moving, hard-to-predict\nobstacles, classical motion planners may not be able to keep up with limited\nonboard computation. For learning-based planners, high-quality demonstrations\nare difficult to acquire for imitation learning while reinforcement learning\nbecomes inefficient due to the high probability of collision during\nexploration. To safely and efficiently provide training data, the Learning from\nHallucination (LfH) approaches synthesize difficult navigation environments\nbased on past successful navigation experiences in relatively easy or\ncompletely open ones, but unfortunately cannot address dynamic obstacles. In\nour new Dynamic Learning from Learned Hallucination (Dyna-LfLH), we design and\nlearn a novel latent distribution and sample dynamic obstacles from it, so the\ngenerated training data can be used to learn a motion planner to navigate in\ndynamic environments. Dyna-LfLH is evaluated on a ground robot in both\nsimulated and physical environments and achieves up to 25% better success rate\ncompared to baselines.\n","authors":["Saad Abdul Ghani","Zizhao Wang","Peter Stone","Xuesu Xiao"],"pdf_url":"https://arxiv.org/pdf/2403.17231v1.pdf","comment":"Submitted to International Conference on Intelligent Robots and\n  Systems (IROS) 2024"},{"id":"http://arxiv.org/abs/2310.10863v2","updated":"2024-03-25T20:46:28Z","published":"2023-10-16T22:23:18Z","title":"Greedy Perspectives: Multi-Drone View Planning for Collaborative\n  Perception in Cluttered Environments","summary":"  Deployment of teams of aerial robots could enable large-scale filming of\ndynamic groups of people (actors) in complex environments for applications in\nareas such as team sports and cinematography. Toward this end, methods for\nsubmodular maximization via sequential greedy planning can be used for scalable\noptimization of camera views across teams of robots but face challenges with\nefficient coordination in cluttered environments. Obstacles can produce\nocclusions and increase chances of inter-robot collision which can violate\nrequirements for near-optimality guarantees. To coordinate teams of aerial\nrobots in filming groups of people in dense environments, a more general\nview-planning approach is required. We explore how collision and occlusion\nimpact performance in filming applications through the development of a\nmulti-robot multi-actor view planner with an occlusion-aware objective for\nfilming groups of people and compare with a formation planner and a greedy\nplanner that ignores inter-robot collisions. We evaluate our approach based on\nfive test environments and complex multi-actor behaviors. Compared with a\nformation planner, our sequential planner generates 14% greater view reward\nover the actors for three scenarios and comparable performance to formation\nplanning on two others. We also observe near identical view rewards for\nsequential planning both with and without inter-robot collision constraints\nwhich indicates that robots are able to avoid collisions without impairing\nperformance in the perception task. Overall, we demonstrate effective\ncoordination of teams of aerial robots for filming groups that may split,\nmerge, or spread apart and in environments cluttered with obstacles that may\ncause collisions or occlusions.\n","authors":["Krishna Suresh","Aditya Rauniyar","Micah Corah","Sebastian Scherer"],"pdf_url":"https://arxiv.org/pdf/2310.10863v2.pdf","comment":"Submitted to IROS'24; 8 pages, 8 figures, 2 tables"},{"id":"http://arxiv.org/abs/2309.10275v2","updated":"2024-03-25T20:28:22Z","published":"2023-09-19T03:02:43Z","title":"Optimizing Crowd-Aware Multi-Agent Path Finding through Local\n  Broadcasting with Graph Neural Networks","summary":"  Multi-Agent Path Finding (MAPF) in crowded environments presents a\nchallenging problem in motion planning, aiming to find collision-free paths for\nall agents in the system. MAPF finds a wide range of applications in various\ndomains, including aerial swarms, autonomous warehouse robotics, and\nself-driving vehicles. Current approaches to MAPF generally fall into two main\ncategories: centralized and decentralized planning. Centralized planning\nsuffers from the curse of dimensionality when the number of agents or states\nincreases and thus does not scale well in large and complex environments. On\nthe other hand, decentralized planning enables agents to engage in real-time\npath planning within a partially observable environment, demonstrating implicit\ncoordination. However, they suffer from slow convergence and performance\ndegradation in dense environments. In this paper, we introduce CRAMP, a novel\ncrowd-aware decentralized reinforcement learning approach to address this\nproblem by enabling efficient local communication among agents via Graph Neural\nNetworks (GNNs), facilitating situational awareness and decision-making\ncapabilities in congested environments. We test CRAMP on simulated environments\nand demonstrate that our method outperforms the state-of-the-art decentralized\nmethods for MAPF on various metrics. CRAMP improves the solution quality up to\n59% measured in makespan and collision count, and up to 35% improvement in\nsuccess rate in comparison to previous methods.\n","authors":["Phu Pham","Aniket Bera"],"pdf_url":"https://arxiv.org/pdf/2309.10275v2.pdf","comment":"8 pages, 5 figures, 2 tables"},{"id":"http://arxiv.org/abs/2305.18983v3","updated":"2024-03-25T20:21:25Z","published":"2023-05-30T12:27:47Z","title":"SO(2)-Equivariant Downwash Models for Close Proximity Flight","summary":"  Multirotors flying in close proximity induce aerodynamic wake effects on each\nother through propeller downwash. Conventional methods have fallen short of\nproviding adequate 3D force-based models that can be incorporated into robust\ncontrol paradigms for deploying dense formations. Thus, learning a model for\nthese downwash patterns presents an attractive solution. In this paper, we\npresent a novel learning-based approach for modelling the downwash forces that\nexploits the latent geometries (i.e. symmetries) present in the problem. We\ndemonstrate that when trained with only 5 minutes of real-world flight data,\nour geometry-aware model outperforms state-of-the-art baseline models trained\nwith more than 15 minutes of data. In dense real-world flights with two\nvehicles, deploying our model online improves 3D trajectory tracking by nearly\n36% on average (and vertical tracking by 56%).\n","authors":["H. Smith","A. Shankar","J. Gielis","J. Blumenkamp","A. Prorok"],"pdf_url":"https://arxiv.org/pdf/2305.18983v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17161v1","updated":"2024-03-25T20:18:12Z","published":"2024-03-25T20:18:12Z","title":"Multi-Contact Inertial Estimation and Localization in Legged Robots","summary":"  Optimal estimation is a promising tool for multi-contact inertial estimation\nand localization. To harness its advantages in robotics, it is crucial to solve\nthese large and challenging optimization problems efficiently. To tackle this,\nwe (i) develop a multiple-shooting solver that exploits both temporal and\nparametric structures through a parametrized Riccati recursion. Additionally,\nwe (ii) propose an inertial local manifold that ensures its full physical\nconsistency. It also enhances convergence compared to the singularity-free\nlog-Cholesky approach. To handle its singularities, we (iii) introduce a\nnullspace approach in our optimal estimation solver. We (iv) finally develop\nthe analytical derivatives of contact dynamics for both inertial\nparametrizations. Our framework can successfully solve estimation problems for\ncomplex maneuvers such as brachiation in humanoids. We demonstrate its\nnumerical capabilities across various robotics tasks and its benefits in\nexperimental trials with the Go1 robot.\n","authors":["Sergi Martinez","Robert Griffin","Carlos Mastalli"],"pdf_url":"https://arxiv.org/pdf/2403.17161v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.01519v2","updated":"2024-03-25T20:14:46Z","published":"2023-10-02T18:11:01Z","title":"Decision-Oriented Learning Using Differentiable Submodular Maximization\n  for Multi-Robot Coordination","summary":"  We present a differentiable, decision-oriented learning framework for cost\nprediction in a class of multi-robot decision-making problems, in which the\nrobots need to trade off the task performance with the costs of taking actions\nwhen they select actions to take. Specifically, we consider the cases where the\ntask performance is measured by a known monotone submodular function (e.g.,\ncoverage, mutual information), and the cost of actions depends on the context\n(e.g., wind and terrain conditions). We need to learn a function that maps the\ncontext to the costs. Classically, we treat such a learning problem and the\ndownstream decision-making problem as two decoupled problems, i.e., we first\nlearn to predict the cost function without considering the downstream\ndecision-making problem, and then use the learned function for predicting the\ncost and using it in the decision-making problem. However, the loss function\nused in learning a prediction function may not be aligned with the downstream\ndecision-making. We propose a decision-oriented learning framework that\nincorporates the downstream task performance in the prediction phase via a\ndifferentiable optimization layer. The main computational challenge in such a\nframework is to make the combinatorial optimization, i.e., non-monotone\nsubmodular maximization, differentiable. This function is not naturally\ndifferentiable. We propose the Differentiable Cost Scaled Greedy algorithm\n(D-CSG), which is a continuous and differentiable relaxation of CSG. We\ndemonstrate the efficacy of the proposed framework through numerical\nsimulations. The results show that the proposed framework can result in better\nperformance than the traditional two-stage approach.\n","authors":["Guangyao Shi","Chak Lam Shek","Nare Karapetyan","Pratap Tokekar"],"pdf_url":"https://arxiv.org/pdf/2310.01519v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2303.01543"},{"id":"http://arxiv.org/abs/2403.17147v1","updated":"2024-03-25T19:50:07Z","published":"2024-03-25T19:50:07Z","title":"Hearing the shape of an arena with spectral swarm robotics","summary":"  Swarm robotics promises adaptability to unknown situations and robustness\nagainst failures. However, it still struggles with global tasks that require\nunderstanding the broader context in which the robots operate, such as\nidentifying the shape of the arena in which the robots are embedded. Biological\nswarms, such as shoals of fish, flocks of birds, and colonies of insects,\nroutinely solve global geometrical problems through the diffusion of local\ncues. This paradigm can be explicitly described by mathematical models that\ncould be directly computed and exploited by a robotic swarm. Diffusion over a\ndomain is mathematically encapsulated by the Laplacian, a linear operator that\nmeasures the local curvature of a function. Crucially the geometry of a domain\ncan generally be reconstructed from the eigenspectrum of its Laplacian. Here we\nintroduce spectral swarm robotics where robots diffuse information to their\nneighbors to emulate the Laplacian operator - enabling them to \"hear\" the\nspectrum of their arena. We reveal a universal scaling that links the optimal\nnumber of robots (a global parameter) with their optimal radius of interaction\n(a local parameter). We validate experimentally spectral swarm robotics under\nchallenging conditions with the one-shot classification of arena shapes using a\nsparse swarm of Kilobots. Spectral methods can assist with challenging tasks\nwhere robots need to build an emergent consensus on their environment, such as\nadaptation to unknown terrains, division of labor, or quorum sensing. Spectral\nmethods may extend beyond robotics to analyze and coordinate swarms of agents\nof various natures, such as traffic or crowds, and to better understand the\nlong-range dynamics of natural systems emerging from short-range interactions.\n","authors":["Leo Cazenille","Nicolas Lobato-Dauzier","Alessia Loi","Mika Ito","Olivier Marchal","Nathanael Aubert-Kato","Nicolas Bredeche","Anthony J. Genot"],"pdf_url":"https://arxiv.org/pdf/2403.17147v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.07021v2","updated":"2024-03-25T19:46:25Z","published":"2023-10-10T21:16:29Z","title":"Pre-Trained Masked Image Model for Mobile Robot Navigation","summary":"  2D top-down maps are commonly used for the navigation and exploration of\nmobile robots through unknown areas. Typically, the robot builds the navigation\nmaps incrementally from local observations using onboard sensors. Recent works\nhave shown that predicting the structural patterns in the environment through\nlearning-based approaches can greatly enhance task efficiency. While many such\nworks build task-specific networks using limited datasets, we show that the\nexisting foundational vision networks can accomplish the same without any\nfine-tuning. Specifically, we use Masked Autoencoders, pre-trained on street\nimages, to present novel applications for field-of-view expansion, single-agent\ntopological exploration, and multi-agent exploration for indoor mapping, across\ndifferent input modalities. Our work motivates the use of foundational vision\nmodels for generalized structure prediction-driven applications, especially in\nthe dearth of training data. For more qualitative results see\nhttps://raaslab.org/projects/MIM4Robots.\n","authors":["Vishnu Dutt Sharma","Anukriti Singh","Pratap Tokekar"],"pdf_url":"https://arxiv.org/pdf/2310.07021v2.pdf","comment":"Accepted at ICRA 2024"},{"id":"http://arxiv.org/abs/2403.14887v2","updated":"2024-03-25T19:25:21Z","published":"2024-03-21T23:44:42Z","title":"GelLink: A Compact Multi-phalanx Finger with Vision-based Tactile\n  Sensing and Proprioception","summary":"  Compared to fully-actuated robotic end-effectors, underactuated ones are\ngenerally more adaptive, robust, and cost-effective. However, state estimation\nfor underactuated hands is usually more challenging. Vision-based tactile\nsensors, like Gelsight, can mitigate this issue by providing high-resolution\ntactile sensing and accurate proprioceptive sensing. As such, we present\nGelLink, a compact, underactuated, linkage-driven robotic finger with low-cost,\nhigh-resolution vision-based tactile sensing and proprioceptive sensing\ncapabilities. In order to reduce the amount of embedded hardware, i.e. the\ncameras and motors, we optimize the linkage transmission with a planar linkage\nmechanism simulator and develop a planar reflection simulator to simplify the\ntactile sensing hardware. As a result, GelLink only requires one motor to\nactuate the three phalanges, and one camera to capture tactile signals along\nthe entire finger. Overall, GelLink is a compact robotic finger that shows\nadaptability and robustness when performing grasping tasks. The integration of\nvision-based tactile sensors can significantly enhance the capabilities of\nunderactuated fingers and potentially broaden their future usage.\n","authors":["Yuxiang Ma","Jialiang Zhao","Edward Adelson"],"pdf_url":"https://arxiv.org/pdf/2403.14887v2.pdf","comment":"Supplement video: https://www.youtube.com/watch?v=hZwUpAig5C0 . 7\n  pages, 9 figures. ICRA 2024 (IEEE International Conference on Robotics and\n  Automation)"},{"id":"http://arxiv.org/abs/2403.17136v1","updated":"2024-03-25T19:18:25Z","published":"2024-03-25T19:18:25Z","title":"Adaptive Step Duration for Precise Foot Placement: Achieving Robust\n  Bipedal Locomotion on Terrains with Restricted Footholds","summary":"  This paper introduces a novel multi-step preview foot placement planning\nalgorithm designed to enhance the robustness of bipedal robotic walking across\nchallenging terrains with restricted footholds. Traditional one-step preview\nplanning struggles to maintain stability when stepping areas are severely\nlimited, such as with random stepping stones. In this work, we developed a\ndiscrete-time Model Predictive Control (MPC) based on the step-to-step discrete\nevolution of the Divergent Component of Motion (DCM) of bipedal locomotion.\nThis approach adaptively changes the step duration for optimal foot placement\nunder constraints, thereby ensuring the robot's operational viability over\nmultiple future steps and significantly improving its ability to navigate\nthrough environments with tight constraints on possible footholds. The\neffectiveness of this planning algorithm is demonstrated through simulations\nthat include a variety of complex stepping-stone configurations and external\nperturbations. These tests underscore the algorithm's improved performance for\nnavigating foothold-restricted environments, even with the presence of external\ndisturbances.\n","authors":["Zhaoyang Xiang","Victor Paredes","Ayonga Hereid"],"pdf_url":"https://arxiv.org/pdf/2403.17136v1.pdf","comment":"8 pages, 8 figures, submitted to CDC 2024, for associated simulation\n  video, see https://youtu.be/2jhikPlZmbE"},{"id":"http://arxiv.org/abs/2403.05972v3","updated":"2024-03-25T19:15:44Z","published":"2024-03-09T17:37:05Z","title":"C3D: Cascade Control with Change Point Detection and Deep Koopman\n  Learning for Autonomous Surface Vehicles","summary":"  In this paper, we discuss the development and deployment of a robust\nautonomous system capable of performing various tasks in the maritime domain\nunder unknown dynamic conditions. We investigate a data-driven approach based\non modular design for ease of transfer of autonomy across different maritime\nsurface vessel platforms. The data-driven approach alleviates issues related to\na priori identification of system models that may become deficient under\nevolving system behaviors or shifting, unanticipated, environmental influences.\nOur proposed learning-based platform comprises a deep Koopman system model and\na change point detector that provides guidance on domain shifts prompting\nrelearning under severe exogenous and endogenous perturbations. Motion control\nof the autonomous system is achieved via an optimal controller design. The\nKoopman linearized model naturally lends itself to a linear-quadratic regulator\n(LQR) control design. We propose the C3D control architecture Cascade Control\nwith Change Point Detection and Deep Koopman Learning. The framework is\nverified in station keeping task on an ASV in both simulation and real\nexperiments. The approach achieved at least 13.9 percent improvement in mean\ndistance error in all test cases compared to the methods that do not consider\nsystem changes.\n","authors":["Jianwen Li","Hyunsang Park","Wenjian Hao","Lei Xin","Jalil Chavez-Galaviz","Ajinkya Chaudhary","Meredith Bloss","Kyle Pattison","Christopher Vo","Devesh Upadhyay","Shreyas Sundaram","Shaoshuai Mou","Nina Mahmoudian"],"pdf_url":"https://arxiv.org/pdf/2403.05972v3.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2403.17124v1","updated":"2024-03-25T19:04:59Z","published":"2024-03-25T19:04:59Z","title":"Grounding Language Plans in Demonstrations Through Counterfactual\n  Perturbations","summary":"  Grounding the common-sense reasoning of Large Language Models in physical\ndomains remains a pivotal yet unsolved problem for embodied AI. Whereas prior\nworks have focused on leveraging LLMs directly for planning in symbolic spaces,\nthis work uses LLMs to guide the search of task structures and constraints\nimplicit in multi-step demonstrations. Specifically, we borrow from\nmanipulation planning literature the concept of mode families, which group\nrobot configurations by specific motion constraints, to serve as an abstraction\nlayer between the high-level language representations of an LLM and the\nlow-level physical trajectories of a robot. By replaying a few human\ndemonstrations with synthetic perturbations, we generate coverage over the\ndemonstrations' state space with additional successful executions as well as\ncounterfactuals that fail the task. Our explanation-based learning framework\ntrains an end-to-end differentiable neural network to predict successful\ntrajectories from failures and as a by-product learns classifiers that ground\nlow-level states and images in mode families without dense labeling. The\nlearned grounding classifiers can further be used to translate language plans\ninto reactive policies in the physical domain in an interpretable manner. We\nshow our approach improves the interpretability and reactivity of imitation\nlearning through 2D navigation and simulated and real robot manipulation tasks.\nWebsite: https://sites.google.com/view/grounding-plans\n","authors":["Yanwei Wang","Tsun-Hsuan Wang","Jiayuan Mao","Michael Hagenow","Julie Shah"],"pdf_url":"https://arxiv.org/pdf/2403.17124v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17111v1","updated":"2024-03-25T18:49:12Z","published":"2024-03-25T18:49:12Z","title":"Vision-Based Dexterous Motion Planning by Dynamic Movement Primitives\n  with Human Hand Demonstration","summary":"  This paper proposes a vision-based framework for a 7-degree-of-freedom\nrobotic manipulator, with the primary objective of facilitating its capacity to\nacquire information from human hand demonstrations for the execution of\ndexterous pick-and-place tasks. Most existing works only focus on the position\ndemonstration without considering the orientations. In this paper, by employing\na single depth camera, MediaPipe is applied to generate the three-dimensional\ncoordinates of a human hand, thereby comprehensively recording the hand's\nmotion, encompassing the trajectory of the wrist, orientation of the hand, and\nthe grasp motion. A mean filter is applied during data pre-processing to smooth\nthe raw data. The demonstration is designed to pick up an object at a specific\nangle, navigate around obstacles in its path and subsequently, deposit it\nwithin a sloped container. The robotic system demonstrates its learning\ncapabilities, facilitated by the implementation of Dynamic Movement Primitives,\nenabling the assimilation of user actions into its trajectories with different\nstart and end poi\n","authors":["Nuo Chen","Ya-Jun Pan"],"pdf_url":"https://arxiv.org/pdf/2403.17111v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17099v1","updated":"2024-03-25T18:37:01Z","published":"2024-03-25T18:37:01Z","title":"Berry Twist: a Twisting-Tube Soft Robotic Gripper for Blackberry\n  Harvesting","summary":"  As global demand for fruits and vegetables continues to rise, the\nagricultural industry faces challenges in securing adequate labor. Robotic\nharvesting devices offer a promising solution to solve this issue. However,\nharvesting delicate fruits, notably blackberries, poses unique challenges due\nto their fragility. This study introduces and evaluates a prototype robotic\ngripper specifically designed for blackberry harvesting. The gripper features\nan innovative fabric tube mechanism employing motorized twisting action to\ngently envelop the fruit, ensuring uniform pressure application and minimizing\ndamage. Three types of tubes were developed, varying in elasticity and\ncompressibility using foam padding, spandex, and food-safe cotton cheesecloth.\nPerformance testing focused on assessing each gripper's ability to detach and\nrelease blackberries, with emphasis on quantifying damage rates. Results\nindicate the proposed gripper achieved an 82% success rate in detaching\nblackberries and a 95% success rate in releasing them, showcasing the promised\npotential for robotic harvesting applications.\n","authors":["Johannes F. Elfferich","Ebrahim Shahabi","Cosimo Della Santina","Dimitra Dodou"],"pdf_url":"https://arxiv.org/pdf/2403.17099v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2004.01041v8","updated":"2024-03-25T18:21:39Z","published":"2020-04-01T06:37:54Z","title":"On the Feedback Law in Stochastic Optimal Nonlinear Control","summary":"  We consider the problem of nonlinear stochastic optimal control. This problem\nis thought to be fundamentally intractable owing to Bellman's ``curse of\ndimensionality\". We present a result that shows that repeatedly solving an\nopen-loop deterministic problem from the current state with progressively\nshorter horizons, similar to Model Predictive Control (MPC), results in a\nfeedback policy that is $O(\\epsilon^4)$ near to the true global stochastic\noptimal policy, \\nxx{where $\\epsilon$ is a perturbation parameter modulating\nthe noise.} We show that the optimal deterministic feedback problem has a\nperturbation structure in that higher-order terms of the feedback law do not\naffect lower-order terms, and that this structure is lost in the optimal\nstochastic feedback problem. Consequently, solving the Stochastic Dynamic\nProgramming problem is highly susceptible to noise, even when tractable, and in\npractice, the MPC-type feedback law offers superior performance even for\nstochastic systems.\n","authors":["Mohamed Naveed Gul Mohamed","Suman Chakravorty","Raman Goyal","Ran Wang"],"pdf_url":"https://arxiv.org/pdf/2004.01041v8.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2002.10505,\n  arXiv:2002.09478"},{"id":"http://arxiv.org/abs/2403.17084v1","updated":"2024-03-25T18:18:12Z","published":"2024-03-25T18:18:12Z","title":"A Comparative Analysis of Visual Odometry in Virtual and Real-World\n  Railways Environments","summary":"  Perception tasks play a crucial role in the development of automated\noperations and systems across multiple application fields. In the railway\ntransportation domain, these tasks can improve the safety, reliability, and\nefficiency of various perations, including train localization, signal\nrecognition, and track discrimination. However, collecting considerable and\nprecisely labeled datasets for testing such novel algorithms poses extreme\nchallenges in the railway environment due to the severe restrictions in\naccessing the infrastructures and the practical difficulties associated with\nproperly equipping trains with the required sensors, such as cameras and\nLiDARs. The remarkable innovations of graphic engine tools offer new solutions\nto craft realistic synthetic datasets. To illustrate the advantages of\nemploying graphic simulation for early-stage testing of perception tasks in the\nrailway domain, this paper presents a comparative analysis of the performance\nof a SLAM algorithm applied both in a virtual synthetic environment and a\nreal-world scenario. The analysis leverages virtual railway environments\ncreated with the latest version of Unreal Engine, facilitating data collection\nand allowing the examination of challenging scenarios, including\nlow-visibility, dangerous operational modes, and complex environments. The\nresults highlight the feasibility and potentiality of graphic simulation to\nadvance perception tasks in the railway domain.\n","authors":["Gianluca D'Amico","Mauro Marinoni","Giorgio Buttazzo"],"pdf_url":"https://arxiv.org/pdf/2403.17084v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17067v1","updated":"2024-03-25T18:03:50Z","published":"2024-03-25T18:03:50Z","title":"Trajectory Optimization with Global Yaw Parameterization for\n  Field-of-View Constrained Autonomous Flight","summary":"  Trajectory generation for quadrotors with limited field-of-view sensors has\nnumerous applications such as aerial exploration, coverage, inspection,\nvideography, and target tracking. Most previous works simplify the task of\noptimizing yaw trajectories by either aligning the heading of the robot with\nits velocity, or potentially restricting the feasible space of candidate\ntrajectories by using a limited yaw domain to circumvent angular singularities.\nIn this paper, we propose a novel \\textit{global} yaw parameterization method\nfor trajectory optimization that allows a 360-degree yaw variation as demanded\nby the underlying algorithm. This approach effectively bypasses inherent\nsingularities by including supplementary quadratic constraints and transforming\nthe final decision variables into the desired state representation. This method\nsignificantly reduces the needed control effort, and improves optimization\nfeasibility. Furthermore, we apply the method to several examples of different\napplications that require jointly optimizing over both the yaw and position\ntrajectories. Ultimately, we present a comprehensive numerical analysis and\nevaluation of our proposed method in both simulation and real-world\nexperiments.\n","authors":["Yuwei Wu","Yuezhan Tao","Igor Spasojevic","Vijay Kumar"],"pdf_url":"https://arxiv.org/pdf/2403.17067v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17010v1","updated":"2024-03-25T17:59:59Z","published":"2024-03-25T17:59:59Z","title":"Calib3D: Calibrating Model Preferences for Reliable 3D Scene\n  Understanding","summary":"  Safety-critical 3D scene understanding tasks necessitate not only accurate\nbut also confident predictions from 3D perception models. This study introduces\nCalib3D, a pioneering effort to benchmark and scrutinize the reliability of 3D\nscene understanding models from an uncertainty estimation viewpoint. We\ncomprehensively evaluate 28 state-of-the-art models across 10 diverse 3D\ndatasets, uncovering insightful phenomena that cope with both the aleatoric and\nepistemic uncertainties in 3D scene understanding. We discover that despite\nachieving impressive levels of accuracy, existing models frequently fail to\nprovide reliable uncertainty estimates -- a pitfall that critically undermines\ntheir applicability in safety-sensitive contexts. Through extensive analysis of\nkey factors such as network capacity, LiDAR representations, rasterization\nresolutions, and 3D data augmentation techniques, we correlate these aspects\ndirectly with the model calibration efficacy. Furthermore, we introduce DeptS,\na novel depth-aware scaling approach aimed at enhancing 3D model calibration.\nExtensive experiments across a wide range of configurations validate the\nsuperiority of our method. We hope this work could serve as a cornerstone for\nfostering reliable 3D scene understanding. Code and benchmark toolkits are\npublicly available.\n","authors":["Lingdong Kong","Xiang Xu","Jun Cen","Wenwei Zhang","Liang Pan","Kai Chen","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2403.17010v1.pdf","comment":"Preprint; 37 pages, 8 figures, 11 tables; Code at\n  https://github.com/ldkong1205/Calib3D"},{"id":"http://arxiv.org/abs/2403.17009v1","updated":"2024-03-25T17:59:58Z","published":"2024-03-25T17:59:58Z","title":"Optimizing LiDAR Placements for Robust Driving Perception in Adverse\n  Conditions","summary":"  The robustness of driving perception systems under unprecedented conditions\nis crucial for safety-critical usages. Latest advancements have prompted\nincreasing interests towards multi-LiDAR perception. However, prevailing\ndriving datasets predominantly utilize single-LiDAR systems and collect data\ndevoid of adverse conditions, failing to capture the complexities of real-world\nenvironments accurately. Addressing these gaps, we proposed Place3D, a\nfull-cycle pipeline that encompasses LiDAR placement optimization, data\ngeneration, and downstream evaluations. Our framework makes three appealing\ncontributions. 1) To identify the most effective configurations for multi-LiDAR\nsystems, we introduce a Surrogate Metric of the Semantic Occupancy Grids\n(M-SOG) to evaluate LiDAR placement quality. 2) Leveraging the M-SOG metric, we\npropose a novel optimization strategy to refine multi-LiDAR placements. 3)\nCentered around the theme of multi-condition multi-LiDAR perception, we collect\na 364,000-frame dataset from both clean and adverse conditions. Extensive\nexperiments demonstrate that LiDAR placements optimized using our approach\noutperform various baselines. We showcase exceptional robustness in both 3D\nobject detection and LiDAR semantic segmentation tasks, under diverse adverse\nweather and sensor failure conditions. Code and benchmark toolkit are publicly\navailable.\n","authors":["Ye Li","Lingdong Kong","Hanjiang Hu","Xiaohao Xu","Xiaonan Huang"],"pdf_url":"https://arxiv.org/pdf/2403.17009v1.pdf","comment":"Preprint; 40 pages, 11 figures, 15 tables; Code at\n  https://github.com/ywyeli/Place3D"},{"id":"http://arxiv.org/abs/2403.16996v1","updated":"2024-03-25T17:59:01Z","published":"2024-03-25T17:59:01Z","title":"DriveCoT: Integrating Chain-of-Thought Reasoning with End-to-End Driving","summary":"  End-to-end driving has made significant progress in recent years,\ndemonstrating benefits such as system simplicity and competitive driving\nperformance under both open-loop and closed-loop settings. Nevertheless, the\nlack of interpretability and controllability in its driving decisions hinders\nreal-world deployment for end-to-end driving systems. In this paper, we collect\na comprehensive end-to-end driving dataset named DriveCoT, leveraging the CARLA\nsimulator. It contains sensor data, control decisions, and chain-of-thought\nlabels to indicate the reasoning process. We utilize the challenging driving\nscenarios from the CARLA leaderboard 2.0, which involve high-speed driving and\nlane-changing, and propose a rule-based expert policy to control the vehicle\nand generate ground truth labels for its reasoning process across different\ndriving aspects and the final decisions. This dataset can serve as an open-loop\nend-to-end driving benchmark, enabling the evaluation of accuracy in various\nchain-of-thought aspects and the final decision. In addition, we propose a\nbaseline model called DriveCoT-Agent, trained on our dataset, to generate\nchain-of-thought predictions and final decisions. The trained model exhibits\nstrong performance in both open-loop and closed-loop evaluations, demonstrating\nthe effectiveness of our proposed dataset.\n","authors":["Tianqi Wang","Enze Xie","Ruihang Chu","Zhenguo Li","Ping Luo"],"pdf_url":"https://arxiv.org/pdf/2403.16996v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16967v1","updated":"2024-03-25T17:26:08Z","published":"2024-03-25T17:26:08Z","title":"Visual Whole-Body Control for Legged Loco-Manipulation","summary":"  We study the problem of mobile manipulation using legged robots equipped with\nan arm, namely legged loco-manipulation. The robot legs, while usually utilized\nfor mobility, offer an opportunity to amplify the manipulation capabilities by\nconducting whole-body control. That is, the robot can control the legs and the\narm at the same time to extend its workspace. We propose a framework that can\nconduct the whole-body control autonomously with visual observations. Our\napproach, namely \\ourFull~(\\our), is composed of a low-level policy using all\ndegrees of freedom to track the end-effector manipulator position and a\nhigh-level policy proposing the end-effector position based on visual inputs.\nWe train both levels of policies in simulation and perform Sim2Real transfer\nfor real robot deployment. We perform extensive experiments and show\nsignificant improvements over baselines in picking up diverse objects in\ndifferent configurations (heights, locations, orientations) and environments.\nProject page: https://wholebody-b1.github.io\n","authors":["Minghuan Liu","Zixuan Chen","Xuxin Cheng","Yandong Ji","Ruihan Yang","Xiaolong Wang"],"pdf_url":"https://arxiv.org/pdf/2403.16967v1.pdf","comment":"The first two authors contribute equally. Project page:\n  https://wholebody-b1.github.io"},{"id":"http://arxiv.org/abs/2403.16956v1","updated":"2024-03-25T17:17:35Z","published":"2024-03-25T17:17:35Z","title":"Bayesian Methods for Trust in Collaborative Multi-Agent Autonomy","summary":"  Multi-agent, collaborative sensor fusion is a vital component of a\nmulti-national intelligence toolkit. In safety-critical and/or contested\nenvironments, adversaries may infiltrate and compromise a number of agents. We\nanalyze state of the art multi-target tracking algorithms under this\ncompromised agent threat model. We prove that the track existence probability\ntest (\"track score\") is significantly vulnerable to even small numbers of\nadversaries. To add security awareness, we design a trust estimation framework\nusing hierarchical Bayesian updating. Our framework builds beliefs of trust on\ntracks and agents by mapping sensor measurements to trust pseudomeasurements\n(PSMs) and incorporating prior trust beliefs in a Bayesian context. In case\nstudies, our trust estimation algorithm accurately estimates the\ntrustworthiness of tracks/agents, subject to observability limitations.\n","authors":["R. Spencer Hallyburton","Miroslav Pajic"],"pdf_url":"https://arxiv.org/pdf/2403.16956v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16953v1","updated":"2024-03-25T17:15:13Z","published":"2024-03-25T17:15:13Z","title":"Learning Symbolic and Subsymbolic Temporal Task Constraints from\n  Bimanual Human Demonstrations","summary":"  Learning task models of bimanual manipulation from human demonstration and\ntheir execution on a robot should take temporal constraints between actions\ninto account. This includes constraints on (i) the symbolic level such as\nprecedence relations or temporal overlap in the execution, and (ii) the\nsubsymbolic level such as the duration of different actions, or their starting\nand end points in time. Such temporal constraints are crucial for temporal\nplanning, reasoning, and the exact timing for the execution of bimanual actions\non a bimanual robot. In our previous work, we addressed the learning of\ntemporal task constraints on the symbolic level and demonstrated how a robot\ncan leverage this knowledge to respond to failures during execution. In this\nwork, we propose a novel model-driven approach for the combined learning of\nsymbolic and subsymbolic temporal task constraints from multiple bimanual human\ndemonstrations. Our main contributions are a subsymbolic foundation of a\ntemporal task model that describes temporal nexuses of actions in the task\nbased on distributions of temporal differences between semantic action\nkeypoints, as well as a method based on fuzzy logic to derive symbolic temporal\ntask constraints from this representation. This complements our previous work\non learning comprehensive temporal task models by integrating symbolic and\nsubsymbolic information based on a subsymbolic foundation, while still\nmaintaining the symbolic expressiveness of our previous approach. We compare\nour proposed approach with our previous pure-symbolic approach and show that we\ncan reproduce and even outperform it. Additionally, we show how the subsymbolic\ntemporal task constraints can synchronize otherwise unimanual movement\nprimitives for bimanual behavior on a humanoid robot.\n","authors":["Christian Dreher","Tamim Asfour"],"pdf_url":"https://arxiv.org/pdf/2403.16953v1.pdf","comment":"8 pages, submitted to IROS 2024"},{"id":"http://arxiv.org/abs/2310.07822v2","updated":"2024-03-25T17:06:57Z","published":"2023-10-11T19:03:55Z","title":"Body-mounted MR-conditional Robot for Minimally Invasive Liver\n  Intervention","summary":"  MR-guided microwave ablation (MWA) has proven effective in treating\nhepatocellular carcinoma (HCC) with small-sized tumors, but the\nstate-of-the-art technique suffers from sub-optimal workflow due to speed and\naccuracy of needle placement. This paper presents a compact body-mounted\nMR-conditional robot that can operate in closed-bore MR scanners for accurate\nneedle guidance. The robotic platform consists of two stacked Cartesian XY\nstages, each with two degrees of freedom, that facilitate needle guidance. The\nrobot is actuated using 3D-printed pneumatic turbines with MR-conditional bevel\ngear transmission systems. Pneumatic valves and control mechatronics are\nlocated inside the MRI control room and are connected to the robot with\npneumatic transmission lines and optical fibers. Free space experiments\nindicated robot-assisted needle insertion error of 2.6$\\pm$1.3 mm at an\ninsertion depth of 80 mm. The MR-guided phantom studies were conducted to\nverify the MR-conditionality and targeting performance of the robot. Future\nwork will focus on the system optimization and validations in animal trials.\n","authors":["Zhefeng Huang","Anthony L. Gunderman","Samuel E. Wilcox","Saikat Sengupta","Jay Shah","Aiming Lu","David Woodrum","Yue Chen"],"pdf_url":"https://arxiv.org/pdf/2310.07822v2.pdf","comment":"10 figures"},{"id":"http://arxiv.org/abs/2403.06186v3","updated":"2024-03-25T16:18:38Z","published":"2024-03-10T12:06:45Z","title":"Mind Meets Robots: A Review of EEG-Based Brain-Robot Interaction Systems","summary":"  Brain-robot interaction (BRI) empowers individuals to control\n(semi-)automated machines through their brain activity, either passively or\nactively. In the past decade, BRI systems have achieved remarkable success,\npredominantly harnessing electroencephalogram (EEG) signals as the central\ncomponent. This paper offers an up-to-date and exhaustive examination of 87\ncurated studies published during the last five years (2018-2023), focusing on\nidentifying the research landscape of EEG-based BRI systems. This review aims\nto consolidate and underscore methodologies, interaction modes, application\ncontexts, system evaluation, existing challenges, and potential avenues for\nfuture investigations in this domain. Based on our analysis, we present a BRI\nsystem model with three entities: Brain, Robot, and Interaction, depicting the\ninternal relationships of a BRI system. We especially investigate the essence\nand principles on interaction modes between human brains and robots, a domain\nthat has not yet been identified anywhere. We then discuss these entities with\ndifferent dimensions encompassed. Within this model, we scrutinize and classify\ncurrent research, reveal insights, specify challenges, and provide\nrecommendations for future research trajectories in this field. Meanwhile, we\nenvision our findings offer a design space for future human-robot interaction\n(HRI) research, informing the creation of efficient BRI frameworks.\n","authors":["Yuchong Zhang","Nona Rajabi","Farzaneh Taleb","Andrii Matviienko","Yong Ma","Mårten Björkman","Danica Kragic"],"pdf_url":"https://arxiv.org/pdf/2403.06186v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.10855v2","updated":"2024-03-25T16:07:24Z","published":"2024-03-16T08:30:55Z","title":"Reinforcement Learning with Options and State Representation","summary":"  The current thesis aims to explore the reinforcement learning field and build\non existing methods to produce improved ones to tackle the problem of learning\nin high-dimensional and complex environments. It addresses such goals by\ndecomposing learning tasks in a hierarchical fashion known as Hierarchical\nReinforcement Learning.\n  We start in the first chapter by getting familiar with the Markov Decision\nProcess framework and presenting some of its recent techniques that the\nfollowing chapters use. We then proceed to build our Hierarchical Policy\nlearning as an answer to the limitations of a single primitive policy. The\nhierarchy is composed of a manager agent at the top and employee agents at the\nlower level.\n  In the last chapter, which is the core of this thesis, we attempt to learn\nlower-level elements of the hierarchy independently of the manager level in\nwhat is known as the \"Eigenoption\". Based on the graph structure of the\nenvironment, Eigenoptions allow us to build agents that are aware of the\ngeometric and dynamic properties of the environment. Their decision-making has\na special property: it is invariant to symmetric transformations of the\nenvironment, allowing as a consequence to greatly reduce the complexity of the\nlearning task.\n","authors":["Ayoub Ghriss","Masashi Sugiyama","Alessandro Lazaric"],"pdf_url":"https://arxiv.org/pdf/2403.10855v2.pdf","comment":"Master Thesis 2018, MVA ENS Paris-Saclay, Tokyo RIKEN AIP"},{"id":"http://arxiv.org/abs/2403.16880v1","updated":"2024-03-25T15:47:06Z","published":"2024-03-25T15:47:06Z","title":"DHP-Mapping: A Dense Panoptic Mapping System with Hierarchical World\n  Representation and Label Optimization Techniques","summary":"  Maps provide robots with crucial environmental knowledge, thereby enabling\nthem to perform interactive tasks effectively. Easily accessing accurate\nabstract-to-detailed geometric and semantic concepts from maps is crucial for\nrobots to make informed and efficient decisions. To comprehensively model the\nenvironment and effectively manage the map data structure, we propose\nDHP-Mapping, a dense mapping system that utilizes multiple Truncated Signed\nDistance Field (TSDF) submaps and panoptic labels to hierarchically model the\nenvironment. The output map is able to maintain both voxel- and submap-level\nmetric and semantic information. Two modules are presented to enhance the\nmapping efficiency and label consistency: (1) an inter-submaps label fusion\nstrategy to eliminate duplicate points across submaps and (2) a conditional\nrandom field (CRF) based approach to enhance panoptic labels through object\nlabel comprehension and contextual information. We conducted experiments with\ntwo public datasets including indoor and outdoor scenarios. Our system performs\ncomparably to state-of-the-art (SOTA) methods across geometry and label\naccuracy evaluation metrics. The experiment results highlight the effectiveness\nand scalability of our system, as it is capable of constructing precise\ngeometry and maintaining consistent panoptic labels. Our code is publicly\navailable at https://github.com/hutslib/DHP-Mapping.\n","authors":["Tianshuai Hu","Jianhao Jiao","Yucheng Xu","Hongji Liu","Sheng Wang","Ming Liu"],"pdf_url":"https://arxiv.org/pdf/2403.16880v1.pdf","comment":"Submit to IROS 2024. Project website\n  https://github.com/hutslib/DHP-Mapping"},{"id":"http://arxiv.org/abs/2403.16877v1","updated":"2024-03-25T15:42:09Z","published":"2024-03-25T15:42:09Z","title":"Proprioception Is All You Need: Terrain Classification for Boreal\n  Forests","summary":"  Recent works in field robotics highlighted the importance of resiliency\nagainst different types of terrains. Boreal forests, in particular, are home to\nmany mobility-impeding terrains that should be considered for off-road\nautonomous navigation. Also, being one of the largest land biomes on Earth,\nboreal forests are an area where autonomous vehicles are expected to become\nincreasingly common. In this paper, we address this issue by introducing\nBorealTC, a publicly available dataset for proprioceptive-based terrain\nclassification (TC). Recorded with a Husky A200, our dataset contains 116 min\nof Inertial Measurement Unit (IMU), motor current, and wheel odometry data,\nfocusing on typical boreal forest terrains, notably snow, ice, and silty loam.\nCombining our dataset with another dataset from the state-of-the-art, we\nevaluate both a Convolutional Neural Network (CNN) and the novel state space\nmodel (SSM)-based Mamba architecture on a TC task. Interestingly, we show that\nwhile CNN outperforms Mamba on each separate dataset, Mamba achieves greater\naccuracy when trained on a combination of both. In addition, we demonstrate\nthat Mamba's learning capacity is greater than a CNN for increasing amounts of\ndata. We show that the combination of two TC datasets yields a latent space\nthat can be interpreted with the properties of the terrains. We also discuss\nthe implications of merging datasets on classification. Our source code and\ndataset are publicly available online:\nhttps://github.com/norlab-ulaval/BorealTC.\n","authors":["Damien LaRocque","William Guimont-Martin","David-Alexandre Duclos","Philippe Giguère","François Pomerleau"],"pdf_url":"https://arxiv.org/pdf/2403.16877v1.pdf","comment":"Submitted to the 2024 IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS 2024)"},{"id":"http://arxiv.org/abs/2403.16875v1","updated":"2024-03-25T15:39:46Z","published":"2024-03-25T15:39:46Z","title":"TAIL: A Terrain-Aware Multi-Modal SLAM Dataset for Robot Locomotion in\n  Deformable Granular Environments","summary":"  Terrain-aware perception holds the potential to improve the robustness and\naccuracy of autonomous robot navigation in the wilds, thereby facilitating\neffective off-road traversals. However, the lack of multi-modal perception\nacross various motion patterns hinders the solutions of Simultaneous\nLocalization And Mapping (SLAM), especially when confronting non-geometric\nhazards in demanding landscapes. In this paper, we first propose a\nTerrain-Aware multI-modaL (TAIL) dataset tailored to deformable and sandy\nterrains. It incorporates various types of robotic proprioception and distinct\nground interactions for the unique challenges and benchmark of multi-sensor\nfusion SLAM. The versatile sensor suite comprises stereo frame cameras,\nmultiple ground-pointing RGB-D cameras, a rotating 3D LiDAR, an IMU, and an RTK\ndevice. This ensemble is hardware-synchronized, well-calibrated, and\nself-contained. Utilizing both wheeled and quadrupedal locomotion, we\nefficiently collect comprehensive sequences to capture rich unstructured\nscenarios. It spans the spectrum of scope, terrain interactions, scene changes,\nground-level properties, and dynamic robot characteristics. We benchmark\nseveral state-of-the-art SLAM methods against ground truth and provide\nperformance validations. Corresponding challenges and limitations are also\nreported. All associated resources are accessible upon request at\n\\url{https://tailrobot.github.io/}.\n","authors":["Chen Yao","Yangtao Ge","Guowei Shi","Zirui Wang","Ningbo Yang","Zheng Zhu","Hexiang Wei","Yuntian Zhao","Jing Wu","Zhenzhong Jia"],"pdf_url":"https://arxiv.org/pdf/2403.16875v1.pdf","comment":"Submitted to IEEE Robotics and Automation Letters"},{"id":"http://arxiv.org/abs/2403.16859v1","updated":"2024-03-25T15:23:14Z","published":"2024-03-25T15:23:14Z","title":"A Semi-Lagrangian Approach for Time and Energy Path Planning\n  Optimization in Static Flow Fields","summary":"  Efficient path planning for autonomous mobile robots is a critical problem\nacross numerous domains, where optimizing both time and energy consumption is\nparamount. This paper introduces a novel methodology that considers the dynamic\ninfluence of an environmental flow field and considers geometric constraints,\nincluding obstacles and forbidden zones, enriching the complexity of the\nplanning problem. We formulate it as a multi-objective optimal control problem,\npropose a novel transformation called Harmonic Transformation, and apply a\nsemi-Lagrangian scheme to solve it. The set of Pareto efficient solutions is\nobtained considering two distinct approaches: a deterministic method and an\nevolutionary-based one, both of which are designed to make use of the proposed\nHarmonic Transformation. Through an extensive analysis of these approaches, we\ndemonstrate their efficacy in finding optimized paths.\n","authors":["Víctor C. da S. Campos","Armando A. Neto","Douglas G. Macharet"],"pdf_url":"https://arxiv.org/pdf/2403.16859v1.pdf","comment":"12 pages, initial paper submission; Preprint submitted to the IEEE\n  Transactions on Intelligent Transportation Systems"},{"id":"http://arxiv.org/abs/2402.13848v2","updated":"2024-03-25T14:45:53Z","published":"2024-02-21T14:50:24Z","title":"Zero-BEV: Zero-shot Projection of Any First-Person Modality to BEV Maps","summary":"  Bird's-eye view (BEV) maps are an important geometrically structured\nrepresentation widely used in robotics, in particular self-driving vehicles and\nterrestrial robots. Existing algorithms either require depth information for\nthe geometric projection, which is not always reliably available, or are\ntrained end-to-end in a fully supervised way to map visual first-person\nobservations to BEV representation, and are therefore restricted to the output\nmodality they have been trained for. In contrast, we propose a new model\ncapable of performing zero-shot projections of any modality available in a\nfirst person view to the corresponding BEV map. This is achieved by\ndisentangling the geometric inverse perspective projection from the modality\ntransformation, eg. RGB to occupancy. The method is general and we showcase\nexperiments projecting to BEV three different modalities: semantic\nsegmentation, motion vectors and object bounding boxes detected in first\nperson. We experimentally show that the model outperforms competing methods, in\nparticular the widely used baseline resorting to monocular depth estimation.\n","authors":["Gianluca Monaci","Leonid Antsfeld","Boris Chidlovskii","Christian Wolf"],"pdf_url":"https://arxiv.org/pdf/2402.13848v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16803v1","updated":"2024-03-25T14:21:49Z","published":"2024-03-25T14:21:49Z","title":"Exploiting Priors from 3D Diffusion Models for RGB-Based One-Shot View\n  Planning","summary":"  Object reconstruction is relevant for many autonomous robotic tasks that\nrequire interaction with the environment. A key challenge in such scenarios is\nplanning view configurations to collect informative measurements for\nreconstructing an initially unknown object. One-shot view planning enables\nefficient data collection by predicting view configurations and planning the\nglobally shortest path connecting all views at once. However, geometric priors\nabout the object are required to conduct one-shot view planning. In this work,\nwe propose a novel one-shot view planning approach that utilizes the powerful\n3D generation capabilities of diffusion models as priors. By incorporating such\ngeometric priors into our pipeline, we achieve effective one-shot view planning\nstarting with only a single RGB image of the object to be reconstructed. Our\nplanning experiments in simulation and real-world setups indicate that our\napproach balances well between object reconstruction quality and movement cost.\n","authors":["Sicong Pan","Liren Jin","Xuying Huang","Cyrill Stachniss","Marija Popović","Maren Bennewitz"],"pdf_url":"https://arxiv.org/pdf/2403.16803v1.pdf","comment":"Sicong Pan and Liren Jin have equal contribution. Submitted to IROS\n  2024"},{"id":"http://arxiv.org/abs/2403.16794v1","updated":"2024-03-25T14:13:09Z","published":"2024-03-25T14:13:09Z","title":"CurbNet: Curb Detection Framework Based on LiDAR Point Cloud\n  Segmentation","summary":"  Curb detection is an important function in intelligent driving and can be\nused to determine drivable areas of the road. However, curbs are difficult to\ndetect due to the complex road environment. This paper introduces CurbNet, a\nnovel framework for curb detection, leveraging point cloud segmentation.\nAddressing the dearth of comprehensive curb datasets and the absence of 3D\nannotations, we have developed the 3D-Curb dataset, encompassing 7,100 frames,\nwhich represents the largest and most categorically diverse collection of curb\npoint clouds currently available. Recognizing that curbs are primarily\ncharacterized by height variations, our approach harnesses spatially-rich 3D\npoint clouds for training. To tackle the challenges presented by the uneven\ndistribution of curb features on the xy-plane and their reliance on z-axis\nhigh-frequency features, we introduce the multi-scale and channel attention\n(MSCA) module, a bespoke solution designed to optimize detection performance.\nMoreover, we propose an adaptive weighted loss function group, specifically\nformulated to counteract the imbalance in the distribution of curb point clouds\nrelative to other categories. Our extensive experimentation on 2 major datasets\nhas yielded results that surpass existing benchmarks set by leading curb\ndetection and point cloud segmentation models. By integrating multi-clustering\nand curve fitting techniques in our post-processing stage, we have\nsubstantially reduced noise in curb detection, thereby enhancing precision to\n0.8744. Notably, CurbNet has achieved an exceptional average metrics of over\n0.95 at a tolerance of just 0.15m, thereby establishing a new benchmark.\nFurthermore, corroborative real-world experiments and dataset analyzes mutually\nvalidate each other, solidifying CurbNet's superior detection proficiency and\nits robust generalizability.\n","authors":["Guoyang Zhao","Fulong Ma","Yuxuan Liu","Weiqing Qi","Ming Liu"],"pdf_url":"https://arxiv.org/pdf/2403.16794v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16786v1","updated":"2024-03-25T14:01:58Z","published":"2024-03-25T14:01:58Z","title":"DBPF: A Framework for Efficient and Robust Dynamic Bin-Picking","summary":"  Efficiency and reliability are critical in robotic bin-picking as they\ndirectly impact the productivity of automated industrial processes. However,\ntraditional approaches, demanding static objects and fixed collisions, lead to\ndeployment limitations, operational inefficiencies, and process unreliability.\nThis paper introduces a Dynamic Bin-Picking Framework (DBPF) that challenges\ntraditional static assumptions. The DBPF endows the robot with the reactivity\nto pick multiple moving arbitrary objects while avoiding dynamic obstacles,\nsuch as the moving bin. Combined with scene-level pose generation, the proposed\npose selection metric leverages the Tendency-Aware Manipulability Network\noptimizing suction pose determination. Heuristic task-specific designs like\nvelocity-matching, dynamic obstacle avoidance, and the resight policy, enhance\nthe picking success rate and reliability. Empirical experiments demonstrate the\nimportance of these components. Our method achieves an average 84% success\nrate, surpassing the 60% of the most comparable baseline, crucially, with zero\ncollisions. Further evaluations under diverse dynamic scenarios showcase DBPF's\nrobust performance in dynamic bin-picking. Results suggest that our framework\noffers a promising solution for efficient and reliable robotic bin-picking\nunder dynamics.\n","authors":["Yichuan Li","Junkai Zhao","Yixiao Li","Zheng Wu","Rui Cao","Masayoshi Tomizuka","Yunhui Liu"],"pdf_url":"https://arxiv.org/pdf/2403.16786v1.pdf","comment":"8 pages, 5 figures. This paper has been accepted by IEEE RA-L on\n  2024-03-24. See the supplementary video at youtube:\n  https://youtu.be/n5af2VsKhkg"},{"id":"http://arxiv.org/abs/2403.16781v1","updated":"2024-03-25T13:55:49Z","published":"2024-03-25T13:55:49Z","title":"Visual Action Planning with Multiple Heterogeneous Agents","summary":"  Visual planning methods are promising to handle complex settings where\nextracting the system state is challenging. However, none of the existing works\ntackles the case of multiple heterogeneous agents which are characterized by\ndifferent capabilities and/or embodiment. In this work, we propose a method to\nrealize visual action planning in multi-agent settings by exploiting a roadmap\nbuilt in a low-dimensional structured latent space and used for planning. To\nenable multi-agent settings, we infer possible parallel actions from a dataset\ncomposed of tuples associated with individual actions. Next, we evaluate\nfeasibility and cost of them based on the capabilities of the multi-agent\nsystem and endow the roadmap with this information, building a capability\nlatent space roadmap (C-LSR). Additionally, a capability suggestion strategy is\ndesigned to inform the human operator about possible missing capabilities when\nno paths are found. The approach is validated in a simulated burger cooking\ntask and a real-world box packing task.\n","authors":["Martina Lippi","Michael C. Welle","Marco Moletta","Alessandro Marino","Andrea Gasparri","Danica Kragic"],"pdf_url":"https://arxiv.org/pdf/2403.16781v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11742v2","updated":"2024-03-25T13:47:06Z","published":"2024-03-18T12:54:33Z","title":"Accelerating Model Predictive Control for Legged Robots through\n  Distributed Optimization","summary":"  This paper presents a novel approach to enhance Model Predictive Control\n(MPC) for legged robots through Distributed Optimization. Our method focuses on\ndecomposing the robot dynamics into smaller, parallelizable subsystems, and\nutilizing the Alternating Direction Method of Multipliers (ADMM) to ensure\nconsensus among them. Each subsystem is managed by its own Optimal Control\nProblem, with ADMM facilitating consistency between their optimizations. This\napproach not only decreases the computational time but also allows for\neffective scaling with more complex robot configurations, facilitating the\nintegration of additional subsystems such as articulated arms on a quadruped\nrobot. We demonstrate, through numerical evaluations, the convergence of our\napproach on two systems with increasing complexity. In addition, we showcase\nthat our approach converges towards the same solution when compared to a\nstate-of-the-art centralized whole-body MPC implementation. Moreover, we\nquantitatively compare the computational efficiency of our method to the\ncentralized approach, revealing up to a 75\\% reduction in computational time.\nOverall, our approach offers a promising avenue for accelerating MPC solutions\nfor legged robots, paving the way for more effective utilization of the\ncomputational performance of modern hardware.\n","authors":["Lorenzo Amatucci","Giulio Turrisi","Angelo Bratta","Victor Barasuol","Claudio Semini"],"pdf_url":"https://arxiv.org/pdf/2403.11742v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16764v1","updated":"2024-03-25T13:41:57Z","published":"2024-03-25T13:41:57Z","title":"Low-Cost Teleoperation with Haptic Feedback through Vision-based Tactile\n  Sensors for Rigid and Soft Object Manipulation","summary":"  Haptic feedback is essential for humans to successfully perform complex and\ndelicate manipulation tasks. A recent rise in tactile sensors has enabled\nrobots to leverage the sense of touch and expand their capability drastically.\nHowever, many tasks still need human intervention/guidance. For this reason, we\npresent a teleoperation framework designed to provide haptic feedback to human\noperators based on the data from camera-based tactile sensors mounted on the\nrobot gripper. Partial autonomy is introduced to prevent slippage of grasped\nobjects during task execution. Notably, we rely exclusively on low-cost\noff-the-shelf hardware to realize an affordable solution. We demonstrate the\nversatility of the framework on nine different objects ranging from rigid to\nsoft and fragile ones, using three different operators on real hardware.\n","authors":["Martina Lippi","Michael C. Welle","Maciej K. Wozniak","Andrea Gasparri","Danica Kragic"],"pdf_url":"https://arxiv.org/pdf/2403.16764v1.pdf","comment":"https://vision-tactile-manip.github.io/teleop/"},{"id":"http://arxiv.org/abs/2401.16700v2","updated":"2024-03-25T13:33:51Z","published":"2024-01-30T03:00:25Z","title":"Towards Precise 3D Human Pose Estimation with Multi-Perspective\n  Spatial-Temporal Relational Transformers","summary":"  3D human pose estimation captures the human joint points in three-dimensional\nspace while keeping the depth information and physical structure. That is\nessential for applications that require precise pose information, such as\nhuman-computer interaction, scene understanding, and rehabilitation training.\nDue to the challenges in data collection, mainstream datasets of 3D human pose\nestimation are primarily composed of multi-view video data collected in\nlaboratory environments, which contains rich spatial-temporal correlation\ninformation besides the image frame content. Given the remarkable\nself-attention mechanism of transformers, capable of capturing the\nspatial-temporal correlation from multi-view video datasets, we propose a\nmulti-stage framework for 3D sequence-to-sequence (seq2seq) human pose\ndetection. Firstly, the spatial module represents the human pose feature by\nintra-image content, while the frame-image relation module extracts temporal\nrelationships and 3D spatial positional relationship features between the\nmulti-perspective images. Secondly, the self-attention mechanism is adopted to\neliminate the interference from non-human body parts and reduce computing\nresources. Our method is evaluated on Human3.6M, a popular 3D human pose\ndetection dataset. Experimental results demonstrate that our approach achieves\nstate-of-the-art performance on this dataset. The source code will be available\nat https://github.com/WUJINHUAN/3D-human-pose.\n","authors":["Jianbin Jiao","Xina Cheng","Weijie Chen","Xiaoting Yin","Hao Shi","Kailun Yang"],"pdf_url":"https://arxiv.org/pdf/2401.16700v2.pdf","comment":"Accepted to IJCNN 2024. The source code will be available at\n  https://github.com/WUJINHUAN/3D-human-pose"},{"id":"http://arxiv.org/abs/2402.02423v2","updated":"2024-03-25T13:20:46Z","published":"2024-02-04T09:40:22Z","title":"Uni-RLHF: Universal Platform and Benchmark Suite for Reinforcement\n  Learning with Diverse Human Feedback","summary":"  Reinforcement Learning with Human Feedback (RLHF) has received significant\nattention for performing tasks without the need for costly manual reward design\nby aligning human preferences. It is crucial to consider diverse human feedback\ntypes and various learning methods in different environments. However,\nquantifying progress in RLHF with diverse feedback is challenging due to the\nlack of standardized annotation platforms and widely used unified benchmarks.\nTo bridge this gap, we introduce Uni-RLHF, a comprehensive system\nimplementation tailored for RLHF. It aims to provide a complete workflow from\nreal human feedback, fostering progress in the development of practical\nproblems. Uni-RLHF contains three packages: 1) a universal multi-feedback\nannotation platform, 2) large-scale crowdsourced feedback datasets, and 3)\nmodular offline RLHF baseline implementations. Uni-RLHF develops a\nuser-friendly annotation interface tailored to various feedback types,\ncompatible with a wide range of mainstream RL environments. We then establish a\nsystematic pipeline of crowdsourced annotations, resulting in large-scale\nannotated datasets comprising more than 15 million steps across 30+ popular\ntasks. Through extensive experiments, the results in the collected datasets\ndemonstrate competitive performance compared to those from well-designed manual\nrewards. We evaluate various design choices and offer insights into their\nstrengths and potential areas of improvement. We wish to build valuable\nopen-source platforms, datasets, and baselines to facilitate the development of\nmore robust and reliable RLHF solutions based on realistic human feedback. The\nwebsite is available at https://uni-rlhf.github.io/.\n","authors":["Yifu Yuan","Jianye Hao","Yi Ma","Zibin Dong","Hebin Liang","Jinyi Liu","Zhixin Feng","Kai Zhao","Yan Zheng"],"pdf_url":"https://arxiv.org/pdf/2402.02423v2.pdf","comment":"Published as a conference paper at ICLR 2024. The website is\n  available at https://uni-rlhf.github.io/"},{"id":"http://arxiv.org/abs/2209.09020v3","updated":"2024-03-25T09:38:32Z","published":"2022-09-09T09:48:35Z","title":"Vehicle Trajectory Tracking Through Magnetic Sensors: A Case Study of\n  Two-lane Road","summary":"  Intelligent Transportation Systems (ITS) have a pressing need for efficient\nand reliable traffic surveillance solutions. This paper for the first time\nproposes a surveillance system that utilizes low-cost magnetic sensors for\ndetecting and tracking vehicles continuously along the road. The system uses\nmultiple sensors mounted along the roadside and lane boundaries to capture the\nmovement of vehicles. Real-time measurement data is collected by base stations\nand processed to produce vehicle trajectories that include position, timestamp,\nand speed. To address the challenge of tracking vehicles continuously on a road\nnetwork using a large amount of unlabeled magnetic sensor measurements, we\nfirst define a vehicle trajectory tracking problem. We then propose a\ngraph-based data association algorithm to track each detected vehicle, and\ndesign a related online algorithm framework respectively. We finally validate\nthe performance via both experimental simulation and real-world road\ndeployment. The experimental results demonstrate that the proposed solution\nprovides a cost-effective solution to capture the driving status of vehicles\nand on that basis form various traffic safety and efficiency applications.\n","authors":["Xiaojiang Ren","Yan Wang","Yingfan Geng"],"pdf_url":"https://arxiv.org/pdf/2209.09020v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16374v1","updated":"2024-03-25T02:38:34Z","published":"2024-03-25T02:38:34Z","title":"ProIn: Learning to Predict Trajectory Based on Progressive Interactions\n  for Autonomous Driving","summary":"  Accurate motion prediction of pedestrians, cyclists, and other surrounding\nvehicles (all called agents) is very important for autonomous driving. Most\nexisting works capture map information through an one-stage interaction with\nmap by vector-based attention, to provide map constraints for social\ninteraction and multi-modal differentiation. However, these methods have to\nencode all required map rules into the focal agent's feature, so as to retain\nall possible intentions' paths while at the meantime to adapt to potential\nsocial interaction. In this work, a progressive interaction network is proposed\nto enable the agent's feature to progressively focus on relevant maps, in order\nto better learn agents' feature representation capturing the relevant map\nconstraints. The network progressively encode the complex influence of map\nconstraints into the agent's feature through graph convolutions at the\nfollowing three stages: after historical trajectory encoder, after social\ninteraction, and after multi-modal differentiation. In addition, a weight\nallocation mechanism is proposed for multi-modal training, so that each mode\ncan obtain learning opportunities from a single-mode ground truth. Experiments\nhave validated the superiority of progressive interactions to the existing\none-stage interaction, and demonstrate the effectiveness of each component.\nEncouraging results were obtained in the challenging benchmarks.\n","authors":["Yinke Dong","Haifeng Yuan","Hongkun Liu","Wei Jing","Fangzhen Li","Hongmin Liu","Bin Fan"],"pdf_url":"https://arxiv.org/pdf/2403.16374v1.pdf","comment":null}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2403.16732v1","updated":"2024-03-25T13:06:31Z","published":"2024-03-25T13:06:31Z","title":"Enabling Uncertainty Estimation in Iterative Neural Networks","summary":"  Turning pass-through network architectures into iterative ones, which use\ntheir own output as input, is a well-known approach for boosting performance.\nIn this paper, we argue that such architectures offer an additional benefit:\nThe convergence rate of their successive outputs is highly correlated with the\naccuracy of the value to which they converge. Thus, we can use the convergence\nrate as a useful proxy for uncertainty. This results in an approach to\nuncertainty estimation that provides state-of-the-art estimates at a much lower\ncomputational cost than techniques like Ensembles, and without requiring any\nmodifications to the original iterative model. We demonstrate its practical\nvalue by embedding it in two application domains: road detection in aerial\nimages and the estimation of aerodynamic properties of 2D and 3D shapes.\n","authors":["Nikita Durasov","Doruk Oner","Jonathan Donier","Hieu Le","Pascal Fua"],"pdf_url":"https://arxiv.org/pdf/2403.16732v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16728v1","updated":"2024-03-25T13:02:43Z","published":"2024-03-25T13:02:43Z","title":"Improving Diffusion Models's Data-Corruption Resistance using Scheduled\n  Pseudo-Huber Loss","summary":"  Diffusion models are known to be vulnerable to outliers in training data. In\nthis paper we study an alternative diffusion loss function, which can preserve\nthe high quality of generated data like the original squared $L_{2}$ loss while\nat the same time being robust to outliers. We propose to use pseudo-Huber loss\nfunction with a time-dependent parameter to allow for the trade-off between\nrobustness on the most vulnerable early reverse-diffusion steps and fine\ndetails restoration on the final steps. We show that pseudo-Huber loss with the\ntime-dependent parameter exhibits better performance on corrupted datasets in\nboth image and audio domains. In addition, the loss function we propose can\npotentially help diffusion models to resist dataset corruption while not\nrequiring data filtering or purification compared to conventional training\nalgorithms.\n","authors":["Artem Khrapov","Vadim Popov","Tasnima Sadekova","Assel Yermekova","Mikhail Kudinov"],"pdf_url":"https://arxiv.org/pdf/2403.16728v1.pdf","comment":"13 pages, 16 figures"},{"id":"http://arxiv.org/abs/2403.16719v1","updated":"2024-03-25T12:56:48Z","published":"2024-03-25T12:56:48Z","title":"Towards a Formalisation of Value-based Actions and Consequentialist\n  Ethics","summary":"  Agents act to bring about a state of the world that is more compatible with\ntheir personal or institutional values. To formalise this intuition, the paper\nproposes an action framework based on the STRIPS formalisation. Technically,\nthe contribution expresses actions in terms of Value-based Formal Reasoning\n(VFR), which provides a set of propositions derived from an Agent's value\nprofile and the Agent's assessment of propositions with respect to the profile.\nConceptually, the contribution provides a computational framework for a form of\nconsequentialist ethics which is satisficing, luralistic, act-based, and\npreferential.\n","authors":["Adam Wyner","Tomasz Zurek","DOrota Stachura-Zurek"],"pdf_url":"https://arxiv.org/pdf/2403.16719v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16707v1","updated":"2024-03-25T12:44:52Z","published":"2024-03-25T12:44:52Z","title":"One-Shot Domain Incremental Learning","summary":"  Domain incremental learning (DIL) has been discussed in previous studies on\ndeep neural network models for classification. In DIL, we assume that samples\non new domains are observed over time. The models must classify inputs on all\ndomains. In practice, however, we may encounter a situation where we need to\nperform DIL under the constraint that the samples on the new domain are\nobserved only infrequently. Therefore, in this study, we consider the extreme\ncase where we have only one sample from the new domain, which we call one-shot\nDIL. We first empirically show that existing DIL methods do not work well in\none-shot DIL. We have analyzed the reason for this failure through various\ninvestigations. According to our analysis, we clarify that the difficulty of\none-shot DIL is caused by the statistics in the batch normalization layers.\nTherefore, we propose a technique regarding these statistics and demonstrate\nthe effectiveness of our technique through experiments on open datasets.\n","authors":["Yasushi Esaki","Satoshi Koide","Takuro Kutsuna"],"pdf_url":"https://arxiv.org/pdf/2403.16707v1.pdf","comment":"accepted at IEEE International Joint Conference on Neural Networks\n  (IJCNN) 2024"},{"id":"http://arxiv.org/abs/2403.16687v1","updated":"2024-03-25T12:23:12Z","published":"2024-03-25T12:23:12Z","title":"Investigation of the effectiveness of applying ChatGPT in Dialogic\n  Teaching Using Electroencephalography","summary":"  In recent years, the rapid development of artificial intelligence technology,\nespecially the emergence of large language models (LLMs) such as ChatGPT, has\npresented significant prospects for application in the field of education. LLMs\npossess the capability to interpret knowledge, answer questions, and consider\ncontext, thus providing support for dialogic teaching to students. Therefore,\nan examination of the capacity of LLMs to effectively fulfill instructional\nroles, thereby facilitating student learning akin to human educators within\ndialogic teaching scenarios, is an exceptionally valuable research topic. This\nresearch recruited 34 undergraduate students as participants, who were randomly\ndivided into two groups. The experimental group engaged in dialogic teaching\nusing ChatGPT, while the control group interacted with human teachers. Both\ngroups learned the histogram equalization unit in the information-related\ncourse \"Digital Image Processing\". The research findings show comparable scores\nbetween the two groups on the retention test. However, students who engaged in\ndialogue with ChatGPT exhibited lower performance on the transfer test.\nElectroencephalography data revealed that students who interacted with ChatGPT\nexhibited higher levels of cognitive activity, suggesting that ChatGPT could\nhelp students establish a knowledge foundation and stimulate cognitive\nactivity. However, its strengths on promoting students. knowledge application\nand creativity were insignificant. Based upon the research findings, it is\nevident that ChatGPT cannot fully excel in fulfilling teaching tasks in the\ndialogue teaching in information related courses. Combining ChatGPT with\ntraditional human teachers might be a more ideal approach. The synergistic use\nof both can provide students with more comprehensive learning support, thus\ncontributing to enhancing the quality of teaching.\n","authors":["Jiayue Zhang","Yiheng Liu","Wenqi Cai","Yali Peng","Senqing Qi","Taotao Long","Bao Ge"],"pdf_url":"https://arxiv.org/pdf/2403.16687v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16674v1","updated":"2024-03-25T12:13:20Z","published":"2024-03-25T12:13:20Z","title":"Understanding the Functional Roles of Modelling Components in Spiking\n  Neural Networks","summary":"  Spiking neural networks (SNNs), inspired by the neural circuits of the brain,\nare promising in achieving high computational efficiency with biological\nfidelity. Nevertheless, it is quite difficult to optimize SNNs because the\nfunctional roles of their modelling components remain unclear. By designing and\nevaluating several variants of the classic model, we systematically investigate\nthe functional roles of key modelling components, leakage, reset, and\nrecurrence, in leaky integrate-and-fire (LIF) based SNNs. Through extensive\nexperiments, we demonstrate how these components influence the accuracy,\ngeneralization, and robustness of SNNs. Specifically, we find that the leakage\nplays a crucial role in balancing memory retention and robustness, the reset\nmechanism is essential for uninterrupted temporal processing and computational\nefficiency, and the recurrence enriches the capability to model complex\ndynamics at a cost of robustness degradation. With these interesting\nobservations, we provide optimization suggestions for enhancing the performance\nof SNNs in different scenarios. This work deepens the understanding of how SNNs\nwork, which offers valuable guidance for the development of more effective and\nrobust neuromorphic models.\n","authors":["Huifeng Yin","Hanle Zheng","Jiayi Mao","Siyuan Ding","Xing Liu","Mingkun Xu","Yifan Hu","Jing Pei","Lei Deng"],"pdf_url":"https://arxiv.org/pdf/2403.16674v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16667v1","updated":"2024-03-25T12:04:03Z","published":"2024-03-25T12:04:03Z","title":"Deep Reinforcement Learning and Mean-Variance Strategies for Responsible\n  Portfolio Optimization","summary":"  Portfolio optimization involves determining the optimal allocation of\nportfolio assets in order to maximize a given investment objective.\nTraditionally, some form of mean-variance optimization is used with the aim of\nmaximizing returns while minimizing risk, however, more recently, deep\nreinforcement learning formulations have been explored. Increasingly, investors\nhave demonstrated an interest in incorporating ESG objectives when making\ninvestment decisions, and modifications to the classical mean-variance\noptimization framework have been developed. In this work, we study the use of\ndeep reinforcement learning for responsible portfolio optimization, by\nincorporating ESG states and objectives, and provide comparisons against\nmodified mean-variance approaches. Our results show that deep reinforcement\nlearning policies can provide competitive performance against mean-variance\napproaches for responsible portfolio allocation across additive and\nmultiplicative utility functions of financial and ESG responsibility\nobjectives.\n","authors":["Fernando Acero","Parisa Zehtabi","Nicolas Marchesotti","Michael Cashmore","Daniele Magazzeni","Manuela Veloso"],"pdf_url":"https://arxiv.org/pdf/2403.16667v1.pdf","comment":"Presented at the AAAI 2024 Workshop on AI in Finance for Social\n  Impact"},{"id":"http://arxiv.org/abs/2311.16515v2","updated":"2024-03-25T12:01:59Z","published":"2023-11-25T14:24:49Z","title":"Word4Per: Zero-shot Composed Person Retrieval","summary":"  Searching for specific person has great social benefits and security value,\nand it often involves a combination of visual and textual information.\nConventional person retrieval methods, whether image-based or text-based,\nusually fall short in effectively harnessing both types of information, leading\nto the loss of accuracy. In this paper, a whole new task called Composed Person\nRetrieval (CPR) is proposed to jointly utilize both image and text information\nfor target person retrieval. However, the supervised CPR requires very costly\nmanual annotation dataset, while there are currently no available resources. To\nmitigate this issue, we firstly introduce the Zero-shot Composed Person\nRetrieval (ZS-CPR), which leverages existing domain-related data to resolve the\nCPR problem without expensive annotations. Secondly, to learn ZS-CPR model, we\npropose a two-stage learning framework, Word4Per, where a lightweight Textual\nInversion Network (TINet) and a text-based person retrieval model based on\nfine-tuned Contrastive Language-Image Pre-training (CLIP) network are learned\nwithout utilizing any CPR data. Thirdly, a finely annotated Image-Text Composed\nPerson Retrieval (ITCPR) dataset is built as the benchmark to assess the\nperformance of the proposed Word4Per framework. Extensive experiments under\nboth Rank-1 and mAP demonstrate the effectiveness of Word4Per for the ZS-CPR\ntask, surpassing the comparative methods by over 10\\%. The code and ITCPR\ndataset will be publicly available at\nhttps://github.com/Delong-liu-bupt/Word4Per.\n","authors":["Delong Liu","Haiwen Li","Zhicheng Zhao","Fei Su","Yuan Dong"],"pdf_url":"https://arxiv.org/pdf/2311.16515v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16666v1","updated":"2024-03-25T12:01:27Z","published":"2024-03-25T12:01:27Z","title":"Revisiting the Sleeping Beauty problem","summary":"  The Sleeping Beauty problem is a probability riddle with no definite solution\nfor more than two decades and its solution is of great interest in many fields\nof knowledge. There are two main competing solutions to the problem: the halfer\napproach, and the thirder approach. The main reason for disagreement in the\nliterature is connected to the use of different probability spaces to represent\nthe same probabilistic riddle. In this work, we analyse the problem from a\nmathematical perspective, identifying probability distributions induced\ndirectly from the thought experiment's rules. The precise choices of\nprobability spaces provide both halfer and thirder solutions to the problem. To\ntry and decide on which approach to follow, a criterion involving the\ninformation available to Sleeping Beauty is proposed.\n","authors":["Paulo S. Piva","Gabriel Ruffolo"],"pdf_url":"https://arxiv.org/pdf/2403.16666v1.pdf","comment":"14 pages, 1 figure"},{"id":"http://arxiv.org/abs/2403.12061v2","updated":"2024-03-25T11:50:42Z","published":"2024-02-07T20:41:00Z","title":"Design-Space Exploration of SNN Models using Application-Specific\n  Multi-Core Architectures","summary":"  With the motivation and the difficulties that currently exist in\ncomprehending and utilizing the promising features of SNNs, we proposed a novel\nrun-time multi-core architecture-based simulator called \"RAVSim\" (Runtime\nAnalysis and Visualization Simulator), a cutting-edge SNN simulator, developed\nusing LabVIEW and it is publicly available on their website as an official\nmodule. RAVSim is a runtime virtual simulation environment tool that enables\nthe user to interact with the model, observe its behavior of output\nconcentration, and modify the set of parametric values at any time while the\nsimulation is in execution. Recently some popular tools have been presented,\nbut we believe that none of the tools allow users to interact with the model\nsimulation in run time.\n","authors":[" Sanaullah","Shamini Koravuna","Ulrich Rückert","Thorsten Jungeblut"],"pdf_url":"https://arxiv.org/pdf/2403.12061v2.pdf","comment":"Abstract Presentation in 2023 Neuro-Inspired Computing Elements\n  (NICE) Conference"},{"id":"http://arxiv.org/abs/2402.10685v2","updated":"2024-03-25T11:50:32Z","published":"2024-02-16T13:39:34Z","title":"LongHeads: Multi-Head Attention is Secretly a Long Context Processor","summary":"  Large language models (LLMs) have achieved impressive performance in numerous\ndomains but often struggle to process lengthy inputs effectively and\nefficiently due to limited length generalization and attention's quadratic\ncomputational demands. Many sought to mitigate this by restricting the\nattention window within the pre-trained length. However, these methods\nintroduce new issues such as ignoring the middle context and requiring\nadditional training. To address these problems, we propose LongHeads, a\ntraining-free framework that enhances LLM's long context ability by unlocking\nmulti-head attention's untapped potential. Instead of allowing each head to\nattend to the full sentence, which struggles with generalizing to longer\nsequences due to out-of-distribution (OOD) issues, we allow each head to\nprocess in-distribution length by selecting and attending to important context\nchunks. To this end, we propose a chunk selection strategy that relies on the\ninherent correlation between the query and the key representations, efficiently\ndistributing context chunks to different heads. In this way, each head ensures\nit can effectively process attended tokens within the trained length, while\ndifferent heads in different layers can collectively process longer contexts.\nLongHeads works efficiently in linear time, fits seamlessly with many LLMs that\nuse relative positional encoding. LongHeads achieves 100% accuracy at the 128k\nlength on passkey retrieval task, verifying LongHeads's efficacy in extending\nthe usable context window for existing models. We release our code at\nhttps://github.com/LuLuLuyi/LongHeads .\n","authors":["Yi Lu","Xin Zhou","Wei He","Jun Zhao","Tao Ji","Tao Gui","Qi Zhang","Xuanjing Huang"],"pdf_url":"https://arxiv.org/pdf/2402.10685v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16649v1","updated":"2024-03-25T11:37:15Z","published":"2024-03-25T11:37:15Z","title":"CLHA: A Simple yet Effective Contrastive Learning Framework for Human\n  Alignment","summary":"  Reinforcement learning from human feedback (RLHF) is a crucial technique in\naligning large language models (LLMs) with human preferences, ensuring these\nLLMs behave in beneficial and comprehensible ways to users. However, a\nlongstanding challenge in human alignment techniques based on reinforcement\nlearning lies in their inherent complexity and difficulty in training. To\naddress this challenge, we present a simple yet effective Contrastive Learning\nFramework for Human Alignment (CLHA) to align LLMs with human preferences\ndirectly. CLHA employs a novel rescoring strategy to evaluate the noise within\nthe data by considering its inherent quality and dynamically adjusting the\ntraining process. Simultaneously, CLHA utilizes pairwise contrastive loss and\nadaptive supervised fine-tuning loss to adaptively modify the likelihood of\ngenerating responses, ensuring enhanced alignment with human preferences. Using\nadvanced methods, CLHA surpasses other algorithms, showcasing superior\nperformance in terms of reward model scores, automatic evaluations, and human\nassessments on the widely used ``\\textit{Helpful and Harmless}'' dataset.\n","authors":["Feiteng Fang","Liang Zhu","Min Yang","Xi Feng","Jinchang Hou","Qixuan Zhao","Chengming Li","Xiping Hu","Ruifeng Xu"],"pdf_url":"https://arxiv.org/pdf/2403.16649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.16476v4","updated":"2024-03-25T11:24:45Z","published":"2023-12-27T08:50:01Z","title":"SVGDreamer: Text Guided SVG Generation with Diffusion Model","summary":"  Recently, text-guided scalable vector graphics (SVGs) synthesis has shown\npromise in domains such as iconography and sketch. However, existing\ntext-to-SVG generation methods lack editability and struggle with visual\nquality and result diversity. To address these limitations, we propose a novel\ntext-guided vector graphics synthesis method called SVGDreamer. SVGDreamer\nincorporates a semantic-driven image vectorization (SIVE) process that enables\nthe decomposition of synthesis into foreground objects and background, thereby\nenhancing editability. Specifically, the SIVE process introduce attention-based\nprimitive control and an attention-mask loss function for effective control and\nmanipulation of individual elements. Additionally, we propose a Vectorized\nParticle-based Score Distillation (VPSD) approach to tackle the challenges of\nshape over-smoothing, color over-saturation, limited diversity in results, and\nslow convergence in existing text-to-SVG generation methods. VPSD models SVGs\nas distributions of control points and colors to counteract over-smoothing and\nover-saturation. Furthermore, VPSD leverages a reward model to reweight vector\nparticles, which improves aesthetic appeal and accelerates convergence.\nExtensive experiments have been conducted to validate the effectiveness of\nSVGDreamer, demonstrating its superiority over baseline methods in terms of\neditability, visual quality, and diversity. The code and demo of SVGDreamer can\nbe found at https://ximinng.github.io/SVGDreamer-project/\n","authors":["Ximing Xing","Haitao Zhou","Chuang Wang","Jing Zhang","Dong Xu","Qian Yu"],"pdf_url":"https://arxiv.org/pdf/2312.16476v4.pdf","comment":"Accepted by CVPR 2024. project link:\n  https://ximinng.github.io/SVGDreamer-project/"},{"id":"http://arxiv.org/abs/2310.07471v2","updated":"2024-03-25T11:07:13Z","published":"2023-10-11T13:18:23Z","title":"The Implications of Decentralization in Blockchained Federated Learning:\n  Evaluating the Impact of Model Staleness and Inconsistencies","summary":"  Blockchain promises to enhance distributed machine learning (ML) approaches\nsuch as federated learning (FL) by providing further decentralization,\nsecurity, immutability, and trust, which are key properties for enabling\ncollaborative intelligence in next-generation applications. Nonetheless, the\nintrinsic decentralized operation of peer-to-peer (P2P) blockchain nodes leads\nto an uncharted setting for FL, whereby the concepts of FL round and global\nmodel become meaningless, as devices' synchronization is lost without the\nfigure of a central orchestrating server. In this paper, we study the practical\nimplications of outsourcing the orchestration of FL to a democratic setting\nsuch as in a blockchain. In particular, we focus on the effects that model\nstaleness and inconsistencies, endorsed by blockchains' modus operandi, have on\nthe training procedure held by FL devices asynchronously. Using simulation, we\nevaluate the blockchained FL operation by applying two different ML models\n(ranging from low to high complexity) on the well-known MNIST and CIFAR-10\ndatasets, respectively, and focus on the accuracy and timeliness of the\nsolutions. Our results show the high impact of model inconsistencies on the\naccuracy of the models (up to a ~35% decrease in prediction accuracy), which\nunderscores the importance of properly designing blockchain systems based on\nthe characteristics of the underlying FL application.\n","authors":["Francesc Wilhelmi","Nima Afraz","Elia Guerra","Paolo Dini"],"pdf_url":"https://arxiv.org/pdf/2310.07471v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.00591v3","updated":"2024-03-25T10:52:20Z","published":"2024-02-01T13:37:53Z","title":"Sandra -- A Neuro-Symbolic Reasoner Based On Descriptions And Situations","summary":"  This paper presents sandra, a neuro-symbolic reasoner combining vectorial\nrepresentations with deductive reasoning. Sandra builds a vector space\nconstrained by an ontology and performs reasoning over it. The geometric nature\nof the reasoner allows its combination with neural networks, bridging the gap\nwith symbolic knowledge representations. Sandra is based on the Description and\nSituation (DnS) ontology design pattern, a formalization of frame semantics.\nGiven a set of facts (a situation) it allows to infer all possible perspectives\n(descriptions) that can provide a plausible interpretation for it, even in\npresence of incomplete information. We prove that our method is correct with\nrespect to the DnS model. We experiment with two different tasks and their\nstandard benchmarks, demonstrating that, without increasing complexity, sandra\n(i) outperforms all the baselines (ii) provides interpretability in the\nclassification process, and (iii) allows control over the vector space, which\nis designed a priori.\n","authors":["Nicolas Lazzari","Stefano De Giorgis","Aldo Gangemi","Valentina Presutti"],"pdf_url":"https://arxiv.org/pdf/2402.00591v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16591v1","updated":"2024-03-25T10:06:45Z","published":"2024-03-25T10:06:45Z","title":"Deciphering the Interplay between Local Differential Privacy, Average\n  Bayesian Privacy, and Maximum Bayesian Privacy","summary":"  The swift evolution of machine learning has led to emergence of various\ndefinitions of privacy due to the threats it poses to privacy, including the\nconcept of local differential privacy (LDP). Although widely embraced and\nutilized across numerous domains, this conventional approach to measure privacy\nstill exhibits certain limitations, spanning from failure to prevent\ninferential disclosure to lack of consideration for the adversary's background\nknowledge. In this comprehensive study, we introduce Bayesian privacy and delve\ninto the intricate relationship between local differential privacy and its\nBayesian counterparts, unveiling novel insights into utility-privacy\ntrade-offs. We introduce a framework that encapsulates both attack and defense\nstrategies, highlighting their interplay and effectiveness. Our theoretical\ncontributions are anchored in the rigorous definitions and relationships\nbetween Average Bayesian Privacy (ABP) and Maximum Bayesian Privacy (MBP),\nencapsulated by equations $\\epsilon_{p,a} \\leq\n\\frac{1}{\\sqrt{2}}\\sqrt{(\\epsilon_{p,m} + \\epsilon)\\cdot(e^{\\epsilon_{p,m} +\n\\epsilon} - 1)}$ and the equivalence between $\\xi$-MBP and $2\\xi$-LDP\nestablished under uniform prior distribution. These relationships fortify our\nunderstanding of the privacy guarantees provided by various mechanisms, leading\nto the realization that a mechanism satisfying $\\xi$-LDP also confers\n$\\xi$-MBP, and vice versa. Our work not only lays the groundwork for future\nempirical exploration but also promises to enhance the design of\nprivacy-preserving algorithms that do not compromise on utility, thereby\nfostering the development of trustworthy machine learning solutions.\n","authors":["Xiaojin Zhang","Yulin Fei","Wei Chen","Hai Jin"],"pdf_url":"https://arxiv.org/pdf/2403.16591v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16582v1","updated":"2024-03-25T09:49:42Z","published":"2024-03-25T09:49:42Z","title":"In the Search for Optimal Multi-view Learning Models for Crop\n  Classification with Global Remote Sensing Data","summary":"  Crop classification is of critical importance due to its role in studying\ncrop pattern changes, resource management, and carbon sequestration. When\nemploying data-driven techniques for its prediction, utilizing various temporal\ndata sources is necessary. Deep learning models have proven to be effective for\nthis task by mapping time series data to high-level representation for\nprediction. However, they face substantial challenges when dealing with\nmultiple input patterns. The literature offers limited guidance for Multi-View\nLearning (MVL) scenarios, as it has primarily focused on exploring fusion\nstrategies with specific encoders and validating them in local regions. In\ncontrast, we investigate the impact of simultaneous selection of the fusion\nstrategy and the encoder architecture evaluated on a global-scale cropland and\ncrop-type classifications. We use a range of five fusion strategies (Input,\nFeature, Decision, Ensemble, Hybrid) and five temporal encoder architectures\n(LSTM, GRU, TempCNN, TAE, L-TAE) as possible MVL model configurations. The\nvalidation is on the CropHarvest dataset that provides optical, radar, and\nweather time series, and topographic information as input data. We found that\nin scenarios with a limited number of labeled samples, a unique configuration\nis insufficient for all the cases. Instead, a specialized combination,\nincluding encoder and fusion strategy, should be meticulously sought. To\nstreamline this search process, we suggest initially identifying the optimal\nencoder architecture tailored for a particular fusion strategy, and then\ndetermining the most suitable fusion strategy for the classification task. We\nprovide a technical framework for researchers exploring crop classification or\nrelated tasks through a MVL approach.\n","authors":["Francisco Mena","Diego Arenas","Andreas Dengel"],"pdf_url":"https://arxiv.org/pdf/2403.16582v1.pdf","comment":"submitted to journal"},{"id":"http://arxiv.org/abs/2403.16578v1","updated":"2024-03-25T09:43:56Z","published":"2024-03-25T09:43:56Z","title":"SegICL: A Universal In-context Learning Framework for Enhanced\n  Segmentation in Medical Imaging","summary":"  Medical image segmentation models adapting to new tasks in a training-free\nmanner through in-context learning is an exciting advancement. Universal\nsegmentation models aim to generalize across the diverse modality of medical\nimages, yet their effectiveness often diminishes when applied to\nout-of-distribution (OOD) data modalities and tasks, requiring intricate\nfine-tuning of model for optimal performance. For addressing this challenge, we\nintroduce SegICL, a novel approach leveraging In-Context Learning (ICL) for\nimage segmentation. Unlike existing methods, SegICL has the capability to\nemploy text-guided segmentation and conduct in-context learning with a small\nset of image-mask pairs, eliminating the need for training the model from\nscratch or fine-tuning for OOD tasks (including OOD modality and dataset).\nExtensive experimental validation of SegICL demonstrates a positive correlation\nbetween the number of prompt samples and segmentation performance on OOD\nmodalities and tasks. This indicates that SegICL effectively address new\nsegmentation tasks based on contextual information. Additionally, SegICL also\nexhibits comparable segmentation performance to mainstream models on OOD and\nin-distribution tasks. Our code will be released soon.\n","authors":["Lingdong Shen","Fangxin Shang","Yehui Yang","Xiaoshuang Huang","Shining Xiang"],"pdf_url":"https://arxiv.org/pdf/2403.16578v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16571v1","updated":"2024-03-25T09:36:51Z","published":"2024-03-25T09:36:51Z","title":"NSINA: A News Corpus for Sinhala","summary":"  The introduction of large language models (LLMs) has advanced natural\nlanguage processing (NLP), but their effectiveness is largely dependent on\npre-training resources. This is especially evident in low-resource languages,\nsuch as Sinhala, which face two primary challenges: the lack of substantial\ntraining data and limited benchmarking datasets. In response, this study\nintroduces NSINA, a comprehensive news corpus of over 500,000 articles from\npopular Sinhala news websites, along with three NLP tasks: news media\nidentification, news category prediction, and news headline generation. The\nrelease of NSINA aims to provide a solution to challenges in adapting LLMs to\nSinhala, offering valuable resources and benchmarks for improving NLP in the\nSinhala language. NSINA is the largest news corpus for Sinhala, available up to\ndate.\n","authors":["Hansi Hettiarachchi","Damith Premasiri","Lasitha Uyangodage","Tharindu Ranasinghe"],"pdf_url":"https://arxiv.org/pdf/2403.16571v1.pdf","comment":"Accepted to LREC-COLING 2024 (The 2024 Joint International Conference\n  on Computational Linguistics, Language Resources and Evaluation)"},{"id":"http://arxiv.org/abs/2403.16561v1","updated":"2024-03-25T09:24:05Z","published":"2024-03-25T09:24:05Z","title":"FedFixer: Mitigating Heterogeneous Label Noise in Federated Learning","summary":"  Federated Learning (FL) heavily depends on label quality for its performance.\nHowever, the label distribution among individual clients is always both noisy\nand heterogeneous. The high loss incurred by client-specific samples in\nheterogeneous label noise poses challenges for distinguishing between\nclient-specific and noisy label samples, impacting the effectiveness of\nexisting label noise learning approaches. To tackle this issue, we propose\nFedFixer, where the personalized model is introduced to cooperate with the\nglobal model to effectively select clean client-specific samples. In the dual\nmodels, updating the personalized model solely at a local level can lead to\noverfitting on noisy data due to limited samples, consequently affecting both\nthe local and global models' performance. To mitigate overfitting, we address\nthis concern from two perspectives. Firstly, we employ a confidence regularizer\nto alleviate the impact of unconfident predictions caused by label noise.\nSecondly, a distance regularizer is implemented to constrain the disparity\nbetween the personalized and global models. We validate the effectiveness of\nFedFixer through extensive experiments on benchmark datasets. The results\ndemonstrate that FedFixer can perform well in filtering noisy label samples on\ndifferent clients, especially in highly heterogeneous label noise scenarios.\n","authors":["Xinyuan Ji","Zhaowei Zhu","Wei Xi","Olga Gadyatskaya","Zilong Song","Yong Cai","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2403.16561v1.pdf","comment":"accepted by AAA24"},{"id":"http://arxiv.org/abs/2403.16554v1","updated":"2024-03-25T09:04:14Z","published":"2024-03-25T09:04:14Z","title":"PE: A Poincare Explanation Method for Fast Text Hierarchy Generation","summary":"  The black-box nature of deep learning models in NLP hinders their widespread\napplication. The research focus has shifted to Hierarchical Attribution (HA)\nfor its ability to model feature interactions. Recent works model\nnon-contiguous combinations with a time-costly greedy search in Eculidean\nspaces, neglecting underlying linguistic information in feature\nrepresentations. In this work, we introduce a novel method, namely Poincar\\'e\nExplanation (PE), for modeling feature interactions using hyperbolic spaces in\nan $O(n^2logn)$ time complexity. Inspired by Poincar\\'e model, we propose a\nframework to project the embeddings into hyperbolic spaces, which exhibit\nbetter inductive biases for syntax and semantic hierarchical structures.\nEventually, we prove that the hierarchical clustering process in the projected\nspace could be viewed as building a minimum spanning tree and propose a time\nefficient algorithm. Experimental results demonstrate the effectiveness of our\napproach.\n","authors":["Qian Chen","Xiaofeng He","Hongzhao Li","Hongyu Yi"],"pdf_url":"https://arxiv.org/pdf/2403.16554v1.pdf","comment":"12 pages, 10 figures"},{"id":"http://arxiv.org/abs/2310.14714v4","updated":"2024-03-25T08:58:39Z","published":"2023-10-23T08:51:05Z","title":"BatteryML:An Open-source platform for Machine Learning on Battery\n  Degradation","summary":"  Battery degradation remains a pivotal concern in the energy storage domain,\nwith machine learning emerging as a potent tool to drive forward insights and\nsolutions. However, this intersection of electrochemical science and machine\nlearning poses complex challenges. Machine learning experts often grapple with\nthe intricacies of battery science, while battery researchers face hurdles in\nadapting intricate models tailored to specific datasets. Beyond this, a\ncohesive standard for battery degradation modeling, inclusive of data formats\nand evaluative benchmarks, is conspicuously absent. Recognizing these\nimpediments, we present BatteryML - a one-step, all-encompass, and open-source\nplatform designed to unify data preprocessing, feature extraction, and the\nimplementation of both traditional and state-of-the-art models. This\nstreamlined approach promises to enhance the practicality and efficiency of\nresearch applications. BatteryML seeks to fill this void, fostering an\nenvironment where experts from diverse specializations can collaboratively\ncontribute, thus elevating the collective understanding and advancement of\nbattery research.The code for our project is publicly available on GitHub at\nhttps://github.com/microsoft/BatteryML.\n","authors":["Han Zhang","Xiaofan Gui","Shun Zheng","Ziheng Lu","Yuqi Li","Jiang Bian"],"pdf_url":"https://arxiv.org/pdf/2310.14714v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.02760v2","updated":"2024-03-25T08:57:47Z","published":"2023-11-05T20:33:18Z","title":"Causal Question Answering with Reinforcement Learning","summary":"  Causal questions inquire about causal relationships between different events\nor phenomena. They are important for a variety of use cases, including virtual\nassistants and search engines. However, many current approaches to causal\nquestion answering cannot provide explanations or evidence for their answers.\nHence, in this paper, we aim to answer causal questions with a causality graph,\na large-scale dataset of causal relations between noun phrases along with the\nrelations' provenance data. Inspired by recent, successful applications of\nreinforcement learning to knowledge graph tasks, such as link prediction and\nfact-checking, we explore the application of reinforcement learning on a\ncausality graph for causal question answering. We introduce an\nActor-Critic-based agent which learns to search through the graph to answer\ncausal questions. We bootstrap the agent with a supervised learning procedure\nto deal with large action spaces and sparse rewards. Our evaluation shows that\nthe agent successfully prunes the search space to answer binary causal\nquestions by visiting less than 30 nodes per question compared to over 3,000\nnodes by a naive breadth-first search. Our ablation study indicates that our\nsupervised learning strategy provides a strong foundation upon which our\nreinforcement learning agent improves. The paths returned by our agent explain\nthe mechanisms by which a cause produces an effect. Moreover, for each edge on\na path, our causality graph provides its original source allowing for easy\nverification of paths.\n","authors":["Lukas Blübaum","Stefan Heindorf"],"pdf_url":"https://arxiv.org/pdf/2311.02760v2.pdf","comment":"Accepted at WWW 2024"},{"id":"http://arxiv.org/abs/2403.16552v1","updated":"2024-03-25T08:57:27Z","published":"2024-03-25T08:57:27Z","title":"QKFormer: Hierarchical Spiking Transformer using Q-K Attention","summary":"  Spiking Transformers, which integrate Spiking Neural Networks (SNNs) with\nTransformer architectures, have attracted significant attention due to their\npotential for energy efficiency and high performance. However, existing models\nin this domain still suffer from suboptimal performance. We introduce several\ninnovations to improve the performance: i) We propose a novel spike-form Q-K\nattention mechanism, tailored for SNNs, which efficiently models the importance\nof token or channel dimensions through binary vectors with linear complexity.\nii) We incorporate the hierarchical structure, which significantly benefits the\nperformance of both the brain and artificial neural networks, into spiking\ntransformers to obtain multi-scale spiking representation. iii) We design a\nversatile and powerful patch embedding module with a deformed shortcut\nspecifically for spiking transformers. Together, we develop QKFormer, a\nhierarchical spiking transformer based on Q-K attention with direct training.\nQKFormer shows significantly superior performance over existing\nstate-of-the-art SNN models on various mainstream datasets. Notably, with\ncomparable size to Spikformer (66.34 M, 74.81%), QKFormer (64.96 M) achieves a\ngroundbreaking top-1 accuracy of 85.65% on ImageNet-1k, substantially\noutperforming Spikformer by 10.84%. To our best knowledge, this is the first\ntime that directly training SNNs have exceeded 85% accuracy on ImageNet-1K. The\ncode and models are publicly available at\nhttps://github.com/zhouchenlin2096/QKFormer\n","authors":["Chenlin Zhou","Han Zhang","Zhaokun Zhou","Liutao Yu","Liwei Huang","Xiaopeng Fan","Li Yuan","Zhengyu Ma","Huihui Zhou","Yonghong Tian"],"pdf_url":"https://arxiv.org/pdf/2403.16552v1.pdf","comment":"10 pages, code: https://github.com/zhouchenlin2096/QKFormer"},{"id":"http://arxiv.org/abs/2403.01479v3","updated":"2024-03-25T08:46:15Z","published":"2024-03-03T11:13:44Z","title":"Align-to-Distill: Trainable Attention Alignment for Knowledge\n  Distillation in Neural Machine Translation","summary":"  The advent of scalable deep models and large datasets has improved the\nperformance of Neural Machine Translation. Knowledge Distillation (KD) enhances\nefficiency by transferring knowledge from a teacher model to a more compact\nstudent model. However, KD approaches to Transformer architecture often rely on\nheuristics, particularly when deciding which teacher layers to distill from. In\nthis paper, we introduce the 'Align-to-Distill' (A2D) strategy, designed to\naddress the feature mapping problem by adaptively aligning student attention\nheads with their teacher counterparts during training. The Attention Alignment\nModule in A2D performs a dense head-by-head comparison between student and\nteacher attention heads across layers, turning the combinatorial mapping\nheuristics into a learning problem. Our experiments show the efficacy of A2D,\ndemonstrating gains of up to +3.61 and +0.63 BLEU points for WMT-2022 De->Dsb\nand WMT-2014 En->De, respectively, compared to Transformer baselines.\n","authors":["Heegon Jin","Seonil Son","Jemin Park","Youngseok Kim","Hyungjong Noh","Yeonsoo Lee"],"pdf_url":"https://arxiv.org/pdf/2403.01479v3.pdf","comment":"Accepted to LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2402.09132v3","updated":"2024-03-25T08:46:02Z","published":"2024-02-14T12:28:38Z","title":"Exploring the Adversarial Capabilities of Large Language Models","summary":"  The proliferation of large language models (LLMs) has sparked widespread and\ngeneral interest due to their strong language generation capabilities, offering\ngreat potential for both industry and research. While previous research delved\ninto the security and privacy issues of LLMs, the extent to which these models\ncan exhibit adversarial behavior remains largely unexplored. Addressing this\ngap, we investigate whether common publicly available LLMs have inherent\ncapabilities to perturb text samples to fool safety measures, so-called\nadversarial examples resp.~attacks. More specifically, we investigate whether\nLLMs are inherently able to craft adversarial examples out of benign samples to\nfool existing safe rails. Our experiments, which focus on hate speech\ndetection, reveal that LLMs succeed in finding adversarial perturbations,\neffectively undermining hate speech detection systems. Our findings carry\nsignificant implications for (semi-)autonomous systems relying on LLMs,\nhighlighting potential challenges in their interaction with existing systems\nand safety measures.\n","authors":["Lukas Struppek","Minh Hieu Le","Dominik Hintersdorf","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2402.09132v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16543v1","updated":"2024-03-25T08:36:06Z","published":"2024-03-25T08:36:06Z","title":"Efficient Information Extraction in Few-Shot Relation Classification\n  through Contrastive Representation Learning","summary":"  Differentiating relationships between entity pairs with limited labeled\ninstances poses a significant challenge in few-shot relation classification.\nRepresentations of textual data extract rich information spanning the domain,\nentities, and relations. In this paper, we introduce a novel approach to\nenhance information extraction combining multiple sentence representations and\ncontrastive learning. While representations in relation classification are\ncommonly extracted using entity marker tokens, we argue that substantial\ninformation within the internal model representations remains untapped. To\naddress this, we propose aligning multiple sentence representations, such as\nthe [CLS] token, the [MASK] token used in prompting, and entity marker tokens.\nOur method employs contrastive learning to extract complementary discriminative\ninformation from these individual representations. This is particularly\nrelevant in low-resource settings where information is scarce. Leveraging\nmultiple sentence representations is especially effective in distilling\ndiscriminative information for relation classification when additional\ninformation, like relation descriptions, are not available. We validate the\nadaptability of our approach, maintaining robust performance in scenarios that\ninclude relation descriptions, and showcasing its flexibility to adapt to\ndifferent resource constraints.\n","authors":["Philipp Borchert","Jochen De Weerdt","Marie-Francine Moens"],"pdf_url":"https://arxiv.org/pdf/2403.16543v1.pdf","comment":"NAACL 2024"},{"id":"http://arxiv.org/abs/2309.08503v2","updated":"2024-03-25T08:33:37Z","published":"2023-09-15T16:05:48Z","title":"HealthFC: Verifying Health Claims with Evidence-Based Medical\n  Fact-Checking","summary":"  In the digital age, seeking health advice on the Internet has become a common\npractice. At the same time, determining the trustworthiness of online medical\ncontent is increasingly challenging. Fact-checking has emerged as an approach\nto assess the veracity of factual claims using evidence from credible knowledge\nsources. To help advance automated Natural Language Processing (NLP) solutions\nfor this task, in this paper we introduce a novel dataset HealthFC. It consists\nof 750 health-related claims in German and English, labeled for veracity by\nmedical experts and backed with evidence from systematic reviews and clinical\ntrials. We provide an analysis of the dataset, highlighting its characteristics\nand challenges. The dataset can be used for NLP tasks related to automated\nfact-checking, such as evidence retrieval, claim verification, or explanation\ngeneration. For testing purposes, we provide baseline systems based on\ndifferent approaches, examine their performance, and discuss the findings. We\nshow that the dataset is a challenging test bed with a high potential for\nfuture use.\n","authors":["Juraj Vladika","Phillip Schneider","Florian Matthes"],"pdf_url":"https://arxiv.org/pdf/2309.08503v2.pdf","comment":"Accepted to LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2401.11504v2","updated":"2024-03-25T08:16:06Z","published":"2024-01-21T14:28:41Z","title":"With Greater Text Comes Greater Necessity: Inference-Time Training Helps\n  Long Text Generation","summary":"  Long text generation, such as novel writing and discourse-level translation\nwith extremely long contexts, presents significant challenges to current\nlanguage models. Existing methods mainly focus on extending the model's context\nwindow through strategies like length extrapolation. However, these approaches\ndemand substantial hardware resources during the training and/or inference\nphases. Our proposed method, Temp-Lora, introduces an alternative concept.\nInstead of relying on the KV cache to store all context information, we embeds\nthis information directly into a temporary Lora module. In the process of long\ntext generation, this module is progressively trained with text generated\npreviously. This approach not only efficiently preserves contextual knowledge\nbut also prevents any permanent alteration to the model's parameters given that\nthe module is discarded post-generation. Extensive experiments on the PG19\nlanguage modeling benchmark and the GuoFeng discourse-level translation\nbenchmark validate the effectiveness of Temp-Lora. Our results show that: 1)\nTemp-Lora substantially enhances generation quality for long text, as indicated\nby a 13.2% decrease in perplexity (PPL) on a subset of PG19, and a 29.3%\ndecrease in PPL along with a 113.2% increase in BLEU score on a subset of\nGuoFeng, 2) Temp-Lora is compatible with and enhances most existing long text\ngeneration methods, and 3) Temp-Lora can greatly reduce computational costs by\nshortening the context window. For example, we can ensure a moderate\nimprovement in generation quality (a decrease of 3.8% in PPL) while enabling a\n51.5% memory usage reduction and a 60.0% decrease in latency for inference.\n","authors":["Y. Wang","D. Ma","D. Cai"],"pdf_url":"https://arxiv.org/pdf/2401.11504v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16530v1","updated":"2024-03-25T08:16:06Z","published":"2024-03-25T08:16:06Z","title":"An Intermediate Fusion ViT Enables Efficient Text-Image Alignment in\n  Diffusion Models","summary":"  Diffusion models have been widely used for conditional data cross-modal\ngeneration tasks such as text-to-image and text-to-video. However,\nstate-of-the-art models still fail to align the generated visual concepts with\nhigh-level semantics in a language such as object count, spatial relationship,\netc. We approach this problem from a multimodal data fusion perspective and\ninvestigate how different fusion strategies can affect vision-language\nalignment. We discover that compared to the widely used early fusion of\nconditioning text in a pretrained image feature space, a specially designed\nintermediate fusion can: (i) boost text-to-image alignment with improved\ngeneration quality and (ii) improve training and inference efficiency by\nreducing low-rank text-to-image attention calculations. We perform experiments\nusing a text-to-image generation task on the MS-COCO dataset. We compare our\nintermediate fusion mechanism with the classic early fusion mechanism on two\ncommon conditioning methods on a U-shaped ViT backbone. Our intermediate fusion\nmodel achieves a higher CLIP Score and lower FID, with 20% reduced FLOPs, and\n50% increased training speed compared to a strong U-ViT baseline with an early\nfusion.\n","authors":["Zizhao Hu","Shaochong Jia","Mohammad Rostami"],"pdf_url":"https://arxiv.org/pdf/2403.16530v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16527v1","updated":"2024-03-25T08:11:02Z","published":"2024-03-25T08:11:02Z","title":"Hallucination Detection in Foundation Models for Decision-Making: A\n  Flexible Definition and Review of the State of the Art","summary":"  Autonomous systems are soon to be ubiquitous, from manufacturing autonomy to\nagricultural field robots, and from health care assistants to the entertainment\nindustry. The majority of these systems are developed with modular\nsub-components for decision-making, planning, and control that may be\nhand-engineered or learning-based. While these existing approaches have been\nshown to perform well under the situations they were specifically designed for,\nthey can perform especially poorly in rare, out-of-distribution scenarios that\nwill undoubtedly arise at test-time. The rise of foundation models trained on\nmultiple tasks with impressively large datasets from a variety of fields has\nled researchers to believe that these models may provide common sense reasoning\nthat existing planners are missing. Researchers posit that this common sense\nreasoning will bridge the gap between algorithm development and deployment to\nout-of-distribution tasks, like how humans adapt to unexpected scenarios. Large\nlanguage models have already penetrated the robotics and autonomous systems\ndomains as researchers are scrambling to showcase their potential use cases in\ndeployment. While this application direction is very promising empirically,\nfoundation models are known to hallucinate and generate decisions that may\nsound reasonable, but are in fact poor. We argue there is a need to step back\nand simultaneously design systems that can quantify the certainty of a model's\ndecision, and detect when it may be hallucinating. In this work, we discuss the\ncurrent use cases of foundation models for decision-making tasks, provide a\ngeneral definition for hallucinations with examples, discuss existing\napproaches to hallucination detection and mitigation with a focus on decision\nproblems, and explore areas for further research in this exciting field.\n","authors":["Neeloy Chakraborty","Melkior Ornik","Katherine Driggs-Campbell"],"pdf_url":"https://arxiv.org/pdf/2403.16527v1.pdf","comment":"31 pages, 2 tables"},{"id":"http://arxiv.org/abs/2403.16524v1","updated":"2024-03-25T08:09:01Z","published":"2024-03-25T08:09:01Z","title":"Harnessing the power of LLMs for normative reasoning in MASs","summary":"  Software agents, both human and computational, do not exist in isolation and\noften need to collaborate or coordinate with others to achieve their goals. In\nhuman society, social mechanisms such as norms ensure efficient functioning,\nand these techniques have been adopted by researchers in multi-agent systems\n(MAS) to create socially aware agents. However, traditional techniques have\nlimitations, such as operating in limited environments often using brittle\nsymbolic reasoning. The advent of Large Language Models (LLMs) offers a\npromising solution, providing a rich and expressive vocabulary for norms and\nenabling norm-capable agents that can perform a range of tasks such as norm\ndiscovery, normative reasoning and decision-making. This paper examines the\npotential of LLM-based agents to acquire normative capabilities, drawing on\nrecent Natural Language Processing (NLP) and LLM research. We present our\nvision for creating normative LLM agents. In particular, we discuss how the\nrecently proposed \"LLM agent\" approaches can be extended to implement such\nnormative LLM agents. We also highlight challenges in this emerging field. This\npaper thus aims to foster collaboration between MAS, NLP and LLM researchers in\norder to advance the field of normative agents.\n","authors":["Bastin Tony Roy Savarimuthu","Surangika Ranathunga","Stephen Cranefield"],"pdf_url":"https://arxiv.org/pdf/2403.16524v1.pdf","comment":"12 pages, 1 figure, accepted to COINE 2024 workshop at AAMAS 2024\n  (https://coin-workshop.github.io/coine-2024-auckland/accepted_papers.html)"},{"id":"http://arxiv.org/abs/2403.16523v1","updated":"2024-03-25T08:06:08Z","published":"2024-03-25T08:06:08Z","title":"Causal Discovery from Poisson Branching Structural Causal Model Using\n  High-Order Cumulant with Path Analysis","summary":"  Count data naturally arise in many fields, such as finance, neuroscience, and\nepidemiology, and discovering causal structure among count data is a crucial\ntask in various scientific and industrial scenarios. One of the most common\ncharacteristics of count data is the inherent branching structure described by\na binomial thinning operator and an independent Poisson distribution that\ncaptures both branching and noise. For instance, in a population count\nscenario, mortality and immigration contribute to the count, where survival\nfollows a Bernoulli distribution, and immigration follows a Poisson\ndistribution. However, causal discovery from such data is challenging due to\nthe non-identifiability issue: a single causal pair is Markov equivalent, i.e.,\n$X\\rightarrow Y$ and $Y\\rightarrow X$ are distributed equivalent. Fortunately,\nin this work, we found that the causal order from $X$ to its child $Y$ is\nidentifiable if $X$ is a root vertex and has at least two directed paths to\n$Y$, or the ancestor of $X$ with the most directed path to $X$ has a directed\npath to $Y$ without passing $X$. Specifically, we propose a Poisson Branching\nStructure Causal Model (PB-SCM) and perform a path analysis on PB-SCM using\nhigh-order cumulants. Theoretical results establish the connection between the\npath and cumulant and demonstrate that the path information can be obtained\nfrom the cumulant. With the path information, causal order is identifiable\nunder some graphical conditions. A practical algorithm for learning causal\nstructure under PB-SCM is proposed and the experiments demonstrate and verify\nthe effectiveness of the proposed method.\n","authors":["Jie Qiao","Yu Xiang","Zhengming Chen","Ruichu Cai","Zhifeng Hao"],"pdf_url":"https://arxiv.org/pdf/2403.16523v1.pdf","comment":"Accepted by AAAI-2024"},{"id":"http://arxiv.org/abs/2403.16512v1","updated":"2024-03-25T07:55:29Z","published":"2024-03-25T07:55:29Z","title":"LLMs Are Few-Shot In-Context Low-Resource Language Learners","summary":"  In-context learning (ICL) empowers large language models (LLMs) to perform\ndiverse tasks in underrepresented languages using only short in-context\ninformation, offering a crucial avenue for narrowing the gap between\nhigh-resource and low-resource languages. Nonetheless, there is only a handful\nof works explored ICL for low-resource languages with most of them focusing on\nrelatively high-resource languages, such as French and Spanish. In this work,\nwe extensively study ICL and its cross-lingual variation (X-ICL) on 25\nlow-resource and 7 relatively higher-resource languages. Our study not only\nassesses the effectiveness of ICL with LLMs in low-resource languages but also\nidentifies the shortcomings of in-context label alignment, and introduces a\nmore effective alternative: query alignment. Moreover, we provide valuable\ninsights into various facets of ICL for low-resource languages. Our study\nconcludes the significance of few-shot in-context information on enhancing the\nlow-resource understanding quality of LLMs through semantically relevant\ninformation by closing the language gap in the target language and aligning the\nsemantics between the targeted low-resource and the high-resource language that\nthe model is proficient in. Our work highlights the importance of advancing ICL\nresearch, particularly for low-resource languages.\n","authors":["Samuel Cahyawijaya","Holy Lovenia","Pascale Fung"],"pdf_url":"https://arxiv.org/pdf/2403.16512v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16508v1","updated":"2024-03-25T07:47:52Z","published":"2024-03-25T07:47:52Z","title":"Return to Tradition: Learning Reliable Heuristics with Classical Machine\n  Learning","summary":"  Current approaches for learning for planning have yet to achieve competitive\nperformance against classical planners in several domains, and have poor\noverall performance. In this work, we construct novel graph representations of\nlifted planning tasks and use the WL algorithm to generate features from them.\nThese features are used with classical machine learning methods which have up\nto 2 orders of magnitude fewer parameters and train up to 3 orders of magnitude\nfaster than the state-of-the-art deep learning for planning models. Our novel\napproach, WL-GOOSE, reliably learns heuristics from scratch and outperforms the\n$h^{\\text{FF}}$ heuristic in a fair competition setting. It also outperforms or\nties with LAMA on 4 out of 10 domains on coverage and 7 out of 10 domains on\nplan quality. WL-GOOSE is the first learning for planning model which achieves\nthese feats. Furthermore, we study the connections between our novel WL feature\ngeneration method, previous theoretically flavoured learning architectures, and\nDescription Logic Features for planning.\n","authors":["Dillon Z. Chen","Felipe Trevizan","Sylvie Thiébaux"],"pdf_url":"https://arxiv.org/pdf/2403.16508v1.pdf","comment":"Extended version of ICAPS 2024 paper"},{"id":"http://arxiv.org/abs/2403.16501v1","updated":"2024-03-25T07:34:42Z","published":"2024-03-25T07:34:42Z","title":"Learning To Guide Human Decision Makers With Vision-Language Models","summary":"  There is increasing interest in developing AIs for assisting human decision\nmaking in \\textit{high-stakes} tasks, such as medical diagnosis, for the\npurpose of improving decision quality and reducing cognitive strain.\n  %\n  Mainstream approaches team up an expert with a machine learning model to\nwhich safer decisions are offloaded, thus letting the former focus on cases\nthat demand their attention.\n  %\n  This \\textit{separation of responsibilities} setup, however, is inadequate\nfor high-stakes scenarios. On the one hand, the expert may end up over-relying\non the machine's decisions due to \\textit{anchoring bias}, thus losing the\nhuman oversight that is increasingly being required by regulatory agencies to\nensure trustworthy AI. On the other hand, the expert is left entirely\nunassisted on the (typically hardest) decisions on which the model abstained.\n  %\n  As a remedy, we introduce \\textit{learning to guide} (LTG), an alternative\nframework in which -- rather than taking control from the human expert -- the\nmachine provides \\textit{guidance} useful for decision making, and the human is\nentirely responsible for coming up with a decision.\n  %\n  In order to ensure guidance is \\textit{interpretable} and\n\\textit{task-specific}, we develop \\method, an approach for turning\n\\textit{any} vision-language model into a capable generator of textual guidance\nby leveraging a modicum of human feedback.\n  %\n  Our empirical evaluation highlights the promise of \\method on a challenging,\nreal-world medical diagnosis task.\n","authors":["Debodeep Banerjee","Stefano Teso","Burcu Sayin Grunel","Andrea Passerini"],"pdf_url":"https://arxiv.org/pdf/2403.16501v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16495v1","updated":"2024-03-25T07:23:23Z","published":"2024-03-25T07:23:23Z","title":"LSTTN: A Long-Short Term Transformer-based Spatio-temporal Neural\n  Network for Traffic Flow Forecasting","summary":"  Accurate traffic forecasting is a fundamental problem in intelligent\ntransportation systems and learning long-range traffic representations with key\ninformation through spatiotemporal graph neural networks (STGNNs) is a basic\nassumption of current traffic flow prediction models. However, due to\nstructural limitations, existing STGNNs can only utilize short-range traffic\nflow data; therefore, the models cannot adequately learn the complex trends and\nperiodic features in traffic flow. Besides, it is challenging to extract the\nkey temporal information from the long historical traffic series and obtain a\ncompact representation. To solve the above problems, we propose a novel LSTTN\n(Long-Short Term Transformer-based Network) framework comprehensively\nconsidering the long- and short-term features in historical traffic flow.\nFirst, we employ a masked subseries Transformer to infer the content of masked\nsubseries from a small portion of unmasked subseries and their temporal context\nin a pretraining manner, forcing the model to efficiently learn compressed and\ncontextual subseries temporal representations from long historical series.\nThen, based on the learned representations, long-term trend is extracted by\nusing stacked 1D dilated convolution layers, and periodic features are\nextracted by dynamic graph convolution layers. For the difficulties in making\ntime-step level prediction, LSTTN adopts a short-term trend extractor to learn\nfine-grained short-term temporal features. Finally, LSTTN fuses the long-term\ntrend, periodic features and short-term features to obtain the prediction\nresults. Experiments on four real-world datasets show that in 60-minute-ahead\nlong-term forecasting, the LSTTN model achieves a minimum improvement of 5.63\\%\nand a maximum improvement of 16.78\\% over baseline models. The source code is\navailable at https://github.com/GeoX-Lab/LSTTN.\n","authors":["Qinyao Luo","Silu He","Xing Han","Yuhan Wang","Haifeng Li"],"pdf_url":"https://arxiv.org/pdf/2403.16495v1.pdf","comment":"15 pages, 10 figures, 6 tables"},{"id":"http://arxiv.org/abs/2312.11834v2","updated":"2024-03-25T07:00:29Z","published":"2023-12-19T04:02:50Z","title":"Multi-agent reinforcement learning using echo-state network and its\n  application to pedestrian dynamics","summary":"  In recent years, simulations of pedestrians using the multi-agent\nreinforcement learning (MARL) have been studied. This study considered the\nroads on a grid-world environment, and implemented pedestrians as MARL agents\nusing an echo-state network and the least squares policy iteration method.\nUnder this environment, the ability of these agents to learn to move forward by\navoiding other agents was investigated. Specifically, we considered two types\nof tasks: the choice between a narrow direct route and a broad detour, and the\nbidirectional pedestrian flow in a corridor. The simulations results indicated\nthat the learning was successful when the density of the agents was not that\nhigh.\n","authors":["Hisato Komatsu"],"pdf_url":"https://arxiv.org/pdf/2312.11834v2.pdf","comment":"26 pages, 17 figures"},{"id":"http://arxiv.org/abs/2306.04357v4","updated":"2024-03-25T06:54:10Z","published":"2023-06-07T11:40:07Z","title":"Dial-MAE: ConTextual Masked Auto-Encoder for Retrieval-based Dialogue\n  Systems","summary":"  Dialogue response selection aims to select an appropriate response from\nseveral candidates based on a given user and system utterance history. Most\nexisting works primarily focus on post-training and fine-tuning tailored for\ncross-encoders. However, there are no post-training methods tailored for dense\nencoders in dialogue response selection. We argue that when the current\nlanguage model, based on dense dialogue systems (such as BERT), is employed as\na dense encoder, it separately encodes dialogue context and response, leading\nto a struggle to achieve the alignment of both representations. Thus, we\npropose Dial-MAE (Dialogue Contextual Masking Auto-Encoder), a straightforward\nyet effective post-training technique tailored for dense encoders in dialogue\nresponse selection. Dial-MAE uses an asymmetric encoder-decoder architecture to\ncompress the dialogue semantics into dense vectors, which achieves better\nalignment between the features of the dialogue context and response. Our\nexperiments have demonstrated that Dial-MAE is highly effective, achieving\nstate-of-the-art performance on two commonly evaluated benchmarks.\n","authors":["Zhenpeng Su","Xing Wu","Wei Zhou","Guangyuan Ma","Songlin Hu"],"pdf_url":"https://arxiv.org/pdf/2306.04357v4.pdf","comment":"This paper has been accepted by NAACL 2024"},{"id":"http://arxiv.org/abs/2403.16460v1","updated":"2024-03-25T06:43:28Z","published":"2024-03-25T06:43:28Z","title":"FedAC: A Adaptive Clustered Federated Learning Framework for\n  Heterogeneous Data","summary":"  Clustered federated learning (CFL) is proposed to mitigate the performance\ndeterioration stemming from data heterogeneity in federated learning (FL) by\ngrouping similar clients for cluster-wise model training. However, current CFL\nmethods struggle due to inadequate integration of global and intra-cluster\nknowledge and the absence of an efficient online model similarity metric, while\ntreating the cluster count as a fixed hyperparameter limits flexibility and\nrobustness. In this paper, we propose an adaptive CFL framework, named FedAC,\nwhich (1) efficiently integrates global knowledge into intra-cluster learning\nby decoupling neural networks and utilizing distinct aggregation methods for\neach submodule, significantly enhancing performance; (2) includes a\ncosteffective online model similarity metric based on dimensionality reduction;\n(3) incorporates a cluster number fine-tuning module for improved adaptability\nand scalability in complex, heterogeneous environments. Extensive experiments\nshow that FedAC achieves superior empirical performance, increasing the test\naccuracy by around 1.82% and 12.67% on CIFAR-10 and CIFAR-100 datasets,\nrespectively, under different non-IID settings compared to SOTA methods.\n","authors":["Yuxin Zhang","Haoyu Chen","Zheng Lin","Zhe Chen","Jin Zhao"],"pdf_url":"https://arxiv.org/pdf/2403.16460v1.pdf","comment":"14 pages, 4 figures"},{"id":"http://arxiv.org/abs/2312.16430v5","updated":"2024-03-25T06:32:49Z","published":"2023-12-27T06:34:54Z","title":"Preference as Reward, Maximum Preference Optimization with Importance\n  Sampling","summary":"  Preference learning is a key technology for aligning language models with\nhuman values. Reinforcement Learning from Human Feedback (RLHF) is a\nmodel-based algorithm to optimize preference learning, which first fits a\nreward model for preference scores and then optimizes the generating policy\nwith an on-policy PPO algorithm to maximize the reward. The processing of RLHF\nis complex, time-consuming, and unstable. The Direct Preference Optimization\n(DPO) algorithm uses an off-policy algorithm to directly optimize the\ngenerating policy and eliminates the need for a reward model. DPO is more\ndata-efficient and stable. However, DPO has a drawback of overfitting to the\npreference data and ignoring the KL-regularization term when the preference is\ndeterministic. Identity mapping Preference Optimization(IPO) uses a\nroot-finding MSE loss to incorporate KL-regularization. However, both DPO and\nIPO fail to properly address the KL-regularization term because the support of\nthe preference distribution is not equal to the reference distribution. In this\npaper, we propose a simple and intuitive off-policy preference optimization\nalgorithm from an importance sampling view, which we call Maximum Preference\nOptimization (MPO). MPO incorporates the off-policy KL-regularization term,\nmaking regularization truly effective. MPO achieves the best of both worlds by\ncombining the objectives of RLHF and IPO while being an off-policy algorithm.\nFurthermore, MPO eliminates the need for a reward model and reference policy,\nsimplifying the learning process and reducing memory usage.\n","authors":["Zaifan Jiang","Xing Huang","Chao Wei"],"pdf_url":"https://arxiv.org/pdf/2312.16430v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16451v1","updated":"2024-03-25T06:30:54Z","published":"2024-03-25T06:30:54Z","title":"DeepMachining: Online Prediction of Machining Errors of Lathe Machines","summary":"  We describe DeepMachining, a deep learning-based AI system for online\nprediction of machining errors of lathe machine operations. We have built and\nevaluated DeepMachining based on manufacturing data from factories.\nSpecifically, we first pretrain a deep learning model for a given lathe\nmachine's operations to learn the salient features of machining states. Then,\nwe fine-tune the pretrained model to adapt to specific machining tasks. We\ndemonstrate that DeepMachining achieves high prediction accuracy for multiple\ntasks that involve different workpieces and cutting tools. To the best of our\nknowledge, this work is one of the first factory experiments using pre-trained\ndeep-learning models to predict machining errors of lathe machines.\n","authors":["Xiang-Li Lu","Hwai-Jung Hsu","Che-Wei Chou","H. T. Kung","Chen-Hsin Lee"],"pdf_url":"https://arxiv.org/pdf/2403.16451v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16443v1","updated":"2024-03-25T06:09:55Z","published":"2024-03-25T06:09:55Z","title":"CodeS: Natural Language to Code Repository via Multi-Layer Sketch","summary":"  The impressive performance of large language models (LLMs) on code-related\ntasks has shown the potential of fully automated software development. In light\nof this, we introduce a new software engineering task, namely Natural Language\nto code Repository (NL2Repo). This task aims to generate an entire code\nrepository from its natural language requirements. To address this task, we\npropose a simple yet effective framework CodeS, which decomposes NL2Repo into\nmultiple sub-tasks by a multi-layer sketch. Specifically, CodeS includes three\nmodules: RepoSketcher, FileSketcher, and SketchFiller. RepoSketcher first\ngenerates a repository's directory structure for given requirements;\nFileSketcher then generates a file sketch for each file in the generated\nstructure; SketchFiller finally fills in the details for each function in the\ngenerated file sketch. To rigorously assess CodeS on the NL2Repo task, we carry\nout evaluations through both automated benchmarking and manual feedback\nanalysis. For benchmark-based evaluation, we craft a repository-oriented\nbenchmark, SketchEval, and design an evaluation metric, SketchBLEU. For\nfeedback-based evaluation, we develop a VSCode plugin for CodeS and engage 30\nparticipants in conducting empirical studies. Extensive experiments prove the\neffectiveness and practicality of CodeS on the NL2Repo task.\n","authors":["Daoguang Zan","Ailun Yu","Wei Liu","Dong Chen","Bo Shen","Wei Li","Yafen Yao","Yongshun Gong","Xiaolin Chen","Bei Guan","Zhiguang Yang","Yongji Wang","Qianxiang Wang","Lizhen Cui"],"pdf_url":"https://arxiv.org/pdf/2403.16443v1.pdf","comment":"https://github.com/NL2Code/CodeS"},{"id":"http://arxiv.org/abs/2311.08298v2","updated":"2024-03-25T06:01:49Z","published":"2023-11-14T16:43:29Z","title":"A Survey of Confidence Estimation and Calibration in Large Language\n  Models","summary":"  Large language models (LLMs) have demonstrated remarkable capabilities across\na wide range of tasks in various domains. Despite their impressive performance,\nthey can be unreliable due to factual errors in their generations. Assessing\ntheir confidence and calibrating them across different tasks can help mitigate\nrisks and enable LLMs to produce better generations. There has been a lot of\nrecent research aiming to address this, but there has been no comprehensive\noverview to organize it and outline the main lessons learned. The present\nsurvey aims to bridge this gap. In particular, we outline the challenges and we\nsummarize recent technical advancements for LLM confidence estimation and\ncalibration. We further discuss their applications and suggest promising\ndirections for future work.\n","authors":["Jiahui Geng","Fengyu Cai","Yuxia Wang","Heinz Koeppl","Preslav Nakov","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2311.08298v2.pdf","comment":"16 pages, 1 page, 1 table"},{"id":"http://arxiv.org/abs/2305.17196v2","updated":"2024-03-25T05:50:33Z","published":"2023-05-26T18:39:25Z","title":"A Knowledge Engineering Primer","summary":"  The aim of this primer is to introduce the subject of knowledge engineering\nin a concise but synthetic way to develop the reader's intuition about the\narea.\n","authors":["Agnieszka Ławrynowicz"],"pdf_url":"https://arxiv.org/pdf/2305.17196v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14643v2","updated":"2024-03-25T05:35:12Z","published":"2024-02-21T16:44:35Z","title":"Exploring ChatGPT and its Impact on Society","summary":"  Artificial intelligence has been around for a while, but suddenly it has\nreceived more attention than ever before. Thanks to innovations from companies\nlike Google, Microsoft, Meta, and other major brands in technology. OpenAI,\nthough, has triggered the button with its ground-breaking invention ChatGPT.\nChatGPT is a Large Language Model (LLM) based on Transformer architecture that\nhas the ability to generate human-like responses in a conversational context.\nIt uses deep learning algorithms to generate natural language responses to\ninput text. Its large number of parameters, contextual generation, and\nopen-domain training make it a versatile and effective tool for a wide range of\napplications, from chatbots to customer service to language translation. It has\nthe potential to revolutionize various industries and transform the way we\ninteract with technology. However, the use of ChatGPT has also raised several\nconcerns, including ethical, social, and employment challenges, which must be\ncarefully considered to ensure the responsible use of this technology. The\narticle provides an overview of ChatGPT, delving into its architecture and\ntraining process. It highlights the potential impacts of ChatGPT on the\nsociety. In this paper, we suggest some approaches involving technology,\nregulation, education, and ethics in an effort to maximize ChatGPT's benefits\nwhile minimizing its negative impacts. This study is expected to contribute to\na greater understanding of ChatGPT and aid in predicting the potential changes\nit may bring about.\n","authors":["Md. Asraful Haque","Shuai Li"],"pdf_url":"https://arxiv.org/pdf/2403.14643v2.pdf","comment":"13 Pages"},{"id":"http://arxiv.org/abs/2403.16432v1","updated":"2024-03-25T05:27:35Z","published":"2024-03-25T05:27:35Z","title":"$\\textit{LinkPrompt}$: Natural and Universal Adversarial Attacks on\n  Prompt-based Language Models","summary":"  Prompt-based learning is a new language model training paradigm that adapts\nthe Pre-trained Language Models (PLMs) to downstream tasks, which revitalizes\nthe performance benchmarks across various natural language processing (NLP)\ntasks. Instead of using a fixed prompt template to fine-tune the model, some\nresearch demonstrates the effectiveness of searching for the prompt via\noptimization. Such prompt optimization process of prompt-based learning on PLMs\nalso gives insight into generating adversarial prompts to mislead the model,\nraising concerns about the adversarial vulnerability of this paradigm. Recent\nstudies have shown that universal adversarial triggers (UATs) can be generated\nto alter not only the predictions of the target PLMs but also the prediction of\ncorresponding Prompt-based Fine-tuning Models (PFMs) under the prompt-based\nlearning paradigm. However, UATs found in previous works are often unreadable\ntokens or characters and can be easily distinguished from natural texts with\nadaptive defenses. In this work, we consider the naturalness of the UATs and\ndevelop $\\textit{LinkPrompt}$, an adversarial attack algorithm to generate UATs\nby a gradient-based beam search algorithm that not only effectively attacks the\ntarget PLMs and PFMs but also maintains the naturalness among the trigger\ntokens. Extensive results demonstrate the effectiveness of\n$\\textit{LinkPrompt}$, as well as the transferability of UATs generated by\n\\textit{LinkPrompt} to open-sourced Large Language Model (LLM) Llama2 and\nAPI-accessed LLM GPT-3.5-turbo.\n","authors":["Yue Xu","Wenjie Wang"],"pdf_url":"https://arxiv.org/pdf/2403.16432v1.pdf","comment":"Accepted to the main conference of NAACL2024"},{"id":"http://arxiv.org/abs/2403.16431v1","updated":"2024-03-25T05:22:34Z","published":"2024-03-25T05:22:34Z","title":"DOCTR: Disentangled Object-Centric Transformer for Point Scene\n  Understanding","summary":"  Point scene understanding is a challenging task to process real-world scene\npoint cloud, which aims at segmenting each object, estimating its pose, and\nreconstructing its mesh simultaneously. Recent state-of-the-art method first\nsegments each object and then processes them independently with multiple stages\nfor the different sub-tasks. This leads to a complex pipeline to optimize and\nmakes it hard to leverage the relationship constraints between multiple\nobjects. In this work, we propose a novel Disentangled Object-Centric\nTRansformer (DOCTR) that explores object-centric representation to facilitate\nlearning with multiple objects for the multiple sub-tasks in a unified manner.\nEach object is represented as a query, and a Transformer decoder is adapted to\niteratively optimize all the queries involving their relationship. In\nparticular, we introduce a semantic-geometry disentangled query (SGDQ) design\nthat enables the query features to attend separately to semantic information\nand geometric information relevant to the corresponding sub-tasks. A hybrid\nbipartite matching module is employed to well use the supervisions from all the\nsub-tasks during training. Qualitative and quantitative experimental results\ndemonstrate that our method achieves state-of-the-art performance on the\nchallenging ScanNet dataset. Code is available at\nhttps://github.com/SAITPublic/DOCTR.\n","authors":["Xiaoxuan Yu","Hao Wang","Weiming Li","Qiang Wang","Soonyong Cho","Younghun Sung"],"pdf_url":"https://arxiv.org/pdf/2403.16431v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.13964v3","updated":"2024-03-25T05:18:04Z","published":"2023-12-21T15:51:12Z","title":"PIA: Your Personalized Image Animator via Plug-and-Play Modules in\n  Text-to-Image Models","summary":"  Recent advancements in personalized text-to-image (T2I) models have\nrevolutionized content creation, empowering non-experts to generate stunning\nimages with unique styles. While promising, adding realistic motions into these\npersonalized images by text poses significant challenges in preserving distinct\nstyles, high-fidelity details, and achieving motion controllability by text. In\nthis paper, we present PIA, a Personalized Image Animator that excels in\naligning with condition images, achieving motion controllability by text, and\nthe compatibility with various personalized T2I models without specific tuning.\nTo achieve these goals, PIA builds upon a base T2I model with well-trained\ntemporal alignment layers, allowing for the seamless transformation of any\npersonalized T2I model into an image animation model. A key component of PIA is\nthe introduction of the condition module, which utilizes the condition frame\nand inter-frame affinity as input to transfer appearance information guided by\nthe affinity hint for individual frame synthesis in the latent space. This\ndesign mitigates the challenges of appearance-related image alignment within\nand allows for a stronger focus on aligning with motion-related guidance.\n","authors":["Yiming Zhang","Zhening Xing","Yanhong Zeng","Youqing Fang","Kai Chen"],"pdf_url":"https://arxiv.org/pdf/2312.13964v3.pdf","comment":"Project page: https://pi-animator.github.io/"},{"id":"http://arxiv.org/abs/2403.16427v1","updated":"2024-03-25T05:12:18Z","published":"2024-03-25T05:12:18Z","title":"Re2LLM: Reflective Reinforcement Large Language Model for Session-based\n  Recommendation","summary":"  Large Language Models (LLMs) are emerging as promising approaches to enhance\nsession-based recommendation (SBR), where both prompt-based and\nfine-tuning-based methods have been widely investigated to align LLMs with SBR.\n  However, the former methods struggle with optimal prompts to elicit the\ncorrect reasoning of LLMs due to the lack of task-specific feedback, leading to\nunsatisfactory recommendations.\n  Although the latter methods attempt to fine-tune LLMs with domain-specific\nknowledge, they face limitations such as high computational costs and reliance\non open-source backbones.\n  To address such issues, we propose a \\underline{Re}flective\n\\underline{Re}inforcement \\underline{L}arge \\underline{L}anguage\n\\underline{M}odel (Re2LLM) for SBR, guiding LLMs to focus on specialized\nknowledge essential for more accurate recommendations effectively and\nefficiently.\n  In particular, we first design the Reflective Exploration Module to\neffectively extract knowledge that is readily understandable and digestible by\nLLMs.\n  To be specific, we direct LLMs to examine recommendation errors through\nself-reflection and construct a knowledge base (KB) comprising hints capable of\nrectifying these errors.\n  To efficiently elicit the correct reasoning of LLMs, we further devise the\nReinforcement Utilization Module to train a lightweight retrieval agent.\n  It learns to select hints from the constructed KB based on the task-specific\nfeedback, where the hints can serve as guidance to help correct LLMs reasoning\nfor better recommendations. Extensive experiments on multiple real-world\ndatasets demonstrate that our method consistently outperforms state-of-the-art\nmethods.\n","authors":["Ziyan Wang","Yingpeng Du","Zhu Sun","Haoyan Chua","Kaidong Feng","Wenya Wang","Jie Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.16427v1.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2403.16424v1","updated":"2024-03-25T05:04:52Z","published":"2024-03-25T05:04:52Z","title":"An Experiment with the Use of ChatGPT for LCSH Subject Assignment on\n  Electronic Theses and Dissertations","summary":"  This study delves into the potential use of Large Language Models (LLMs) for\ngenerating Library of Congress Subject Headings (LCSH). The authors employed\nChatGPT to generate subject headings for electronic theses and dissertations\n(ETDs) based on their titles and summaries. The results revealed that although\nsome generated subject headings were valid, there were issues regarding\nspecificity and exhaustiveness. The study showcases that LLMs can serve as a\nstrategic response to the backlog of items awaiting cataloging in academic\nlibraries, while also offering a cost-effective approach for promptly\ngenerating LCSH. Nonetheless, human catalogers remain essential for verifying\nand enhancing the validity, exhaustiveness, and specificity of LCSH generated\nby LLMs.\n","authors":["Eric H. C. Chow","TJ Kao","Xiaoli Li"],"pdf_url":"https://arxiv.org/pdf/2403.16424v1.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2312.03009v2","updated":"2024-03-25T05:04:04Z","published":"2023-12-04T19:01:19Z","title":"I-PHYRE: Interactive Physical Reasoning","summary":"  Current evaluation protocols predominantly assess physical reasoning in\nstationary scenes, creating a gap in evaluating agents' abilities to interact\nwith dynamic events. While contemporary methods allow agents to modify initial\nscene configurations and observe consequences, they lack the capability to\ninteract with events in real time. To address this, we introduce I-PHYRE, a\nframework that challenges agents to simultaneously exhibit intuitive physical\nreasoning, multi-step planning, and in-situ intervention. Here, intuitive\nphysical reasoning refers to a quick, approximate understanding of physics to\naddress complex problems; multi-step denotes the need for extensive sequence\nplanning in I-PHYRE, considering each intervention can significantly alter\nsubsequent choices; and in-situ implies the necessity for timely object\nmanipulation within a scene, where minor timing deviations can result in task\nfailure. We formulate four game splits to scrutinize agents' learning and\ngeneralization of essential principles of interactive physical reasoning,\nfostering learning through interaction with representative scenarios. Our\nexploration involves three planning strategies and examines several supervised\nand reinforcement agents' zero-shot generalization proficiency on I-PHYRE. The\noutcomes highlight a notable gap between existing learning algorithms and human\nperformance, emphasizing the imperative for more research in enhancing agents\nwith interactive physical reasoning capabilities. The environment and baselines\nwill be made publicly available.\n","authors":["Shiqian Li","Kewen Wu","Chi Zhang","Yixin Zhu"],"pdf_url":"https://arxiv.org/pdf/2312.03009v2.pdf","comment":"21 pages, ICLR 2024"},{"id":"http://arxiv.org/abs/2403.16422v1","updated":"2024-03-25T04:54:49Z","published":"2024-03-25T04:54:49Z","title":"Refining Text-to-Image Generation: Towards Accurate Training-Free\n  Glyph-Enhanced Image Generation","summary":"  Over the past few years, Text-to-Image (T2I) generation approaches based on\ndiffusion models have gained significant attention. However, vanilla diffusion\nmodels often suffer from spelling inaccuracies in the text displayed within the\ngenerated images. The capability to generate visual text is crucial, offering\nboth academic interest and a wide range of practical applications. To produce\naccurate visual text images, state-of-the-art techniques adopt a\nglyph-controlled image generation approach, consisting of a text layout\ngenerator followed by an image generator that is conditioned on the generated\ntext layout. Nevertheless, our study reveals that these models still face three\nprimary challenges, prompting us to develop a testbed to facilitate future\nresearch. We introduce a benchmark, LenCom-Eval, specifically designed for\ntesting models' capability in generating images with Lengthy and Complex visual\ntext. Subsequently, we introduce a training-free framework to enhance the\ntwo-stage generation approaches. We examine the effectiveness of our approach\non both LenCom-Eval and MARIO-Eval benchmarks and demonstrate notable\nimprovements across a range of evaluation metrics, including CLIPScore, OCR\nprecision, recall, F1 score, accuracy, and edit distance scores. For instance,\nour proposed framework improves the backbone model, TextDiffuser, by more than\n23\\% and 13.5\\% in terms of OCR word F1 on LenCom-Eval and MARIO-Eval,\nrespectively. Our work makes a unique contribution to the field by focusing on\ngenerating images with long and rare text sequences, a niche previously\nunexplored by existing literature\n","authors":["Sanyam Lakhanpal","Shivang Chopra","Vinija Jain","Aman Chadha","Man Luo"],"pdf_url":"https://arxiv.org/pdf/2403.16422v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16418v1","updated":"2024-03-25T04:43:47Z","published":"2024-03-25T04:43:47Z","title":"An incremental MaxSAT-based model to learn balanced rules","summary":"  The increasing advancements in the field of machine learning have led to the\ndevelopment of numerous applications that effectively address a wide range of\nproblems with accurate predictions. However, in certain cases, accuracy alone\nmay not be sufficient. Many real-world problems also demand explanations and\ninterpretability behind the predictions. One of the most popular interpretable\nmodels that are classification rules. This work aims to propose an incremental\nmodel for learning interpretable and balanced rules based on MaxSAT, called\nIMLIB. This new model was based on two other approaches, one based on SAT and\nthe other on MaxSAT. The one based on SAT limits the size of each generated\nrule, making it possible to balance them. We suggest that such a set of rules\nseem more natural to be understood compared to a mixture of large and small\nrules. The approach based on MaxSAT, called IMLI, presents a technique to\nincrease performance that involves learning a set of rules by incrementally\napplying the model in a dataset. Finally, IMLIB and IMLI are compared using\ndiverse databases. IMLIB obtained results comparable to IMLI in terms of\naccuracy, generating more balanced rules with smaller sizes.\n","authors":["Antônio Carlos Souza Ferreira Júnior","Thiago Alves Rocha"],"pdf_url":"https://arxiv.org/pdf/2403.16418v1.pdf","comment":"16 pages, 5 tables, submitted to BRACIS 2023 (Brazilian Conference on\n  Intelligent Systems), accepted version published in Intelligent Systems,\n  LNCS, vol 14195"},{"id":"http://arxiv.org/abs/2403.14689v2","updated":"2024-03-25T04:21:13Z","published":"2024-03-13T22:38:08Z","title":"Developing and Deploying Industry Standards for Artificial Intelligence\n  in Education (AIED): Challenges, Strategies, and Future Directions","summary":"  The adoption of Artificial Intelligence in Education (AIED) holds the promise\nof revolutionizing educational practices by offering personalized learning\nexperiences, automating administrative and pedagogical tasks, and reducing the\ncost of content creation. However, the lack of standardized practices in the\ndevelopment and deployment of AIED solutions has led to fragmented ecosystems,\nwhich presents challenges in interoperability, scalability, and ethical\ngovernance. This article aims to address the critical need to develop and\nimplement industry standards in AIED, offering a comprehensive analysis of the\ncurrent landscape, challenges, and strategic approaches to overcome these\nobstacles. We begin by examining the various applications of AIED in various\neducational settings and identify key areas lacking in standardization,\nincluding system interoperability, ontology mapping, data integration,\nevaluation, and ethical governance. Then, we propose a multi-tiered framework\nfor establishing robust industry standards for AIED. In addition, we discuss\nmethodologies for the iterative development and deployment of standards,\nincorporating feedback loops from real-world applications to refine and adapt\nstandards over time. The paper also highlights the role of emerging\ntechnologies and pedagogical theories in shaping future standards for AIED.\nFinally, we outline a strategic roadmap for stakeholders to implement these\nstandards, fostering a cohesive and ethical AIED ecosystem. By establishing\ncomprehensive industry standards, such as those by IEEE Artificial Intelligence\nStandards Committee (AISC) and International Organization for Standardization\n(ISO), we can accelerate and scale AIED solutions to improve educational\noutcomes, ensuring that technological advances align with the principles of\ninclusivity, fairness, and educational excellence.\n","authors":["Richard Tong","Haoyang Li","Joleen Liang","Qingsong Wen"],"pdf_url":"https://arxiv.org/pdf/2403.14689v2.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2403.16416v1","updated":"2024-03-25T04:21:06Z","published":"2024-03-25T04:21:06Z","title":"How Reliable is Your Simulator? Analysis on the Limitations of Current\n  LLM-based User Simulators for Conversational Recommendation","summary":"  Conversational Recommender System (CRS) interacts with users through natural\nlanguage to understand their preferences and provide personalized\nrecommendations in real-time. CRS has demonstrated significant potential,\nprompting researchers to address the development of more realistic and reliable\nuser simulators as a key focus. Recently, the capabilities of Large Language\nModels (LLMs) have attracted a lot of attention in various fields.\nSimultaneously, efforts are underway to construct user simulators based on\nLLMs. While these works showcase innovation, they also come with certain\nlimitations that require attention. In this work, we aim to analyze the\nlimitations of using LLMs in constructing user simulators for CRS, to guide\nfuture research. To achieve this goal, we conduct analytical validation on the\nnotable work, iEvaLM. Through multiple experiments on two widely-used datasets\nin the field of conversational recommendation, we highlight several issues with\nthe current evaluation methods for user simulators based on LLMs: (1) Data\nleakage, which occurs in conversational history and the user simulator's\nreplies, results in inflated evaluation results. (2) The success of CRS\nrecommendations depends more on the availability and quality of conversational\nhistory than on the responses from user simulators. (3) Controlling the output\nof the user simulator through a single prompt template proves challenging. To\novercome these limitations, we propose SimpleUserSim, employing a\nstraightforward strategy to guide the topic toward the target items. Our study\nvalidates the ability of CRS models to utilize the interaction information,\nsignificantly improving the recommendation results.\n","authors":["Lixi Zhu","Xiaowen Huang","Jitao Sang"],"pdf_url":"https://arxiv.org/pdf/2403.16416v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.06928v2","updated":"2024-03-25T03:40:19Z","published":"2023-04-14T05:25:52Z","title":"CiPR: An Efficient Framework with Cross-instance Positive Relations for\n  Generalized Category Discovery","summary":"  We tackle the issue of generalized category discovery (GCD). GCD considers\nthe open-world problem of automatically clustering a partially labelled\ndataset, in which the unlabelled data may contain instances from both novel\ncategories and labelled classes. In this paper, we address the GCD problem with\nan unknown category number for the unlabelled data. We propose a framework,\nnamed CiPR, to bootstrap the representation by exploiting Cross-instance\nPositive Relations in the partially labelled data for contrastive learning,\nwhich have been neglected in existing methods. To obtain reliable\ncross-instance relations to facilitate representation learning, we introduce a\nsemi-supervised hierarchical clustering algorithm, named selective neighbor\nclustering (SNC), which can produce a clustering hierarchy directly from the\nconnected components of a graph constructed from selective neighbors. We\nfurther present a method to estimate the unknown class number using SNC with a\njoint reference score that considers clustering indexes of both labelled and\nunlabelled data, and extend SNC to allow label assignment for the unlabelled\ninstances with a given class number. We thoroughly evaluate our framework on\npublic generic image recognition datasets and challenging fine-grained\ndatasets, and establish a new state-of-the-art. Code:\nhttps://github.com/haoosz/CiPR\n","authors":["Shaozhe Hao","Kai Han","Kwan-Yee K. Wong"],"pdf_url":"https://arxiv.org/pdf/2304.06928v2.pdf","comment":"Accepted to TMLR. Code: https://github.com/haoosz/CiPR"},{"id":"http://arxiv.org/abs/2311.13614v2","updated":"2024-03-25T03:39:45Z","published":"2023-11-22T04:52:58Z","title":"HalluciDoctor: Mitigating Hallucinatory Toxicity in Visual Instruction\n  Data","summary":"  Multi-modal Large Language Models (MLLMs) tuned on machine-generated\ninstruction-following data have demonstrated remarkable performance in various\nmulti-modal understanding and generation tasks. However, the hallucinations\ninherent in machine-generated data, which could lead to hallucinatory outputs\nin MLLMs, remain under-explored. This work aims to investigate various\nhallucinations (i.e., object, relation, attribute hallucinations) and mitigate\nthose hallucinatory toxicities in large-scale machine-generated visual\ninstruction datasets. Drawing on the human ability to identify factual errors,\nwe present a novel hallucination detection and elimination framework,\nHalluciDoctor, based on the cross-checking paradigm. We use our framework to\nidentify and eliminate hallucinations in the training data automatically.\nInterestingly, HalluciDoctor also indicates that spurious correlations arising\nfrom long-tail object co-occurrences contribute to hallucinations. Based on\nthat, we execute counterfactual visual instruction expansion to balance data\ndistribution, thereby enhancing MLLMs' resistance to hallucinations.\nComprehensive experiments on hallucination evaluation benchmarks show that our\nmethod successfully mitigates 44.6% hallucinations relatively and maintains\ncompetitive performance compared to LLaVA. The data and code for this paper are\npublicly available. \\url{https://github.com/Yuqifan1117/HalluciDoctor}.\n","authors":["Qifan Yu","Juncheng Li","Longhui Wei","Liang Pang","Wentao Ye","Bosheng Qin","Siliang Tang","Qi Tian","Yueting Zhuang"],"pdf_url":"https://arxiv.org/pdf/2311.13614v2.pdf","comment":"Accepted by CVPR 2024"},{"id":"http://arxiv.org/abs/2403.16398v1","updated":"2024-03-25T03:26:01Z","published":"2024-03-25T03:26:01Z","title":"Rethinking the Representation in Federated Unsupervised Learning with\n  Non-IID Data","summary":"  Federated learning achieves effective performance in modeling decentralized\ndata. In practice, client data are not well-labeled, which makes it potential\nfor federated unsupervised learning (FUSL) with non-IID data. However, the\nperformance of existing FUSL methods suffers from insufficient representations,\ni.e., (1) representation collapse entanglement among local and global models,\nand (2) inconsistent representation spaces among local models. The former\nindicates that representation collapse in local model will subsequently impact\nthe global model and other local models. The latter means that clients model\ndata representation with inconsistent parameters due to the deficiency of\nsupervision signals. In this work, we propose FedU2 which enhances generating\nuniform and unified representation in FUSL with non-IID data. Specifically,\nFedU2 consists of flexible uniform regularizer (FUR) and efficient unified\naggregator (EUA). FUR in each client avoids representation collapse via\ndispersing samples uniformly, and EUA in server promotes unified representation\nby constraining consistent client model updating. To extensively validate the\nperformance of FedU2, we conduct both cross-device and cross-silo evaluation\nexperiments on two benchmark datasets, i.e., CIFAR10 and CIFAR100.\n","authors":["Xinting Liao","Weiming Liu","Chaochao Chen","Pengyang Zhou","Fengyuan Yu","Huabin Zhu","Binhui Yao","Tao Wang","Xiaolin Zheng","Yanchao Tan"],"pdf_url":"https://arxiv.org/pdf/2403.16398v1.pdf","comment":"CVPR 2024"},{"id":"http://arxiv.org/abs/2403.16397v1","updated":"2024-03-25T03:23:10Z","published":"2024-03-25T03:23:10Z","title":"RadioGAT: A Joint Model-based and Data-driven Framework for Multi-band\n  Radiomap Reconstruction via Graph Attention Networks","summary":"  Multi-band radiomap reconstruction (MB-RMR) is a key component in wireless\ncommunications for tasks such as spectrum management and network planning.\nHowever, traditional machine-learning-based MB-RMR methods, which rely heavily\non simulated data or complete structured ground truth, face significant\ndeployment challenges. These challenges stem from the differences between\nsimulated and actual data, as well as the scarcity of real-world measurements.\nTo address these challenges, our study presents RadioGAT, a novel framework\nbased on Graph Attention Network (GAT) tailored for MB-RMR within a single\narea, eliminating the need for multi-region datasets. RadioGAT innovatively\nmerges model-based spatial-spectral correlation encoding with data-driven\nradiomap generalization, thus minimizing the reliance on extensive data\nsources. The framework begins by transforming sparse multi-band data into a\ngraph structure through an innovative encoding strategy that leverages radio\npropagation models to capture the spatial-spectral correlation inherent in the\ndata. This graph-based representation not only simplifies data handling but\nalso enables tailored label sampling during training, significantly enhancing\nthe framework's adaptability for deployment. Subsequently, The GAT is employed\nto generalize the radiomap information across various frequency bands.\nExtensive experiments using raytracing datasets based on real-world\nenvironments have demonstrated RadioGAT's enhanced accuracy in supervised\nlearning settings and its robustness in semi-supervised scenarios. These\nresults underscore RadioGAT's effectiveness and practicality for MB-RMR in\nenvironments with limited data availability.\n","authors":["Xiaojie Li","Songyang Zhang","Hang Li","Xiaoyang Li","Lexi Xu","Haigao Xu","Hui Mei","Guangxu Zhu","Nan Qi","Ming Xiao"],"pdf_url":"https://arxiv.org/pdf/2403.16397v1.pdf","comment":"submitted to IEEE journal for possible publication"},{"id":"http://arxiv.org/abs/2402.11734v2","updated":"2024-03-25T03:23:01Z","published":"2024-02-18T23:19:21Z","title":"Solving Data-centric Tasks using Large Language Models","summary":"  Large language models (LLMs) are rapidly replacing help forums like\nStackOverflow, and are especially helpful for non-professional programmers and\nend users. These users are often interested in data-centric tasks, such as\nspreadsheet manipulation and data wrangling, which are hard to solve if the\nintent is only communicated using a natural-language description, without\nincluding the data. But how do we decide how much data and which data to\ninclude in the prompt? This paper makes two contributions towards answering\nthis question. First, we create a dataset of real-world NL-to-code tasks\nmanipulating tabular data, mined from StackOverflow posts. Second, we introduce\na cluster-then-select prompting technique, which adds the most representative\nrows from the input data to the LLM prompt. Our experiments show that LLM\nperformance is indeed sensitive to the amount of data passed in the prompt, and\nthat for tasks with a lot of syntactic variation in the input table, our\ncluster-then-select technique outperforms a random selection baseline.\n","authors":["Shraddha Barke","Christian Poelitz","Carina Suzana Negreanu","Benjamin Zorn","José Cambronero","Andrew D. Gordon","Vu Le","Elnaz Nouri","Nadia Polikarpova","Advait Sarkar","Brian Slininger","Neil Toronto","Jack Williams"],"pdf_url":"https://arxiv.org/pdf/2402.11734v2.pdf","comment":"Paper accepted to NAACL 2024 (Findings)"},{"id":"http://arxiv.org/abs/2403.16394v1","updated":"2024-03-25T03:18:39Z","published":"2024-03-25T03:18:39Z","title":"Skews in the Phenomenon Space Hinder Generalization in Text-to-Image\n  Generation","summary":"  The literature on text-to-image generation is plagued by issues of faithfully\ncomposing entities with relations. But there lacks a formal understanding of\nhow entity-relation compositions can be effectively learned. Moreover, the\nunderlying phenomenon space that meaningfully reflects the problem structure is\nnot well-defined, leading to an arms race for larger quantities of data in the\nhope that generalization emerges out of large-scale pretraining. We hypothesize\nthat the underlying phenomenological coverage has not been proportionally\nscaled up, leading to a skew of the presented phenomenon which harms\ngeneralization. We introduce statistical metrics that quantify both the\nlinguistic and visual skew of a dataset for relational learning, and show that\ngeneralization failures of text-to-image generation are a direct result of\nincomplete or unbalanced phenomenological coverage. We first perform\nexperiments in a synthetic domain and demonstrate that systematically\ncontrolled metrics are strongly predictive of generalization performance. Then\nwe move to natural images and show that simple distribution perturbations in\nlight of our theories boost generalization without enlarging the absolute data\nsize. This work informs an important direction towards quality-enhancing the\ndata diversity or balance orthogonal to scaling up the absolute size. Our\ndiscussions point out important open questions on 1) Evaluation of generated\nentity-relation compositions, and 2) Better models for reasoning with abstract\nrelations.\n","authors":["Yingshan Chang","Yasi Zhang","Zhiyuan Fang","Yingnian Wu","Yonatan Bisk","Feng Gao"],"pdf_url":"https://arxiv.org/pdf/2403.16394v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16393v1","updated":"2024-03-25T03:17:27Z","published":"2024-03-25T03:17:27Z","title":"Concurrent Linguistic Error Detection (CLED) for Large Language Models","summary":"  The wide adoption of Large language models (LLMs) makes their dependability a\npressing concern. Detection of errors is the first step to mitigating their\nimpact on a system and thus, efficient error detection for LLMs is an important\nissue. In many settings, the LLM is considered as a black box with no access to\nthe internal nodes; this prevents the use of many error detection schemes that\nneed access to the model's internal nodes. An interesting observation is that\nthe output of LLMs in error-free operation should be valid and normal text.\nTherefore, when the text is not valid or differs significantly from normal\ntext, it is likely that there is an error. Based on this observation we propose\nto perform Concurrent Linguistic Error Detection (CLED); this scheme extracts\nsome linguistic features of the text generated by the LLM and feeds them to a\nconcurrent classifier that detects errors. Since the proposed error detection\nmechanism only relies on the outputs of the model, then it can be used on LLMs\nin which there is no access to the internal nodes. The proposed CLED scheme has\nbeen evaluated on the T5 model when used for news summarization and on the\nOPUS-MT model when used for translation. In both cases, the same set of\nlinguistic features has been used for error detection to illustrate the\napplicability of the proposed scheme beyond a specific case. The results show\nthat CLED can detect most of the errors at a low overhead penalty. The use of\nthe concurrent classifier also enables a trade-off between error detection\neffectiveness and its associated overhead, so providing flexibility to a\ndesigner.\n","authors":["Jinhua Zhu","Javier Conde","Zhen Gao","Pedro Reviriego","Shanshan Liu","Fabrizio Lombardi"],"pdf_url":"https://arxiv.org/pdf/2403.16393v1.pdf","comment":"11 pages, 6 figures, 30 references"},{"id":"http://arxiv.org/abs/2403.16386v1","updated":"2024-03-25T03:02:51Z","published":"2024-03-25T03:02:51Z","title":"Dia-LLaMA: Towards Large Language Model-driven CT Report Generation","summary":"  Medical report generation has achieved remarkable advancements yet has still\nbeen faced with several challenges. First, the inherent imbalance in the\ndistribution of normal and abnormal cases may lead models to exhibit a biased\nfocus on normal samples, resulting in unreliable diagnoses. Second, the\nfrequent occurrence of common template sentences in the reports may overwhelm\nthe critical abnormal information. Moreover, existing works focus on 2D chest\nX-rays, leaving CT report generation underexplored due to the high-dimensional\nnature of CT images and the limited availability of CT-report pairs. Recently,\nLLM has shown a great ability to generate reliable answers with appropriate\nprompts, which shed light on addressing the aforementioned challenges. In this\npaper, we propose Dia-LLaMA, a framework to adapt the LLaMA2-7B for CT report\ngeneration by incorporating diagnostic information as guidance prompts.\nConsidering the high dimension of CT, we leverage a pre-trained ViT3D with\nperceiver to extract the visual information. To tailor the LLM for report\ngeneration and emphasize abnormality, we extract additional diagnostic\ninformation by referring to a disease prototype memory bank, which is updated\nduring training to capture common disease representations. Furthermore, we\nintroduce disease-aware attention to enable the model to adjust attention for\ndifferent diseases. Experiments on the chest CT dataset demonstrated that our\nproposed method outperformed previous methods and achieved state-of-the-art on\nboth clinical efficacy performance and natural language generation metrics. The\ncode will be made publically available.\n","authors":["Zhixuan Chen","Luyang Luo","Yequan Bie","Hao Chen"],"pdf_url":"https://arxiv.org/pdf/2403.16386v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2308.11432v4","updated":"2024-03-25T02:56:58Z","published":"2023-08-22T13:30:37Z","title":"A Survey on Large Language Model based Autonomous Agents","summary":"  Autonomous agents have long been a prominent research focus in both academic\nand industry communities. Previous research in this field often focuses on\ntraining agents with limited knowledge within isolated environments, which\ndiverges significantly from human learning processes, and thus makes the agents\nhard to achieve human-like decisions. Recently, through the acquisition of vast\namounts of web knowledge, large language models (LLMs) have demonstrated\nremarkable potential in achieving human-level intelligence. This has sparked an\nupsurge in studies investigating LLM-based autonomous agents. In this paper, we\npresent a comprehensive survey of these studies, delivering a systematic review\nof the field of LLM-based autonomous agents from a holistic perspective. More\nspecifically, we first discuss the construction of LLM-based autonomous agents,\nfor which we propose a unified framework that encompasses a majority of the\nprevious work. Then, we present a comprehensive overview of the diverse\napplications of LLM-based autonomous agents in the fields of social science,\nnatural science, and engineering. Finally, we delve into the evaluation\nstrategies commonly used for LLM-based autonomous agents. Based on the previous\nstudies, we also present several challenges and future directions in this\nfield. To keep track of this field and continuously update our survey, we\nmaintain a repository of relevant references at\nhttps://github.com/Paitesanshi/LLM-Agent-Survey.\n","authors":["Lei Wang","Chen Ma","Xueyang Feng","Zeyu Zhang","Hao Yang","Jingsen Zhang","Zhiyuan Chen","Jiakai Tang","Xu Chen","Yankai Lin","Wayne Xin Zhao","Zhewei Wei","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2308.11432v4.pdf","comment":"35 pages, 5 figures, 3 tables, has been accepted by frontiers of\n  computer science (FCS), doi={10.1007/s11704-024-40231-1}"},{"id":"http://arxiv.org/abs/2403.09506v2","updated":"2024-03-25T02:45:35Z","published":"2024-03-14T15:53:04Z","title":"Don't Judge by the Look: Towards Motion Coherent Video Representation","summary":"  Current training pipelines in object recognition neglect Hue Jittering when\ndoing data augmentation as it not only brings appearance changes that are\ndetrimental to classification, but also the implementation is inefficient in\npractice. In this study, we investigate the effect of hue variance in the\ncontext of video understanding and find this variance to be beneficial since\nstatic appearances are less important in videos that contain motion\ninformation. Based on this observation, we propose a data augmentation method\nfor video understanding, named Motion Coherent Augmentation (MCA), that\nintroduces appearance variation in videos and implicitly encourages the model\nto prioritize motion patterns, rather than static appearances. Concretely, we\npropose an operation SwapMix to efficiently modify the appearance of video\nsamples, and introduce Variation Alignment (VA) to resolve the distribution\nshift caused by SwapMix, enforcing the model to learn appearance invariant\nrepresentations. Comprehensive empirical evaluation across various\narchitectures and different datasets solidly validates the effectiveness and\ngeneralization ability of MCA, and the application of VA in other augmentation\nmethods. Code is available at https://github.com/BeSpontaneous/MCA-pytorch.\n","authors":["Yitian Zhang","Yue Bai","Huan Wang","Yizhou Wang","Yun Fu"],"pdf_url":"https://arxiv.org/pdf/2403.09506v2.pdf","comment":"Accepted by ICLR2024"},{"id":"http://arxiv.org/abs/2204.10438v4","updated":"2024-03-25T02:37:09Z","published":"2022-04-21T23:59:17Z","title":"EVOTER: Evolution of Transparent Explainable Rule-sets","summary":"  Most AI systems are black boxes generating reasonable outputs for given\ninputs. Some domains, however, have explainability and trustworthiness\nrequirements that cannot be directly met by these approaches. Various methods\nhave therefore been developed to interpret black-box models after training.\nThis paper advocates an alternative approach where the models are transparent\nand explainable to begin with. This approach, EVOTER, evolves rule-sets based\non simple logical expressions. The approach is evaluated in several\nprediction/classification and prescription/policy search domains with and\nwithout a surrogate. It is shown to discover meaningful rule sets that perform\nsimilarly to black-box models. The rules can provide insight into the domain,\nand make biases hidden in the data explicit. It may also be possible to edit\nthem directly to remove biases and add constraints. EVOTER thus forms a\npromising foundation for building trustworthy AI systems for real-world\napplications in the future.\n","authors":["Hormoz Shahrzad","Babak Hodjat","Risto Miikkulainen"],"pdf_url":"https://arxiv.org/pdf/2204.10438v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16369v1","updated":"2024-03-25T02:17:54Z","published":"2024-03-25T02:17:54Z","title":"Learning Action-based Representations Using Invariance","summary":"  Robust reinforcement learning agents using high-dimensional observations must\nbe able to identify relevant state features amidst many exogeneous distractors.\nA representation that captures controllability identifies these state elements\nby determining what affects agent control. While methods such as inverse\ndynamics and mutual information capture controllability for a limited number of\ntimesteps, capturing long-horizon elements remains a challenging problem.\nMyopic controllability can capture the moment right before an agent crashes\ninto a wall, but not the control-relevance of the wall while the agent is still\nsome distance away. To address this we introduce action-bisimulation encoding,\na method inspired by the bisimulation invariance pseudometric, that extends\nsingle-step controllability with a recursive invariance constraint. By doing\nthis, action-bisimulation learns a multi-step controllability metric that\nsmoothly discounts distant state features that are relevant for control. We\ndemonstrate that action-bisimulation pretraining on reward-free, uniformly\nrandom data improves sample efficiency in several environments, including a\nphotorealistic 3D simulation domain, Habitat. Additionally, we provide\ntheoretical analysis and qualitative results demonstrating the information\ncaptured by action-bisimulation.\n","authors":["Max Rudolph","Caleb Chuck","Kevin Black","Misha Lvovsky","Scott Niekum","Amy Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.16369v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15048v2","updated":"2024-03-25T02:08:01Z","published":"2024-03-22T09:13:09Z","title":"Cartoon Hallucinations Detection: Pose-aware In Context Visual Learning","summary":"  Large-scale Text-to-Image (TTI) models have become a common approach for\ngenerating training data in various generative fields. However, visual\nhallucinations, which contain perceptually critical defects, remain a concern,\nespecially in non-photorealistic styles like cartoon characters. We propose a\nnovel visual hallucination detection system for cartoon character images\ngenerated by TTI models. Our approach leverages pose-aware in-context visual\nlearning (PA-ICVL) with Vision-Language Models (VLMs), utilizing both RGB\nimages and pose information. By incorporating pose guidance from a fine-tuned\npose estimator, we enable VLMs to make more accurate decisions. Experimental\nresults demonstrate significant improvements in identifying visual\nhallucinations compared to baseline methods relying solely on RGB images. This\nresearch advances TTI models by mitigating visual hallucinations, expanding\ntheir potential in non-photorealistic domains.\n","authors":["Bumsoo Kim","Wonseop Shin","Kyuchul Lee","Sanghyun Seo"],"pdf_url":"https://arxiv.org/pdf/2403.15048v2.pdf","comment":"11 pages, 12 figures, 1 table, Project page:\n  https://gh-bumsookim.github.io/Cartoon-Hallucinations-Detection/"},{"id":"http://arxiv.org/abs/2403.14692v2","updated":"2024-03-25T01:47:10Z","published":"2024-03-15T08:00:02Z","title":"The AI Assessment Scale (AIAS) in action: A pilot implementation of\n  GenAI supported assessment","summary":"  The rapid adoption of Generative Artificial Intelligence (GenAI) technologies\nin higher education has raised concerns about academic integrity, assessment\npractices, and student learning. Banning or blocking GenAI tools has proven\nineffective, and punitive approaches ignore the potential benefits of these\ntechnologies. This paper presents the findings of a pilot study conducted at\nBritish University Vietnam (BUV) exploring the implementation of the Artificial\nIntelligence Assessment Scale (AIAS), a flexible framework for incorporating\nGenAI into educational assessments. The AIAS consists of five levels, ranging\nfrom 'No AI' to 'Full AI', enabling educators to design assessments that focus\non areas requiring human input and critical thinking.\n  Following the implementation of the AIAS, the pilot study results indicate a\nsignificant reduction in academic misconduct cases related to GenAI, a 5.9%\nincrease in student attainment across the university, and a 33.3% increase in\nmodule passing rates. The AIAS facilitated a shift in pedagogical practices,\nwith faculty members incorporating GenAI tools into their modules and students\nproducing innovative multimodal submissions. The findings suggest that the AIAS\ncan support the effective integration of GenAI in HE, promoting academic\nintegrity while leveraging the technology's potential to enhance learning\nexperiences.\n","authors":["Leon Furze","Mike Perkins","Jasper Roe","Jason MacVaugh"],"pdf_url":"https://arxiv.org/pdf/2403.14692v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16354v1","updated":"2024-03-25T01:12:57Z","published":"2024-03-25T01:12:57Z","title":"ChatDBG: An AI-Powered Debugging Assistant","summary":"  This paper presents ChatDBG, the first AI-powered debugging assistant.\nChatDBG integrates large language models (LLMs) to significantly enhance the\ncapabilities and user-friendliness of conventional debuggers. ChatDBG lets\nprogrammers engage in a collaborative dialogue with the debugger, allowing them\nto pose complex questions about program state, perform root cause analysis for\ncrashes or assertion failures, and explore open-ended queries like \"why is x\nnull?\". To handle these queries, ChatDBG grants the LLM autonomy to take the\nwheel and drive debugging by issuing commands to navigate through stacks and\ninspect program state; it then reports its findings and yields back control to\nthe programmer. Our ChatDBG prototype integrates with standard debuggers\nincluding LLDB, GDB, and WinDBG for native code and Pdb for Python. Our\nevaluation across a diverse set of code, including C/C++ code with known bugs\nand a suite of Python code including standalone scripts and Jupyter notebooks,\ndemonstrates that ChatDBG can successfully analyze root causes, explain bugs,\nand generate accurate fixes for a wide range of real-world errors. For the\nPython programs, a single query led to an actionable bug fix 67% of the time;\none additional follow-up query increased the success rate to 85%. ChatDBG has\nseen rapid uptake; it has already been downloaded nearly 30,000 times.\n","authors":["Kyla Levin","Nicolas van Kempen","Emery D. Berger","Stephen N. Freund"],"pdf_url":"https://arxiv.org/pdf/2403.16354v1.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2403.16347v1","updated":"2024-03-25T00:50:27Z","published":"2024-03-25T00:50:27Z","title":"ChatGPT Incorrectness Detection in Software Reviews","summary":"  We conducted a survey of 135 software engineering (SE) practitioners to\nunderstand how they use Generative AI-based chatbots like ChatGPT for SE tasks.\nWe find that they want to use ChatGPT for SE tasks like software library\nselection but often worry about the truthfulness of ChatGPT responses. We\ndeveloped a suite of techniques and a tool called CID (ChatGPT Incorrectness\nDetector) to automatically test and detect the incorrectness in ChatGPT\nresponses. CID is based on the iterative prompting to ChatGPT by asking it\ncontextually similar but textually divergent questions (using an approach that\nutilizes metamorphic relationships in texts). The underlying principle in CID\nis that for a given question, a response that is different from other responses\n(across multiple incarnations of the question) is likely an incorrect response.\nIn a benchmark study of library selection, we show that CID can detect\nincorrect responses from ChatGPT with an F1-score of 0.74 - 0.75.\n","authors":["Minaoar Hossain Tanzil","Junaed Younus Khan","Gias Uddin"],"pdf_url":"https://arxiv.org/pdf/2403.16347v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16345v1","updated":"2024-03-25T00:43:44Z","published":"2024-03-25T00:43:44Z","title":"Enhanced Facet Generation with LLM Editing","summary":"  In information retrieval, facet identification of a user query is an\nimportant task. If a search service can recognize the facets of a user's query,\nit has the potential to offer users a much broader range of search results.\nPrevious studies can enhance facet prediction by leveraging retrieved documents\nand related queries obtained through a search engine. However, there are\nchallenges in extending it to other applications when a search engine operates\nas part of the model. First, search engines are constantly updated. Therefore,\nadditional information may change during training and test, which may reduce\nperformance. The second challenge is that public search engines cannot search\nfor internal documents. Therefore, a separate search system needs to be built\nto incorporate documents from private domains within the company. We propose\ntwo strategies that focus on a framework that can predict facets by taking only\nqueries as input without a search engine. The first strategy is multi-task\nlearning to predict SERP. By leveraging SERP as a target instead of a source,\nthe proposed model deeply understands queries without relying on external\nmodules. The second strategy is to enhance the facets by combining Large\nLanguage Model (LLM) and the small model. Overall performance improves when\nsmall model and LLM are combined rather than facet generation individually.\n","authors":["Joosung Lee","Jinhong Kim"],"pdf_url":"https://arxiv.org/pdf/2403.16345v1.pdf","comment":"Accepted at LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2403.16338v1","updated":"2024-03-25T00:24:10Z","published":"2024-03-25T00:24:10Z","title":"Impact of Video Compression Artifacts on Fisheye Camera Visual\n  Perception Tasks","summary":"  Autonomous driving systems require extensive data collection schemes to cover\nthe diverse scenarios needed for building a robust and safe system. The data\nvolumes are in the order of Exabytes and have to be stored for a long period of\ntime (i.e., more than 10 years of the vehicle's life cycle). Lossless\ncompression doesn't provide sufficient compression ratios, hence, lossy video\ncompression has been explored. It is essential to prove that lossy video\ncompression artifacts do not impact the performance of the perception\nalgorithms. However, there is limited work in this area to provide a solid\nconclusion. In particular, there is no such work for fisheye cameras, which\nhave high radial distortion and where compression may have higher artifacts.\nFisheye cameras are commonly used in automotive systems for 3D object detection\ntask. In this work, we provide the first analysis of the impact of standard\nvideo compression codecs on wide FOV fisheye camera images. We demonstrate that\nthe achievable compression with negligible impact depends on the dataset and\ntemporal prediction of the video codec. We propose a radial distortion-aware\nzonal metric to evaluate the performance of artifacts in fisheye images. In\naddition, we present a novel method for estimating affine mode parameters of\nthe latest VVC codec, and suggest some areas for improvement in video codecs\nfor the application to fisheye imagery.\n","authors":["Madhumitha Sakthi","Louis Kerofsky","Varun Ravi Kumar","Senthil Yogamani"],"pdf_url":"https://arxiv.org/pdf/2403.16338v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16334v1","updated":"2024-03-25T00:15:34Z","published":"2024-03-25T00:15:34Z","title":"Graphs Generalization under Distribution Shifts","summary":"  Traditional machine learning methods heavily rely on the independent and\nidentically distribution assumption, which imposes limitations when the test\ndistribution deviates from the training distribution. To address this crucial\nissue, out-of-distribution (OOD) generalization, which aims to achieve\nsatisfactory generalization performance when faced with unknown distribution\nshifts, has made a significant process. However, the OOD method for\ngraph-structured data currently lacks clarity and remains relatively unexplored\ndue to two primary challenges. Firstly, distribution shifts on graphs often\noccur simultaneously on node attributes and graph topology. Secondly, capturing\ninvariant information amidst diverse distribution shifts proves to be a\nformidable challenge. To overcome these obstacles, in this paper, we introduce\na novel framework, namely Graph Learning Invariant Domain genERation (GLIDER).\nThe goal is to (1) diversify variations across domains by modeling the\npotential seen or unseen variations of attribute distribution and topological\nstructure and (2) minimize the discrepancy of the variation in a representation\nspace where the target is to predict semantic labels. Extensive experiment\nresults indicate that our model outperforms baseline methods on node-level OOD\ngeneralization across domains in distribution shift on node features and\ntopological structures simultaneously.\n","authors":["Qin Tian","Wenjun Wang","Chen Zhao","Minglai Shao","Wang Zhang","Dong Li"],"pdf_url":"https://arxiv.org/pdf/2403.16334v1.pdf","comment":null}],"Optimization and Control":[{"id":"http://arxiv.org/abs/2403.16734v1","updated":"2024-03-25T13:07:19Z","published":"2024-03-25T13:07:19Z","title":"Anderson Acceleration Without Restart: A Novel Method with $n$-Step\n  Super Quadratic Convergence Rate","summary":"  In this paper, we propose a novel Anderson's acceleration method to solve\nnonlinear equations, which does \\emph{not} require a restart strategy to\nachieve numerical stability. We propose the greedy and random versions of our\nalgorithm. Specifically, the greedy version selects the direction to maximize a\ncertain measure of progress for approximating the current Jacobian matrix. In\ncontrast, the random version chooses the random Gaussian vector as the\ndirection to update the approximate Jacobian. Furthermore, our algorithm,\nincluding both greedy and random versions, has an $n$-step super quadratic\nconvergence rate, where $n$ is the dimension of the objective problem. For\nexample, the explicit convergence rate of the random version can be presented\nas $ \\norm{\\vx_{k+n+1} - \\vx_*} / \\norm{\\vx_k- \\vx_*}^2 =\n\\cO\\left(\\left(1-\\frac{1}{n}\\right)^{kn}\\right)$ for any $k\\geq 0$ where\n$\\vx_*$ is the optimum of the objective problem. This kind of convergence rate\nis new to Anderson's acceleration and quasi-Newton methods. The experiments\nalso validate the fast convergence rate of our algorithm.\n","authors":["Haishan Ye","Dachao Lin","Xiangyu Chang","Zhihua Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.16734v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16727v1","updated":"2024-03-25T13:01:29Z","published":"2024-03-25T13:01:29Z","title":"SIS epidemics on open networks: A replacement-based approximation","summary":"  In this paper we analyze continuous-time SIS epidemics subject to arrivals\nand departures of agents, by using an approximated process based on\nreplacements. In defining the SIS dynamics in an open network, we consider a\nstochastic setting in which arrivals and departures take place according to\nPoisson processes with similar rates, and the new value of the infection\nprobability of an arriving agent is drawn from a continuous distribution. Since\nthe system size changes with time, we define an approximated process, in which\nreplacements take place instead of arrivals and departures, and we focus on the\nevolution of an aggregate measure of the level of infection. So long as the\nreproduction number is less than one, the long-term behavior of this function\nmeasures the impact of the changes of the set of agents in the epidemic. We\nderive upper bounds for the expectation and variance of this function and we\ninclude a numerical example to show that the approximated process is close to\nthe original SIS process.\n","authors":["Renato Vizuete","Paolo Frasca","Elena Panteley"],"pdf_url":"https://arxiv.org/pdf/2403.16727v1.pdf","comment":"7 pages, 2 figures, to appear in European Control Conference (ECC\n  2024)"},{"id":"http://arxiv.org/abs/2403.16683v1","updated":"2024-03-25T12:19:12Z","published":"2024-03-25T12:19:12Z","title":"Optimal Mass Transport of Nonlinear Systems under Input and Density\n  Constraints","summary":"  We investigate optimal mass transport problem of affine-nonlinear dynamical\nsystems with input and density constraints. Three algorithms are proposed to\ntackle this problem, including two Uzawa-type methods and a splitting algorithm\nbased on the Douglas-Rachford algorithm. Some preliminary simulation results\nare presented to demonstrate the effectiveness of our approaches.\n","authors":["Dongjun Wu","Anders Rantzer"],"pdf_url":"https://arxiv.org/pdf/2403.16683v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.14409v3","updated":"2024-03-25T12:03:21Z","published":"2023-10-22T20:47:34Z","title":"Combining Learning and Control in Linear Systems","summary":"  In this paper, we provide a theoretical framework that separates the control\nand learning tasks in a linear system. This separation allows us to combine\noffline model-based control with online learning approaches and thus circumvent\ncurrent challenges in deriving optimal control strategies in applications where\na large volume of data is added to the system gradually in real time and not\naltogether in advance. We provide an analytical example to illustrate the\nframework.\n","authors":["Andreas A. Malikopoulos"],"pdf_url":"https://arxiv.org/pdf/2310.14409v3.pdf","comment":"6 pages, 1 figure. arXiv admin note: text overlap with\n  arXiv:2211.14972"},{"id":"http://arxiv.org/abs/2311.08321v2","updated":"2024-03-25T11:48:53Z","published":"2023-11-14T17:05:49Z","title":"Peak Estimation of Rational Systems using Convex Optimization","summary":"  This paper presents algorithms that upper-bound the peak value of a state\nfunction along trajectories of a continuous-time system with rational dynamics.\nThe finite-dimensional but nonconvex peak estimation problem is cast as a\nconvex infinite-dimensional linear program in occupation measures. This\ninfinite-dimensional program is then truncated into finite-dimensions using the\nmoment-Sum-of-Squares (SOS) hierarchy of semidefinite programs. Prior work on\ntreating rational dynamics using the moment-SOS approach involves clearing\ndynamics to common denominators or adding lifting variables to handle\nreciprocal terms under new equality constraints. Our solution method uses a\nsum-of-rational method based on absolute continuity of measures. The Moment-SOS\ntruncations of our program possess lower computational complexity and\n(empirically demonstrated) higher accuracy of upper bounds on example systems\nas compared to prior approaches.\n","authors":["Jared Miller","Roy S. Smith"],"pdf_url":"https://arxiv.org/pdf/2311.08321v2.pdf","comment":"9 pages, 2 figures, 4 tables"},{"id":"http://arxiv.org/abs/2403.16654v1","updated":"2024-03-25T11:42:01Z","published":"2024-03-25T11:42:01Z","title":"A Novel Loss Function-based Support Vector Machine for Binary\n  Classification","summary":"  The previous support vector machine(SVM) including $0/1$ loss SVM, hinge loss\nSVM, ramp loss SVM, truncated pinball loss SVM, and others, overlooked the\ndegree of penalty for the correctly classified samples within the margin. This\noversight affects the generalization ability of the SVM classifier to some\nextent. To address this limitation, from the perspective of confidence margin,\nwe propose a novel Slide loss function ($\\ell_s$) to construct the support\nvector machine classifier($\\ell_s$-SVM). By introducing the concept of proximal\nstationary point, and utilizing the property of Lipschitz continuity, we derive\nthe first-order optimality conditions for $\\ell_s$-SVM. Based on this, we\ndefine the $\\ell_s$ support vectors and working set of $\\ell_s$-SVM. To\nefficiently handle $\\ell_s$-SVM, we devise a fast alternating direction method\nof multipliers with the working set ($\\ell_s$-ADMM), and provide the\nconvergence analysis. The numerical experiments on real world datasets confirm\nthe robustness and effectiveness of the proposed method.\n","authors":["Yan Li","Liping Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.16654v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16622v1","updated":"2024-03-25T11:09:02Z","published":"2024-03-25T11:09:02Z","title":"Improving the Optimization in Model Predictive Controllers: Scheduling\n  Large Groups of Electric Vehicles","summary":"  In parking lots with large groups of electric vehicles (EVs), charging has to\nhappen in a coordinated manner, among others, due to the high load per vehicle\nand the limited capacity of the electricity grid. To achieve such coordination,\nmodel predictive control can be applied, thereby repeatedly solving an\noptimization problem. Due to its repetitive nature and its dependency on the\ntime granularity, optimization has to be (computationally) efficient. The work\npresented here focuses on that optimization subroutine, its computational\nefficiency and how to speed up the optimization for large groups of EVs. In\nparticular, we adapt FOCS, an algorithm that can solve the underlying\noptimization problem, to better suit the repetitive set-up of model predictive\ncontrol by adding a pre-mature stop feature. Based on real-world data, we\nempirically show that the added feature speeds up the median computation time\nfor 1-minute granularity by up to 44%. Furthermore, since FOCS is an algorithm\nthat uses maximum flow methods as a subroutine, the impact of choosing various\nmaximum flow methods on the runtime is investigated. Finally, we compare FOCS\nto a commercially available solver, concluding that FOCS outperforms the\nstate-of-the-art when making a full-day schedule for large groups of EVs.\n","authors":["Leoni Winschermann","Marco E. T. Gerards","Johann Hurink"],"pdf_url":"https://arxiv.org/pdf/2403.16622v1.pdf","comment":"9 pages, 8 figures, latex template based on IEEE template\n  https://www.overleaf.com/latex/templates/ieee-conference-template/grfzhhncsfqn"},{"id":"http://arxiv.org/abs/2311.00957v2","updated":"2024-03-25T10:03:06Z","published":"2023-11-02T03:00:34Z","title":"An equivalent reformulation and multi-proximity gradient algorithms for\n  a class of nonsmooth fractional programming","summary":"  In this paper, we consider a class of structured fractional programs, where\nthe numerator part is the sum of a block-separable (possibly nonsmooth\nnonconvex) function and a locally Lipschitz differentiable (possibly nonconvex)\nfunction, while the denominator is a convex (possibly nonsmooth) function. We\nfirst present a novel reformulation for the original problem and show the\nrelationship between optimal solutions, critical points and KL exponents of\nthese two problems. Inspired by the reformulation, we propose a flexible\nframework of multi-proximity gradient algorithms (MPGA), which computes the\nproximity operator with respect to the Fenchel conjugate associated with the\nconvex denominator of the original problem rather than evaluating its\nsubgradient as in the existing methods. Also, MPGA employs a nonmonotone\nlinear-search scheme in its gradient descent step, since the smooth part in the\nnumerator of the original problem is not globally Lipschitz differentiable.\nBased on the framework of MPGA, we develop two specific algorithms, namely,\ncyclic MPGA and randomized MPGA, and establish their subsequential convergence\nunder mild conditions. Moreover, the sequential convergence of cyclic MPGA with\nthe monotone line-search (CMPGA_ML) is guaranteed if the extended objective\nassociated with the reformulated problem satisfies the Kurdyka-{\\L}ojasiewicz\n(KL) property and some other mild assumptions. In particular, we prove that the\ncorresponding KL exponents are 1/2 for several special cases of the fractional\nprograms, and so, CMPGA_ML exhibits a linear convergence rate. Finally, some\npreliminary numerical experiments are performed to demonstrate the efficiency\nof our proposed algorithms.\n","authors":["Junpeng Zhou","Na Zhang","Qia Li"],"pdf_url":"https://arxiv.org/pdf/2311.00957v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16587v1","updated":"2024-03-25T09:58:17Z","published":"2024-03-25T09:58:17Z","title":"A nonlocal approach to graded surface modeling in topology optimization","summary":"  Additively manufactured structures often exhibit a correlation between their\nmechanical properties, such as stiffness, strength, and porosity, and their\nwall thickness. This correlation stems from the interplay between the\nmanufacturing process and the properties of the filler material. In this study,\nwe investigate the thickness-dependent effect on structural stiffness and\npropose a nonlocal integral model that introduces surface grading of Young's\nmodulus to capture this phenomenon. We incorporate this model into topology\noptimization for designing structures with optimized compliance subject to a\nvolume constraint. Notably, elastically degraded surfaces penalize excessively\nthin features, effectively eliminating them from the optimized design. We\nshowcase the efficacy of our proposed framework by optimizing the design of a\ntwo-dimensional cantilever beam and a bridge.\n","authors":["Sukhminder Singh","Lukas Pflug","Fabian Wein","Michael Stingl"],"pdf_url":"https://arxiv.org/pdf/2403.16587v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16580v1","updated":"2024-03-25T09:47:07Z","published":"2024-03-25T09:47:07Z","title":"Identification of Cyclists' Route Choice Criteria","summary":"  The behavior of cyclists when choosing the path to follow along a road\nnetwork is not uniform. Some of them are mostly interested in minimizing the\ntravelled distance, but some others may also take into account other features\nsuch as safety of the roads or pollution. Individuating the different groups of\nusers, estimating the numerical consistency of each of these groups, and\nreporting the weights assigned by each group to different characteristics of\nthe road network, is quite relevant. Indeed, when decision makers need to\nassign some budget for infrastructural interventions, they need to know the\nimpact of their decisions, and this is strictly related to the way users\nperceive different features of the road network. In this paper, we propose an\noptimization approach to detect the weights assigned to different road features\nby various user groups, leveraging knowledge of the true paths followed by\nthem, accessible, for example, through data collected by bike-sharing services.\n","authors":["Stefano Ardizzoni","Mattia Laurini","Rafael Praxedes","Luca Consolini","Marco Locatelli"],"pdf_url":"https://arxiv.org/pdf/2403.16580v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.12875v2","updated":"2024-03-25T09:15:44Z","published":"2024-03-19T16:18:12Z","title":"Markovian lifting and optimal control for integral stochastic Volterra\n  equations with completely monotone kernels","summary":"  In this paper, we focus on solving the optimal control problem for integral\nstochastic Volterra equations in a finite dimensional setting. In our setting,\nthe noise term is driven by a pure jump L\\'evy noise and the control acts on\nthe intensity of the jumps.\n  We use recent techniques proposed by Hamaguchi, where a crucial requirement\nis that the convolution kernel should be a completely monotone function. This\nallows us to use Bernstein's representation and the machinery of Laplace\ntransform to obtain a Markovian lift.\n  It is natural that the Markovian lift, in whatever form constructed,\ntransforms the state equation into a stochastic differential equation in an\ninfinite-dimensional space. This space should be large enough to contain all\nthe information about the history of the process. Hence, although the original\nequation is taken in a finite dimensional space, the resulting lift is always\ninfinite dimensional.\n  We solve the problem by using the forward-backward approach in the\ninfinite-dimensional setting and prove the existence of the optimal control for\nthe original problem. Under additional assumptions on the coefficients, we see\nthat a control in closed-loop form can be achieved.\n","authors":["Stefano Bonaccorsi","Fulvia Confortola"],"pdf_url":"https://arxiv.org/pdf/2403.12875v2.pdf","comment":"19 pages. v2: updated references"},{"id":"http://arxiv.org/abs/2403.09133v2","updated":"2024-03-25T09:06:39Z","published":"2024-03-14T06:57:16Z","title":"A Low-Rank ADMM Splitting Approach for Semidefinite Programming","summary":"  We introduce a new first-order method for solving general semidefinite\nprogramming problems, based on the alternating direction method of multipliers\n(ADMM) and a matrix-splitting technique. Our algorithm has an advantage over\nthe Burer-Monteiro approach as it only involves much easier quadratically\nregularized subproblems in each iteration. For a linear objective, the\nsubproblems are well-conditioned quadratic programs that can be efficiently\nsolved by the standard conjugate gradient method. We show that the ADMM\nalgorithm achieves sublinear or linear convergence rates to the KKT solutions\nunder different conditions. Building on this theoretical development, we\npresent LoRADS, a new solver for linear SDP based on the Low-Rank ADMM\nSplitting approach. LoRADS incorporates several strategies that significantly\nincrease its efficiency. Firstly, it initiates with a warm-start phase that\nuses the Burer-Monteiro approach. Moreover, motivated by the SDP low-rank\ntheory [So et al. 2008], LoRADS chooses an initial rank of logarithmic order\nand then employs a dynamic approach to increase the rank. Numerical experiments\nindicate that LoRADS exhibits promising performance on various SDP problems. A\nnoteworthy achievement of LoRADS is its successful solving of a matrix\ncompletion problem with $15,694,167$ constraints and a matrix variable of size\n$40,000 \\times 40,000$ in $351$ seconds.\n","authors":["Qiushi Han","Chenxi Li","Zhenwei Lin","Caihua Chen","Qi Deng","Dongdong Ge","Huikang Liu","Yinyu Ye"],"pdf_url":"https://arxiv.org/pdf/2403.09133v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16511v1","updated":"2024-03-25T07:54:38Z","published":"2024-03-25T07:54:38Z","title":"Extremality of collections of sets with respect to general perturbations","summary":"  The paper proposes another extension of the extremal principle. A new\nextremality model involving arbitrary families of perturbations (deformations)\nof the given sets is studied. It generalizes the conventional model based on\nlinear translations of the sets as well as its set-valued extensions. This\napproach leads to a more general and simpler version of fuzzy separation. We\ndemonstrate the applicability of the new model to set-valued optimization\nproblems, weakening the assumptions of the known results and streamlining their\nproofs.\n","authors":["Nguyen Duy Cuong","Alexander Y. Kruger","Nguyen Hieu Thao"],"pdf_url":"https://arxiv.org/pdf/2403.16511v1.pdf","comment":"29 pages"},{"id":"http://arxiv.org/abs/2403.16480v1","updated":"2024-03-25T07:07:01Z","published":"2024-03-25T07:07:01Z","title":"Low-rank quaternion tensor completion for color video inpainting via a\n  novel factorization strategy","summary":"  Recently, a quaternion tensor product named Qt-product was proposed, and then\nthe singular value decomposition and the rank of a third-order quaternion\ntensor were given. From a more applicable perspective, we extend the Qt-product\nand propose a novel multiplication principle for third-order quaternion tensor\nnamed gQt-product. With the gQt-product, we introduce a brand-new singular\nvalue decomposition for third-order quaternion tensors named gQt-SVD and then\ndefine gQt-rank and multi-gQt-rank. We prove that the optimal low-rank\napproximation of a third-order quaternion tensor exists and some numerical\nexperiments demonstrate the low-rankness of color videos. So, we apply the\nlow-rank quaternion tensor completion to color video inpainting problems and\npresent alternating least-square algorithms to solve the proposed low gQt-rank\nand multi-gQt-rank quaternion tensor completion models. The convergence\nanalyses of the proposed algorithms are established and some numerical\nexperiments on various color video datasets show the high recovery accuracy and\ncomputational efficiency of our methods.\n","authors":["Zhenzhi Qin","Zhenyu Ming","Defeng Sun","Liping Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.16480v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16470v1","updated":"2024-03-25T06:52:26Z","published":"2024-03-25T06:52:26Z","title":"Data-Driven Extrusion Force Control Tuning for 3D Printing","summary":"  The quality of 3D prints often varies due to different conditions inherent to\neach print, such as filament type, print speed, and nozzle size. Closed-loop\nprocess control methods improve the accuracy and repeatability of 3D prints.\nHowever, optimal tuning of controllers for given process parameters and design\ngeometry is often a challenge with manually tuned controllers resulting in\ninconsistent and suboptimal results. This work employs Bayesian optimization to\nidentify the optimal controller parameters. Additionally, we explore transfer\nlearning in the context of 3D printing by leveraging prior information from\npast trials. By integrating optimized extrusion force control and transfer\nlearning, we provide a novel framework for closed-loop 3D printing and propose\nan automated calibration routine that produces high-quality prints for a\ndesired combination of print settings, material, and shape.\n","authors":["Xavier Guidetti","Ankita Mukne","Marvin Rueppel","Yannick Nagel","Efe C. Balta","John Lygeros"],"pdf_url":"https://arxiv.org/pdf/2403.16470v1.pdf","comment":"Submitted to IEEE CASE 2024"},{"id":"http://arxiv.org/abs/2403.16462v1","updated":"2024-03-25T06:44:15Z","published":"2024-03-25T06:44:15Z","title":"Unbiased Extremum Seeking for PDEs","summary":"  There have been recent efforts that combine seemingly disparate methods,\nextremum seeking (ES) optimization and partial differential equation (PDE)\nbackstepping, to address the problem of model-free optimization with PDE\nactuator dynamics. In contrast to prior PDE-compensating ES designs, which only\nguarantee local stability around the extremum, we introduce unbiased ES that\ncompensates for delay and diffusion PDE dynamics while ensuring exponential and\nunbiased convergence to the optimum. Our method leverages exponentially\ndecaying/growing signals within the modulation/demodulation stages and\ncarefully selected design parameters. The stability analysis of our designs\nrelies on a state transformation, infinite-dimensional averaging, local\nexponential stability of the averaged system, local stability of the\ntransformed system, and local exponential stability of the original system.\nNumerical simulations are presented to demonstrate the efficacy of the\ndeveloped designs.\n","authors":["Cemal Tugrul Yilmaz","Mamadou Diagne","Miroslav Krstic"],"pdf_url":"https://arxiv.org/pdf/2403.16462v1.pdf","comment":"Submitted to the 63rd IEEE Conference on Decision and Control (CDC),\n  2024"},{"id":"http://arxiv.org/abs/2308.02921v3","updated":"2024-03-25T05:54:29Z","published":"2023-08-05T16:54:59Z","title":"PowerSimulationsDynamics.jl -- An Open Source Modeling Package for\n  Modern Power Systems with Inverter-Based Resources","summary":"  In this paper we present the development of an open-source simulation\ntoolbox, PowerSimulationsDynamics.jl, to study the dynamic response of power\nsystems, focusing on the requirements to model systems with high penetrations\nof Inverter-Based Resources (IBRs). PowerSimulationsDynamics.jl is implemented\nin Julia and features a rich library of synchronous generator, inverter, and\nload models. In addition, it allows the study of quasi-static phasors and\nelectromagnetic dq models that use a dynamic network representation. Case\nstudies and validation exercises show that PowerSimulationsDynamics.jl results\nclosely match other commercial and open-source simulation tools.\n","authors":["Jose Daniel Lara","Rodrigo Henriquez-Auba","Matthew Bossart","Duncan S. Callaway","Clayton Barrows"],"pdf_url":"https://arxiv.org/pdf/2308.02921v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16381v1","updated":"2024-03-25T02:56:31Z","published":"2024-03-25T02:56:31Z","title":"Augmented Lagrangian method for coupled-cluster","summary":"  We propose to improve the convergence properties of the single-reference\ncoupled cluster (CC) method through an augmented Lagrangian formalism. The\nconventional CC method changes a linear high-dimensional eigenvalue problem\nwith exponential size into a problem of determining the roots of a nonlinear\nsystem of equations that has a manageable size. However, current numerical\nprocedures for solving this system of equations to get the lowest eigenvalue\nsuffer from two practical issues: First, solving the CC equations may not\nconverge, and second, when converging, they may converge to other --\npotentially unphysical -- states, which are stationary points of the CC energy\nexpression. We show that both issues can be dealt with when a suitably defined\nenergy is minimized in addition to solving the original CC equations. We\nfurther propose an augmented Lagrangian method for coupled cluster (alm-CC) to\nsolve the resulting constrained optimization problem. We numerically\ninvestigate the proposed augmented Lagrangian formulation showing that the\nconvergence towards the ground state is significantly more stable and that the\noptimization procedure is less susceptible to local minima. Furthermore, the\ncomputational cost of alm-CC is comparable to the conventional CC method.\n","authors":["Fabian M. Faulstich","Yuehaw Khoo","Kangbo Li"],"pdf_url":"https://arxiv.org/pdf/2403.16381v1.pdf","comment":"17 pages, 8 figures"},{"id":"http://arxiv.org/abs/2403.16337v1","updated":"2024-03-25T00:23:38Z","published":"2024-03-25T00:23:38Z","title":"On solution of tropical discrete best approximation problems","summary":"  We consider a discrete best approximation problem formulated in the framework\nof tropical algebra, which deals with the theory and applications of algebraic\nsystems with idempotent operations. Given a set of samples of input and output\nof an unknown function, the problem is to construct a generalized tropical\nPuiseux polynomial that best approximates the function in the sense of a\ntropical distance function. The construction of an approximate polynomial\ninvolves the evaluation of both unknown coefficient and exponent of each\nmonomial in the polynomial. To solve the approximation problem, we first reduce\nthe problem to an equation in unknown vector of coefficients, which is given by\na matrix with entries parameterized by unknown exponents. We derive a best\napproximate solution of the equation, which yields both vector of coefficients\nand approximation error parameterized by the exponents. Optimal values of\nexponents are found by minimization of the approximation error, which is\nreduced to a minimization of a function of exponents over all partitions of a\nfinite set. We solve this minimization problem in terms of max-plus algebra\n(where addition is defined as maximum and multiplication as arithmetic\naddition) by using a computational procedure based on the agglomerative\nclustering technique. This solution is extended to the minimization problem of\nfinding optimal exponents in the polynomial in terms of max-algebra (where\naddition is defined as maximum). The results obtained are applied to develop\nnew solutions for conventional problems of discrete best approximation of real\nfunctions by piecewise linear functions and piecewise Puiseux polynomials. We\ndiscuss computational complexity of the proposed solution and estimate upper\nbounds on the computational time. We demonstrate examples of approximation\nproblems solved in terms of max-plus and max-algebra, and give graphical\nillustrations.\n","authors":["Nikolai Krivulin"],"pdf_url":"https://arxiv.org/pdf/2403.16337v1.pdf","comment":"21 pages, 6 figures"},{"id":"http://arxiv.org/abs/2403.17247v1","updated":"2024-03-25T22:49:56Z","published":"2024-03-25T22:49:56Z","title":"DASA: Delay-Adaptive Multi-Agent Stochastic Approximation","summary":"  We consider a setting in which $N$ agents aim to speedup a common Stochastic\nApproximation (SA) problem by acting in parallel and communicating with a\ncentral server. We assume that the up-link transmissions to the server are\nsubject to asynchronous and potentially unbounded time-varying delays. To\nmitigate the effect of delays and stragglers while reaping the benefits of\ndistributed computation, we propose \\texttt{DASA}, a Delay-Adaptive algorithm\nfor multi-agent Stochastic Approximation. We provide a finite-time analysis of\n\\texttt{DASA} assuming that the agents' stochastic observation processes are\nindependent Markov chains. Significantly advancing existing results,\n\\texttt{DASA} is the first algorithm whose convergence rate depends only on the\nmixing time $\\tmix$ and on the average delay $\\tau_{avg}$ while jointly\nachieving an $N$-fold convergence speedup under Markovian sampling. Our work is\nrelevant for various SA applications, including multi-agent and distributed\ntemporal difference (TD) learning, Q-learning and stochastic optimization with\ncorrelated data.\n","authors":["Nicolo Dal Fabbro","Arman Adibi","H. Vincent Poor","Sanjeev R. Kulkarni","Aritra Mitra","George J. Pappas"],"pdf_url":"https://arxiv.org/pdf/2403.17247v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.11800v2","updated":"2024-03-25T22:48:22Z","published":"2024-02-19T03:08:02Z","title":"Stochastic Approximation with Delayed Updates: Finite-Time Rates under\n  Markovian Sampling","summary":"  Motivated by applications in large-scale and multi-agent reinforcement\nlearning, we study the non-asymptotic performance of stochastic approximation\n(SA) schemes with delayed updates under Markovian sampling. While the effect of\ndelays has been extensively studied for optimization, the manner in which they\ninteract with the underlying Markov process to shape the finite-time\nperformance of SA remains poorly understood. In this context, our first main\ncontribution is to show that under time-varying bounded delays, the delayed SA\nupdate rule guarantees exponentially fast convergence of the \\emph{last\niterate} to a ball around the SA operator's fixed point. Notably, our bound is\n\\emph{tight} in its dependence on both the maximum delay $\\tau_{max}$, and the\nmixing time $\\tau_{mix}$. To achieve this tight bound, we develop a novel\ninductive proof technique that, unlike various existing delayed-optimization\nanalyses, relies on establishing uniform boundedness of the iterates. As such,\nour proof may be of independent interest. Next, to mitigate the impact of the\nmaximum delay on the convergence rate, we provide the first finite-time\nanalysis of a delay-adaptive SA scheme under Markovian sampling. In particular,\nwe show that the exponent of convergence of this scheme gets scaled down by\n$\\tau_{avg}$, as opposed to $\\tau_{max}$ for the vanilla delayed SA rule; here,\n$\\tau_{avg}$ denotes the average delay across all iterations. Moreover, the\nadaptive scheme requires no prior knowledge of the delay sequence for step-size\ntuning. Our theoretical findings shed light on the finite-time effects of\ndelays for a broad class of algorithms, including TD learning, Q-learning, and\nstochastic gradient descent under Markovian sampling.\n","authors":["Arman Adibi","Nicolo Dal Fabbro","Luca Schenato","Sanjeev Kulkarni","H. Vincent Poor","George J. Pappas","Hamed Hassani","Aritra Mitra"],"pdf_url":"https://arxiv.org/pdf/2402.11800v2.pdf","comment":"Accepted to the 27th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2024!"},{"id":"http://arxiv.org/abs/2403.17241v1","updated":"2024-03-25T22:42:26Z","published":"2024-03-25T22:42:26Z","title":"Tightness of the matrix Moment-SOS hierarchy","summary":"  This paper studies the matrix Moment-SOS hierarchy for solving polynomial\nmatrix optimization. Our first result is to show the tightness (i.e., the\nfinite convergence) of this hierarchy, if the nondegeneracy condition, strict\ncomplementarity condition and second order sufficient condition hold at every\nminimizer, under the usual archimedeanness assumption. A useful criterion for\ndetecting tightness is the flat truncation. Our second result is to show that\nevery minimizer of the moment relaxation must have a flat truncation when the\nrelaxation order is big enough, under the above mentioned optimality\nassumptions. These results give connections between nonlinear semidefinite\noptimization theory and Moment-SOS methods for solving polynomial matrix\noptimization.\n","authors":["Lei Huang","Jiawang Nie"],"pdf_url":"https://arxiv.org/pdf/2403.17241v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17184v1","updated":"2024-03-25T20:53:17Z","published":"2024-03-25T20:53:17Z","title":"Robust Finite-time Stabilization of Linear Systems with Limited State\n  Quantization","summary":"  This paper investigates the robust asymptotic stabilization of a linear\ntime-invariant (LTI) system by a static feedback with a static state\nquantization. It is shown that the controllable LTI system can be stabilized to\nzero in a finite time by means of a nonlinear feedback with a quantizer having\na limited (finite) number of values (quantization seeds) even when all\nparameters of the controller and the quantizer are time-invariant. The control\ndesign is based on generalized homogeneity. A homogeneous spherical quantizer\nis introduced. The static homogeneous feedback is shown to be local (or global)\nfinite-time stabilizer for the linear system (dependently of the system\nmatrix). The tuning rules for both the quantizer and the feedback law are\nobtained in the form of Linear Matrix Inequalities (LMIs). The closed-loop\nsystem is proven to be robust with respect to some bounded matched and\nvanishing mismatched perturbations. Theoretical results are supported by\nnumerical simulations. \\\n","authors":["Yu Zhou","Andrey Polyakov","Gang Zheng"],"pdf_url":"https://arxiv.org/pdf/2403.17184v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.04152v3","updated":"2024-03-25T20:50:12Z","published":"2022-11-08T10:50:29Z","title":"Federated Learning Using Three-Operator ADMM","summary":"  Federated learning (FL) has emerged as an instance of distributed machine\nlearning paradigm that avoids the transmission of data generated on the users'\nside. Although data are not transmitted, edge devices have to deal with limited\ncommunication bandwidths, data heterogeneity, and straggler effects due to the\nlimited computational resources of users' devices. A prominent approach to\novercome such difficulties is FedADMM, which is based on the classical\ntwo-operator consensus alternating direction method of multipliers (ADMM). The\ncommon assumption of FL algorithms, including FedADMM, is that they learn a\nglobal model using data only on the users' side and not on the edge server.\nHowever, in edge learning, the server is expected to be near the base station\nand have direct access to rich datasets. In this paper, we argue that\nleveraging the rich data on the edge server is much more beneficial than\nutilizing only user datasets. Specifically, we show that the mere application\nof FL with an additional virtual user node representing the data on the edge\nserver is inefficient. We propose FedTOP-ADMM, which generalizes FedADMM and is\nbased on a three-operator ADMM-type technique that exploits a smooth cost\nfunction on the edge server to learn a global model parallel to the edge\ndevices. Our numerical experiments indicate that FedTOP-ADMM has substantial\ngain up to 33\\% in communication efficiency to reach a desired test accuracy\nwith respect to FedADMM, including a virtual user on the edge server.\n","authors":["Shashi Kant","José Mairton B. da Silva Jr.","Gabor Fodor","Bo Göransson","Mats Bengtsson","Carlo Fischione"],"pdf_url":"https://arxiv.org/pdf/2211.04152v3.pdf","comment":"accepted to IEEE Journal of Selected Topics in Signal Processing,\n  2022"},{"id":"http://arxiv.org/abs/2403.17174v1","updated":"2024-03-25T20:43:17Z","published":"2024-03-25T20:43:17Z","title":"Belief Samples Are All You Need For Social Learning","summary":"  In this paper, we consider the problem of social learning, where a group of\nagents embedded in a social network are interested in learning an underlying\nstate of the world. Agents have incomplete, noisy, and heterogeneous sources of\ninformation, providing them with recurring private observations of the\nunderlying state of the world. Agents can share their learning experience with\ntheir peers by taking actions observable to them, with values from a finite\nfeasible set of states. Actions can be interpreted as samples from the beliefs\nwhich agents may form and update on what the true state of the world is.\nSharing samples, in place of full beliefs, is motivated by the limited\ncommunication, cognitive, and information-processing resources available to\nagents especially in large populations. Previous work (Salhab et al.) poses the\nquestion as to whether learning with probability one is still achievable if\nagents are only allowed to communicate samples from their beliefs. We provide a\ndefinite positive answer to this question, assuming a strongly connected\nnetwork and a ``collective distinguishability'' assumption, which are both\nrequired for learning even in full-belief-sharing settings. In our proposed\nbelief update mechanism, each agent's belief is a normalized weighted geometric\ninterpolation between a fully Bayesian private belief -- aggregating\ninformation from the private source -- and an ensemble of empirical\ndistributions of the samples shared by her neighbors over time. By carefully\nconstructing asymptotic almost-sure lower/upper bounds on the frequency of\nshared samples matching the true state/or not, we rigorously prove the\nconvergence of all the beliefs to the true state, with probability one.\n","authors":["Mahyar JafariNodeh","Amir Ajorlou","Ali Jadbabaie"],"pdf_url":"https://arxiv.org/pdf/2403.17174v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2208.03406v2","updated":"2024-03-25T20:32:00Z","published":"2022-08-05T23:32:33Z","title":"Multilinear formulations for computing Nash equilibrium of multi-player\n  matrix games","summary":"  We present multilinear and mixed-integer multilinear programs to find a Nash\nequilibrium in multi-player noncooperative games. We compare the formulations\nto common algorithms in Gambit, and conclude that a multilinear feasibility\nprogram finds a Nash equilibrium faster than any of the methods we compare it\nto, including the quantal response equilibrium method, which is recommended for\nlarge games. Hence, the multilinear feasibility program is an alternative\nmethod to find a Nash equilibrium in multi-player games, and outperforms many\ncommon algorithms. The mixed-integer formulations are generalisations of known\nmixed-integer programs for two-player games, however unlike two-player games,\nthese mixed-integer programs do not give better performance than existing\nalgorithms.\n","authors":["Miriam Fischer","Akshay Gupte"],"pdf_url":"https://arxiv.org/pdf/2208.03406v2.pdf","comment":"15 page conference paper accepted"},{"id":"http://arxiv.org/abs/2403.17157v1","updated":"2024-03-25T20:16:05Z","published":"2024-03-25T20:16:05Z","title":"Output-feedback Synthesis Orbit Geometry: Quotient Manifolds and LQG\n  Direct Policy Optimization","summary":"  In this paper, we consider direct policy optimization for the\nlinear-quadratic Gaussian (LQG) setting. Over the past few years, it has been\nrecognized that the landscape of stabilizing output-feedback controllers of\nrelevance to LQG has an intricate geometry, particularly as it pertains to the\nexistence of spurious stationary points. In order to address such challenges,\nin this paper, we first adopt a Riemannian metric for the space of stabilizing\nfull-order minimal output-feedback controllers. We then proceed to prove that\nthe orbit of such controllers modulo coordinate transformation admits a\nRiemannian quotient manifold structure. This geometric structure is then used\nto develop a Riemannian gradient descent for the direct LQG policy\noptimization. We prove a local convergence guarantee with linear rate and show\nthe proposed approach exhibits significantly faster and more robust numerical\nperformance as compared with ordinary gradient descent for LQG. Subsequently,\nwe provide reasons for this observed behavior; in particular, we argue that\noptimizing over the orbit space of controllers is the right theoretical and\ncomputational setup for direct LQG policy optimization.\n","authors":["Spencer Kraisler","Mehran Mesbahi"],"pdf_url":"https://arxiv.org/pdf/2403.17157v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.02047v2","updated":"2024-03-25T20:10:06Z","published":"2023-11-03T17:22:01Z","title":"On the Diameter of a 2-Sum of Polyhedra","summary":"  The study of the combinatorial diameter of a polyhedron is a classical topic\nin linear-programming theory due to its close connection with the possibility\nof a polynomial simplex-method pivot rule. The 2-sum operation is a classical\noperation for graphs, matrices, and matroids; we extend this definition to\npolyhedra. We analyze the diameters of 2-sum polyhedra, which are those\npolyhedra that arise from this operation. These polyhedra appear in matroid and\ninteger-programming theory as a natural way to link two systems in a joint\nmodel with a single shared constraint and the 2-sum also appears as a key\noperation in Seymour's decomposition theorem for totally-unimodular matrices.\n  We show that the diameter of a 2-sum polyhedron is quadratic in the diameters\nof its summands. The methods transfer to a linear bound for the addition of a\nunit column to an equality system, or equivalently, to the relaxation of an\nequality constraint to an inequality constraint. Further, we use our methods to\nanalyze the distance between vertices on certain faces of a 3-sum polyhedron.\n","authors":["Steffen Borgwardt","Weston Grewe","Jon Lee"],"pdf_url":"https://arxiv.org/pdf/2311.02047v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17142v1","updated":"2024-03-25T19:39:17Z","published":"2024-03-25T19:39:17Z","title":"Approximation with Random Shallow ReLU Networks with Applications to\n  Model Reference Adaptive Control","summary":"  Neural networks are regularly employed in adaptive control of nonlinear\nsystems and related methods o reinforcement learning. A common architecture\nuses a neural network with a single hidden layer (i.e. a shallow network), in\nwhich the weights and biases are fixed in advance and only the output layer is\ntrained. While classical results show that there exist neural networks of this\ntype that can approximate arbitrary continuous functions over bounded regions,\nthey are non-constructive, and the networks used in practice have no\napproximation guarantees. Thus, the approximation properties required for\ncontrol with neural networks are assumed, rather than proved. In this paper, we\naim to fill this gap by showing that for sufficiently smooth functions, ReLU\nnetworks with randomly generated weights and biases achieve $L_{\\infty}$ error\nof $O(m^{-1/2})$ with high probability, where $m$ is the number of neurons. It\nsuffices to generate the weights uniformly over a sphere and the biases\nuniformly over an interval. We show how the result can be used to get\napproximations of required accuracy in a model reference adaptive control\napplication.\n","authors":["Andrew Lamperski","Tyler Lekang"],"pdf_url":"https://arxiv.org/pdf/2403.17142v1.pdf","comment":"Under Review for Conference on Decision and Control"},{"id":"http://arxiv.org/abs/2310.13843v2","updated":"2024-03-25T19:36:52Z","published":"2023-10-20T22:32:42Z","title":"Long Solution Times or Low Solution Quality: On Trade-Offs in Choosing a\n  Power Flow Formulation for the Optimal Power Shutoff Problem","summary":"  The Optimal Power Shutoff (OPS) problem is an optimization problem that makes\npower line de-energization decisions in order to reduce the risk of igniting a\nwildfire, while minimizing the load shed of customers. This problem, with DC\nlinear power flow equations, has been used in many studies in recent years.\nHowever, using linear approximations for power flow when making decisions on\nthe network topology is known to cause challenges with AC feasibility of the\nresulting network, as studied in the related contexts of optimal transmission\nswitching or grid restoration planning. This paper explores the accuracy of the\nDC OPS formulation and the ability to recover an AC-feasible power flow\nsolution after de-energization decisions are made. We also extend the OPS\nproblem to include variants with the AC, Second-Order-Cone, and Network-Flow\npower flow equations, and compare them to the DC approximation with respect to\nsolution quality and time. The results highlight that the DC approximation\noverestimates the amount of load that can be served, leading to poor\nde-energization decisions. The AC and SOC-based formulations are better, but\nprohibitively slow to solve for even modestly sized networks thus demonstrating\nthe need for new solution methods with better trade-offs between computational\ntime and solution quality.\n","authors":["Eric Haag","Noah Rhodes","Line Roald"],"pdf_url":"https://arxiv.org/pdf/2310.13843v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17100v1","updated":"2024-03-25T18:38:47Z","published":"2024-03-25T18:38:47Z","title":"Practical Acceleration of the Condat-Vũ Algorithm","summary":"  The Condat-V\\~u algorithm is a widely used primal-dual method for optimizing\ncomposite objectives of three functions. Several algorithms for optimizing\ncomposite objectives of two functions are special cases of Condat-V\\~u,\nincluding proximal gradient descent (PGD). It is well-known that PGD exhibits\nsuboptimal performance, and a simple adjustment to PGD can accelerate its\nconvergence rate from $\\mathcal{O}(1/T)$ to $\\mathcal{O}(1/T^2)$ on convex\nobjectives, and this accelerated rate is optimal. In this work, we show that a\nsimple adjustment to the Condat-V\\~u algorithm allows it to recover accelerated\nPGD (APGD) as a special case, instead of PGD. We prove that this accelerated\nCondat--V\\~u algorithm achieves optimal convergence rates and significantly\noutperforms the traditional Condat-V\\~u algorithm in regimes where the\nCondat--V\\~u algorithm approximates the dynamics of PGD. We demonstrate the\neffectiveness of our approach in various applications in machine learning and\ncomputational imaging.\n","authors":["Derek Driggs","Matthias J. Ehrhardt","Carola-Bibiane Schönlieb","Junqi Tang"],"pdf_url":"https://arxiv.org/pdf/2403.17100v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03157v2","updated":"2024-03-25T18:14:54Z","published":"2023-02-06T23:34:51Z","title":"A distribution-free mixed-integer optimization approach to hierarchical\n  modelling of clustered and longitudinal data","summary":"  Recent advancements in Mixed Integer Optimization (MIO) algorithms, paired\nwith hardware enhancements, have led to significant speedups in resolving MIO\nproblems. These strategies have been utilized for optimal subset selection,\nspecifically for choosing $k$ features out of $p$ in linear regression given\n$n$ observations. In this paper, we broaden this method to facilitate\ncluster-aware regression, where selection aims to choose $\\lambda$ out of $K$\nclusters in a linear mixed effects (LMM) model with $n_k$ observations for each\ncluster. Through comprehensive testing on a multitude of synthetic and real\ndatasets, we exhibit that our method efficiently solves problems within\nminutes. Through numerical experiments, we also show that the MIO approach\noutperforms both Gaussian- and Laplace-distributed LMMs in terms of generating\nsparse solutions with high predictive power. Traditional LMMs typically assume\nthat clustering effects are independent of individual features. However, we\nintroduce an innovative algorithm that evaluates cluster effects for new data\npoints, thereby increasing the robustness and precision of this model. The\ninferential and predictive efficacy of this approach is further illustrated\nthrough its application in student scoring and protein expression.\n","authors":["Madhav Sankaranarayanan","Intekhab Hossain","Tom Chen"],"pdf_url":"https://arxiv.org/pdf/2302.03157v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17073v1","updated":"2024-03-25T18:05:03Z","published":"2024-03-25T18:05:03Z","title":"Non-stationary Bandits with Habituation and Recover Dynamics and\n  Knapsack Constraints","summary":"  Multi-armed bandit models have proven to be useful in modeling many real\nworld problems in the areas of control and sequential decision making with\npartial information. However, in many scenarios, such as those prevalent in\nhealthcare and operations management, the decision maker's expected reward will\ndecrease if an action is selected too frequently while it may recover if they\nabstain from selecting this action. This scenario is further complicated when\nchoosing a particular action also expends a random amount of a limited resource\nwhere the distribution is also initially unknown to the decision maker. In this\npaper we study a class of models that address this setting that we call\nreducing or gaining unknown efficacy bandits with stochastic knapsack\nconstraints (ROGUEwK). We propose a combination upper confidence bound (UCB)\nand lower confidence bound (LCB) approximation algorithm for optimizing this\nmodel. Our algorithm chooses which action to play at each time point by solving\na linear program (LP) with the UCB for the average rewards and LCB for the\naverage costs as inputs. We show that the regret of our algorithm is sub-linear\nas a function of time and total constraint budget when compared to a dynamic\noracle. We validate the performance of our algorithm against existing state of\nthe art non-stationary and knapsack bandit approaches in a simulation study and\nshow that our methods are able to on average achieve a 13% improvement in terms\nof total reward.\n","authors":["Qinyang He","Yonatan Mintz"],"pdf_url":"https://arxiv.org/pdf/2403.17073v1.pdf","comment":"8 pages, 3 figures"},{"id":"http://arxiv.org/abs/2403.16982v1","updated":"2024-03-25T17:43:50Z","published":"2024-03-25T17:43:50Z","title":"State-Augmented Linear Games with Antagonistic Error for\n  High-Dimensional, Nonlinear Hamilton-Jacobi Reachability","summary":"  Hamilton-Jacobi Reachability (HJR) is a popular method for analyzing the\nliveness and safety of a dynamical system with bounded control and disturbance.\nThe corresponding HJ value function offers a robust controller and\ncharacterizes the reachable sets, but is traditionally solved with Dynamic\nProgramming (DP) and limited to systems of dimension less than six. Recently,\nthe space-parallelizeable, generalized Hopf formula has been shown to also\nsolve the HJ value with a nearly three-log increase in dimension limit, but is\nlimited to linear systems. To extend this potential, we demonstrate how\nstate-augmented (SA) spaces, which are well-known for their improved\nlinearization accuracy, may be used to solve tighter, conservative\napproximations of the value function with any linear model in this SA space.\nNamely, we show that with a representation of the true dynamics in the SA\nspace, a series of inequalities confirms that the value of a SA linear game\nwith antagonistic error is a conservative envelope of the true value function.\nIt follows that if the optimal controller for the HJ SA linear game with error\nmay succeed, it will also succeed in the true system. Unlike previous methods,\nthis result offers the ability to safely approximate reachable sets and their\ncorresponding controllers with the Hopf formula in a non-convex manner.\nFinally, we demonstrate this in the slow manifold system for clarity, and in\nthe controlled Van der Pol system with different lifting functions.\n","authors":["Will Sharpless","Yat Tin Chow","Sylvia Herbert"],"pdf_url":"https://arxiv.org/pdf/2403.16982v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16979v1","updated":"2024-03-25T17:41:52Z","published":"2024-03-25T17:41:52Z","title":"An Optimal Solution to Infinite Horizon Nonlinear Control Problems: Part\n  II","summary":"  This paper considers the infinite horizon optimal control problem for\nnonlinear systems. Under the condition of nonlinear controllability of the\nsystem to any terminal set containing the origin and forward invariance of the\nterminal set, we establish a regularized solution approach consisting of a\n``finite free final time\" optimal transfer problem to the terminal set which\nrenders the set globally asymptotically stable. Further, we show that the\napproximations converge to the optimal infinite horizon cost as the size of the\nterminal set decreases to zero. We also perform the analysis for the discounted\nproblem and show that the terminal set is asymptotically stable only for a\nsubset of the state space and not globally. The theory is empirically evaluated\non various nonholonomic robotic systems to show that the cost of our\napproximate problem converges and the transfer time into the terminal set is\ndependent on the initial state of the system, necessitating the free final time\nformulation.\n","authors":["Mohamed Naveed Gul Mohamed","Aayushman Sharma","Raman Goyal","Suman Chakravorty"],"pdf_url":"https://arxiv.org/pdf/2403.16979v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16966v1","updated":"2024-03-25T17:25:44Z","published":"2024-03-25T17:25:44Z","title":"Unsupervised Feature Selection via Nonnegative Orthogonal Constrained\n  Regularized Minimization","summary":"  Unsupervised feature selection has drawn wide attention in the era of big\ndata since it is a primary technique for dimensionality reduction. However,\nmany existing unsupervised feature selection models and solution methods were\npresented for the purpose of application, and lack of theoretical support,\ne.g., without convergence analysis. In this paper, we first establish a novel\nunsupervised feature selection model based on regularized minimization with\nnonnegative orthogonal constraints, which has advantages of embedding feature\nselection into the nonnegative spectral clustering and preventing overfitting.\nAn effective inexact augmented Lagrangian multiplier method is proposed to\nsolve our model, which adopts the proximal alternating minimization method to\nsolve subproblem at each iteration. We show that the sequence generated by our\nmethod globally converges to a Karush-Kuhn-Tucker point of our model. Extensive\nnumerical experiments on popular datasets demonstrate the stability and\nrobustness of our method. Moreover, comparison results of algorithm performance\nshow that our method outperforms some existing state-of-the-art methods.\n","authors":["Yan Li","Defeng Sun","Liping Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.16966v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16962v1","updated":"2024-03-25T17:21:21Z","published":"2024-03-25T17:21:21Z","title":"An $α$-potential game framework for $N$-player games","summary":"  This paper proposes and studies a general form of dynamic $N$-player\nnon-cooperative games called $\\alpha$-potential games, where the change of a\nplayer's value function upon her unilateral deviation from her strategy is\nequal to the change of an $\\alpha$-potential function up to an error $\\alpha$.\nAnalogous to the static potential game (which corresponds to $\\alpha=0$), the\n$\\alpha$-potential game framework is shown to reduce the challenging task of\nfinding approximate Nash equilibria for a dynamic game to minimizing the\n$\\alpha$-potential function. Moreover, an analytical characterization of\n$\\alpha$-potential functions is established, with $\\alpha$ represented in terms\nof the magnitude of the asymmetry of value functions' second-order derivatives.\nFor stochastic differential games in which the state dynamic is a controlled\ndiffusion, $\\alpha$ is explicitly identified in terms of the number of players,\nthe choice of admissible strategies, and the intensity of interactions, and the\nlevel of heterogeneity among players. This is achieved by introducing a\nsuitable linear derivative of the value functions with respect to unilateral\ndeviations of strategies and via analyzing the sensitivity processes of state\ndynamics with respect to controls.\n  For games with mean-field type interactions, $\\alpha$ is shown to decay to\nzero as the number of players goes to infinity, even with heterogeneity in\nstate dynamics, cost functions, and admissible strategy classes. For\ndistributed games, if a static potential function can be derived from the cost\nfunctions, then $\\alpha=0$. For crowd aversion games, $\\alpha$ is capable of\ncapturing the subtle difference between the choice of admissible strategies.\n","authors":["Xin Guo","Xinyu Li","Yufei Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.16962v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.12293v2","updated":"2024-03-25T17:16:56Z","published":"2022-12-23T12:51:12Z","title":"A Tikhonov theorem for McKean-Vlasov two-scale systems and a new\n  application to mean field optimal control problems","summary":"  We provide a new version of the Tikhonov theorem for both two-scale forward\nsystems and also two-scale forward-backward systems of stochastic differential\nequations, which also covers the McKean-Vlasov case. Differently from what is\nusually done in the literature, we prove a type of convergence for the ''fast''\nvariable, which allows the limiting process to be discontinuous. This is\nrelevant for the second part of the paper, where we present a new application\nof this theory to the approximation of the solution of mean field control\nproblems. Towards this aim, we construct a two-scale system whose ''fast''\ncomponent converges to the optimal control process, while the ''slow''\ncomponent converges to the optimal state process. The interest in such a\nprocedure is that it allows to approximate the solution of the control problem\navoiding the usual step of the minimization of the Hamiltonian.\n","authors":["Matteo Burzoni","Alekos Cecchin","Andrea Cosso"],"pdf_url":"https://arxiv.org/pdf/2212.12293v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17042v1","updated":"2024-03-25T15:58:26Z","published":"2024-03-25T15:58:26Z","title":"Provably Robust Score-Based Diffusion Posterior Sampling for\n  Plug-and-Play Image Reconstruction","summary":"  In a great number of tasks in science and engineering, the goal is to infer\nan unknown image from a small number of measurements collected from a known\nforward model describing certain sensing or imaging modality. Due to resource\nconstraints, this task is often extremely ill-posed, which necessitates the\nadoption of expressive prior information to regularize the solution space.\nScore-based diffusion models, due to its impressive empirical success, have\nemerged as an appealing candidate of an expressive prior in image\nreconstruction. In order to accommodate diverse tasks at once, it is of great\ninterest to develop efficient, consistent and robust algorithms that\nincorporate {\\em unconditional} score functions of an image prior distribution\nin conjunction with flexible choices of forward models.\n  This work develops an algorithmic framework for employing score-based\ndiffusion models as an expressive data prior in general nonlinear inverse\nproblems. Motivated by the plug-and-play framework in the imaging community, we\nintroduce a diffusion plug-and-play method (\\textsf{DPnP}) that alternatively\ncalls two samplers, a proximal consistency sampler based solely on the\nlikelihood function of the forward model, and a denoising diffusion sampler\nbased solely on the score functions of the image prior. The key insight is that\ndenoising under white Gaussian noise can be solved {\\em rigorously} via both\nstochastic (i.e., DDPM-type) and deterministic (i.e., DDIM-type) samplers using\nthe unconditional score functions. We establish both asymptotic and\nnon-asymptotic performance guarantees of \\textsf{DPnP}, and provide numerical\nexperiments to illustrate its promise in solving both linear and nonlinear\nimage reconstruction tasks. To the best of our knowledge, \\textsf{DPnP} is the\nfirst provably-robust posterior sampling method for nonlinear inverse problems\nusing unconditional diffusion priors.\n","authors":["Xingyu Xu","Yuejie Chi"],"pdf_url":"https://arxiv.org/pdf/2403.17042v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16879v1","updated":"2024-03-25T15:46:34Z","published":"2024-03-25T15:46:34Z","title":"Algebraic Constraints on Common Lines with Applications to Community\n  Detection in Cryo-EM","summary":"  We revisit the topic of common lines between 2D class averages in single\nparticle cryo-electron microscopy (cryo-EM). We derive a novel low-rank\nconstraint on a certain $2n \\times n$ matrix storing properly-scaled basis\nvectors for the common lines between $n$ tomographic images of one molecular\nconformation. Using this constraint and others, we introduce an optimization\nalgorithm to denoise the common lines of one conformation. As a main\napplication, we develop a clustering algorithm to partition a set of noisy\ncommon lines into homogeneous communities, in the case of discrete\nheterogeneity in cryo-EM. We demonstrate the methods on synthetic and\nexperimental datasets.\n","authors":["Tommi Muller","Adriana L. Duncan","Eric J. Verbeke","Joe Kileel"],"pdf_url":"https://arxiv.org/pdf/2403.16879v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16874v1","updated":"2024-03-25T15:39:45Z","published":"2024-03-25T15:39:45Z","title":"Optimality of spherical codes via exact semidefinite programming bounds","summary":"  We show that the spectral embeddings of all known triangle-free strongly\nregular graphs are optimal spherical codes (the new cases are $56$ points in\n$20$ dimensions, $50$ points in $21$ dimensions, and $77$ points in $21$\ndimensions), as are certain mutually unbiased basis arrangements constructed\nusing Kerdock codes in up to $1024$ dimensions (namely, $2^{4k} + 2^{2k+1}$\npoints in $2^{2k}$ dimensions for $2 \\le k \\le 5$). As a consequence of the\nlatter, we obtain optimality of the Kerdock binary codes of block length $64$,\n$256$, and $1024$, as well as uniqueness for block length $64$. We also prove\nuniversal optimality for $288$ points on a sphere in $16$ dimensions. To prove\nthese results, we use three-point semidefinite programming bounds, for which\nonly a few sharp cases were known previously. To obtain rigorous results, we\ndevelop improved techniques for rounding approximate solutions of semidefinite\nprograms to produce exact optimal solutions.\n","authors":["Henry Cohn","David de Laat","Nando Leijenhorst"],"pdf_url":"https://arxiv.org/pdf/2403.16874v1.pdf","comment":"32 pages, 1 figure"},{"id":"http://arxiv.org/abs/2403.16864v1","updated":"2024-03-25T15:27:21Z","published":"2024-03-25T15:27:21Z","title":"Improved convergence rates for the Difference-of-Convex algorithm","summary":"  We consider a difference-of-convex formulation where one of the terms is\nallowed to be hypoconvex (or weakly convex). We first examine the precise\nbehavior of a single iteration of the Difference-of-Convex algorithm (DCA),\ngiving a tight characterization of the objective function decrease. This\nrequires distinguishing between eight distinct parameter regimes.\n  Our proofs are inspired by the performance estimation framework, but are much\nsimplified compared to similar previous work.\n  We then derive sublinear DCA convergence rates towards critical points,\ndistinguishing between cases where at least one of the functions is smooth and\nwhere both functions are nonsmooth. We conjecture the tightness of these rates\nfor four parameter regimes, based on strong numerical evidence obtained via\nperformance estimation, as well as the leading constant in the asymptotic\nsublinear rate for two more regimes.\n","authors":["Teodor Rotaru","Panagiotis Patrinos","François Glineur"],"pdf_url":"https://arxiv.org/pdf/2403.16864v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.02490v2","updated":"2024-03-25T14:55:11Z","published":"2024-02-04T13:33:56Z","title":"Decentralized Finite-Sum Optimization over Time-Varying Networks","summary":"  We consider decentralized time-varying stochastic optimization problems where\neach of the functions held by the nodes has a finite sum structure. Such\nproblems can be efficiently solved using variance reduction techniques. Our aim\nis to explore the lower complexity bounds (for communication and number of\nstochastic oracle calls) and find optimal algorithms. The paper studies\nstrongly convex and nonconvex scenarios. To the best of our knowledge, variance\nreduced schemes and lower bounds for time-varying graphs have not been studied\nin the literature. For nonconvex objectives, we obtain lower bounds and develop\nan optimal method GT-PAGE. For strongly convex objectives, we propose the first\ndecentralized time-varying variance-reduction method ADOM+VR and establish\nlower bound in this scenario, highlighting the open question of matching the\nalgorithms complexity and lower bounds even in static network case.\n","authors":["Dmitry Metelev","Savelii Chezhegov","Alexander Rogozin","Aleksandr Beznosikov","Alexander Sholokhov","Alexander Gasnikov","Dmitry Kovalev"],"pdf_url":"https://arxiv.org/pdf/2402.02490v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16825v1","updated":"2024-03-25T14:49:01Z","published":"2024-03-25T14:49:01Z","title":"Weak Convergence Analysis of Online Neural Actor-Critic Algorithms","summary":"  We prove that a single-layer neural network trained with the online actor\ncritic algorithm converges in distribution to a random ordinary differential\nequation (ODE) as the number of hidden units and the number of training steps\n$\\rightarrow \\infty$. In the online actor-critic algorithm, the distribution of\nthe data samples dynamically changes as the model is updated, which is a key\nchallenge for any convergence analysis. We establish the geometric ergodicity\nof the data samples under a fixed actor policy. Then, using a Poisson equation,\nwe prove that the fluctuations of the model updates around the limit\ndistribution due to the randomly-arriving data samples vanish as the number of\nparameter updates $\\rightarrow \\infty$. Using the Poisson equation and weak\nconvergence techniques, we prove that the actor neural network and critic\nneural network converge to the solutions of a system of ODEs with random\ninitial conditions. Analysis of the limit ODE shows that the limit critic\nnetwork will converge to the true value function, which will provide the actor\nan asymptotically unbiased estimate of the policy gradient. We then prove that\nthe limit actor network will converge to a stationary point.\n","authors":["Samuel Chun-Hei Lam","Justin Sirignano","Ziheng Wang"],"pdf_url":"https://arxiv.org/pdf/2403.16825v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.00670v2","updated":"2024-03-25T14:37:40Z","published":"2024-01-01T05:20:43Z","title":"Hybrid physics-informed metabolic cybergenetics: process rates augmented\n  with machine-learning surrogates informed by flux balance analysis","summary":"  Metabolic cybergenetics is a promising concept that interfaces gene\nexpression and cellular metabolism with computers for real-time dynamic\nmetabolic control. The focus is on control at the transcriptional level,\nserving as a means to modulate intracellular metabolic fluxes. Recent\nstrategies in this field have employed constraint-based dynamic models for\nprocess optimization, control, and estimation. However, this results in bilevel\ndynamic optimization problems, which pose considerable numerical and conceptual\nchallenges. In this study, we present an alternative hybrid physics-informed\ndynamic modeling framework for metabolic cybergenetics, aimed at simplifying\noptimization, control, and estimation tasks. By utilizing machine-learning\nsurrogates, our approach effectively embeds the physics of metabolic networks\ninto the process rates of structurally simpler macro-kinetic models coupled\nwith gene expression. These surrogates, informed by flux balance analysis, link\nthe domains of manipulatable intracellular enzymes to metabolic exchange\nfluxes. This ensures that critical knowledge captured by the system's metabolic\nnetwork is preserved. The resulting models can be integrated into metabolic\ncybergenetic schemes involving single-level optimizations. Additionally, the\nhybrid modeling approach maintains the number of system states at a necessary\nminimum, easing the burden of process monitoring and estimation. Our hybrid\nphysics-informed metabolic cybergenetic framework is demonstrated using a\ncomputational case study on the optogenetically-assisted production of\nitaconate by $\\textit{Escherichia coli}$.\n","authors":["Sebastián Espinel-Ríos","José L. Avalos"],"pdf_url":"https://arxiv.org/pdf/2401.00670v2.pdf","comment":"25 pages, 10 figures, journal submission (reviewed/accepted version)"},{"id":"http://arxiv.org/abs/2403.06708v2","updated":"2024-03-25T14:08:00Z","published":"2024-03-11T13:33:31Z","title":"Tikhonov Regularization for Stochastic Non-Smooth Convex Optimization in\n  Hilbert Spaces","summary":"  To solve non-smooth convex optimization problems with a noisy gradient input,\nwe analyze the global behavior of subgradient-like flows under stochastic\nerrors. The objective function is composite, being equal to the sum of two\nconvex functions, one being differentiable and the other potentially\nnon-smooth. We then use stochastic differential inclusions where the drift term\nis minus the subgradient of the objective function, and the diffusion term is\neither bounded or square-integrable. In this context, under Lipschitz's\ncontinuity of the differentiable term and a growth condition of the non-smooth\nterm, our first main result shows almost sure weak convergence of the\ntrajectory process towards a minimizer of the objective function. Then, using\nTikhonov regularization with a properly tuned vanishing parameter, we can\nobtain almost sure strong convergence of the trajectory towards the minimum\nnorm solution. We find an explicit tuning of this parameter when our objective\nfunction satisfies a local error-bound inequality. We also provide a\ncomprehensive complexity analysis by establishing several new pointwise and\nergodic convergence rates in expectation for the convex and strongly convex\ncase.\n","authors":["Rodrigo Maulen-Soto","Jalal Fadili","Hedy Attouch"],"pdf_url":"https://arxiv.org/pdf/2403.06708v2.pdf","comment":"34 pages, 2 tables. arXiv admin note: text overlap with\n  arXiv:2207.02750"},{"id":"http://arxiv.org/abs/2403.16787v1","updated":"2024-03-25T14:02:22Z","published":"2024-03-25T14:02:22Z","title":"Local search and trajectory metaheuristics for the flexible job shop\n  scheduling problem with sequencing flexibility and position-based learning\n  effect","summary":"  The flexible job shop scheduling problem with sequencing flexibility and\nposition-based learning effect is considered in the present work. In [K. A. G.\nAraujo, E. G. Birgin, and D. P. Ronconi, Technical Report MCDO02022024, 2024],\nmodels, constructive heuristics, and benchmark instances for the same problem\nwere introduced. In the present work, we are concerned with the development of\neffective and efficient methods for its resolution. For this purpose, a local\nsearch method and four trajectory metaheuristics are considered. In the local\nsearch, we show that the classical strategy of only reallocating operations\nthat are part of the critical path can miss better quality neighbors, as\nopposed to what happens in the case where there is no learning effect.\nConsequently, we analyze an alternative type of neighborhood reduction that\neliminates only neighbors that are not better than the current solution. In\naddition, we also suggest a neighborhood cut and experimentally verify that\nthis significantly reduces the neighborhood size, bringing efficiency, with\nminimal loss in effectiveness. Extensive numerical experiments with the local\nsearch and the metaheuristics are carried on. The experiments show that tabu\nsearch, built on the reduced neighborhood, when applied to large-sized\ninstances, stands out in relation to other the other three metaheuristics,\nnamely, iterated local search, greedy randomized adaptive search procedure, and\nsimulating annealing. Experiments with classical instances without sequencing\nflexibility show that the introduced methods also stand out in relation to\nmethods from the literature. All the methods introduced, as well as the\ninstances and solutions found, are freely available. As a whole, we build a\ntest suite that can be used in future work.\n","authors":["Kennedy A. G. Araújo","Ernesto G. Birgin","Débora P. Ronconi"],"pdf_url":"https://arxiv.org/pdf/2403.16787v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16775v1","updated":"2024-03-25T13:52:36Z","published":"2024-03-25T13:52:36Z","title":"Stochastic Inertial Dynamics Via Time Scaling and Averaging","summary":"  Our work is part of the close link between continuous-time dissipative\ndynamical systems and optimization algorithms, and more precisely here, in the\nstochastic setting. We aim to study stochastic convex minimization problems\nthrough the lens of stochastic inertial differential inclusions that are driven\nby the subgradient of a convex objective function. This will provide a general\nmathematical framework for analyzing the convergence properties of stochastic\nsecond-order inertial continuous-time dynamics involving vanishing viscous\ndamping and measurable stochastic subgradient selections. Our chief goal in\nthis paper is to develop a systematic and unified way that transfers the\nproperties recently studied for first-order stochastic differential equations\nto second-order ones involving even subgradients in lieu of gradients. This\nprogram will rely on two tenets: time scaling and averaging, following an\napproach recently developed in the literature by one of the co-authors in the\ndeterministic case.\n  Under a mild integrability assumption involving the diffusion term and the\nviscous damping, our first main result shows that almost surely, there is weak\nconvergence of the trajectory towards a minimizer of the objective function and\nfast convergence of the values and gradients. We also provide a comprehensive\ncomplexity analysis by establishing several new pointwise and ergodic\nconvergence rates in expectation for the convex, strongly convex, and (local)\nPolyak-Lojasiewicz case. Finally, using Tikhonov regularization with a properly\ntuned vanishing parameter, we can obtain almost sure strong convergence of the\ntrajectory towards the minimum norm solution.\n","authors":["Rodrigo Maulen-Soto","Jalal Fadili","Hedy Attouch","Peter Ochs"],"pdf_url":"https://arxiv.org/pdf/2403.16775v1.pdf","comment":"31 pages. arXiv admin note: text overlap with arXiv:2403.06708"},{"id":"http://arxiv.org/abs/2403.16766v1","updated":"2024-03-25T13:42:47Z","published":"2024-03-25T13:42:47Z","title":"Models, constructive heuristics, and benchmark instances for the\n  flexible job shop scheduling problem with sequencing flexibility and\n  position-based learning effect","summary":"  This paper addresses the flexible job shop scheduling problem with sequencing\nflexibility and position-based learning effect. In this variant of the flexible\njob shop scheduling problem, precedence constraints of the operations\nconstituting a job are given by an arbitrary directed acyclic graph, in\nopposition to the classical case in which a total order is imposed.\nAdditionally, it is assumed that the processing time of an operation in a\nmachine is subject to a learning process such that the larger the position of\nthe operation in the machine, the faster the operation is processed. Mixed\ninteger programming and constraint programming models are presented and\ncompared in the present work. In addition, constructive heuristics are\nintroduced to provide an initial solution to the models' solvers. Sets of\nbenchmark instances are also introduced. The problem considered corresponds to\nmodern problems of great relevance in the printing industry. The models and\ninstances presented are intended to support the development of new heuristic\nand metaheuristics methods for this problem.\n","authors":["Kennedy A. G. Araújo","Ernesto G. Birgin","Débora P. Ronconi"],"pdf_url":"https://arxiv.org/pdf/2403.16766v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16765v1","updated":"2024-03-25T13:42:13Z","published":"2024-03-25T13:42:13Z","title":"The stability of the multivariate geometric Brownian motion as a\n  bilinear matrix inequality problem","summary":"  In this manuscript, we study the stability of the origin for the multivariate\ngeometric Brownian motion. More precisely, under suitable sufficient\nconditions, we construct a Lyapunov function such that the origin of the\nmultivariate geometric Brownian motion is globally asymptotically stable in\nprobability. Moreover, we show that such conditions can be rewritten as a\nBilinear Matrix Inequality (BMI) feasibility problem. We stress that no\ncommutativity relations between the drift matrix and the noise dispersion\nmatrices are assumed and therefore the so-called Magnus representation of the\nsolution of the multivariate geometric Brownian motion is complicated. In\naddition, we exemplify our method in numerous specific models from the\nliterature such as random linear oscillators, satellite dynamics, inertia\nsystems, diagonal noise systems, cancer self-remission and smoking.\n","authors":["Gerardo Barrera","Eyleifur Bjarkason","Sigurdur Hafstein"],"pdf_url":"https://arxiv.org/pdf/2403.16765v1.pdf","comment":"34 pages"},{"id":"http://arxiv.org/abs/2202.00992v3","updated":"2024-03-25T13:31:05Z","published":"2022-02-02T12:24:03Z","title":"Tight Convergence Rate Bounds for Optimization Under Power Law Spectral\n  Conditions","summary":"  Performance of optimization on quadratic problems sensitively depends on the\nlow-lying part of the spectrum. For large (effectively infinite-dimensional)\nproblems, this part of the spectrum can often be naturally represented or\napproximated by power law distributions, resulting in power law convergence\nrates for iterative solutions of these problems by gradient-based algorithms.\nIn this paper, we propose a new spectral condition providing tighter upper\nbounds for problems with power law optimization trajectories. We use this\ncondition to build a complete picture of upper and lower bounds for a wide\nrange of optimization algorithms -- Gradient Descent, Steepest Descent, Heavy\nBall, and Conjugate Gradients -- with an emphasis on the underlying schedules\nof learning rate and momentum. In particular, we demonstrate how an optimally\naccelerated method, its schedule, and convergence upper bound can be obtained\nin a unified manner for a given shape of the spectrum. Also, we provide first\nproofs of tight lower bounds for convergence rates of Steepest Descent and\nConjugate Gradients under spectral power laws with general exponents. Our\nexperiments show that the obtained convergence bounds and acceleration\nstrategies are not only relevant for exactly quadratic optimization problems,\nbut also fairly accurate when applied to the training of neural networks.\n","authors":["Maksim Velikanov","Dmitry Yarotsky"],"pdf_url":"https://arxiv.org/pdf/2202.00992v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.04966v4","updated":"2024-03-25T12:56:23Z","published":"2023-01-12T12:21:10Z","title":"Aerial Base Station Placement via Propagation Radio Maps","summary":"  The deployment of aerial base stations (ABSs) on unmanned aerial vehicles\n(UAVs) presents a promising solution for extending cellular connectivity to\nareas where terrestrial infrastructure is overloaded, damaged, or absent. A\npivotal challenge in this domain is to decide the locations of a set of ABSs to\neffectively serve ground-based users. Most existing approaches oversimplify\nthis problem by assuming that the channel gain between two points is a function\nof solely distance and, sometimes, also the elevation angle. In turn, this\npaper leverages propagation radio maps to account for arbitrary air-to-ground\nchannel gains. This methodology enables the identification of an approximately\nminimal set of locations where ABSs need to be deployed to ensure that all\nground terminals achieve a target service rate, while adhering to backhaul\ncapacity limitations and avoiding designated no-fly zones. Relying on a convex\nrelaxation technique and the alternating direction method of multipliers\n(ADMM), this paper puts forth a scalable solver whose computational complexity\nscales linearly with the number of ground terminals. Convergence is established\nanalytically and an extensive set of simulations corroborate the merits of the\nproposed scheme relative to conventional methods.\n","authors":["Daniel Romero","Pham Q. Viet","Raju Shrestha"],"pdf_url":"https://arxiv.org/pdf/2301.04966v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.00814v2","updated":"2024-03-25T06:00:27Z","published":"2022-06-02T01:02:54Z","title":"Extremely Fast Convergence Rates for Extremum Seeking Control with\n  Polyak-Ruppert Averaging","summary":"  Stochastic approximation is a foundation for many algorithms found in machine\nlearning and optimization. It is in general slow to converge: the mean square\nerror vanishes as $O(n^{-1})$. A deterministic counterpart known as\nquasi-stochastic approximation is a viable alternative in many applications,\nincluding gradient-free optimization and reinforcement learning. It was assumed\nin prior research that the optimal achievable convergence rate is $O(n^{-2})$.\nIt is shown in this paper that through design it is possible to obtain far\nfaster convergence, of order $O(n^{-4+\\delta})$, with $\\delta>0$ arbitrary. Two\ntechniques are introduced for the first time to achieve this rate of\nconvergence. The theory is also specialized within the context of gradient-free\noptimization, and tested on standard benchmarks. The main results are based on\na combination of novel application of results from number theory and techniques\nadapted from stochastic approximation theory.\n","authors":["Caio Kalil Lauand","Sean Meyn"],"pdf_url":"https://arxiv.org/pdf/2206.00814v2.pdf","comment":"36 pages, 14 figures"}],"Systems and Control":[{"id":"http://arxiv.org/abs/2403.16742v1","updated":"2024-03-25T13:13:39Z","published":"2024-03-25T13:13:39Z","title":"A Branch and Bound method for the exact parameter identification of the\n  PK/PD model for anesthetic drugs","summary":"  We address the problem of parameter identification for the standard\npharmacokinetic/pharmacodynamic (PK/PD) model for anesthetic drugs. Our main\ncontribution is the development of a global optimization method that guarantees\nfinding the parameters that minimize the one-step ahead prediction error. The\nmethod is based on a branch-and-bound algorithm, that can be applied to solve a\nmore general class of nonlinear regression problems. We present some simulation\nresults, based on a dataset of twelve patients. In these simulations, we are\nalways able to identify the exact parameters, despite the non-convexity of the\noverall identification problem.\n","authors":["Giulia Di Credico","Luca Consolini","Mattia Laurini","Marco Locatelli","Marco Milanesi","Michele Schiavo","Antonio Visioli"],"pdf_url":"https://arxiv.org/pdf/2403.16742v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16740v1","updated":"2024-03-25T13:12:39Z","published":"2024-03-25T13:12:39Z","title":"Looking back and forward: A retrospective and future directions on\n  Software Engineering for systems-of-systems","summary":"  Modern systems are increasingly connected and more integrated with other\nexisting systems, giving rise to systems-of-systems (SoS). An SoS consists of a\nset of independent, heterogeneous systems that interact to provide new\nfunctionalities and accomplish global missions through emergent behavior\nmanifested at runtime. The distinctive characteristics of SoS, when contrasted\nto traditional systems, pose significant research challenges within Software\nEngineering. These challenges motivate the need for a paradigm shift and the\nexploration of novel approaches for designing, developing, deploying, and\nevolving these systems. The International Workshop on Software Engineering for\nSystems-of-Systems (SESoS) series started in 2013 to fill a gap in scientific\nforums addressing SoS from the Software Engineering perspective, becoming the\nfirst venue for this purpose. This article presents a study aimed at outlining\nthe evolution and future trajectory of Software Engineering for SoS based on\nthe examination of 57 papers spanning the 11 editions of the SESoS workshop\n(2013-2023). The study combined scoping review and scientometric analysis\nmethods to categorize and analyze the research contributions concerning\ntemporal and geographic distribution, topics of interest, research\nmethodologies employed, application domains, and research impact. Based on such\na comprehensive overview, this article discusses current and future directions\nin Software Engineering for SoS.\n","authors":["Everton Cavalcante","Thais Batista","Flavio Oquendo"],"pdf_url":"https://arxiv.org/pdf/2403.16740v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16738v1","updated":"2024-03-25T13:09:53Z","published":"2024-03-25T13:09:53Z","title":"A data-based comparison of methods for reducing the peak volume flow\n  rate in a district heating system","summary":"  This work concerns reduction of the peak flow rate of a district heating\ngrid, a key system property which is bounded by pipe dimensions and pumping\ncapacity. The peak flow rate constrains the number of additional consumers that\ncan be connected, and may be a limiting factor in reducing supply temperatures\nwhen transitioning to the 4th generation of district heating. We evaluate a\nfull year of operational data from a subset of customer meters in a district\nheating system in Germany. We consider the peak flow rate reduction that could\nbe achieved with full a posteriori knowledge of this data. Three strategies for\nreducing the peak flow rate are investigated: A load shifting demand response\nstrategy, an upper limitation in substation return temperatures, and an upper\nlimitation on each substation's volume flow rate. We show that imposing up to\nto 18 % load flexibility for the customers provides an equal reduction in the\npeak system flow rate under the load shifting strategy. The limited return\ntemperature strategy is less efficient at curtailing the peak flow rate, but\nprovides an overall reduction of volume flow rates. Finally, the flow rate\nlimitation method can introduce new, higher flow rate peaks, reducing\nperformance.\n","authors":["Felix Agner","Ulrich Trabert","Anders Rantzer","Janybek Orozaliev"],"pdf_url":"https://arxiv.org/pdf/2403.16738v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16727v1","updated":"2024-03-25T13:01:29Z","published":"2024-03-25T13:01:29Z","title":"SIS epidemics on open networks: A replacement-based approximation","summary":"  In this paper we analyze continuous-time SIS epidemics subject to arrivals\nand departures of agents, by using an approximated process based on\nreplacements. In defining the SIS dynamics in an open network, we consider a\nstochastic setting in which arrivals and departures take place according to\nPoisson processes with similar rates, and the new value of the infection\nprobability of an arriving agent is drawn from a continuous distribution. Since\nthe system size changes with time, we define an approximated process, in which\nreplacements take place instead of arrivals and departures, and we focus on the\nevolution of an aggregate measure of the level of infection. So long as the\nreproduction number is less than one, the long-term behavior of this function\nmeasures the impact of the changes of the set of agents in the epidemic. We\nderive upper bounds for the expectation and variance of this function and we\ninclude a numerical example to show that the approximated process is close to\nthe original SIS process.\n","authors":["Renato Vizuete","Paolo Frasca","Elena Panteley"],"pdf_url":"https://arxiv.org/pdf/2403.16727v1.pdf","comment":"7 pages, 2 figures, to appear in European Control Conference (ECC\n  2024)"},{"id":"http://arxiv.org/abs/2403.16711v1","updated":"2024-03-25T12:49:09Z","published":"2024-03-25T12:49:09Z","title":"Predictable Interval MDPs through Entropy Regularization","summary":"  Regularization of control policies using entropy can be instrumental in\nadjusting predictability of real-world systems. Applications benefiting from\nsuch approaches range from, e.g., cybersecurity, which aims at maximal\nunpredictability, to human-robot interaction, where predictable behavior is\nhighly desirable. In this paper, we consider entropy regularization for\ninterval Markov decision processes (IMDPs). IMDPs are uncertain MDPs, where\ntransition probabilities are only known to belong to intervals. Lately, IMDPs\nhave gained significant popularity in the context of abstracting stochastic\nsystems for control design. In this work, we address robust minimization of the\nlinear combination of entropy and a standard cumulative cost in IMDPs, thereby\nestablishing a trade-off between optimality and predictability. We show that\noptimal deterministic policies exist, and devise a value-iteration algorithm to\ncompute them. The algorithm solves a number of convex programs at each step.\nFinally, through an illustrative example we show the benefits of penalizing\nentropy in IMDPs.\n","authors":["Menno van Zutphen","Giannis Delimpaltadakis","Maurice Heemels","Duarte Antunes"],"pdf_url":"https://arxiv.org/pdf/2403.16711v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16696v1","updated":"2024-03-25T12:27:24Z","published":"2024-03-25T12:27:24Z","title":"BatDeck: Advancing Nano-drone Navigation with Low-power Ultrasound-based\n  Obstacle Avoidance","summary":"  Nano-drones, distinguished by their agility, minimal weight, and\ncost-effectiveness, are particularly well-suited for exploration in confined,\ncluttered and narrow spaces. Recognizing transparent, highly reflective or\nabsorbing materials, such as glass and metallic surfaces is challenging, as\nclassical sensors, such as cameras or laser rangers, often do not detect them.\nInspired by bats, which can fly at high speeds in complete darkness with the\nhelp of ultrasound, this paper introduces \\textit{BatDeck}, a pioneering\nsensor-deck employing a lightweight and low-power ultrasonic sensor for\nnano-drone autonomous navigation. This paper first provides insights about\nsensor characteristics, highlighting the influence of motor noise on the\nultrasound readings, then it introduces the results of extensive experimental\ntests for obstacle avoidance (OA) in a diverse environment. Results show that\n\\textit{BatDeck} allows exploration for a flight time of 8 minutes while\ncovering 136m on average before crash in a challenging environment with\ntransparent and reflective obstacles, proving the effectiveness of ultrasonic\nsensors for OA on nano-drones.\n","authors":["Hanna Müller","Victor Kartsch","Michele Magno","Luca Benini"],"pdf_url":"https://arxiv.org/pdf/2403.16696v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2311.08321v2","updated":"2024-03-25T11:48:53Z","published":"2023-11-14T17:05:49Z","title":"Peak Estimation of Rational Systems using Convex Optimization","summary":"  This paper presents algorithms that upper-bound the peak value of a state\nfunction along trajectories of a continuous-time system with rational dynamics.\nThe finite-dimensional but nonconvex peak estimation problem is cast as a\nconvex infinite-dimensional linear program in occupation measures. This\ninfinite-dimensional program is then truncated into finite-dimensions using the\nmoment-Sum-of-Squares (SOS) hierarchy of semidefinite programs. Prior work on\ntreating rational dynamics using the moment-SOS approach involves clearing\ndynamics to common denominators or adding lifting variables to handle\nreciprocal terms under new equality constraints. Our solution method uses a\nsum-of-rational method based on absolute continuity of measures. The Moment-SOS\ntruncations of our program possess lower computational complexity and\n(empirically demonstrated) higher accuracy of upper bounds on example systems\nas compared to prior approaches.\n","authors":["Jared Miller","Roy S. Smith"],"pdf_url":"https://arxiv.org/pdf/2311.08321v2.pdf","comment":"9 pages, 2 figures, 4 tables"},{"id":"http://arxiv.org/abs/2403.16652v1","updated":"2024-03-25T11:40:32Z","published":"2024-03-25T11:40:32Z","title":"Trajectory Planning of Robotic Manipulator in Dynamic Environment\n  Exploiting DRL","summary":"  This study is about the implementation of a reinforcement learning algorithm\nin the trajectory planning of manipulators. We have a 7-DOF robotic arm to pick\nand place the randomly placed block at a random target point in an unknown\nenvironment. The obstacle is randomly moving which creates a hurdle in picking\nthe object. The objective of the robot is to avoid the obstacle and pick the\nblock with constraints to a fixed timestamp. In this literature, we have\napplied a deep deterministic policy gradient (DDPG) algorithm and compared the\nmodel's efficiency with dense and sparse rewards.\n","authors":["Osama Ahmad","Zawar Hussain","Hammad Naeem"],"pdf_url":"https://arxiv.org/pdf/2403.16652v1.pdf","comment":"Accepted in ICIESTR-2024"},{"id":"http://arxiv.org/abs/2403.16634v1","updated":"2024-03-25T11:22:38Z","published":"2024-03-25T11:22:38Z","title":"Symbolic and User-friendly Geometric Algebra Routines (SUGAR) for\n  Computations in Matlab","summary":"  Geometric algebra (GA) is a mathematical tool for geometric computing,\nproviding a framework that allows a unified and compact approach to geometric\nrelations which in other mathematical systems are typically described using\ndifferent more complicated elements. This fact has led to an increasing\nadoption of GA in applied mathematics and engineering problems. However, the\nscarcity of symbolic implementations of GA and its inherent complexity,\nrequiring a specific mathematical background, make it challenging and less\nintuitive for engineers to work with. This prevents wider adoption among more\napplied professionals. To address this challenge, this paper introduces SUGAR\n(Symbolic and User-friendly Geometric Algebra Routines), an open-source toolbox\ndesigned for Matlab and licensed under the MIT License. SUGAR facilitates the\ntranslation of GA concepts into Matlab and provides a collection of\nuser-friendly functions tailored for GA computations, including support for\nsymbolic operations. It supports both numeric and symbolic computations in\nhigh-dimensional GAs. Specifically tailored for applied mathematics and\nengineering applications, SUGAR has been meticulously engineered to represent\ngeometric elements and transformations within two and three-dimensional\nprojective and conformal geometric algebras, aligning with established\ncomputational methodologies in the literature. Furthermore, SUGAR efficiently\nhandles functions of multivectors, such as exponential, logarithmic,\nsinusoidal, and cosine functions, enhancing its applicability across various\nengineering domains, including robotics, control systems, and power\nelectronics. Finally, this work includes four distinct validation examples,\ndemonstrating SUGAR's capabilities across the above-mentioned fields and its\npractical utility in addressing real-world applied mathematics and engineering\nproblems.\n","authors":["Manel Velasco","Isiah Zaplana","Arnau Dória-Cerezo","Pau Martí"],"pdf_url":"https://arxiv.org/pdf/2403.16634v1.pdf","comment":"33 pages, 6 figures, journal paper submitted to ACM TOMS"},{"id":"http://arxiv.org/abs/2403.16619v1","updated":"2024-03-25T10:51:30Z","published":"2024-03-25T10:51:30Z","title":"Guided Bayesian Optimization: Data-Efficient Controller Tuning with\n  Digital Twin","summary":"  This article presents the guided Bayesian optimization algorithm as an\nefficient data-driven method for iteratively tuning closed-loop controller\nparameters using an event-triggered digital twin of the system based on\navailable closed-loop data. We define a controller tuning framework independent\nof the controller or the plant structure. Our proposed methodology is\nmodel-free, making it suitable for nonlinear and unmodelled plants with\nmeasurement noise. The objective function consists of performance metrics\nmodeled by Gaussian processes. We utilize the available information in the\nclosed-loop system to identify and progressively maintain a digital twin that\nguides the optimizer, improving the data efficiency of our method. Switching\nthe digital twin on and off is triggered by data-driven criteria related to the\ndigital twin's uncertainty estimations in the BO tuning framework. Effectively,\nit replaces much of the exploration of the real system with exploration\nperformed on the digital twin. We analyze the properties of our method in\nsimulation and demonstrate its performance on two real closed-loop systems with\ndifferent plant and controller structures. The experimental results show that\nour method requires fewer experiments on the physical plant than Bayesian\noptimization to find the optimal controller parameters.\n","authors":["Mahdi Nobar","Jürg Keller","Alisa Rupenyan","Mohammad Khosravi","John Lygeros"],"pdf_url":"https://arxiv.org/pdf/2403.16619v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2310.00262v2","updated":"2024-03-25T10:45:50Z","published":"2023-09-30T05:26:42Z","title":"Robust Integral Consensus Control of Multi-Agent Networks Perturbed by\n  Matched and Unmatched Disturbances: The Case of Directed Graphs","summary":"  This work presents a new method to design consensus controllers for perturbed\ndouble integrator systems whose interconnection is described by a directed\ngraph containing a rooted spanning tree. We propose new robust controllers to\nsolve the consensus and synchronization problems when the systems are under the\neffects of matched and unmatched disturbances. In both problems, we present\nsimple continuous controllers, whose integral actions allow us to handle the\ndisturbances. A rigorous stability analysis based on Lyapunov's direct method\nfor unperturbed networked systems is presented. To assess the performance of\nour result, a representative simulation study is presented.\n","authors":["Jose Guadalupe Romero","David Navarro-Alarcon"],"pdf_url":"https://arxiv.org/pdf/2310.00262v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16595v1","updated":"2024-03-25T10:16:51Z","published":"2024-03-25T10:16:51Z","title":"The Adaptive Workplace: Orchestrating Architectural Services around the\n  Wellbeing of Individual Occupants","summary":"  As the academic consortia members of the EU Horizon project SONATA\n(\"Situation-aware OrchestratioN of AdapTive Architecture\"), we respond to the\nworkshop call for \"Office Wellbeing by Design: Don't Stand for Anything Less\"\nby proposing the \"Adaptive Workplace\" concept. In essence, our vision aims to\nadapt a workplace to the ever-changing needs of individual occupants, instead\nof that occupants are expected to adapt to their workplace.\n","authors":["Andrew Vande Moere","Sara Arko","Alena Safrova Drasilova","Tomáš Ondráček","Ilaria Pigliautile","Benedetta Pioppi","Anna Laura Pisello","Jakub Prochazka","Paula Acuna Roncancio","Davide Schaumann","Marcel Schweiker","Binh Vinh Duc Nguyen"],"pdf_url":"https://arxiv.org/pdf/2403.16595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16593v1","updated":"2024-03-25T10:09:42Z","published":"2024-03-25T10:09:42Z","title":"Counter-example guided Imitation Learning of Feedback Controllers from\n  Temporal Logic Specifications","summary":"  We present a novel method for imitation learning for control requirements\nexpressed using Signal Temporal Logic (STL). More concretely we focus on the\nproblem of training a neural network to imitate a complex controller. The\nlearning process is guided by efficient data aggregation based on\ncounter-examples and a coverage measure. Moreover, we introduce a method to\nevaluate the performance of the learned controller via parameterization and\nparameter estimation of the STL requirements. We demonstrate our approach with\na flying robot case study.\n","authors":["Thao Dang","Alexandre Donzé","Inzemamul Haque","Nikolaos Kekatos","Indranil Saha"],"pdf_url":"https://arxiv.org/pdf/2403.16593v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16585v1","updated":"2024-03-25T09:53:59Z","published":"2024-03-25T09:53:59Z","title":"Sparsity-Constrained Linear Quadratic Regulation Problem: Greedy\n  Approach with Performance Guarantee","summary":"  We study a linear quadratic regulation problem with a constraint where the\ncontrol input can be nonzero only at a limited number of times. Given that this\nconstraint leads to a combinational optimization problem, we adopt a greedy\nmethod to find a suboptimal solution. To quantify the performance of the greedy\nalgorithm, we employ two metrics that reflect the submodularity level of the\nobjective function: The submodularity ratio and curvature. We first present an\nexplicit form of the optimal control input that is amenable to evaluating these\nmetrics. Subsequently, we establish bounds on the submodularity ratio and\ncurvature, which enable us to offer a practical performance guarantee for the\ngreedy algorithm. The effectiveness of our guarantee is further demonstrated\nthrough numerical simulations.\n","authors":["Shumpei Nishida","Kunihisa Okano"],"pdf_url":"https://arxiv.org/pdf/2403.16585v1.pdf","comment":"8 pages, 3 figures"},{"id":"http://arxiv.org/abs/2403.16565v1","updated":"2024-03-25T09:32:29Z","published":"2024-03-25T09:32:29Z","title":"Decoupling parameter variation from noise: Biquadratic Lyapunov forms in\n  data-driven LPV control","summary":"  A promising step from linear towards nonlinear data-driven control is via the\ndesign of controllers for linear parameter-varying (LPV) systems, which are\nlinear systems whose parameters are varying along a measurable scheduling\nsignal. However, the interplay between uncertainty arising from corrupted data\nand the parameter-varying nature of these systems impacts the stability\nanalysis, and limits the generalization of well-understood data-driven methods\nfor linear time-invariant systems. In this work, we decouple this interplay\nusing a recently developed variant of the Fundamental Lemma for LPV systems and\nthe viewpoint of data-informativity, in combination with biquadratic Lyapunov\nforms. Together, these allow us to develop novel linear matrix inequality\nconditions for the existence of scheduling-dependent Lyapunov functions,\nincorporating the intrinsic nonlinearity. Appealingly, these results are stated\npurely in terms of the collected data and bounds on the noise, and they are\ncomputationally favorable to check.\n","authors":["Chris Verhoek","Jaap Eising","Florian Dörfler","Roland Tóth"],"pdf_url":"https://arxiv.org/pdf/2403.16565v1.pdf","comment":"Submitted for CDC 2024"},{"id":"http://arxiv.org/abs/2403.16555v1","updated":"2024-03-25T09:10:57Z","published":"2024-03-25T09:10:57Z","title":"Hybrid low-dimensional limiting state of charge estimator for multi-cell\n  lithium-ion batteries","summary":"  The state of charge (SOC) of lithium-ion batteries needs to be accurately\nestimated for safety and reliability purposes. For battery packs made of a\nlarge number of cells, it is not always feasible to design one SOC estimator\nper cell due to limited computational resources. Instead, only the minimum and\nthe maximum SOC need to be estimated. The challenge is that the cells having\nminimum and maximum SOC typically change over time. In this context, we present\na low-dimensional hybrid estimator of the minimum (maximum) SOC, whose\nconvergence is analytically guaranteed. We consider for this purpose a battery\nconsisting of cells interconnected in series, which we model by electric\nequivalent circuit models. We then present the hybrid estimator, which runs an\nobserver designed for a single cell at any time instant, selected by a\nswitching-like logic mechanism. We establish a practical exponential stability\nproperty for the estimation error on the minimum (maximum) SOC thereby\nguaranteeing the ability of the hybrid scheme to generate accurate estimates of\nthe minimum (maximum) SOC. The analysis relies on non-smooth hybrid Lyapunov\ntechniques. A numerical illustration is provided to showcase the relevance of\nthe proposed approach.\n","authors":["Mira Khalil","Romain Postoyan","Stéphane Raël","Dragan Nešić"],"pdf_url":"https://arxiv.org/pdf/2403.16555v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.07039v2","updated":"2024-03-25T07:35:27Z","published":"2023-11-13T02:42:43Z","title":"Time-Optimal Control for High-Order Chain-of-Integrators Systems with\n  Full State Constraints and Arbitrary Terminal States (Part I, Extended\n  Version)","summary":"  Time-optimal control for high-order chain-of-integrators systems with full\nstate constraints and arbitrary given terminal states remains a challenging\nproblem in the optimal control theory domain, yet to be resolved. To enhance\nfurther comprehension of the problem, this paper establishes a novel notation\nsystem and theoretical framework, providing the switching manifold for\nhigh-order problems in the form of switching laws. Through deriving properties\nof switching laws on signs and dimension, this paper proposes a definite\ncondition for time-optimal control. Guided by the developed theory, a\ntrajectory planning method named the manifold-intercept method (MIM) is\ndeveloped. The proposed MIM can plan time-optimal jerk-limited trajectories\nwith full state constraints, and can also plan near-optimal non-chattering\nhigher-order trajectories with negligible extra motion time compared to optimal\nprofiles. Numerical results indicate that the proposed MIM outperforms all\nbaselines in computational time, computational accuracy, and trajectory quality\nby a large gap.\n","authors":["Yunan Wang","Chuxiong Hu","Zeyang Li","Shize Lin","Suqin He","Ze Wang","Yu Zhu"],"pdf_url":"https://arxiv.org/pdf/2311.07039v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16489v1","updated":"2024-03-25T07:17:44Z","published":"2024-03-25T07:17:44Z","title":"Spatially temporally distributed informative path planning for\n  multi-robot systems","summary":"  This paper investigates the problem of informative path planning for a mobile\nrobotic sensor network in spatially temporally distributed mapping. The robots\nare able to gather noisy measurements from an area of interest during their\nmovements to build a Gaussian Process (GP) model of a spatio-temporal field.\nThe model is then utilized to predict the spatio-temporal phenomenon at\ndifferent points of interest. To spatially and temporally navigate the group of\nrobots so that they can optimally acquire maximal information gains while their\nconnectivity is preserved, we propose a novel multistep prediction informative\npath planning optimization strategy employing our newly defined local cost\nfunctions. By using the dual decomposition method, it is feasible and practical\nto effectively solve the optimization problem in a distributed manner. The\nproposed method was validated through synthetic experiments utilizing\nreal-world data sets.\n","authors":["Binh Nguyen","Linh Nguyen","Truong X. Nghiem","Hung La","Jose Baca","Pablo Rangel","Miguel Cid Montoya","Thang Nguyen"],"pdf_url":"https://arxiv.org/pdf/2403.16489v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16488v1","updated":"2024-03-25T07:16:08Z","published":"2024-03-25T07:16:08Z","title":"Ensuring Disturbance Rejection Performance by Synthesizing\n  Grid-Following and Grid-Forming Inverters in Power Systems","summary":"  To meet the dynamic requirement of power systems, it is imperative for\ngrid-connected inverters to ensure good disturbance rejection performance (DRP)\nunder variable grid conditions. This letter discovers and theoretically proves\nthat for the general networks, synthesizing grid-following (GFL) inverters and\ngrid-forming (GFM) inverters can more effectively ensure the DRP of multiple\ninverters, compared to homogeneous inverter-based systems that solely use\neither GFL or GFM inverters. The combination of GFL inverters and GFM inverters\ncan concurrently increases the smallest eigenvalue and decreases the largest\neigenvalue of the grounded network Laplacian matrix. This can be equivalent to\nrematching the proper short-circuit ratio (SCR) for GFL and GFM inverters,\nthereby ensuring the DRP of inverters both in weak and strong grids. The result\nreveals the necessity of synthesizing diverse inverter control schemes from the\nnetwork-based perspective. Sensitivity function-based analysis and real-time\nsimulations confirm the effectiveness of our results.\n","authors":["Fuyilong Ma","Huanhai Xin","Zhiyi Li","Linbin Huang"],"pdf_url":"https://arxiv.org/pdf/2403.16488v1.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2403.16470v1","updated":"2024-03-25T06:52:26Z","published":"2024-03-25T06:52:26Z","title":"Data-Driven Extrusion Force Control Tuning for 3D Printing","summary":"  The quality of 3D prints often varies due to different conditions inherent to\neach print, such as filament type, print speed, and nozzle size. Closed-loop\nprocess control methods improve the accuracy and repeatability of 3D prints.\nHowever, optimal tuning of controllers for given process parameters and design\ngeometry is often a challenge with manually tuned controllers resulting in\ninconsistent and suboptimal results. This work employs Bayesian optimization to\nidentify the optimal controller parameters. Additionally, we explore transfer\nlearning in the context of 3D printing by leveraging prior information from\npast trials. By integrating optimized extrusion force control and transfer\nlearning, we provide a novel framework for closed-loop 3D printing and propose\nan automated calibration routine that produces high-quality prints for a\ndesired combination of print settings, material, and shape.\n","authors":["Xavier Guidetti","Ankita Mukne","Marvin Rueppel","Yannick Nagel","Efe C. Balta","John Lygeros"],"pdf_url":"https://arxiv.org/pdf/2403.16470v1.pdf","comment":"Submitted to IEEE CASE 2024"},{"id":"http://arxiv.org/abs/2308.02921v3","updated":"2024-03-25T05:54:29Z","published":"2023-08-05T16:54:59Z","title":"PowerSimulationsDynamics.jl -- An Open Source Modeling Package for\n  Modern Power Systems with Inverter-Based Resources","summary":"  In this paper we present the development of an open-source simulation\ntoolbox, PowerSimulationsDynamics.jl, to study the dynamic response of power\nsystems, focusing on the requirements to model systems with high penetrations\nof Inverter-Based Resources (IBRs). PowerSimulationsDynamics.jl is implemented\nin Julia and features a rich library of synchronous generator, inverter, and\nload models. In addition, it allows the study of quasi-static phasors and\nelectromagnetic dq models that use a dynamic network representation. Case\nstudies and validation exercises show that PowerSimulationsDynamics.jl results\nclosely match other commercial and open-source simulation tools.\n","authors":["Jose Daniel Lara","Rodrigo Henriquez-Auba","Matthew Bossart","Duncan S. Callaway","Clayton Barrows"],"pdf_url":"https://arxiv.org/pdf/2308.02921v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.02306v3","updated":"2024-03-25T05:35:08Z","published":"2024-01-04T14:55:03Z","title":"Secure Control of Connected and Automated Vehicles Using Trust-Aware\n  Robust Event-Triggered Control Barrier Functions","summary":"  We address the security of a network of Connected and Automated Vehicles\n(CAVs) cooperating to safely navigate through a conflict area (e.g., traffic\nintersections, merging roadways, roundabouts). Previous studies have shown that\nsuch a network can be targeted by adversarial attacks causing traffic jams or\nsafety violations ending in collisions. We focus on attacks targeting the V2X\ncommunication network used to share vehicle data and consider as well\nuncertainties due to noise in sensor measurements and communication channels.\nTo combat these, motivated by recent work on the safe control of CAVs, we\npropose a trust-aware robust event-triggered decentralized control and\ncoordination framework that can provably guarantee safety. We maintain a trust\nmetric for each vehicle in the network computed based on their behavior and\nused to balance the tradeoff between conservativeness (when deeming every\nvehicle as untrustworthy) and guaranteed safety and security. It is important\nto highlight that our framework is invariant to the specific choice of the\ntrust framework. Based on this framework, we propose an attack detection and\nmitigation scheme which has twofold benefits: (i) the trust framework is immune\nto false positives, and (ii) it provably guarantees safety against false\npositive cases. We use extensive simulations (in SUMO and CARLA) to validate\nthe theoretical guarantees and demonstrate the efficacy of our proposed scheme\nto detect and mitigate adversarial attacks.\n","authors":["H M Sabbir Ahmad","Ehsan Sabouni","Akua Dickson","Wei Xiao","Christos G. Cassandras","Wenchao Li"],"pdf_url":"https://arxiv.org/pdf/2401.02306v3.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2305.16818"},{"id":"http://arxiv.org/abs/2311.08942v2","updated":"2024-03-25T04:41:13Z","published":"2023-11-15T13:27:17Z","title":"Thermally-Resilient Soft Gripper for On-Orbit Operations","summary":"  Research in soft manipulators has significantly enhanced object grasping\ncapabilities, thanks to their adaptability to various shapes and sizes.\nApplying this technology to on-orbit servicing, especially during the capture\nand containment stages of active space debris removal missions, might offer a\nsecure, adaptable, and cost-effective solution compared to the trend of\nincreasing the degrees of freedom and complexity of the manipulator (e.g.\nClearSpace, Astroscale). This work aims to conduct an experimental proof of\nconcept, for which challenges such as radiation, vacuum, and microgravity are\nsignificant, but the predominant issue is ensuring effective operation in the\nextreme temperature swings, where flexible materials may exhibit cryogenic\ncrystallization or drastic shifts in their elasticity. This work addresses this\nchallenge through an initial stage of analytical modeling of the thermal\ndynamics inside the manipulator in orbit; which is then used for the\ndevelopment of a first experimental prototype tested with liquid nitrogen and\nheat guns. The multi-layered design for Low Earth Orbit (LEO) leverages the\nproperties of TPU at low infill rates for lightweight inherent flexibility,\nsilicone rubber ensuring structural integrity, PTFE (Teflon) for unparalleled\nthermal stability, and aerogel for insulation. The tendon-actuated servo-driven\ngripper is tested in the laboratory by varying the shape and size of objects\nduring the grasping. The results, based on servomotor force metrics to assess\nthe flexible manipulator's adaptability and object capture efficiency across\ntemperature changes, affirm the concept's viability. Forces increase up to\n220$\\%$ in cryogenic conditions and decrease by no more than 50$\\%$ at high\ntemperatures.\n","authors":["Fernando Ruiz","Begona Arrue","Anibal Ollero"],"pdf_url":"https://arxiv.org/pdf/2311.08942v2.pdf","comment":"Submitted to IROS 2024"},{"id":"http://arxiv.org/abs/2403.16411v1","updated":"2024-03-25T04:11:52Z","published":"2024-03-25T04:11:52Z","title":"A Geometric Perspective on Fusing Gaussian Distributions on Lie Groups","summary":"  Stochastic inference on Lie groups plays a key role in state estimation\nproblems, such as inertial navigation, visual inertial odometry, pose\nestimation in virtual reality, etc. A key problem is fusing independent\nconcentrated Gaussian distributions defined at different reference points on\nthe group. In this paper we approximate distributions at different points in\nthe group in a single set of exponential coordinates and then use classical\nGaussian fusion to obtain the fused posteriori in those coordinates. We\nconsider several approximations including the exact Jacobian of the change of\ncoordinate map, first and second order Taylor's expansions of the Jacobian, and\nparallel transport with and without curvature correction associated with the\nunderlying geometry of the Lie group. Preliminary results on SO(3) demonstrate\nthat a novel approximation using parallel transport with curvature correction\nachieves similar accuracy to the state-of-the-art optimisation based algorithms\nat a fraction of the computational cost.\n","authors":["Yixiao Ge","Pieter van Goor","Robert Mahony"],"pdf_url":"https://arxiv.org/pdf/2403.16411v1.pdf","comment":"Preprint for L-CSS"},{"id":"http://arxiv.org/abs/2403.16402v1","updated":"2024-03-25T03:38:23Z","published":"2024-03-25T03:38:23Z","title":"A Distributionally Robust Model Predictive Control for Static and\n  Dynamic Uncertainties in Smart Grids","summary":"  The integration of various power sources, including renewables and electric\nvehicles, into smart grids is expanding, introducing uncertainties that can\nresult in issues like voltage imbalances, load fluctuations, and power losses.\nThese challenges negatively impact the reliability and stability of online\nscheduling in smart grids. Existing research often addresses uncertainties\naffecting current states but overlooks those that impact future states, such as\nthe unpredictable charging patterns of electric vehicles. To distinguish\nbetween these, we term them static uncertainties and dynamic uncertainties,\nrespectively. This paper introduces WDR-MPC, a novel approach that stands for\ntwo-stage Wasserstein-based Distributionally Robust (WDR) optimization within a\nModel Predictive Control (MPC) framework, aimed at effectively managing both\ntypes of uncertainties in smart grids. The dynamic uncertainties are first\nreformulated into ambiguity tubes and then the distributionally robust bounds\nof both dynamic and static uncertainties can be established using WDR\noptimization. By employing ambiguity tubes and WDR optimization, the stochastic\nMPC system is converted into a nominal one. Moreover, we develop a convex\nreformulation method to speed up WDR computation during the two-stage\noptimization. The distinctive contribution of this paper lies in its holistic\napproach to both static and dynamic uncertainties in smart grids. Comprehensive\nexperiment results on IEEE 38-bus and 94-bus systems reveal the method's\nsuperior performance and the potential to enhance grid stability and\nreliability.\n","authors":["Qi Li","Ye Shi","Yuning Jiang","Yuanming Shi","Haoyu Wang","H. Vincent Poor"],"pdf_url":"https://arxiv.org/pdf/2403.16402v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16391v1","updated":"2024-03-25T03:13:56Z","published":"2024-03-25T03:13:56Z","title":"Physics-informed RL for Maximal Safety Probability Estimation","summary":"  Accurate risk quantification and reachability analysis are crucial for safe\ncontrol and learning, but sampling from rare events, risky states, or long-term\ntrajectories can be prohibitively costly. Motivated by this, we study how to\nestimate the long-term safety probability of maximally safe actions without\nsufficient coverage of samples from risky states and long-term trajectories.\nThe use of maximal safety probability in control and learning is expected to\navoid conservative behaviors due to over-approximation of risk. Here, we first\nshow that long-term safety probability, which is multiplicative in time, can be\nconverted into additive costs and be solved using standard reinforcement\nlearning methods. We then derive this probability as solutions of partial\ndifferential equations (PDEs) and propose Physics-Informed Reinforcement\nLearning (PIRL) algorithm. The proposed method can learn using sparse rewards\nbecause the physics constraints help propagate risk information through\nneighbors. This suggests that, for the purpose of extracting more information\nfor efficient learning, physics constraints can serve as an alternative to\nreward shaping. The proposed method can also estimate long-term risk using\nshort-term samples and deduce the risk of unsampled states. This feature is in\nstark contrast with the unconstrained deep RL that demands sufficient data\ncoverage. These merits of the proposed method are demonstrated in numerical\nsimulation.\n","authors":["Hikaru Hoshino","Yorie Nakahira"],"pdf_url":"https://arxiv.org/pdf/2403.16391v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.02609v3","updated":"2024-03-25T01:50:40Z","published":"2023-09-05T22:53:37Z","title":"Directionality-Aware Mixture Model Parallel Sampling for Efficient\n  Linear Parameter Varying Dynamical System Learning","summary":"  The Linear Parameter Varying Dynamical System (LPV-DS) is an effective\napproach that learns stable, time-invariant motion policies using statistical\nmodeling and semi-definite optimization to encode complex motions for reactive\nrobot control. Despite its strengths, the LPV-DS learning approach faces\nchallenges in achieving a high model accuracy without compromising the\ncomputational efficiency. To address this, we introduce the\nDirectionality-Aware Mixture Model (DAMM), a novel statistical model that\napplies the Riemannian metric on the n-sphere $\\mathbb{S}^n$ to efficiently\nblend non-Euclidean directional data with $\\mathbb{R}^m$ Euclidean states.\nAdditionally, we develop a hybrid Markov chain Monte Carlo technique that\ncombines Gibbs Sampling with Split/Merge Proposal, allowing for parallel\ncomputation to drastically speed up inference. Our extensive empirical tests\ndemonstrate that LPV-DS integrated with DAMM achieves higher reproduction\naccuracy, better model efficiency, and near real-time/online learning compared\nto standard estimation methods on various datasets. Lastly, we demonstrate its\nsuitability for incrementally learning multi-behavior policies in real-world\nrobot experiments.\n","authors":["Sunan Sun","Haihui Gao","Tianyu Li","Nadia Figueroa"],"pdf_url":"https://arxiv.org/pdf/2309.02609v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.00237v2","updated":"2024-03-25T01:14:56Z","published":"2024-03-01T02:37:11Z","title":"Stable Reduced-Rank VAR Identification","summary":"  The vector autoregression (VAR) has been widely used in system\nidentification, econometrics, natural science, and many other areas. However,\nwhen the state dimension becomes large the parameter dimension explodes. So\nrank reduced modelling is attractive and is well developed. But a fundamental\nrequirement in almost all applications is stability of the fitted model. And\nthis has not been addressed in the rank reduced case. Here, we develop, for the\nfirst time, a closed-form formula for an estimator of a rank reduced transition\nmatrix which is guaranteed to be stable. We show that our estimator is\nconsistent and asymptotically statistically efficient and illustrate it in\ncomparative simulations.\n","authors":["Xinhui Rong","Victor Solo"],"pdf_url":"https://arxiv.org/pdf/2403.00237v2.pdf","comment":"16 pages, 6 figures"},{"id":"http://arxiv.org/abs/2403.17272v1","updated":"2024-03-25T23:34:22Z","published":"2024-03-25T23:34:22Z","title":"Optimal Operation of Reconfigurable Active Distribution Networks Aiming\n  at Resiliency Improvement","summary":"  As natural disasters bring about power outage and financial losses, network\nresiliency is an important challenge for distribution network operators (DNOs).\nOn the other side, power loss reduction during normal operating condition is a\nmajor concern of DNOs. In this paper, optimal scheduling of active distribution\nnetwork (ADN) is addressed through simultaneous minimization of power loss in\nnormal condition and load shedding in critical condition after natural\ndisasters. A new formulation is developed for the network reconfiguration to\noptimize the system operation in both normal and emergency conditions in the\npresence of conventional and renewable-energy-based distributed generation (DG)\nas well as energy storage systems (ESSs). The line flow based (LFB) algorithm\nis used for the AC power flow calculations, and all the developed relations\nhave been convexified to construct a mixed-integer quadratically-constrained\nprogramming (MIQCP) optimization model. The simulations have been implemented\non the IEEE 33-bus system in GAMS, and the results are investigated.\n","authors":["Saeed Behzadi","Amir Bagheri","Abbas Rabiee"],"pdf_url":"https://arxiv.org/pdf/2403.17272v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17249v1","updated":"2024-03-25T22:51:27Z","published":"2024-03-25T22:51:27Z","title":"Impact-Aware Bimanual Catching of Large-Momentum Objects","summary":"  This paper investigates one of the most challenging tasks in dynamic\nmanipulation -- catching large-momentum moving objects. Beyond the realm of\nquasi-static manipulation, dealing with highly dynamic objects can\nsignificantly improve the robot's capability of interacting with its\nsurrounding environment. Yet, the inevitable motion mismatch between the fast\nmoving object and the approaching robot will result in large impulsive forces,\nwhich lead to the unstable contacts and irreversible damage to both the object\nand the robot. To address the above problems, we propose an online optimization\nframework to: 1) estimate and predict the linear and angular motion of the\nobject; 2) search and select the optimal contact locations across every surface\nof the object to mitigate impact through sequential quadratic programming\n(SQP); 3) simultaneously optimize the end-effector motion, stiffness, and\ncontact force for both robots using multi-mode trajectory optimization (MMTO);\nand 4) realise the impact-aware catching motion on the compliant robotic system\nbased on indirect force controller. We validate the impulse distribution,\ncontact selection, and impact-aware MMTO algorithms in simulation and\ndemonstrate the benefits of the proposed framework in real-world experiments\nincluding catching large-momentum moving objects with well-defined motion,\nconstrained motion and free-flying motion.\n","authors":["Lei Yan","Theodoros Stouraitis","João Moura","Wenfu Xu","Michael Gienger","Sethu Vijayakumar"],"pdf_url":"https://arxiv.org/pdf/2403.17249v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17247v1","updated":"2024-03-25T22:49:56Z","published":"2024-03-25T22:49:56Z","title":"DASA: Delay-Adaptive Multi-Agent Stochastic Approximation","summary":"  We consider a setting in which $N$ agents aim to speedup a common Stochastic\nApproximation (SA) problem by acting in parallel and communicating with a\ncentral server. We assume that the up-link transmissions to the server are\nsubject to asynchronous and potentially unbounded time-varying delays. To\nmitigate the effect of delays and stragglers while reaping the benefits of\ndistributed computation, we propose \\texttt{DASA}, a Delay-Adaptive algorithm\nfor multi-agent Stochastic Approximation. We provide a finite-time analysis of\n\\texttt{DASA} assuming that the agents' stochastic observation processes are\nindependent Markov chains. Significantly advancing existing results,\n\\texttt{DASA} is the first algorithm whose convergence rate depends only on the\nmixing time $\\tmix$ and on the average delay $\\tau_{avg}$ while jointly\nachieving an $N$-fold convergence speedup under Markovian sampling. Our work is\nrelevant for various SA applications, including multi-agent and distributed\ntemporal difference (TD) learning, Q-learning and stochastic optimization with\ncorrelated data.\n","authors":["Nicolo Dal Fabbro","Arman Adibi","H. Vincent Poor","Sanjeev R. Kulkarni","Aritra Mitra","George J. Pappas"],"pdf_url":"https://arxiv.org/pdf/2403.17247v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.11800v2","updated":"2024-03-25T22:48:22Z","published":"2024-02-19T03:08:02Z","title":"Stochastic Approximation with Delayed Updates: Finite-Time Rates under\n  Markovian Sampling","summary":"  Motivated by applications in large-scale and multi-agent reinforcement\nlearning, we study the non-asymptotic performance of stochastic approximation\n(SA) schemes with delayed updates under Markovian sampling. While the effect of\ndelays has been extensively studied for optimization, the manner in which they\ninteract with the underlying Markov process to shape the finite-time\nperformance of SA remains poorly understood. In this context, our first main\ncontribution is to show that under time-varying bounded delays, the delayed SA\nupdate rule guarantees exponentially fast convergence of the \\emph{last\niterate} to a ball around the SA operator's fixed point. Notably, our bound is\n\\emph{tight} in its dependence on both the maximum delay $\\tau_{max}$, and the\nmixing time $\\tau_{mix}$. To achieve this tight bound, we develop a novel\ninductive proof technique that, unlike various existing delayed-optimization\nanalyses, relies on establishing uniform boundedness of the iterates. As such,\nour proof may be of independent interest. Next, to mitigate the impact of the\nmaximum delay on the convergence rate, we provide the first finite-time\nanalysis of a delay-adaptive SA scheme under Markovian sampling. In particular,\nwe show that the exponent of convergence of this scheme gets scaled down by\n$\\tau_{avg}$, as opposed to $\\tau_{max}$ for the vanilla delayed SA rule; here,\n$\\tau_{avg}$ denotes the average delay across all iterations. Moreover, the\nadaptive scheme requires no prior knowledge of the delay sequence for step-size\ntuning. Our theoretical findings shed light on the finite-time effects of\ndelays for a broad class of algorithms, including TD learning, Q-learning, and\nstochastic gradient descent under Markovian sampling.\n","authors":["Arman Adibi","Nicolo Dal Fabbro","Luca Schenato","Sanjeev Kulkarni","H. Vincent Poor","George J. Pappas","Hamed Hassani","Aritra Mitra"],"pdf_url":"https://arxiv.org/pdf/2402.11800v2.pdf","comment":"Accepted to the 27th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2024!"},{"id":"http://arxiv.org/abs/2403.17235v1","updated":"2024-03-25T22:25:03Z","published":"2024-03-25T22:25:03Z","title":"A Discrete-Time Least-Squares Adaptive State Tracking Control Scheme\n  with A Mobile-Robot System Study","summary":"  This paper develops an adaptive state tracking control scheme for\ndiscrete-time systems, using the least-squares algorithm, as the new solution\nto the long-standing discrete-time adaptive state tracking control problem to\nwhich the Lyapunov method (well-developed for the continuous-time adaptive\nstate tracking problem) is not applicable. The new adaptive state tracking\nscheme is based on a recently-developed new discrete-time error model which has\nbeen used for gradient algorithm based state tracking control schemes, and uses\nthe least-squares algorithm for parameter adaptation. The new least-squares\nalgorithm is derived to minimize an accumulative estimation error, to ensure\ncertain optimality for parameter estimation. The system stability and output\ntracking properties are studied. Technical results are presented in terms of\nplant-model matching, error model, adaptive law, optimality formulation, and\nstability and tracking analysis. The developed adaptive control scheme is\napplied to a discrete-time multiple mobile robot system to meet an adaptive\nstate tracking objective. In addition, a collision avoidance mechanism is\nproposed to prevent collisions in the whole tracking process. Simulation\nresults are presented, which verify the desired system state tracking\nproperties under the developed least-squares algorithm based adaptive control\nscheme.\n","authors":["Qianhong Zhao","Gang Tao"],"pdf_url":"https://arxiv.org/pdf/2403.17235v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17233v1","updated":"2024-03-25T22:20:45Z","published":"2024-03-25T22:20:45Z","title":"Active Learning of Dynamics Using Prior Domain Knowledge in the Sampling\n  Process","summary":"  We present an active learning algorithm for learning dynamics that leverages\nside information by explicitly incorporating prior domain knowledge into the\nsampling process. Our proposed algorithm guides the exploration toward regions\nthat demonstrate high empirical discrepancy between the observed data and an\nimperfect prior model of the dynamics derived from side information. Through\nnumerical experiments, we demonstrate that this strategy explores regions of\nhigh discrepancy and accelerates learning while simultaneously reducing model\nuncertainty. We rigorously prove that our active learning algorithm yields a\nconsistent estimate of the underlying dynamics by providing an explicit rate of\nconvergence for the maximum predictive variance. We demonstrate the efficacy of\nour approach on an under-actuated pendulum system and on the half-cheetah\nMuJoCo environment.\n","authors":["Kevin S. Miller","Adam J. Thorpe","Ufuk Topcu"],"pdf_url":"https://arxiv.org/pdf/2403.17233v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06157v5","updated":"2024-03-25T21:23:11Z","published":"2023-06-10T23:50:02Z","title":"Fault Localization for Buggy Deep Learning Framework Conversions in\n  Image Recognition","summary":"  When deploying Deep Neural Networks (DNNs), developers often convert models\nfrom one deep learning framework to another (e.g., TensorFlow to PyTorch).\nHowever, this process is error-prone and can impact target model accuracy. To\nidentify the extent of such impact, we perform and briefly present a\ndifferential analysis against three DNNs widely used for image recognition\n(MobileNetV2, ResNet101, and InceptionV3) converted across four well-known deep\nlearning frameworks (PyTorch, Keras, TensorFlow (TF), and TFLite), which\nrevealed numerous model crashes and output label discrepancies of up to 100%.\nTo mitigate such errors, we present a novel approach towards fault localization\nand repair of buggy deep learning framework conversions, focusing on\npre-trained image recognition models. Our technique consists of four stages of\nanalysis: 1) conversion tools, 2) model parameters, 3) model hyperparameters,\nand 4) graph representation. In addition, we propose various strategies towards\nfault repair of the faults detected. We implement our technique on top of the\nApache TVM deep learning compiler, and we test it by conducting a preliminary\nfault localization analysis for the conversion of InceptionV3 from TF to\nTFLite. Our approach detected a fault in a common DNN converter tool, which\nintroduced precision errors in weights, reducing model accuracy. After our\nfault localization, we repaired the issue, reducing our conversion error to\nzero.\n","authors":["Nikolaos Louloudakis","Perry Gibson","José Cano","Ajitha Rajan"],"pdf_url":"https://arxiv.org/pdf/2306.06157v5.pdf","comment":"5 pages, 3 figures, 1 table"},{"id":"http://arxiv.org/abs/2306.06208v5","updated":"2024-03-25T21:08:25Z","published":"2023-06-05T23:07:01Z","title":"DeltaNN: Assessing the Impact of Computational Environment Parameters on\n  the Performance of Image Recognition Models","summary":"  Image recognition tasks typically use deep learning and require enormous\nprocessing power, thus relying on hardware accelerators like GPUs and TPUs for\nfast, timely processing. Failure in real-time image recognition tasks can occur\ndue to sub-optimal mapping on hardware accelerators during model deployment,\nwhich may lead to timing uncertainty and erroneous behavior. Mapping on\nhardware accelerators is done using multiple software components like deep\nlearning frameworks, compilers, and device libraries, that we refer to as the\ncomputational environment. Owing to the increased use of image recognition\ntasks in safety-critical applications like autonomous driving and medical\nimaging, it is imperative to assess their robustness to changes in the\ncomputational environment, as the impact of parameters like deep learning\nframeworks, compiler optimizations, and hardware devices on model performance\nand correctness is not yet well understood.\n  In this paper we present a differential testing framework, DeltaNN, that\nallows us to assess the impact of different computational environment\nparameters on the performance of image recognition models during deployment,\npost training. DeltaNN generates different implementations of a given image\nrecognition model for variations in environment parameters, namely, deep\nlearning frameworks, compiler optimizations and hardware devices and analyzes\ndifferences in model performance as a result. Using DeltaNN, we conduct an\nempirical study of robustness analysis of three popular image recognition\nmodels using the ImageNet dataset. We report the impact in terms of\nmisclassifications and inference time differences across different settings. In\ntotal, we observed up to 100% output label differences across deep learning\nframeworks, and up to 81% unexpected performance degradation in terms of\ninference time, when applying compiler optimizations.\n","authors":["Nikolaos Louloudakis","Perry Gibson","José Cano","Ajitha Rajan"],"pdf_url":"https://arxiv.org/pdf/2306.06208v5.pdf","comment":"11 pages, 10 figures, 2 tables"},{"id":"http://arxiv.org/abs/2403.17191v1","updated":"2024-03-25T21:02:51Z","published":"2024-03-25T21:02:51Z","title":"High-dimensional continuification control of large-scale multi-agent\n  systems under limited sensing and perturbations","summary":"  This paper investigates the robustness of a novel high-dimensional\ncontinuification control method for complex multi-agent systems. We begin by\nformulating a partial differential equation describing the spatio-temporal\ndensity dynamics of swarming agents. A stable control action for the density is\nthen derived and validated under nominal conditions. Subsequently, we\ndiscretize this macroscopic strategy into actionable velocity inputs for the\nsystem's agents. Our analysis demonstrates the robustness of the approach\nbeyond idealized assumptions of unlimited sensing and absence of perturbations.\n","authors":["Gian Carlo Maffettone","Mario di Bernardo","Maurizio Porfiri"],"pdf_url":"https://arxiv.org/pdf/2403.17191v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2310.01573"},{"id":"http://arxiv.org/abs/2403.17184v1","updated":"2024-03-25T20:53:17Z","published":"2024-03-25T20:53:17Z","title":"Robust Finite-time Stabilization of Linear Systems with Limited State\n  Quantization","summary":"  This paper investigates the robust asymptotic stabilization of a linear\ntime-invariant (LTI) system by a static feedback with a static state\nquantization. It is shown that the controllable LTI system can be stabilized to\nzero in a finite time by means of a nonlinear feedback with a quantizer having\na limited (finite) number of values (quantization seeds) even when all\nparameters of the controller and the quantizer are time-invariant. The control\ndesign is based on generalized homogeneity. A homogeneous spherical quantizer\nis introduced. The static homogeneous feedback is shown to be local (or global)\nfinite-time stabilizer for the linear system (dependently of the system\nmatrix). The tuning rules for both the quantizer and the feedback law are\nobtained in the form of Linear Matrix Inequalities (LMIs). The closed-loop\nsystem is proven to be robust with respect to some bounded matched and\nvanishing mismatched perturbations. Theoretical results are supported by\nnumerical simulations. \\\n","authors":["Yu Zhou","Andrey Polyakov","Gang Zheng"],"pdf_url":"https://arxiv.org/pdf/2403.17184v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17174v1","updated":"2024-03-25T20:43:17Z","published":"2024-03-25T20:43:17Z","title":"Belief Samples Are All You Need For Social Learning","summary":"  In this paper, we consider the problem of social learning, where a group of\nagents embedded in a social network are interested in learning an underlying\nstate of the world. Agents have incomplete, noisy, and heterogeneous sources of\ninformation, providing them with recurring private observations of the\nunderlying state of the world. Agents can share their learning experience with\ntheir peers by taking actions observable to them, with values from a finite\nfeasible set of states. Actions can be interpreted as samples from the beliefs\nwhich agents may form and update on what the true state of the world is.\nSharing samples, in place of full beliefs, is motivated by the limited\ncommunication, cognitive, and information-processing resources available to\nagents especially in large populations. Previous work (Salhab et al.) poses the\nquestion as to whether learning with probability one is still achievable if\nagents are only allowed to communicate samples from their beliefs. We provide a\ndefinite positive answer to this question, assuming a strongly connected\nnetwork and a ``collective distinguishability'' assumption, which are both\nrequired for learning even in full-belief-sharing settings. In our proposed\nbelief update mechanism, each agent's belief is a normalized weighted geometric\ninterpolation between a fully Bayesian private belief -- aggregating\ninformation from the private source -- and an ensemble of empirical\ndistributions of the samples shared by her neighbors over time. By carefully\nconstructing asymptotic almost-sure lower/upper bounds on the frequency of\nshared samples matching the true state/or not, we rigorously prove the\nconvergence of all the beliefs to the true state, with probability one.\n","authors":["Mahyar JafariNodeh","Amir Ajorlou","Ali Jadbabaie"],"pdf_url":"https://arxiv.org/pdf/2403.17174v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2403.17157v1","updated":"2024-03-25T20:16:05Z","published":"2024-03-25T20:16:05Z","title":"Output-feedback Synthesis Orbit Geometry: Quotient Manifolds and LQG\n  Direct Policy Optimization","summary":"  In this paper, we consider direct policy optimization for the\nlinear-quadratic Gaussian (LQG) setting. Over the past few years, it has been\nrecognized that the landscape of stabilizing output-feedback controllers of\nrelevance to LQG has an intricate geometry, particularly as it pertains to the\nexistence of spurious stationary points. In order to address such challenges,\nin this paper, we first adopt a Riemannian metric for the space of stabilizing\nfull-order minimal output-feedback controllers. We then proceed to prove that\nthe orbit of such controllers modulo coordinate transformation admits a\nRiemannian quotient manifold structure. This geometric structure is then used\nto develop a Riemannian gradient descent for the direct LQG policy\noptimization. We prove a local convergence guarantee with linear rate and show\nthe proposed approach exhibits significantly faster and more robust numerical\nperformance as compared with ordinary gradient descent for LQG. Subsequently,\nwe provide reasons for this observed behavior; in particular, we argue that\noptimizing over the orbit space of controllers is the right theoretical and\ncomputational setup for direct LQG policy optimization.\n","authors":["Spencer Kraisler","Mehran Mesbahi"],"pdf_url":"https://arxiv.org/pdf/2403.17157v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17142v1","updated":"2024-03-25T19:39:17Z","published":"2024-03-25T19:39:17Z","title":"Approximation with Random Shallow ReLU Networks with Applications to\n  Model Reference Adaptive Control","summary":"  Neural networks are regularly employed in adaptive control of nonlinear\nsystems and related methods o reinforcement learning. A common architecture\nuses a neural network with a single hidden layer (i.e. a shallow network), in\nwhich the weights and biases are fixed in advance and only the output layer is\ntrained. While classical results show that there exist neural networks of this\ntype that can approximate arbitrary continuous functions over bounded regions,\nthey are non-constructive, and the networks used in practice have no\napproximation guarantees. Thus, the approximation properties required for\ncontrol with neural networks are assumed, rather than proved. In this paper, we\naim to fill this gap by showing that for sufficiently smooth functions, ReLU\nnetworks with randomly generated weights and biases achieve $L_{\\infty}$ error\nof $O(m^{-1/2})$ with high probability, where $m$ is the number of neurons. It\nsuffices to generate the weights uniformly over a sphere and the biases\nuniformly over an interval. We show how the result can be used to get\napproximations of required accuracy in a model reference adaptive control\napplication.\n","authors":["Andrew Lamperski","Tyler Lekang"],"pdf_url":"https://arxiv.org/pdf/2403.17142v1.pdf","comment":"Under Review for Conference on Decision and Control"},{"id":"http://arxiv.org/abs/2310.13843v2","updated":"2024-03-25T19:36:52Z","published":"2023-10-20T22:32:42Z","title":"Long Solution Times or Low Solution Quality: On Trade-Offs in Choosing a\n  Power Flow Formulation for the Optimal Power Shutoff Problem","summary":"  The Optimal Power Shutoff (OPS) problem is an optimization problem that makes\npower line de-energization decisions in order to reduce the risk of igniting a\nwildfire, while minimizing the load shed of customers. This problem, with DC\nlinear power flow equations, has been used in many studies in recent years.\nHowever, using linear approximations for power flow when making decisions on\nthe network topology is known to cause challenges with AC feasibility of the\nresulting network, as studied in the related contexts of optimal transmission\nswitching or grid restoration planning. This paper explores the accuracy of the\nDC OPS formulation and the ability to recover an AC-feasible power flow\nsolution after de-energization decisions are made. We also extend the OPS\nproblem to include variants with the AC, Second-Order-Cone, and Network-Flow\npower flow equations, and compare them to the DC approximation with respect to\nsolution quality and time. The results highlight that the DC approximation\noverestimates the amount of load that can be served, leading to poor\nde-energization decisions. The AC and SOC-based formulations are better, but\nprohibitively slow to solve for even modestly sized networks thus demonstrating\nthe need for new solution methods with better trade-offs between computational\ntime and solution quality.\n","authors":["Eric Haag","Noah Rhodes","Line Roald"],"pdf_url":"https://arxiv.org/pdf/2310.13843v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17136v1","updated":"2024-03-25T19:18:25Z","published":"2024-03-25T19:18:25Z","title":"Adaptive Step Duration for Precise Foot Placement: Achieving Robust\n  Bipedal Locomotion on Terrains with Restricted Footholds","summary":"  This paper introduces a novel multi-step preview foot placement planning\nalgorithm designed to enhance the robustness of bipedal robotic walking across\nchallenging terrains with restricted footholds. Traditional one-step preview\nplanning struggles to maintain stability when stepping areas are severely\nlimited, such as with random stepping stones. In this work, we developed a\ndiscrete-time Model Predictive Control (MPC) based on the step-to-step discrete\nevolution of the Divergent Component of Motion (DCM) of bipedal locomotion.\nThis approach adaptively changes the step duration for optimal foot placement\nunder constraints, thereby ensuring the robot's operational viability over\nmultiple future steps and significantly improving its ability to navigate\nthrough environments with tight constraints on possible footholds. The\neffectiveness of this planning algorithm is demonstrated through simulations\nthat include a variety of complex stepping-stone configurations and external\nperturbations. These tests underscore the algorithm's improved performance for\nnavigating foothold-restricted environments, even with the presence of external\ndisturbances.\n","authors":["Zhaoyang Xiang","Victor Paredes","Ayonga Hereid"],"pdf_url":"https://arxiv.org/pdf/2403.17136v1.pdf","comment":"8 pages, 8 figures, submitted to CDC 2024, for associated simulation\n  video, see https://youtu.be/2jhikPlZmbE"},{"id":"http://arxiv.org/abs/2311.07462v2","updated":"2024-03-25T19:02:47Z","published":"2023-11-13T16:44:43Z","title":"Investigating Robustness in Cyber-Physical Systems:\n  Specification-Centric Analysis in the face of System Deviations","summary":"  The adoption of cyber-physical systems (CPS) is on the rise in complex\nphysical environments, encompassing domains such as autonomous vehicles, the\nInternet of Things (IoT), and smart cities. A critical attribute of CPS is\nrobustness, denoting its capacity to operate safely despite potential\ndisruptions and uncertainties in the operating environment. This paper proposes\na novel specification-based robustness, which characterizes the effectiveness\nof a controller in meeting a specified system requirement, articulated through\nSignal Temporal Logic (STL) while accounting for possible deviations in the\nsystem. This paper also proposes the robustness falsification problem based on\nthe definition, which involves identifying minor deviations capable of\nviolating the specified requirement. We present an innovative two-layer\nsimulation-based analysis framework designed to identify subtle robustness\nviolations. To assess our methodology, we devise a series of benchmark problems\nwherein system parameters can be adjusted to emulate various forms of\nuncertainties and disturbances. Initial evaluations indicate that our\nfalsification approach proficiently identifies robustness violations, providing\nvaluable insights for comparing robustness between conventional and\nreinforcement learning (RL)-based controllers\n","authors":["Changjian Zhang","Parv Kapoor","Romulo Meira-Goes","David Garlan","Eunsuk Kang","Akila Ganlath","Shatadal Mishra","Nejib Ammar"],"pdf_url":"https://arxiv.org/pdf/2311.07462v2.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2004.01041v8","updated":"2024-03-25T18:21:39Z","published":"2020-04-01T06:37:54Z","title":"On the Feedback Law in Stochastic Optimal Nonlinear Control","summary":"  We consider the problem of nonlinear stochastic optimal control. This problem\nis thought to be fundamentally intractable owing to Bellman's ``curse of\ndimensionality\". We present a result that shows that repeatedly solving an\nopen-loop deterministic problem from the current state with progressively\nshorter horizons, similar to Model Predictive Control (MPC), results in a\nfeedback policy that is $O(\\epsilon^4)$ near to the true global stochastic\noptimal policy, \\nxx{where $\\epsilon$ is a perturbation parameter modulating\nthe noise.} We show that the optimal deterministic feedback problem has a\nperturbation structure in that higher-order terms of the feedback law do not\naffect lower-order terms, and that this structure is lost in the optimal\nstochastic feedback problem. Consequently, solving the Stochastic Dynamic\nProgramming problem is highly susceptible to noise, even when tractable, and in\npractice, the MPC-type feedback law offers superior performance even for\nstochastic systems.\n","authors":["Mohamed Naveed Gul Mohamed","Suman Chakravorty","Raman Goyal","Ran Wang"],"pdf_url":"https://arxiv.org/pdf/2004.01041v8.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2002.10505,\n  arXiv:2002.09478"},{"id":"http://arxiv.org/abs/2403.14092v2","updated":"2024-03-25T17:49:07Z","published":"2024-03-21T02:59:56Z","title":"Carbon Footprint Reduction for Sustainable Data Centers in Real-Time","summary":"  As machine learning workloads significantly increase energy consumption,\nsustainable data centers with low carbon emissions are becoming a top priority\nfor governments and corporations worldwide. This requires a paradigm shift in\noptimizing power consumption in cooling and IT loads, shifting flexible loads\nbased on the availability of renewable energy in the power grid, and leveraging\nbattery storage from the uninterrupted power supply in data centers, using\ncollaborative agents. The complex association between these optimization\nstrategies and their dependencies on variable external factors like weather and\nthe power grid carbon intensity makes this a hard problem. Currently, a\nreal-time controller to optimize all these goals simultaneously in a dynamic\nreal-world setting is lacking. We propose a Data Center Carbon Footprint\nReduction (DC-CFR) multi-agent Reinforcement Learning (MARL) framework that\noptimizes data centers for the multiple objectives of carbon footprint\nreduction, energy consumption, and energy cost. The results show that the\nDC-CFR MARL agents effectively resolved the complex interdependencies in\noptimizing cooling, load shifting, and energy storage in real-time for various\nlocations under real-world dynamic weather and grid carbon intensity\nconditions. DC-CFR significantly outperformed the industry standard ASHRAE\ncontroller with a considerable reduction in carbon emissions (14.5%), energy\nusage (14.4%), and energy cost (13.7%) when evaluated over one year across\nmultiple geographical regions.\n","authors":["Soumyendu Sarkar","Avisek Naug","Ricardo Luna","Antonio Guillen","Vineet Gundecha","Sahand Ghorbanpour","Sajad Mousavi","Dejan Markovikj","Ashwin Ramesh Babu"],"pdf_url":"https://arxiv.org/pdf/2403.14092v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16982v1","updated":"2024-03-25T17:43:50Z","published":"2024-03-25T17:43:50Z","title":"State-Augmented Linear Games with Antagonistic Error for\n  High-Dimensional, Nonlinear Hamilton-Jacobi Reachability","summary":"  Hamilton-Jacobi Reachability (HJR) is a popular method for analyzing the\nliveness and safety of a dynamical system with bounded control and disturbance.\nThe corresponding HJ value function offers a robust controller and\ncharacterizes the reachable sets, but is traditionally solved with Dynamic\nProgramming (DP) and limited to systems of dimension less than six. Recently,\nthe space-parallelizeable, generalized Hopf formula has been shown to also\nsolve the HJ value with a nearly three-log increase in dimension limit, but is\nlimited to linear systems. To extend this potential, we demonstrate how\nstate-augmented (SA) spaces, which are well-known for their improved\nlinearization accuracy, may be used to solve tighter, conservative\napproximations of the value function with any linear model in this SA space.\nNamely, we show that with a representation of the true dynamics in the SA\nspace, a series of inequalities confirms that the value of a SA linear game\nwith antagonistic error is a conservative envelope of the true value function.\nIt follows that if the optimal controller for the HJ SA linear game with error\nmay succeed, it will also succeed in the true system. Unlike previous methods,\nthis result offers the ability to safely approximate reachable sets and their\ncorresponding controllers with the Hopf formula in a non-convex manner.\nFinally, we demonstrate this in the slow manifold system for clarity, and in\nthe controlled Van der Pol system with different lifting functions.\n","authors":["Will Sharpless","Yat Tin Chow","Sylvia Herbert"],"pdf_url":"https://arxiv.org/pdf/2403.16982v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16979v1","updated":"2024-03-25T17:41:52Z","published":"2024-03-25T17:41:52Z","title":"An Optimal Solution to Infinite Horizon Nonlinear Control Problems: Part\n  II","summary":"  This paper considers the infinite horizon optimal control problem for\nnonlinear systems. Under the condition of nonlinear controllability of the\nsystem to any terminal set containing the origin and forward invariance of the\nterminal set, we establish a regularized solution approach consisting of a\n``finite free final time\" optimal transfer problem to the terminal set which\nrenders the set globally asymptotically stable. Further, we show that the\napproximations converge to the optimal infinite horizon cost as the size of the\nterminal set decreases to zero. We also perform the analysis for the discounted\nproblem and show that the terminal set is asymptotically stable only for a\nsubset of the state space and not globally. The theory is empirically evaluated\non various nonholonomic robotic systems to show that the cost of our\napproximate problem converges and the transfer time into the terminal set is\ndependent on the initial state of the system, necessitating the free final time\nformulation.\n","authors":["Mohamed Naveed Gul Mohamed","Aayushman Sharma","Raman Goyal","Suman Chakravorty"],"pdf_url":"https://arxiv.org/pdf/2403.16979v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16956v1","updated":"2024-03-25T17:17:35Z","published":"2024-03-25T17:17:35Z","title":"Bayesian Methods for Trust in Collaborative Multi-Agent Autonomy","summary":"  Multi-agent, collaborative sensor fusion is a vital component of a\nmulti-national intelligence toolkit. In safety-critical and/or contested\nenvironments, adversaries may infiltrate and compromise a number of agents. We\nanalyze state of the art multi-target tracking algorithms under this\ncompromised agent threat model. We prove that the track existence probability\ntest (\"track score\") is significantly vulnerable to even small numbers of\nadversaries. To add security awareness, we design a trust estimation framework\nusing hierarchical Bayesian updating. Our framework builds beliefs of trust on\ntracks and agents by mapping sensor measurements to trust pseudomeasurements\n(PSMs) and incorporating prior trust beliefs in a Bayesian context. In case\nstudies, our trust estimation algorithm accurately estimates the\ntrustworthiness of tracks/agents, subject to observability limitations.\n","authors":["R. Spencer Hallyburton","Miroslav Pajic"],"pdf_url":"https://arxiv.org/pdf/2403.16956v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16900v1","updated":"2024-03-25T16:11:29Z","published":"2024-03-25T16:11:29Z","title":"Spline Trajectory Tracking and Obstacle Avoidance for Mobile Agents via\n  Convex Optimization","summary":"  We propose an output feedback control-based motion planning technique for\nagents to enable them to converge to a specified polynomial trajectory while\nimposing a set of safety constraints on our controller to avoid collisions\nwithin the free configuration space (polygonal environment). To achieve this,\nwe 1) decompose our polygonal environment into different overlapping cells 2)\nwrite out our polynomial trajectories as the output of a reference dynamical\nsystem with given initial conditions 3) formulate convergence and safety\nconstraints as Linear Matrix Inequalities (LMIs) on our controller using\nControl Lyapunov Functions (CLFs) and Control Barrier Functions (CBFs) and 4)\nsolve a semi-definite programming (SDP) problem with convergence and safety\nconstraints imposed to synthesize a controller for each convex cell. Extensive\nsimulations are included to test our motion planning method under different\ninitial conditions and different reference trajectories. The synthesized\ncontroller is robust to changes in initial conditions and is always safe\nrelative to the boundaries of the polygonal environment.\n","authors":["Akua Dickson","Christos G. Cassandras","Roberto Tron"],"pdf_url":"https://arxiv.org/pdf/2403.16900v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16899v1","updated":"2024-03-25T16:10:47Z","published":"2024-03-25T16:10:47Z","title":"State Space Models as Foundation Models: A Control Theoretic Overview","summary":"  In recent years, there has been a growing interest in integrating linear\nstate-space models (SSM) in deep neural network architectures of foundation\nmodels. This is exemplified by the recent success of Mamba, showing better\nperformance than the state-of-the-art Transformer architectures in language\ntasks. Foundation models, like e.g. GPT-4, aim to encode sequential data into a\nlatent space in order to learn a compressed representation of the data. The\nsame goal has been pursued by control theorists using SSMs to efficiently model\ndynamical systems. Therefore, SSMs can be naturally connected to deep sequence\nmodeling, offering the opportunity to create synergies between the\ncorresponding research areas. This paper is intended as a gentle introduction\nto SSM-based architectures for control theorists and summarizes the latest\nresearch developments. It provides a systematic review of the most successful\nSSM proposals and highlights their main features from a control theoretic\nperspective. Additionally, we present a comparative analysis of these models,\nevaluating their performance on a standardized benchmark designed for assessing\na model's efficiency at learning long sequences.\n","authors":["Carmen Amo Alonso","Jerome Sieber","Melanie N. Zeilinger"],"pdf_url":"https://arxiv.org/pdf/2403.16899v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.08318v2","updated":"2024-03-25T16:06:34Z","published":"2023-06-14T07:38:01Z","title":"Identification of Energy Management Configuration Concepts from a Set of\n  Pareto-optimal Solutions","summary":"  Implementing resource efficient energy management systems in facilities and\nbuildings becomes increasingly important in the transformation to a sustainable\nsociety. However, selecting a suitable configuration based on multiple,\ntypically conflicting objectives, such as cost, robustness with respect to\nuncertainty of grid operation, or renewable energy utilization, is a difficult\nmulti-criteria decision making problem. The recently developed concept\nidentification technique can facilitate a decision maker by sorting\nconfiguration options into semantically meaningful groups (concepts). In this\nprocess, the partitioning of the objectives and design parameters into\ndifferent sets (called description spaces) is a very important step. In this\nstudy we focus on utilizing the concept identification technique for finding\nrelevant and viable energy management configurations from a very large data set\nof Pareto-optimal solutions. The data set consists of 20000 realistic\nPareto-optimal building energy management configurations generated by a\nmany-objective evolutionary optimization of a high quality Digital Twin energy\nmanagement simulator. We analyze how the choice of description spaces, i.e.,\nthe partitioning of the objectives and parameters, impacts the type of\ninformation that can be extracted. We show that the decision maker can\nintroduce constraints and biases into that process to meet expectations and\npreferences. The iterative approach presented in this work allows for the\ngeneration of valuable insights into trade-offs between specific objectives,\nand constitutes a powerful and flexible tool to support the decision making\nprocess when designing large and complex energy management systems.\n","authors":["Felix Lanfermann","Qiqi Liu","Yaochu Jin","Sebastian Schmitt"],"pdf_url":"https://arxiv.org/pdf/2306.08318v2.pdf","comment":"18 pages, 8 figures, accepted at Energy Conversion and Management: X"},{"id":"http://arxiv.org/abs/2403.16859v1","updated":"2024-03-25T15:23:14Z","published":"2024-03-25T15:23:14Z","title":"A Semi-Lagrangian Approach for Time and Energy Path Planning\n  Optimization in Static Flow Fields","summary":"  Efficient path planning for autonomous mobile robots is a critical problem\nacross numerous domains, where optimizing both time and energy consumption is\nparamount. This paper introduces a novel methodology that considers the dynamic\ninfluence of an environmental flow field and considers geometric constraints,\nincluding obstacles and forbidden zones, enriching the complexity of the\nplanning problem. We formulate it as a multi-objective optimal control problem,\npropose a novel transformation called Harmonic Transformation, and apply a\nsemi-Lagrangian scheme to solve it. The set of Pareto efficient solutions is\nobtained considering two distinct approaches: a deterministic method and an\nevolutionary-based one, both of which are designed to make use of the proposed\nHarmonic Transformation. Through an extensive analysis of these approaches, we\ndemonstrate their efficacy in finding optimized paths.\n","authors":["Víctor C. da S. Campos","Armando A. Neto","Douglas G. Macharet"],"pdf_url":"https://arxiv.org/pdf/2403.16859v1.pdf","comment":"12 pages, initial paper submission; Preprint submitted to the IEEE\n  Transactions on Intelligent Transportation Systems"},{"id":"http://arxiv.org/abs/2403.16855v1","updated":"2024-03-25T15:18:23Z","published":"2024-03-25T15:18:23Z","title":"Semantic-Aware Remote Estimation of Multiple Markov Sources Under\n  Constraints","summary":"  This paper studies semantic-aware communication for remote estimation of\nmultiple Markov sources over a lossy and rate-constrained channel. Unlike most\nexisting studies that treat all source states equally, we exploit the semantics\nof information and consider that the remote actuator has different tolerances\nfor the estimation errors of different states. We aim to find an optimal\nscheduling policy that minimizes the long-term state-dependent costs of\nestimation errors under a transmission frequency constraint. We theoretically\nshow the structure of the optimal policy by leveraging the average-cost\nConstrained Markov Decision Process (CMDP) theory and the Lagrangian dynamic\nprogramming. By exploiting the optimal structural results, we develop a novel\npolicy search algorithm, termed intersection search plus relative value\niteration (Insec-RVI), that can find the optimal policy using only a few\niterations. To avoid the ``curse of dimensionality'' of MDPs, we propose an\nonline low-complexity drift-plus-penalty (DPP) scheduling algorithm based on\nthe Lyapunov optimization theorem. We also design an efficient average-cost\nQ-learning algorithm to estimate the optimal policy without knowing a priori\nthe channel and source statistics. Numerical results show that continuous\ntransmission is inefficient, and remarkably, our semantic-aware policies can\nattain the optimum by strategically utilizing fewer transmissions by exploiting\nthe timing of the important information.\n","authors":["Jiping Luo","Nikolaos Pappas"],"pdf_url":"https://arxiv.org/pdf/2403.16855v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16836v1","updated":"2024-03-25T14:59:11Z","published":"2024-03-25T14:59:11Z","title":"Energy Efficiency Optimization Method of WDM Visible Light Communication\n  System for Indoor Broadcasting Networks","summary":"  This paper introduces a novel approach to optimize energy efficiency in\nwavelength division multiplexing (WDM) Visible Light Communication (VLC)\nsystems designed for indoor broadcasting networks. A physics-based LED model is\nintegrated into system energy efficiency optimization, enabling quantitative\nanalysis of the critical issue of VLC energy efficiency: the nonlinear\ninterplay between illumination and communication performance. The optimization\njointly incorporates constraints on communication quality of each channel, and\nillumination performance, standardized by the International Commission on\nIllumination (CIE). The formulated nonlinear optimization problem is solved by\nthe Sequential Quadratic Programming (SQP) algorithm in an experiment-based\nsimulation. An integrated Red-Green-Blue-Yellow Light Emitting Diode (RGBY-LED)\nis measured for model calibration and three different scenarios are simulated\nto evaluate the generality of the proposed method. Results demonstrate a double\nenhancement in performance and a high versatility in accommodating various\nscenarios. Furthermore, it highlights the importance of balancing communication\nand illumination imperatives in VLC systems, challenging conventional\nperceptions focused solely on minimizing power consumption.\n","authors":["Dayu Shi","Xun Zhang","Ziqi Liu","Xuanbang Chen","Jianghao Li","Xiaodong Liu","William Shieh"],"pdf_url":"https://arxiv.org/pdf/2403.16836v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16823v1","updated":"2024-03-25T14:48:00Z","published":"2024-03-25T14:48:00Z","title":"Resource and Mobility Management in Hybrid LiFi and WiFi Networks: A\n  User-Centric Learning Approach","summary":"  Hybrid light fidelity (LiFi) and wireless fidelity (WiFi) networks (HLWNets)\nare an emerging indoor wireless communication paradigm, which combines the\nadvantages of the capacious optical spectra of LiFi and ubiquitous coverage of\nWiFi. Meanwhile, load balancing (LB) becomes a key challenge in resource\nmanagement for such hybrid networks. The existing LB methods are mostly\nnetwork-centric, relying on a central unit to make a solution for the users all\nat once. Consequently, the solution needs to be updated for all users at the\nsame pace, regardless of their moving status. This would affect the network\nperformance in two aspects: i) when the update frequency is low, it would\ncompromise the connectivity of fast-moving users; ii) when the update frequency\nis high, it would cause unnecessary handovers as well as hefty feedback costs\nfor slow-moving users. Motivated by this, we investigate user-centric LB which\nallows users to update their solutions at different paces. The research is\ndeveloped upon our previous work on adaptive target-condition neural network\n(ATCNN), which can conduct LB for individual users in quasi-static channels. In\nthis paper, a deep neural network (DNN) model is designed to enable an adaptive\nupdate interval for each individual user. This new model is termed as\nmobility-supporting neural network (MSNN). Associating MSNN with ATCNN, a\nuser-centric LB framework named mobility-supporting ATCNN (MS-ATCNN) is\nproposed to handle resource management and mobility management simultaneously.\nResults show that at the same level of average update interval, MS-ATCNN can\nachieve a network throughput up to 215\\% higher than conventional LB methods\nsuch as game theory, especially for a larger number of users. In addition,\nMS-ATCNN costs an ultra low runtime at the level of 100s $\\mu$s, which is two\nto three orders of magnitude lower than game theory.\n","authors":["Han Ji","Xiping Wu"],"pdf_url":"https://arxiv.org/pdf/2403.16823v1.pdf","comment":"12 pages, 12 figures, 3 tables, submitted to IEEE TWC"},{"id":"http://arxiv.org/abs/2403.16821v1","updated":"2024-03-25T14:47:16Z","published":"2024-03-25T14:47:16Z","title":"Scheduling Power-Intensive Operations of Battery Energy Storage Systems\n  and Application to Hybrid Hydropower Plants","summary":"  Classical schedulers for Battery Energy Storage Systems (BESSs) use static\npower constraints, assuming that the BESS can provide the rated power at any\nState-Of-Charge (SOC) level and that these are representative of the underlying\nphysical constraints of the system (BESS voltage and current). Static power\nconstraints, however, can generate unfeasible schedules, especially in\npower-intensive applications, as demonstrated in this paper. This paper derives\na set of alternative constraints for the BESS power that are cognizant of the\nphysical limits of the BESS. It is shown that these constraints, developed by\nleveraging an equivalent circuit model of the BESS, can be formulated as linear\ninequalities in scheduling problems, thus leaving the properties of the\noriginal problem (i.e., linearity and convexity) unaltered. A comparative\nanalysis against traditional schedulers from the literature shows significant\nreductions in current violations and the generation of feasible schedules.\nThese findings underscore the crucial role of implementing more advanced power\nconstraints of BESSs in power-intensive applications, thereby enhancing the\nreliability of BESS scheduling strategies.\n","authors":["Stefano Cassano","Fabrizio Sossan"],"pdf_url":"https://arxiv.org/pdf/2403.16821v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.00670v2","updated":"2024-03-25T14:37:40Z","published":"2024-01-01T05:20:43Z","title":"Hybrid physics-informed metabolic cybergenetics: process rates augmented\n  with machine-learning surrogates informed by flux balance analysis","summary":"  Metabolic cybergenetics is a promising concept that interfaces gene\nexpression and cellular metabolism with computers for real-time dynamic\nmetabolic control. The focus is on control at the transcriptional level,\nserving as a means to modulate intracellular metabolic fluxes. Recent\nstrategies in this field have employed constraint-based dynamic models for\nprocess optimization, control, and estimation. However, this results in bilevel\ndynamic optimization problems, which pose considerable numerical and conceptual\nchallenges. In this study, we present an alternative hybrid physics-informed\ndynamic modeling framework for metabolic cybergenetics, aimed at simplifying\noptimization, control, and estimation tasks. By utilizing machine-learning\nsurrogates, our approach effectively embeds the physics of metabolic networks\ninto the process rates of structurally simpler macro-kinetic models coupled\nwith gene expression. These surrogates, informed by flux balance analysis, link\nthe domains of manipulatable intracellular enzymes to metabolic exchange\nfluxes. This ensures that critical knowledge captured by the system's metabolic\nnetwork is preserved. The resulting models can be integrated into metabolic\ncybergenetic schemes involving single-level optimizations. Additionally, the\nhybrid modeling approach maintains the number of system states at a necessary\nminimum, easing the burden of process monitoring and estimation. Our hybrid\nphysics-informed metabolic cybergenetic framework is demonstrated using a\ncomputational case study on the optogenetically-assisted production of\nitaconate by $\\textit{Escherichia coli}$.\n","authors":["Sebastián Espinel-Ríos","José L. Avalos"],"pdf_url":"https://arxiv.org/pdf/2401.00670v2.pdf","comment":"25 pages, 10 figures, journal submission (reviewed/accepted version)"},{"id":"http://arxiv.org/abs/2403.16809v1","updated":"2024-03-25T14:32:28Z","published":"2024-03-25T14:32:28Z","title":"An LLM-Based Digital Twin for Optimizing Human-in-the Loop Systems","summary":"  The increasing prevalence of Cyber-Physical Systems and the Internet of\nThings (CPS-IoT) applications and Foundation Models are enabling new\napplications that leverage real-time control of the environment. For example,\nreal-time control of Heating, Ventilation and Air-Conditioning (HVAC) systems\ncan reduce its usage when not needed for the comfort of human occupants, hence\nreducing energy consumption. Collecting real-time feedback on human preferences\nin such human-in-the-loop (HITL) systems, however, is difficult in practice. We\npropose the use of large language models (LLMs) to deal with the challenges of\ndynamic environments and difficult-to-obtain data in CPS optimization. In this\npaper, we present a case study that employs LLM agents to mimic the behaviors\nand thermal preferences of various population groups (e.g. young families, the\nelderly) in a shopping mall. The aggregated thermal preferences are integrated\ninto an agent-in-the-loop based reinforcement learning algorithm AitL-RL, which\nemploys the LLM as a dynamic simulation of the physical environment to learn\nhow to balance between energy savings and occupant comfort. Our results show\nthat LLMs are capable of simulating complex population movements within large\nopen spaces. Besides, AitL-RL demonstrates superior performance compared to the\npopular existing policy of set point control, suggesting that adaptive and\npersonalized decision-making is critical for efficient optimization in CPS-IoT\napplications. Through this case study, we demonstrate the potential of\nintegrating advanced Foundation Models like LLMs into CPS-IoT to enhance system\nadaptability and efficiency. The project's code can be found on our GitHub\nrepository.\n","authors":["Hanqing Yang","Marie Siew","Carlee Joe-Wong"],"pdf_url":"https://arxiv.org/pdf/2403.16809v1.pdf","comment":"Accepted at International Workshop on Foundation Models for\n  Cyber-Physical Systems & Internet of Things (FMSys) 2024, Co-located at\n  CPS-IoT Week 2024"},{"id":"http://arxiv.org/abs/2403.16797v1","updated":"2024-03-25T14:14:39Z","published":"2024-03-25T14:14:39Z","title":"Privacy Preservation by Intermittent Transmission in Cooperative LQG\n  Control Systems","summary":"  In this paper, we study a cooperative linear quadratic Gaussian (LQG) control\nsystem with a single user and a server. In this system, the user runs a process\nand employs the server to meet the needs of computation. However, the user\nregards its state trajectories as privacy. Therefore, we propose a privacy\nscheme, in which the user sends data to the server intermittently. By this\nscheme, the server's received information of the user is reduced, and\nconsequently the user's privacy is preserved. In this paper, we consider a\nperiodic transmission scheme. We analyze the performance of privacy\npreservation and LQG control of different transmission periods. Under the given\nthreshold of the control performance loss, a trade-off optimization problem is\nproposed. Finally, we give the solution to the optimization problem.\n","authors":["Wenhao Lin","Yuqing Ni","Wen Yang","Chao Yang"],"pdf_url":"https://arxiv.org/pdf/2403.16797v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16786v1","updated":"2024-03-25T14:01:58Z","published":"2024-03-25T14:01:58Z","title":"DBPF: A Framework for Efficient and Robust Dynamic Bin-Picking","summary":"  Efficiency and reliability are critical in robotic bin-picking as they\ndirectly impact the productivity of automated industrial processes. However,\ntraditional approaches, demanding static objects and fixed collisions, lead to\ndeployment limitations, operational inefficiencies, and process unreliability.\nThis paper introduces a Dynamic Bin-Picking Framework (DBPF) that challenges\ntraditional static assumptions. The DBPF endows the robot with the reactivity\nto pick multiple moving arbitrary objects while avoiding dynamic obstacles,\nsuch as the moving bin. Combined with scene-level pose generation, the proposed\npose selection metric leverages the Tendency-Aware Manipulability Network\noptimizing suction pose determination. Heuristic task-specific designs like\nvelocity-matching, dynamic obstacle avoidance, and the resight policy, enhance\nthe picking success rate and reliability. Empirical experiments demonstrate the\nimportance of these components. Our method achieves an average 84% success\nrate, surpassing the 60% of the most comparable baseline, crucially, with zero\ncollisions. Further evaluations under diverse dynamic scenarios showcase DBPF's\nrobust performance in dynamic bin-picking. Results suggest that our framework\noffers a promising solution for efficient and reliable robotic bin-picking\nunder dynamics.\n","authors":["Yichuan Li","Junkai Zhao","Yixiao Li","Zheng Wu","Rui Cao","Masayoshi Tomizuka","Yunhui Liu"],"pdf_url":"https://arxiv.org/pdf/2403.16786v1.pdf","comment":"8 pages, 5 figures. This paper has been accepted by IEEE RA-L on\n  2024-03-24. See the supplementary video at youtube:\n  https://youtu.be/n5af2VsKhkg"},{"id":"http://arxiv.org/abs/2403.16767v1","updated":"2024-03-25T13:45:55Z","published":"2024-03-25T13:45:55Z","title":"Policy Gradient-based Model Free Optimal LQG Control with a\n  Probabilistic Risk Constraint","summary":"  In this paper, we investigate a model-free optimal control design that\nminimizes an infinite horizon average expected quadratic cost of states and\ncontrol actions subject to a probabilistic risk or chance constraint using\ninput-output data. In particular, we consider linear time-invariant systems and\ndesign an optimal controller within the class of linear state feedback control.\nThree different policy gradient (PG) based algorithms, natural policy gradient\n(NPG), Gauss-Newton policy gradient (GNPG), and deep deterministic policy\ngradient (DDPG), are developed, and compared with the optimal risk-neutral\nlinear-quadratic regulator (LQR) and a scenario-based model predictive control\n(MPC) technique via numerical simulations. The convergence properties and the\naccuracy of all the algorithms are compared numerically. We also establish\nanalytical convergence properties of the NPG and GNPG algorithms under the\nknown model scenario, while the proof of convergence for the unknown model\nscenario is part of our ongoing work.\n","authors":["Arunava Naha","Subhrakanti Dey"],"pdf_url":"https://arxiv.org/pdf/2403.16767v1.pdf","comment":"Submitted to IEEE CDC2024"},{"id":"http://arxiv.org/abs/2403.16755v1","updated":"2024-03-25T13:34:31Z","published":"2024-03-25T13:34:31Z","title":"A Blotto Game Approach to Ride-hailing Markets with Electric Vehicles","summary":"  When a centrally operated ride-hailing company considers to enter a market\nalready served by another company, it has to make a strategic decision about\nhow to distribute its fleet among different regions in the area. This decision\nwill be influenced by the market share the company can secure and the costs\nassociated with charging the vehicles in each region, all while competing with\nthe company already operating in the area. In this paper, we propose a Colonel\nBlotto-like game to model this decision-making. For the class of games that we\nstudy, we first prove the existence and uniqueness of a Nash Equilibrium.\nSubsequently, we provide its general characterization and present an algorithm\nfor computing the ones in the feasible set's interior. Additionally, for a\nsimplified scenario involving two regions, which would correspond to a city\narea with a downtown and a suburban region, we also provide a method to check\nfor the equilibria on the feasible set's boundary. Finally, through a numerical\ncase study, we illustrate the impact of charging prices on the position of the\nNash equilibrium.\n","authors":["Marko Maljkovic","Gustav Nilsson","Nikolas Geroliminis"],"pdf_url":"https://arxiv.org/pdf/2403.16755v1.pdf","comment":"Extended version of the paper accepted for presentation at the 2024\n  European Control Conference (ECC2024)"},{"id":"http://arxiv.org/abs/2207.05370v2","updated":"2024-03-25T06:33:43Z","published":"2022-07-12T08:06:17Z","title":"Joint Ranging and Phase Offset Estimation for Multiple Drones using\n  ADS-B Signatures","summary":"  A new method for joint ranging and Phase Offset (PO) estimation of multiple\ndrones/aircrafts is proposed in this paper. The proposed method employs the\nsuperimposed uncoordinated Automatic Dependent Surveillance Broadcast (ADS-B)\npackets broadcasted by drones/aircrafts for joint range and PO estimation. It\njointly estimates range and PO prior to ADS-B packet decoding; thus, it can\nimprove air safety when packet decoding is infeasible due to packet collision.\nMoreover, it enables coherent detection of ADS-B packets, which can result in\nmore reliable multiple target tracking in aviation systems using cooperative\nsensors for detect and avoid (DAA). By minimizing the Kullback Leibler\nDivergence (KLD) statistical distance measure, we show that the received\ncomplex baseband signal coming from K uncoordinated drones corrupted by\nAdditive White Gaussian Noise (AWGN) at a single antenna receiver can be\napproximated by an independent and identically distributed Gaussian Mixture\n(GM) with 2 power K mixture components in the two dimensional (2D) plane. While\ndirect joint Maximum Likelihood Estimation (MLE) of range and PO from the\nderived GM Probability Density Function (PDF) leads to an intractable\nmaximization, our proposed method employs the Expectation Maximization (EM)\nalgorithm to estimate the modes of the 2D Gaussian mixture followed by a\nreordering estimation technique through combinatorial optimization to estimate\nrange and PO. An extension to a multiple antenna receiver is also investigated\nin this paper. While the proposed estimator can estimate the range of multiple\ndrones with a single receive antenna, a larger number of drones can be\nsupported with higher accuracy by the use of multiple antennas at the receiver.\nThe effectiveness of the proposed estimator is supported by simulation results.\nWe show that the proposed estimator can jointly estimate the range of three\ndrones accurately.\n","authors":["Mostafa Mohammadkarimi","Geert Leus","Raj Thilak Rajan"],"pdf_url":"https://arxiv.org/pdf/2207.05370v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16377v1","updated":"2024-03-25T02:47:29Z","published":"2024-03-25T02:47:29Z","title":"Real-time Adaptation for Condition Monitoring Signal Prediction using\n  Label-aware Neural Processes","summary":"  Building a predictive model that rapidly adapts to real-time condition\nmonitoring (CM) signals is critical for engineering systems/units.\nUnfortunately, many current methods suffer from a trade-off between\nrepresentation power and agility in online settings. For instance, parametric\nmethods that assume an underlying functional form for CM signals facilitate\nefficient online prediction updates. However, this simplification leads to\nvulnerability to model specifications and an inability to capture complex\nsignals. On the other hand, approaches based on over-parameterized or\nnon-parametric models can excel at explaining complex nonlinear signals, but\nreal-time updates for such models pose a challenging task. In this paper, we\npropose a neural process-based approach that addresses this trade-off. It\nencodes available observations within a CM signal into a representation space\nand then reconstructs the signal's history and evolution for prediction. Once\ntrained, the model can encode an arbitrary number of observations without\nrequiring retraining, enabling on-the-spot real-time predictions along with\nquantified uncertainty and can be readily updated as more online data is\ngathered. Furthermore, our model is designed to incorporate qualitative\ninformation (i.e., labels) from individual units. This integration not only\nenhances individualized predictions for each unit but also enables joint\ninference for both signals and their associated labels. Numerical studies on\nboth synthetic and real-world data in reliability engineering highlight the\nadvantageous features of our model in real-time adaptation, enhanced signal\nprediction with uncertainty quantification, and joint prediction for labels and\nsignals.\n","authors":["Seokhyun Chung","Raed Al Kontar"],"pdf_url":"https://arxiv.org/pdf/2403.16377v1.pdf","comment":null}]},"2024-03-24T00:00:00Z":{"Robotics":[{"id":"http://arxiv.org/abs/2311.02787v2","updated":"2024-03-24T23:36:06Z","published":"2023-11-05T22:43:29Z","title":"Make a Donut: Hierarchical EMD-Space Planning for Zero-Shot Deformable\n  Manipulation with Tools","summary":"  Deformable object manipulation stands as one of the most captivating yet\nformidable challenges in robotics. While previous techniques have predominantly\nrelied on learning latent dynamics through demonstrations, typically\nrepresented as either particles or images, there exists a pertinent limitation:\nacquiring suitable demonstrations, especially for long-horizon tasks, can be\nelusive. Moreover, basing learning entirely on demonstrations can hamper the\nmodel's ability to generalize beyond the demonstrated tasks. In this work, we\nintroduce a demonstration-free hierarchical planning approach capable of\ntackling intricate long-horizon tasks without necessitating any training. We\nemploy large language models (LLMs) to articulate a high-level, stage-by-stage\nplan corresponding to a specified task. For every individual stage, the LLM\nprovides both the tool's name and the Python code to craft intermediate subgoal\npoint clouds. With the tool and subgoal for a particular stage at our disposal,\nwe present a granular closed-loop model predictive control strategy. This\nleverages Differentiable Physics with Point-to-Point correspondence\n(DiffPhysics-P2P) loss in the earth mover distance (EMD) space, applied\niteratively. Experimental findings affirm that our technique surpasses multiple\nbenchmarks in dough manipulation, spanning both short and long horizons.\nRemarkably, our model demonstrates robust generalization capabilities to novel\nand previously unencountered complex tasks without any preliminary\ndemonstrations. We further substantiate our approach with experimental trials\non real-world robotic platforms. Our project page:\nhttps://qq456cvb.github.io/projects/donut.\n","authors":["Yang You","Bokui Shen","Congyue Deng","Haoran Geng","Songlin Wei","He Wang","Leonidas Guibas"],"pdf_url":"https://arxiv.org/pdf/2311.02787v2.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2212.13332v3","updated":"2024-03-24T23:18:18Z","published":"2022-12-27T01:06:26Z","title":"Development and Evaluation of a Learning-based Model for Real-time\n  Haptic Texture Rendering","summary":"  Current Virtual Reality (VR) environments lack the rich haptic signals that\nhumans experience during real-life interactions, such as the sensation of\ntexture during lateral movement on a surface. Adding realistic haptic textures\nto VR environments requires a model that generalizes to variations of a user's\ninteraction and to the wide variety of existing textures in the world. Current\nmethodologies for haptic texture rendering exist, but they usually develop one\nmodel per texture, resulting in low scalability. We present a deep\nlearning-based action-conditional model for haptic texture rendering and\nevaluate its perceptual performance in rendering realistic texture vibrations\nthrough a multi part human user study. This model is unified over all materials\nand uses data from a vision-based tactile sensor (GelSight) to render the\nappropriate surface conditioned on the user's action in real time. For\nrendering texture, we use a high-bandwidth vibrotactile transducer attached to\na 3D Systems Touch device. The result of our user study shows that our\nlearning-based method creates high-frequency texture renderings with comparable\nor better quality than state-of-the-art methods without the need for learning a\nseparate model per texture. Furthermore, we show that the method is capable of\nrendering previously unseen textures using a single GelSight image of their\nsurface.\n","authors":["Negin Heravi","Heather Culbertson","Allison M. Okamura","Jeannette Bohg"],"pdf_url":"https://arxiv.org/pdf/2212.13332v3.pdf","comment":"Accepted for publication in IEEE Transactions on Haptics 2024. 12\n  pages, 8 figures"},{"id":"http://arxiv.org/abs/2403.16320v1","updated":"2024-03-24T22:56:08Z","published":"2024-03-24T22:56:08Z","title":"Single-Motor Robotic Gripper with Multi-Surface Fingers for Variable\n  Grasping Configurations","summary":"  This study proposes a novel robotic gripper with variable grasping\nconfigurations for grasping various objects. The fingers of the developed\ngripper incorporate multiple different surfaces. The gripper possesses the\nfunction of altering the finger surfaces facing a target object by rotating the\nfingers in its longitudinal direction. In the proposed design equipped with two\nfingers, the two fingers incorporate three and four surfaces, respectively,\nresulting in the nine available grasping configurations by the combination of\nthese finger surfaces. The developed gripper is equipped with the functions of\nopening/closing its fingers for grasping and rotating its fingers to alter the\ngrasping configuration -all achieved with a single motor. To enable the two\nmotions using a single motor, this study introduces a self-motion switching\nmechanism utilizing magnets. This mechanism automatically transitions between\ngripper motions based on the direction of the motor rotation when the gripper\nis fully opened. In this state, rotating the motor towards closing initiates\nthe finger closing action, while further opening the fingers from the fully\nopened state activates the finger rotation. This letter presents the gripper\ndesign, the mechanics of the self-motion switching mechanism, the control\nmethod, and the grasping configuration selection strategy. The performance of\nthe gripper is experimentally demonstrated.\n","authors":["Toshihiro Nishimura","Yosuke Suzuki","Tokuo Tsuj","Tetsuyou Watanabe"],"pdf_url":"https://arxiv.org/pdf/2403.16320v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16291v1","updated":"2024-03-24T20:43:29Z","published":"2024-03-24T20:43:29Z","title":"Guessing human intentions to avoid dangerous situations in caregiving\n  robots","summary":"  For robots to interact socially, they must interpret human intentions and\nanticipate their potential outcomes accurately. This is particularly important\nfor social robots designed for human care, which may face potentially dangerous\nsituations for people, such as unseen obstacles in their way, that should be\navoided. This paper explores the Artificial Theory of Mind (ATM) approach to\ninferring and interpreting human intentions. We propose an algorithm that\ndetects risky situations for humans, selecting a robot action that removes the\ndanger in real time. We use the simulation-based approach to ATM and adopt the\n'like-me' policy to assign intentions and actions to people. Using this\nstrategy, the robot can detect and act with a high rate of success under\ntime-constrained situations. The algorithm has been implemented as part of an\nexisting robotics cognitive architecture and tested in simulation scenarios.\nThree experiments have been conducted to test the implementation's robustness,\nprecision and real-time response, including a simulated scenario, a\nhuman-in-the-loop hybrid configuration and a real-world scenario.\n","authors":["Noé Zapata","Gerardo Pérez","Lucas Bonilla","Pedro Núñez","Pilar Bachiller","Pablo Bustos"],"pdf_url":"https://arxiv.org/pdf/2403.16291v1.pdf","comment":"8 pages, 6 figures. Submitted to IROS"},{"id":"http://arxiv.org/abs/2403.16277v1","updated":"2024-03-24T19:52:53Z","published":"2024-03-24T19:52:53Z","title":"Combined Task and Motion Planning Via Sketch Decompositions (Extended\n  Version with Supplementary Material)","summary":"  The challenge in combined task and motion planning (TAMP) is the effective\nintegration of a search over a combinatorial space, usually carried out by a\ntask planner, and a search over a continuous configuration space, carried out\nby a motion planner. Using motion planners for testing the feasibility of task\nplans and filling out the details is not effective because it makes the\ngeometrical constraints play a passive role. This work introduces a new\ninterleaved approach for integrating the two dimensions of TAMP that makes use\nof sketches, a recent simple but powerful language for expressing the\ndecomposition of problems into subproblems. A sketch has width 1 if it\ndecomposes the problem into subproblems that can be solved greedily in linear\ntime. In the paper, a general sketch is introduced for several classes of TAMP\nproblems which has width 1 under suitable assumptions. While sketch\ndecompositions have been developed for classical planning, they offer two\nimportant benefits in the context of TAMP. First, when a task plan is found to\nbe unfeasible due to the geometric constraints, the combinatorial search\nresumes in a specific sub-problem. Second, the sampling of object\nconfigurations is not done once, globally, at the start of the search, but\nlocally, at the start of each subproblem. Optimizations of this basic setting\nare also considered and experimental results over existing and new\npick-and-place benchmarks are reported.\n","authors":["Magí Dalmau-Moreno","Néstor García","Vicenç Gómez","Héctor Geffner"],"pdf_url":"https://arxiv.org/pdf/2403.16277v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16275v1","updated":"2024-03-24T19:47:37Z","published":"2024-03-24T19:47:37Z","title":"M^3RS: Multi-robot, Multi-objective, and Multi-mode Routing and\n  Scheduling","summary":"  In this paper, we present a novel problem coined multi-robot,\nmulti-objective, and multi-mode routing and scheduling (M^3RS). The formulation\nfor M^3RS is introduced for time-bound multi-robot, multi-objective routing and\nscheduling missions where each task has multiple execution modes. Different\nexecution modes have distinct resource consumption, associated execution time,\nand quality. M^3RS assigns the optimal sequence of tasks and the execution\nmodes to each agent. The routes and associated modes depend on user preferences\nfor different objective criteria. The need for M^3RS comes from multi-robot\napplications in which a trade-off between multiple criteria arises from\ndifferent task execution modes. We use M^3RS for the application of multi-robot\ndisinfection in public locations. The objectives considered for disinfection\napplication are disinfection quality and number of tasks completed. A\nmixed-integer linear programming model is proposed for M^3RS. Then, a\ntime-efficient column generation scheme is presented to tackle the issue of\ncomputation times for larger problem instances. The advantage of using multiple\nmodes over fixed execution mode is demonstrated using experiments on synthetic\ndata. The results suggest that M^3RS provides flexibility to the user in terms\nof available solutions and performs well in joint performance metrics. The\napplication of the proposed problem is shown for a team of disinfection\nrobots.} The videos for the experiments are available on the project website:\nhttps://sites.google.com/view/g-robot/m3rs/ .\n","authors":["Ishaan Mehta","Junseo Kim","Sharareh Taghipour","Sajad Saeedi"],"pdf_url":"https://arxiv.org/pdf/2403.16275v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.08812v4","updated":"2024-03-24T19:25:20Z","published":"2022-09-19T07:52:02Z","title":"Generative Graphical Inverse Kinematics","summary":"  Quickly and reliably finding accurate inverse kinematics (IK) solutions\nremains a challenging problem for many robot manipulators. Existing numerical\nsolvers are broadly applicable but typically only produce a single solution and\nrely on local search techniques to minimize nonconvex objective functions. More\nrecent learning-based approaches that approximate the entire feasible set of\nsolutions have shown promise as a means to generate multiple fast and accurate\nIK results in parallel. However, existing learning-based techniques have a\nsignificant drawback: each robot of interest requires a specialized model that\nmust be trained from scratch. To address this key shortcoming, we propose a\nnovel distance-geometric robot representation coupled with a graph structure\nthat allows us to leverage the sample efficiency of Euclidean equivariant\nfunctions and the generalizability of graph neural networks (GNNs). Our\napproach is generative graphical inverse kinematics (GGIK), the first learned\nIK solver able to accurately and efficiently produce a large number of diverse\nsolutions in parallel while also displaying the ability to generalize -- a\nsingle learned model can be used to produce IK solutions for a variety of\ndifferent robots. When compared to several other learned IK methods, GGIK\nprovides more accurate solutions with the same amount of data. GGIK can\ngeneralize reasonably well to robot manipulators unseen during training.\nAdditionally, GGIK can learn a constrained distribution that encodes joint\nlimits and scales efficiently to larger robots and a high number of sampled\nsolutions. Finally, GGIK can be used to complement local IK solvers by\nproviding reliable initializations for a local optimization process.\n","authors":["Oliver Limoyo","Filip Marić","Matthew Giamou","Petra Alexson","Ivan Petrović","Jonathan Kelly"],"pdf_url":"https://arxiv.org/pdf/2209.08812v4.pdf","comment":"Submitted to IEEE Transactions on Robotics, June 2023"},{"id":"http://arxiv.org/abs/2403.16262v1","updated":"2024-03-24T18:49:16Z","published":"2024-03-24T18:49:16Z","title":"HT-LIP Model based Robust Control of Quadrupedal Robot Locomotion under\n  Unknown Vertical Ground Motion","summary":"  This paper presents a hierarchical control framework that enables robust\nquadrupedal locomotion on a dynamic rigid surface (DRS) with general and\nunknown vertical motions. The key novelty of the framework lies in its higher\nlayer, which is a discrete-time, provably stabilizing footstep controller. The\nbasis of the footstep controller is a new hybrid, time-varying, linear inverted\npendulum (HT-LIP) model that is low-dimensional and accurately captures the\nessential robot dynamics during DRS locomotion. A new set of sufficient\nstability conditions are then derived to directly guide the controller design\nfor ensuring the asymptotic stability of the HT-LIP model under general,\nunknown, vertical DRS motions. Further, the footstep controller is cast as a\ncomputationally efficient quadratic program that incorporates the proposed\nHT-LIP model and stability conditions. The middle layer takes the desired\nfootstep locations generated by the higher layer as input to produce\nkinematically feasible full-body reference trajectories, which are then\naccurately tracked by a lower-layer torque controller. Hardware experiments on\na Unitree Go1 quadrupedal robot confirm the robustness of the proposed\nframework under various unknown, aperiodic, vertical DRS motions and\nuncertainties (e.g., slippery and uneven surfaces, solid and liquid loads, and\nsudden pushes).\n","authors":["Amir Iqbal","Sushant Veer","Christopher Niezrecki","Yan Gu"],"pdf_url":"https://arxiv.org/pdf/2403.16262v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16252v1","updated":"2024-03-24T18:10:30Z","published":"2024-03-24T18:10:30Z","title":"Legged Robot State Estimation within Non-inertial Environments","summary":"  This paper investigates the robot state estimation problem within a\nnon-inertial environment. The proposed state estimation approach relaxes the\ncommon assumption of static ground in the system modeling. The process and\nmeasurement models explicitly treat the movement of the non-inertial\nenvironments without requiring knowledge of its motion in the inertial frame or\nrelying on GPS or sensing environmental landmarks. Further, the proposed state\nestimator is formulated as an invariant extended Kalman filter (InEKF) with the\ndeterministic part of its process model obeying the group-affine property,\nleading to log-linear error dynamics. The observability analysis of the filter\nconfirms that the robot's pose (i.e., position and orientation) and velocity\nrelative to the non-inertial environment are observable. Hardware experiments\non a humanoid robot moving on a rotating and translating treadmill demonstrate\nthe high convergence rate and accuracy of the proposed InEKF even under\nsignificant treadmill pitch sway, as well as large estimation errors.\n","authors":["Zijian He","Sangli Teng","Tzu-Yuan Lin","Maani Ghaffari","Yan Gu"],"pdf_url":"https://arxiv.org/pdf/2403.16252v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.12188v2","updated":"2024-03-24T17:19:14Z","published":"2023-09-21T15:54:33Z","title":"SG-Bot: Object Rearrangement via Coarse-to-Fine Robotic Imagination on\n  Scene Graphs","summary":"  Object rearrangement is pivotal in robotic-environment interactions,\nrepresenting a significant capability in embodied AI. In this paper, we present\nSG-Bot, a novel rearrangement framework that utilizes a coarse-to-fine scheme\nwith a scene graph as the scene representation. Unlike previous methods that\nrely on either known goal priors or zero-shot large models, SG-Bot exemplifies\nlightweight, real-time, and user-controllable characteristics, seamlessly\nblending the consideration of commonsense knowledge with automatic generation\ncapabilities. SG-Bot employs a three-fold procedure--observation, imagination,\nand execution--to adeptly address the task. Initially, objects are discerned\nand extracted from a cluttered scene during the observation. These objects are\nfirst coarsely organized and depicted within a scene graph, guided by either\ncommonsense or user-defined criteria. Then, this scene graph subsequently\ninforms a generative model, which forms a fine-grained goal scene considering\nthe shape information from the initial scene and object semantics. Finally, for\nexecution, the initial and envisioned goal scenes are matched to formulate\nrobotic action policies. Experimental results demonstrate that SG-Bot\noutperforms competitors by a large margin.\n","authors":["Guangyao Zhai","Xiaoni Cai","Dianye Huang","Yan Di","Fabian Manhardt","Federico Tombari","Nassir Navab","Benjamin Busam"],"pdf_url":"https://arxiv.org/pdf/2309.12188v2.pdf","comment":"ICRA 2024 accepted. Project website:\n  https://sites.google.com/view/sg-bot"},{"id":"http://arxiv.org/abs/2403.16238v1","updated":"2024-03-24T17:00:01Z","published":"2024-03-24T17:00:01Z","title":"KITchen: A Real-World Benchmark and Dataset for 6D Object Pose\n  Estimation in Kitchen Environments","summary":"  Despite the recent progress on 6D object pose estimation methods for robotic\ngrasping, a substantial performance gap persists between the capabilities of\nthese methods on existing datasets and their efficacy in real-world mobile\nmanipulation tasks, particularly when robots rely solely on their monocular\negocentric field of view (FOV). Existing real-world datasets primarily focus on\ntable-top grasping scenarios, where a robotic arm is placed in a fixed position\nand the objects are centralized within the FOV of fixed external camera(s).\nAssessing performance on such datasets may not accurately reflect the\nchallenges encountered in everyday mobile manipulation tasks within kitchen\nenvironments such as retrieving objects from higher shelves, sinks,\ndishwashers, ovens, refrigerators, or microwaves. To address this gap, we\npresent Kitchen, a novel benchmark designed specifically for estimating the 6D\nposes of objects located in diverse positions within kitchen settings. For this\npurpose, we recorded a comprehensive dataset comprising around 205k real-world\nRGBD images for 111 kitchen objects captured in two distinct kitchens,\nutilizing one humanoid robot with its egocentric perspectives. Subsequently, we\ndeveloped a semi-automated annotation pipeline, to streamline the labeling\nprocess of such datasets, resulting in the generation of 2D object labels, 2D\nobject segmentation masks, and 6D object poses with minimized human effort. The\nbenchmark, the dataset, and the annotation pipeline are available at\nhttps://kitchen-dataset.github.io/KITchen.\n","authors":["Abdelrahman Younes","Tamim Asfour"],"pdf_url":"https://arxiv.org/pdf/2403.16238v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16178v1","updated":"2024-03-24T14:38:18Z","published":"2024-03-24T14:38:18Z","title":"Mixed-Initiative Human-Robot Teaming under Suboptimality with Online\n  Bayesian Adaptation","summary":"  For effective human-agent teaming, robots and other artificial intelligence\n(AI) agents must infer their human partner's abilities and behavioral response\npatterns and adapt accordingly. Most prior works make the unrealistic\nassumption that one or more teammates can act near-optimally. In real-world\ncollaboration, humans and autonomous agents can be suboptimal, especially when\neach only has partial domain knowledge. In this work, we develop computational\nmodeling and optimization techniques for enhancing the performance of\nsuboptimal human-agent teams, where the human and the agent have asymmetric\ncapabilities and act suboptimally due to incomplete environmental knowledge. We\nadopt an online Bayesian approach that enables a robot to infer people's\nwillingness to comply with its assistance in a sequential decision-making game.\nOur user studies show that user preferences and team performance indeed vary\nwith robot intervention styles, and our approach for mixed-initiative\ncollaborations enhances objective team performance ($p<.001$) and subjective\nmeasures, such as user's trust ($p<.001$) and perceived likeability of the\nrobot ($p<.001$).\n","authors":["Manisha Natarajan","Chunyue Xue","Sanne van Waveren","Karen Feigh","Matthew Gombolay"],"pdf_url":"https://arxiv.org/pdf/2403.16178v1.pdf","comment":"8 pages, 4 pages for supplementary"},{"id":"http://arxiv.org/abs/2311.12261v2","updated":"2024-03-24T14:18:36Z","published":"2023-11-21T00:45:13Z","title":"EnduRL: Enhancing Safety, Stability, and Efficiency of Mixed Traffic\n  Under Real-World Perturbations Via Reinforcement Learning","summary":"  Human-driven vehicles (HVs) amplify naturally occurring perturbations in\ntraffic, leading to congestion--a major contributor to increased fuel\nconsumption, higher collision risks, and reduced road capacity utilization.\nWhile previous research demonstrates that Robot Vehicles (RVs) can be leveraged\nto mitigate these issues, most such studies rely on simulations with simplistic\nmodels of human car-following behaviors. In this work, we analyze real-world\ndriving trajectories and extract a wide range of acceleration profiles. We then\nincorporates these profiles into simulations for training RVs to mitigate\ncongestion. We evaluate the safety, efficiency, and stability of mixed traffic\nvia comprehensive experiments conducted in two mixed traffic environments (Ring\nand Bottleneck) at various traffic densities, configurations, and RV\npenetration rates. The results show that under real-world perturbations, prior\nRV controllers experience performance degradation on all three objectives\n(sometimes even lower than 100% HVs). To address this, we introduce a\nreinforcement learning based RV that employs a congestion stage classifier to\noptimize the safety, efficiency, and stability of mixed traffic. Our RVs\ndemonstrate significant improvements: safety by up to 66%, efficiency by up to\n54%, and stability by up to 97%.\n","authors":["Bibek Poudel","Weizi Li","Kevin Heaslip"],"pdf_url":"https://arxiv.org/pdf/2311.12261v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.04846v2","updated":"2024-03-24T14:18:28Z","published":"2023-10-07T15:11:31Z","title":"Soft finger rotational stability for precision grasps","summary":"  Soft robotic fingers can safely grasp fragile or variable form objects, but\ntheir force capacity is limited, especially with less contact area: precision\ngrasps and when objects are smaller or not spherical. Current research is\nimproving force capacity through mechanical design by increasing contact area\nor stiffness, typically without models which explain soft finger force\nlimitations. To address this, this paper considers two types of soft grip\nfailure, slip and dynamic rotational stability. For slip, the validity of a\nCoulomb model investigated, identifying the effect of contact area, pressure,\nand relative pose. For rotational stability, bulk linear stiffness of the\nfingers is used to develop conditions for dynamic stability and identify when\nrotation leads to slip. Together, these models suggest contact area improves\nforce capacity by increasing transverse stiffness and normal force. The models\nare validated on pneumatic fingers, both custom PneuNets-based and commercially\navailable. The models are used to find grip parameters which increase force\ncapacity without failure.\n","authors":["Hun Jang","Valentyn Petrichenko","Joonbum Bae","Kevin Haninger"],"pdf_url":"https://arxiv.org/pdf/2310.04846v2.pdf","comment":"Submitted IROS24"},{"id":"http://arxiv.org/abs/2310.04822v2","updated":"2024-03-24T13:57:35Z","published":"2023-10-07T14:21:43Z","title":"Combining Sampling- and Gradient-based Planning for Contact-rich\n  Manipulation","summary":"  Planning over discontinuous dynamics is needed for robotics tasks like\ncontact-rich manipulation, which presents challenges in the numerical stability\nand speed of planning methods when either neural network or analytical models\nare used. On the one hand, sampling-based planners require higher sample\ncomplexity in high-dimensional problems and cannot describe safety constraints\nsuch as force limits. On the other hand, gradient-based solvers can suffer from\nlocal optima and convergence issues when the Hessian is poorly conditioned. We\npropose a planning method with both sampling- and gradient-based elements,\nusing the Cross-entropy Method to initialize a gradient-based solver, providing\nbetter search over local minima and the ability to handle explicit constraints.\nWe show the approach allows smooth, stable contact-rich planning for an\nimpedance-controlled robot making contact with a stiff environment,\nbenchmarking against gradient-only MPC and CEM.\n","authors":["Filippo Rozzi","Loris Roveda","Kevin Haninger"],"pdf_url":"https://arxiv.org/pdf/2310.04822v2.pdf","comment":"Submitted ICRA24. Video available at https://youtu.be/COqR90392Kw\n  Code available at https://gitlab.cc-asp.fraunhofer.de/hanikevi/contact_mpc"},{"id":"http://arxiv.org/abs/2403.16146v1","updated":"2024-03-24T13:36:23Z","published":"2024-03-24T13:36:23Z","title":"Realtime Robust Shape Estimation of Deformable Linear Object","summary":"  Realtime shape estimation of continuum objects and manipulators is essential\nfor developing accurate planning and control paradigms. The existing methods\nthat create dense point clouds from camera images, and/or use distinguishable\nmarkers on a deformable body have limitations in realtime tracking of large\ncontinuum objects/manipulators. The physical occlusion of markers can often\ncompromise accurate shape estimation. We propose a robust method to estimate\nthe shape of linear deformable objects in realtime using scattered and\nunordered key points. By utilizing a robust probability-based labeling\nalgorithm, our approach identifies the true order of the detected key points\nand then reconstructs the shape using piecewise spline interpolation. The\napproach only relies on knowing the number of the key points and the interval\nbetween two neighboring points. We demonstrate the robustness of the method\nwhen key points are partially occluded. The proposed method is also integrated\ninto a simulation in Unity for tracking the shape of a cable with a length of\n1m and a radius of 5mm. The simulation results show that our proposed approach\nachieves an average length error of 1.07% over the continuum's centerline and\nan average cross-section error of 2.11mm. The real-world experiments of\ntracking and estimating a heavy-load cable prove that the proposed approach is\nrobust under occlusion and complex entanglement scenarios.\n","authors":["Jiaming Zhang","Zhaomeng Zhang","Yihao Liu","Yaqian Chen","Amir Kheradmand","Mehran Armand"],"pdf_url":"https://arxiv.org/pdf/2403.16146v1.pdf","comment":"This paper has been accepted to IEEE ICRA 2024 as a contributed paper"},{"id":"http://arxiv.org/abs/2403.16095v1","updated":"2024-03-24T11:19:59Z","published":"2024-03-24T11:19:59Z","title":"CG-SLAM: Efficient Dense RGB-D SLAM in a Consistent Uncertainty-aware 3D\n  Gaussian Field","summary":"  Recently neural radiance fields (NeRF) have been widely exploited as 3D\nrepresentations for dense simultaneous localization and mapping (SLAM). Despite\ntheir notable successes in surface modeling and novel view synthesis, existing\nNeRF-based methods are hindered by their computationally intensive and\ntime-consuming volume rendering pipeline. This paper presents an efficient\ndense RGB-D SLAM system, i.e., CG-SLAM, based on a novel uncertainty-aware 3D\nGaussian field with high consistency and geometric stability. Through an\nin-depth analysis of Gaussian Splatting, we propose several techniques to\nconstruct a consistent and stable 3D Gaussian field suitable for tracking and\nmapping. Additionally, a novel depth uncertainty model is proposed to ensure\nthe selection of valuable Gaussian primitives during optimization, thereby\nimproving tracking efficiency and accuracy. Experiments on various datasets\ndemonstrate that CG-SLAM achieves superior tracking and mapping performance\nwith a notable tracking speed of up to 15 Hz. We will make our source code\npublicly available. Project page: https://zju3dv.github.io/cg-slam.\n","authors":["Jiarui Hu","Xianhao Chen","Boyin Feng","Guanglin Li","Liangjing Yang","Hujun Bao","Guofeng Zhang","Zhaopeng Cui"],"pdf_url":"https://arxiv.org/pdf/2403.16095v1.pdf","comment":"Project Page: https://zju3dv.github.io/cg-slam"},{"id":"http://arxiv.org/abs/2403.16092v1","updated":"2024-03-24T11:09:41Z","published":"2024-03-24T11:09:41Z","title":"Are NeRFs ready for autonomous driving? Towards closing the\n  real-to-simulation gap","summary":"  Neural Radiance Fields (NeRFs) have emerged as promising tools for advancing\nautonomous driving (AD) research, offering scalable closed-loop simulation and\ndata augmentation capabilities. However, to trust the results achieved in\nsimulation, one needs to ensure that AD systems perceive real and rendered data\nin the same way. Although the performance of rendering methods is increasing,\nmany scenarios will remain inherently challenging to reconstruct faithfully. To\nthis end, we propose a novel perspective for addressing the real-to-simulated\ndata gap. Rather than solely focusing on improving rendering fidelity, we\nexplore simple yet effective methods to enhance perception model robustness to\nNeRF artifacts without compromising performance on real data. Moreover, we\nconduct the first large-scale investigation into the real-to-simulated data gap\nin an AD setting using a state-of-the-art neural rendering technique.\nSpecifically, we evaluate object detectors and an online mapping model on real\nand simulated data, and study the effects of different pre-training strategies.\nOur results show notable improvements in model robustness to simulated data,\neven improving real-world performance in some cases. Last, we delve into the\ncorrelation between the real-to-simulated gap and image reconstruction metrics,\nidentifying FID and LPIPS as strong indicators.\n","authors":["Carl Lindström","Georg Hess","Adam Lilja","Maryam Fatemi","Lars Hammarstrand","Christoffer Petersson","Lennart Svensson"],"pdf_url":"https://arxiv.org/pdf/2403.16092v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.16699v2","updated":"2024-03-24T09:46:04Z","published":"2024-02-26T16:13:09Z","title":"SwarmPRM: Probabilistic Roadmap Motion Planning for Large-Scale Swarm\n  Robotic Systems","summary":"  Large-scale swarm robotic systems consisting of numerous cooperative agents\nshow considerable promise for performing autonomous tasks across various\nsectors. Nonetheless, traditional motion planning approaches often face a\ntrade-off between scalability and solution quality due to the exponential\ngrowth of the joint state space of robots. In response, this work proposes\nSwarmPRM, a hierarchical, scalable, computationally efficient, and risk-aware\nsampling-based motion planning approach for large-scale swarm robots. SwarmPRM\nutilizes a Gaussian Mixture Model (GMM) to represent the swarm's macroscopic\nstate and constructs a Probabilistic Roadmap in Gaussian space, referred to as\nthe Gaussian roadmap, to generate a transport trajectory of GMM. This\ntrajectory is then followed by each robot at the microscopic stage. To enhance\ntrajectory safety, SwarmPRM incorporates the conditional value-at-risk (CVaR)\nin the collision checking process to impart the property of risk awareness to\nthe constructed Gaussian roadmap. SwarmPRM then crafts a linear programming\nformulation to compute the optimal GMM transport trajectory within this\nroadmap. Extensive simulations demonstrate that SwarmPRM outperforms\nstate-of-the-art methods in computational efficiency, scalability, and\ntrajectory quality while offering the capability to adjust the risk tolerance\nof generated trajectories.\n","authors":["Yunze Hu","Xuru Yang","Kangjie Zhou","Qinghang Liu","Kang Ding","Han Gao","Pingping Zhu","Chang Liu"],"pdf_url":"https://arxiv.org/pdf/2402.16699v2.pdf","comment":"Submitted to IROS 2024"},{"id":"http://arxiv.org/abs/2403.16023v1","updated":"2024-03-24T05:55:39Z","published":"2024-03-24T05:55:39Z","title":"RPMArt: Towards Robust Perception and Manipulation for Articulated\n  Objects","summary":"  Articulated objects are commonly found in daily life. It is essential that\nrobots can exhibit robust perception and manipulation skills for articulated\nobjects in real-world robotic applications. However, existing methods for\narticulated objects insufficiently address noise in point clouds and struggle\nto bridge the gap between simulation and reality, thus limiting the practical\ndeployment in real-world scenarios. To tackle these challenges, we propose a\nframework towards Robust Perception and Manipulation for Articulated Objects\n(RPMArt), which learns to estimate the articulation parameters and manipulate\nthe articulation part from the noisy point cloud. Our primary contribution is a\nRobust Articulation Network (RoArtNet) that is able to predict both joint\nparameters and affordable points robustly by local feature learning and point\ntuple voting. Moreover, we introduce an articulation-aware classification\nscheme to enhance its ability for sim-to-real transfer. Finally, with the\nestimated affordable point and articulation joint constraint, the robot can\ngenerate robust actions to manipulate articulated objects. After learning only\nfrom synthetic data, RPMArt is able to transfer zero-shot to real-world\narticulated objects. Experimental results confirm our approach's effectiveness,\nwith our framework achieving state-of-the-art performance in both noise-added\nsimulation and real-world environments. The code and data will be open-sourced\nfor reproduction. More results are published on the project website at\nhttps://r-pmart.github.io .\n","authors":["Junbo Wang","Wenhai Liu","Qiaojun Yu","Yang You","Liu Liu","Weiming Wang","Cewu Lu"],"pdf_url":"https://arxiv.org/pdf/2403.16023v1.pdf","comment":"8 pages, 7 figures, submitted to 2024 IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS 2024), project website at\n  https://r-pmart.github.io"},{"id":"http://arxiv.org/abs/2403.16015v1","updated":"2024-03-24T05:13:37Z","published":"2024-03-24T05:13:37Z","title":"MQE: Unleashing the Power of Interaction with Multi-agent Quadruped\n  Environment","summary":"  The advent of deep reinforcement learning (DRL) has significantly advanced\nthe field of robotics, particularly in the control and coordination of\nquadruped robots. However, the complexity of real-world tasks often\nnecessitates the deployment of multi-robot systems capable of sophisticated\ninteraction and collaboration. To address this need, we introduce the\nMulti-agent Quadruped Environment (MQE), a novel platform designed to\nfacilitate the development and evaluation of multi-agent reinforcement learning\n(MARL) algorithms in realistic and dynamic scenarios. MQE emphasizes complex\ninteractions between robots and objects, hierarchical policy structures, and\nchallenging evaluation scenarios that reflect real-world applications. We\npresent a series of collaborative and competitive tasks within MQE, ranging\nfrom simple coordination to complex adversarial interactions, and benchmark\nstate-of-the-art MARL algorithms. Our findings indicate that hierarchical\nreinforcement learning can simplify task learning, but also highlight the need\nfor advanced algorithms capable of handling the intricate dynamics of\nmulti-agent interactions. MQE serves as a stepping stone towards bridging the\ngap between simulation and practical deployment, offering a rich environment\nfor future research in multi-agent systems and robot learning. For open-sourced\ncode and more details of MQE, please refer to\nhttps://ziyanx02.github.io/multiagent-quadruped-environment/ .\n","authors":["Ziyan Xiong","Bo Chen","Shiyu Huang","Wei-Wei Tu","Zhaofeng He","Yang Gao"],"pdf_url":"https://arxiv.org/pdf/2403.16015v1.pdf","comment":"Open-source code is available at\n  https://github.com/ziyanx02/multiagent-quadruped-environment"},{"id":"http://arxiv.org/abs/2308.15991v3","updated":"2024-03-24T04:45:03Z","published":"2023-08-30T12:24:30Z","title":"DRL-Based Trajectory Tracking for Motion-Related Modules in Autonomous\n  Driving","summary":"  Autonomous driving systems are always built on motion-related modules such as\nthe planner and the controller. An accurate and robust trajectory tracking\nmethod is indispensable for these motion-related modules as a primitive\nroutine. Current methods often make strong assumptions about the model such as\nthe context and the dynamics, which are not robust enough to deal with the\nchanging scenarios in a real-world system. In this paper, we propose a Deep\nReinforcement Learning (DRL)-based trajectory tracking method for the\nmotion-related modules in autonomous driving systems. The representation\nlearning ability of DL and the exploration nature of RL bring strong robustness\nand improve accuracy. Meanwhile, it enhances versatility by running the\ntrajectory tracking in a model-free and data-driven manner. Through extensive\nexperiments, we demonstrate both the efficiency and effectiveness of our method\ncompared to current methods. Code and documentation are released to facilitate\nboth further research and industrial deployment.\n","authors":["Yinda Xu","Lidong Yu"],"pdf_url":"https://arxiv.org/pdf/2308.15991v3.pdf","comment":"Technical report. Code:\n  https://github.com/MARMOTatZJU/drl-based-trajectory-tracking Documentation:\n  https://drl-based-trajectory-tracking.readthedocs.io"},{"id":"http://arxiv.org/abs/2403.15993v1","updated":"2024-03-24T03:10:18Z","published":"2024-03-24T03:10:18Z","title":"Robust-Locomotion-by-Logic: Perturbation-Resilient Bipedal Locomotion\n  via Signal Temporal Logic Guided Model Predictive Control","summary":"  This study introduces a robust planning framework that utilizes a model\npredictive control (MPC) approach, enhanced by incorporating signal temporal\nlogic (STL) specifications. This marks the first-ever study to apply STL-guided\ntrajectory optimization for bipedal locomotion, specifically designed to handle\nboth translational and orientational perturbations. Existing recovery\nstrategies often struggle with reasoning complex task logic and evaluating\nlocomotion robustness systematically, making them susceptible to failures\ncaused by inappropriate recovery strategies or lack of robustness. To address\nthese issues, we design an analytical robustness metric for bipedal locomotion\nand quantify this metric using STL specifications, which guide the generation\nof recovery trajectories to achieve maximum locomotion robustness. To enable\nsafe and computational-efficient crossed-leg maneuver, we design data-driven\nself-leg-collision constraints that are $1000$ times faster than the\ntraditional inverse-kinematics-based approach. Our framework outperforms a\nstate-of-the-art locomotion controller, a standard MPC without STL, and a\nlinear-temporal-logic-based planner in a high-fidelity dynamic simulation,\nespecially in scenarios involving crossed-leg maneuvers. Additionally, the\nCassie bipedal robot achieves robust performance under horizontal and\norientational perturbations such as those observed in ship motions. These\nenvironments are validated in simulations and deployed on hardware.\nFurthermore, our proposed method demonstrates versatility on stepping stones\nand terrain-agnostic features on inclined terrains.\n","authors":["Zhaoyuan Gu","Yuntian Zhao","Yipu Chen","Rongming Guo","Jennifer K. Leestma","Gregory S. Sawicki","Ye Zhao"],"pdf_url":"https://arxiv.org/pdf/2403.15993v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2012.04132v4","updated":"2024-03-24T01:23:11Z","published":"2020-12-08T00:37:35Z","title":"A Number Sense as an Emergent Property of the Manipulating Brain","summary":"  The ability to understand and manipulate numbers and quantities emerges\nduring childhood, but the mechanism through which humans acquire and develop\nthis ability is still poorly understood. We explore this question through a\nmodel, assuming that the learner is able to pick up and place small objects\nfrom, and to, locations of its choosing, and will spontaneously engage in such\nundirected manipulation. We further assume that the learner's visual system\nwill monitor the changing arrangements of objects in the scene and will learn\nto predict the effects of each action by comparing perception with a\nsupervisory signal from the motor system. We model perception using standard\ndeep networks for feature extraction and classification, and gradient descent\nlearning. Our main finding is that, from learning the task of action\nprediction, an unexpected image representation emerges exhibiting regularities\nthat foreshadow the perception and representation of numbers and quantity.\nThese include distinct categories for zero and the first few natural numbers, a\nstrict ordering of the numbers, and a one-dimensional signal that correlates\nwith numerical quantity. As a result, our model acquires the ability to\nestimate numerosity, i.e. the number of objects in the scene, as well as\nsubitization, i.e. the ability to recognize at a glance the exact number of\nobjects in small scenes. Remarkably, subitization and numerosity estimation\nextrapolate to scenes containing many objects, far beyond the three objects\nused during training. We conclude that important aspects of a facility with\nnumbers and quantities may be learned with supervision from a simple\npre-training task. Our observations suggest that cross-modal learning is a\npowerful learning mechanism that may be harnessed in artificial intelligence.\n","authors":["Neehar Kondapaneni","Pietro Perona"],"pdf_url":"https://arxiv.org/pdf/2012.04132v4.pdf","comment":"16 pages, 5 figures, 15 supplemental figures"},{"id":"http://arxiv.org/abs/2205.11624v5","updated":"2024-03-24T20:03:38Z","published":"2022-05-23T20:49:40Z","title":"Effective Integration of Weighted Cost-to-go and Conflict Heuristic\n  within Suboptimal CBS","summary":"  Conflict-Based Search (CBS) is a popular multi-agent path finding (MAPF)\nsolver that employs a low-level single agent planner and a high-level\nconstraint tree to resolve conflicts. The vast majority of modern MAPF solvers\nfocus on improving CBS by reducing the size of this tree through various\nstrategies with few methods modifying the low level planner. Typically low\nlevel planners in existing CBS methods use an unweighted cost-to-go heuristic,\nwith suboptimal CBS methods also using a conflict heuristic to help the high\nlevel search. In this paper, we show that, contrary to prevailing CBS beliefs,\na weighted cost-to-go heuristic can be used effectively alongside the conflict\nheuristic in two possible variants. In particular, one of these variants can\nobtain large speedups, 2-100x, across several scenarios and suboptimal CBS\nmethods. Importantly, we discover that performance is related not to the\nweighted cost-to-go heuristic but rather to the relative conflict heuristic\nweight's ability to effectively balance low-level and high-level work.\nAdditionally, to the best of our knowledge, we show the first theoretical\nrelation of prioritized planning and bounded suboptimal CBS and demonstrate\nthat our methods are their natural generalization. Update March 2024: We found\nthat the relative speedup decreases to around 1.2-10x depending on how the\nconflict heuristic is computed (see appendix for more details).\n","authors":["Rishi Veerapaneni","Tushar Kusnur","Maxim Likhachev"],"pdf_url":"https://arxiv.org/pdf/2205.11624v5.pdf","comment":"Published in AAAI 2023"}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2311.02787v2","updated":"2024-03-24T23:36:06Z","published":"2023-11-05T22:43:29Z","title":"Make a Donut: Hierarchical EMD-Space Planning for Zero-Shot Deformable\n  Manipulation with Tools","summary":"  Deformable object manipulation stands as one of the most captivating yet\nformidable challenges in robotics. While previous techniques have predominantly\nrelied on learning latent dynamics through demonstrations, typically\nrepresented as either particles or images, there exists a pertinent limitation:\nacquiring suitable demonstrations, especially for long-horizon tasks, can be\nelusive. Moreover, basing learning entirely on demonstrations can hamper the\nmodel's ability to generalize beyond the demonstrated tasks. In this work, we\nintroduce a demonstration-free hierarchical planning approach capable of\ntackling intricate long-horizon tasks without necessitating any training. We\nemploy large language models (LLMs) to articulate a high-level, stage-by-stage\nplan corresponding to a specified task. For every individual stage, the LLM\nprovides both the tool's name and the Python code to craft intermediate subgoal\npoint clouds. With the tool and subgoal for a particular stage at our disposal,\nwe present a granular closed-loop model predictive control strategy. This\nleverages Differentiable Physics with Point-to-Point correspondence\n(DiffPhysics-P2P) loss in the earth mover distance (EMD) space, applied\niteratively. Experimental findings affirm that our technique surpasses multiple\nbenchmarks in dough manipulation, spanning both short and long horizons.\nRemarkably, our model demonstrates robust generalization capabilities to novel\nand previously unencountered complex tasks without any preliminary\ndemonstrations. We further substantiate our approach with experimental trials\non real-world robotic platforms. Our project page:\nhttps://qq456cvb.github.io/projects/donut.\n","authors":["Yang You","Bokui Shen","Congyue Deng","Haoran Geng","Songlin Wei","He Wang","Leonidas Guibas"],"pdf_url":"https://arxiv.org/pdf/2311.02787v2.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2403.16327v1","updated":"2024-03-24T23:22:02Z","published":"2024-03-24T23:22:02Z","title":"Artificial Neural Microcircuits as Building Blocks: Concept and\n  Challenges","summary":"  Artificial Neural Networks (ANNs) are one of the most widely employed forms\nof bio-inspired computation. However the current trend is for ANNs to be\nstructurally homogeneous. Furthermore, this structural homogeneity requires the\napplication of complex training and learning tools that produce application\nspecific ANNs, susceptible to pitfalls such as overfitting. In this paper, an\nnew approach is explored, inspired by the role played in biology by Neural\nMicrocircuits, the so called ``fundamental processing elements'' of organic\nnervous systems. How large neural networks, particularly Spiking Neural\nNetworks (SNNs) can be assembled using Artificial Neural Microcircuits (ANMs),\nintended as off-the-shelf components, is articulated; the results of initial\nwork to produce a catalogue of such Microcircuits though the use of Novelty\nSearch is shown; followed by efforts to expand upon this initial work,\nincluding a discussion of challenges uncovered during these efforts and\nexplorations of methods by which they might be overcome.\n","authors":["Andrew Walter","Shimeng Wu","Andy M. Tyrrell","Liam McDaid","Malachy McElholm","Nidhin Thandassery Sumithran","Jim Harkin","Martin A. Trefzer"],"pdf_url":"https://arxiv.org/pdf/2403.16327v1.pdf","comment":"12 pages, 31 figures, 3 tables, submitted to A-Life Journal for\n  review"},{"id":"http://arxiv.org/abs/2311.01623v3","updated":"2024-03-24T23:13:06Z","published":"2023-11-03T16:58:10Z","title":"VQPy: An Object-Oriented Approach to Modern Video Analytics","summary":"  Video analytics is widely used in contemporary systems and services. At the\nforefront of video analytics are video queries that users develop to find\nobjects of particular interest. Building upon the insight that video objects\n(e.g., human, animals, cars, etc.), the center of video analytics, are similar\nin spirit to objects modeled by traditional object-oriented languages, we\npropose to develop an object-oriented approach to video analytics. This\napproach, named VQPy, consists of a frontend$\\unicode{x2015}$a Python variant\nwith constructs that make it easy for users to express video objects and their\ninteractions$\\unicode{x2015}$as well as an extensible backend that can\nautomatically construct and optimize pipelines based on video objects. We have\nimplemented and open-sourced VQPy, which has been productized in Cisco as part\nof its DeepVision framework.\n","authors":["Shan Yu","Zhenting Zhu","Yu Chen","Hanchen Xu","Pengzhan Zhao","Yang Wang","Arthi Padmanabhan","Hugo Latapie","Harry Xu"],"pdf_url":"https://arxiv.org/pdf/2311.01623v3.pdf","comment":"MLSys'24"},{"id":"http://arxiv.org/abs/2311.11202v2","updated":"2024-03-24T22:02:47Z","published":"2023-11-19T02:34:12Z","title":"Unmasking and Improving Data Credibility: A Study with Datasets for\n  Training Harmless Language Models","summary":"  Language models have shown promise in various tasks but can be affected by\nundesired data during training, fine-tuning, or alignment. For example, if some\nunsafe conversations are wrongly annotated as safe ones, the model fine-tuned\non these samples may be harmful. Therefore, the correctness of annotations,\ni.e., the credibility of the dataset, is important. This study focuses on the\ncredibility of real-world datasets, including the popular benchmarks Jigsaw\nCivil Comments, Anthropic Harmless & Red Team, PKU BeaverTails & SafeRLHF, that\ncan be used for training a harmless language model. Given the cost and\ndifficulty of cleaning these datasets by humans, we introduce a systematic\nframework for evaluating the credibility of datasets, identifying label errors,\nand evaluating the influence of noisy labels in the curated language data,\nspecifically focusing on unsafe comments and conversation classification. With\nthe framework, we find and fix an average of 6.16% label errors in 11 datasets\nconstructed from the above benchmarks. The data credibility and downstream\nlearning performance can be remarkably improved by directly fixing label\nerrors, indicating the significance of cleaning existing real-world datasets.\nWe provide an open-source tool, Docta, for data cleaning at\nhttps://github.com/Docta-ai/docta.\n","authors":["Zhaowei Zhu","Jialu Wang","Hao Cheng","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2311.11202v2.pdf","comment":"ICLR 2024"},{"id":"http://arxiv.org/abs/2403.03881v2","updated":"2024-03-24T21:38:49Z","published":"2024-03-06T17:41:41Z","title":"Latent Dataset Distillation with Diffusion Models","summary":"  The efficacy of machine learning has traditionally relied on the availability\nof increasingly larger datasets. However, large datasets pose storage\nchallenges and contain non-influential samples, which could be ignored during\ntraining without impacting the final accuracy of the model. In response to\nthese limitations, the concept of distilling the information on a dataset into\na condensed set of (synthetic) samples, namely a distilled dataset, emerged.\nOne crucial aspect is the selected architecture (usually ConvNet) for linking\nthe original and synthetic datasets. However, the final accuracy is lower if\nthe employed model architecture differs from the model used during\ndistillation. Another challenge is the generation of high-resolution images,\ne.g., 128x128 and higher. In this paper, we propose Latent Dataset Distillation\nwith Diffusion Models (LD3M) that combine diffusion in latent space with\ndataset distillation to tackle both challenges. LD3M incorporates a novel\ndiffusion process tailored for dataset distillation, which improves the\ngradient norms for learning synthetic images. By adjusting the number of\ndiffusion steps, LD3M also offers a straightforward way of controlling the\ntrade-off between speed and accuracy. We evaluate our approach in several\nImageNet subsets and for high-resolution images (128x128 and 256x256). As a\nresult, LD3M consistently outperforms state-of-the-art distillation techniques\nby up to 4.8 p.p. and 4.2 p.p. for 1 and 10 images per class, respectively.\n","authors":["Brian B. Moser","Federico Raue","Sebastian Palacio","Stanislav Frolov","Andreas Dengel"],"pdf_url":"https://arxiv.org/pdf/2403.03881v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16303v1","updated":"2024-03-24T21:29:39Z","published":"2024-03-24T21:29:39Z","title":"Large Language Models in Biomedical and Health Informatics: A\n  Bibliometric Review","summary":"  Large Language Models (LLMs) have rapidly become important tools in\nBiomedical and Health Informatics (BHI), enabling new ways to analyze data,\ntreat patients, and conduct research. This bibliometric review aims to provide\na panoramic view of how LLMs have been used in BHI by examining research\narticles and collaboration networks from 2022 to 2023. It further explores how\nLLMs can improve Natural Language Processing (NLP) applications in various BHI\nareas like medical diagnosis, patient engagement, electronic health record\nmanagement, and personalized medicine. To do this, our bibliometric review\nidentifies key trends, maps out research networks, and highlights major\ndevelopments in this fast-moving field. Lastly, it discusses the ethical\nconcerns and practical challenges of using LLMs in BHI, such as data privacy\nand reliable medical recommendations. Looking ahead, we consider how LLMs could\nfurther transform biomedical research as well as healthcare delivery and\npatient outcomes. This comprehensive review serves as a resource for\nstakeholders in healthcare, including researchers, clinicians, and\npolicymakers, to understand the current state and future potential of LLMs in\nBHI.\n","authors":["Huizi Yu","Lizhou Fan","Lingyao Li","Jiayan Zhou","Zihui Ma","Lu Xian","Wenyue Hua","Sijia He","Mingyu Jin","Yongfeng Zhang","Ashvin Gandhi","Xin Ma"],"pdf_url":"https://arxiv.org/pdf/2403.16303v1.pdf","comment":"50 pages, 7 figures, 4 tables"},{"id":"http://arxiv.org/abs/2403.16291v1","updated":"2024-03-24T20:43:29Z","published":"2024-03-24T20:43:29Z","title":"Guessing human intentions to avoid dangerous situations in caregiving\n  robots","summary":"  For robots to interact socially, they must interpret human intentions and\nanticipate their potential outcomes accurately. This is particularly important\nfor social robots designed for human care, which may face potentially dangerous\nsituations for people, such as unseen obstacles in their way, that should be\navoided. This paper explores the Artificial Theory of Mind (ATM) approach to\ninferring and interpreting human intentions. We propose an algorithm that\ndetects risky situations for humans, selecting a robot action that removes the\ndanger in real time. We use the simulation-based approach to ATM and adopt the\n'like-me' policy to assign intentions and actions to people. Using this\nstrategy, the robot can detect and act with a high rate of success under\ntime-constrained situations. The algorithm has been implemented as part of an\nexisting robotics cognitive architecture and tested in simulation scenarios.\nThree experiments have been conducted to test the implementation's robustness,\nprecision and real-time response, including a simulated scenario, a\nhuman-in-the-loop hybrid configuration and a real-world scenario.\n","authors":["Noé Zapata","Gerardo Pérez","Lucas Bonilla","Pedro Núñez","Pilar Bachiller","Pablo Bustos"],"pdf_url":"https://arxiv.org/pdf/2403.16291v1.pdf","comment":"8 pages, 6 figures. Submitted to IROS"},{"id":"http://arxiv.org/abs/2403.16289v1","updated":"2024-03-24T20:40:51Z","published":"2024-03-24T20:40:51Z","title":"Engineering Safety Requirements for Autonomous Driving with Large\n  Language Models","summary":"  Changes and updates in the requirement artifacts, which can be frequent in\nthe automotive domain, are a challenge for SafetyOps. Large Language Models\n(LLMs), with their impressive natural language understanding and generating\ncapabilities, can play a key role in automatically refining and decomposing\nrequirements after each update. In this study, we propose a prototype of a\npipeline of prompts and LLMs that receives an item definition and outputs\nsolutions in the form of safety requirements. This pipeline also performs a\nreview of the requirement dataset and identifies redundant or contradictory\nrequirements. We first identified the necessary characteristics for performing\nHARA and then defined tests to assess an LLM's capability in meeting these\ncriteria. We used design science with multiple iterations and let experts from\ndifferent companies evaluate each cycle quantitatively and qualitatively.\nFinally, the prototype was implemented at a case company and the responsible\nteam evaluated its efficiency.\n","authors":["Ali Nouri","Beatriz Cabrero-Daniel","Fredrik Törner","Hȧkan Sivencrona","Christian Berger"],"pdf_url":"https://arxiv.org/pdf/2403.16289v1.pdf","comment":"Accepted in 32nd IEEE International Requirements Engineering 2024\n  conference, Iceland"},{"id":"http://arxiv.org/abs/2403.16276v1","updated":"2024-03-24T19:50:49Z","published":"2024-03-24T19:50:49Z","title":"AVicuna: Audio-Visual LLM with Interleaver and Context-Boundary\n  Alignment for Temporal Referential Dialogue","summary":"  In everyday communication, humans frequently use speech and gestures to refer\nto specific areas or objects, a process known as Referential Dialogue (RD).\nWhile prior studies have investigated RD through Large Language Models (LLMs)\nor Large Multimodal Models (LMMs) in static contexts, the exploration of\nTemporal Referential Dialogue (TRD) within audio-visual media remains limited.\nTwo primary challenges hinder progress in this field: (1) the absence of\ncomprehensive, untrimmed audio-visual video datasets with precise temporal\nannotations, and (2) the need for methods to integrate complex temporal\nauditory and visual cues effectively. To address these challenges, we introduce\na novel framework to generate PU-VALOR, an extensive audio-visual dataset\ncomprising over 114,000 untrimmed videos with accurate temporal demarcations.\nWe also present AVicuna, featuring an Audio-Visual Tokens Interleaver (AVTI)\nthat ensures the temporal alignment of audio-visual information. Additionally,\nwe develop the A5-222K dataset, encompassing more than 200,000 audio-text\npairings, to facilitate the audio and text alignments. Our experiments\ndemonstrate that AVicuna can effectively handle TRD in audio-visual videos and\nachieve state-of-the-art performance on various audio-visual video\nunderstanding tasks, particularly in untrimmed videos. We further investigate\nthe optimal audio-interleaving rate for interleaved audio-visual inputs, which\nmaximizes performance on the Audio-Visual Event Dense Localization task.\n","authors":["Yunlong Tang","Daiki Shimada","Jing Bi","Chenliang Xu"],"pdf_url":"https://arxiv.org/pdf/2403.16276v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.00915v3","updated":"2024-03-24T19:39:00Z","published":"2022-09-02T09:50:31Z","title":"Detection of diabetic retinopathy using longitudinal self-supervised\n  learning","summary":"  Longitudinal imaging is able to capture both static anatomical structures and\ndynamic changes in disease progression towards earlier and better\npatient-specific pathology management. However, conventional approaches for\ndetecting diabetic retinopathy (DR) rarely take advantage of longitudinal\ninformation to improve DR analysis. In this work, we investigate the benefit of\nexploiting self-supervised learning with a longitudinal nature for DR diagnosis\npurposes. We compare different longitudinal self-supervised learning (LSSL)\nmethods to model the disease progression from longitudinal retinal color fundus\nphotographs (CFP) to detect early DR severity changes using a pair of\nconsecutive exams. The experiments were conducted on a longitudinal DR\nscreening dataset with or without those trained encoders (LSSL) acting as a\nlongitudinal pretext task. Results achieve an AUC of 0.875 for the baseline\n(model trained from scratch) and an AUC of 0.96 (95% CI: 0.9593-0.9655 DeLong\ntest) with a p-value < 2.2e-16 on early fusion using a simple ResNet alike\narchitecture with frozen LSSL weights, suggesting that the LSSL latent space\nenables to encode the dynamic of DR progression.\n","authors":["Rachid Zeghlache","Pierre-Henri Conze","Mostafa El Habib Daho","Ramin Tadayoni","Pascal Massin","Béatrice Cochener","Gwenolé Quellec","Mathieu Lamard"],"pdf_url":"https://arxiv.org/pdf/2209.00915v3.pdf","comment":"Accepted preprint for presentation at MICCAI-OMIA"},{"id":"http://arxiv.org/abs/2403.16272v1","updated":"2024-03-24T19:34:33Z","published":"2024-03-24T19:34:33Z","title":"L-MAE: Longitudinal masked auto-encoder with time and severity-aware\n  encoding for diabetic retinopathy progression prediction","summary":"  Pre-training strategies based on self-supervised learning (SSL) have proven\nto be effective pretext tasks for many downstream tasks in computer vision. Due\nto the significant disparity between medical and natural images, the\napplication of typical SSL is not straightforward in medical imaging.\nAdditionally, those pretext tasks often lack context, which is critical for\ncomputer-aided clinical decision support. In this paper, we developed a\nlongitudinal masked auto-encoder (MAE) based on the well-known\nTransformer-based MAE. In particular, we explored the importance of time-aware\nposition embedding as well as disease progression-aware masking. Taking into\naccount the time between examinations instead of just scheduling them offers\nthe benefit of capturing temporal changes and trends. The masking strategy, for\nits part, evolves during follow-up to better capture pathological changes,\nensuring a more accurate assessment of disease progression. Using OPHDIAT, a\nlarge follow-up screening dataset targeting diabetic retinopathy (DR), we\nevaluated the pre-trained weights on a longitudinal task, which is to predict\nthe severity label of the next visit within 3 years based on the past time\nseries examinations. Our results demonstrated the relevancy of both time-aware\nposition embedding and masking strategies based on disease progression\nknowledge. Compared to popular baseline models and standard longitudinal\nTransformers, these simple yet effective extensions significantly enhance the\npredictive ability of deep classification models.\n","authors":["Rachid Zeghlache","Pierre-Henri Conze","Mostafa El Habib Daho","Yihao Li","Alireza Rezaei","Hugo Le Boité","Ramin Tadayoni","Pascal Massin","Béatrice Cochener","Ikram Brahim","Gwenolé Quellec","Mathieu Lamard"],"pdf_url":"https://arxiv.org/pdf/2403.16272v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16260v1","updated":"2024-03-24T18:43:04Z","published":"2024-03-24T18:43:04Z","title":"Out-of-Distribution Detection via Deep Multi-Comprehension Ensemble","summary":"  Recent research underscores the pivotal role of the Out-of-Distribution (OOD)\nfeature representation field scale in determining the efficacy of models in OOD\ndetection. Consequently, the adoption of model ensembles has emerged as a\nprominent strategy to augment this feature representation field, capitalizing\non anticipated model diversity.\n  However, our introduction of novel qualitative and quantitative model\nensemble evaluation methods, specifically Loss Basin/Barrier Visualization and\nthe Self-Coupling Index, reveals a critical drawback in existing ensemble\nmethods. We find that these methods incorporate weights that are\naffine-transformable, exhibiting limited variability and thus failing to\nachieve the desired diversity in feature representation.\n  To address this limitation, we elevate the dimensions of traditional model\nensembles, incorporating various factors such as different weight\ninitializations, data holdout, etc., into distinct supervision tasks. This\ninnovative approach, termed Multi-Comprehension (MC) Ensemble, leverages\ndiverse training tasks to generate distinct comprehensions of the data and\nlabels, thereby extending the feature representation field.\n  Our experimental results demonstrate the superior performance of the MC\nEnsemble strategy in OOD detection compared to both the naive Deep Ensemble\nmethod and a standalone model of comparable size. This underscores the\neffectiveness of our proposed approach in enhancing the model's capability to\ndetect instances outside its training distribution.\n","authors":["Chenhui Xu","Fuxun Yu","Zirui Xu","Nathan Inkawhich","Xiang Chen"],"pdf_url":"https://arxiv.org/pdf/2403.16260v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.04870v3","updated":"2024-03-24T18:10:03Z","published":"2023-10-07T16:44:53Z","title":"Lemur: Integrating Large Language Models in Automated Program\n  Verification","summary":"  The demonstrated code-understanding capability of LLMs raises the question of\nwhether they can be used for automated program verification, a task that\ndemands high-level abstract reasoning about program properties that is\nchallenging for verification tools. We propose a general methodology to combine\nthe power of LLMs and automated reasoners for automated program verification.\nWe formally describe this methodology as a set of derivation rules and prove\nits soundness. We instantiate the calculus as a sound automated verification\nprocedure, which led to practical improvements on a set of synthetic and\ncompetition benchmarks.\n","authors":["Haoze Wu","Clark Barrett","Nina Narodytska"],"pdf_url":"https://arxiv.org/pdf/2310.04870v3.pdf","comment":"Accepted at ICLR'24"},{"id":"http://arxiv.org/abs/2403.14119v2","updated":"2024-03-24T17:16:53Z","published":"2024-03-21T04:08:29Z","title":"C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via\n  Text Feature Dispersion","summary":"  In deep learning, test-time adaptation has gained attention as a method for\nmodel fine-tuning without the need for labeled data. A prime exemplification is\nthe recently proposed test-time prompt tuning for large-scale vision-language\nmodels such as CLIP. Unfortunately, these prompts have been mainly developed to\nimprove accuracy, overlooking the importance of calibration, which is a crucial\naspect for quantifying prediction uncertainty. However, traditional calibration\nmethods rely on substantial amounts of labeled data, making them impractical\nfor test-time scenarios. To this end, this paper explores calibration during\ntest-time prompt tuning by leveraging the inherent properties of CLIP. Through\na series of observations, we find that the prompt choice significantly affects\nthe calibration in CLIP, where the prompts leading to higher text feature\ndispersion result in better-calibrated predictions. Introducing the Average\nText Feature Dispersion (ATFD), we establish its relationship with calibration\nerror and present a novel method, Calibrated Test-time Prompt Tuning (C-TPT),\nfor optimizing prompts during test-time with enhanced calibration. Through\nextensive experiments on different CLIP architectures and datasets, we show\nthat C-TPT can effectively improve the calibration of test-time prompt tuning\nwithout needing labeled data. The code is publicly accessible at\nhttps://github.com/hee-suk-yoon/C-TPT.\n","authors":["Hee Suk Yoon","Eunseop Yoon","Joshua Tian Jin Tee","Mark Hasegawa-Johnson","Yingzhen Li","Chang D. Yoo"],"pdf_url":"https://arxiv.org/pdf/2403.14119v2.pdf","comment":"ICLR 2024"},{"id":"http://arxiv.org/abs/2403.16230v1","updated":"2024-03-24T16:48:10Z","published":"2024-03-24T16:48:10Z","title":"On machine learning analysis of atomic force microscopy images for image\n  classification, sample surface recognition","summary":"  Atomic force microscopy (AFM or SPM) imaging is one of the best matches with\nmachine learning (ML) analysis among microscopy techniques. The digital format\nof AFM images allows for direct utilization in ML algorithms without the need\nfor additional processing. Additionally, AFM enables the simultaneous imaging\nof distributions of over a dozen different physicochemical properties of sample\nsurfaces, a process known as multidimensional imaging. While this wealth of\ninformation can be challenging to analyze using traditional methods, ML\nprovides a seamless approach to this task. However, the relatively slow speed\nof AFM imaging poses a challenge in applying deep learning methods broadly used\nin image recognition. This Prospective is focused on ML\nrecognition/classification when using a relatively small number of AFM images,\nsmall database. We discuss ML methods other than popular deep-learning neural\nnetworks. The described approach has already been successfully used to analyze\nand classify the surfaces of biological cells. It can be applied to recognize\nmedical images, specific material processing, in forensic studies, even to\nidentify the authenticity of arts. A general template for ML analysis specific\nto AFM is suggested, with a specific example of the identification of cell\nphenotype. Special attention is given to the analysis of the statistical\nsignificance of the obtained results, an important feature that is often\noverlooked in papers dealing with machine learning. A simple method for finding\nstatistical significance is also described.\n","authors":["Igor Sokolov"],"pdf_url":"https://arxiv.org/pdf/2403.16230v1.pdf","comment":"perspective; mini-review; method description; Physical Chemistry\n  Chemical Physics (PCCP) in press, 2024"},{"id":"http://arxiv.org/abs/2403.16222v1","updated":"2024-03-24T16:30:05Z","published":"2024-03-24T16:30:05Z","title":"Cyber-Security Knowledge Graph Generation by Hierarchical Nonnegative\n  Matrix Factorization","summary":"  Much of human knowledge in cybersecurity is encapsulated within the\never-growing volume of scientific papers. As this textual data continues to\nexpand, the importance of document organization methods becomes increasingly\ncrucial for extracting actionable insights hidden within large text datasets.\nKnowledge Graphs (KGs) serve as a means to store factual information in a\nstructured manner, providing explicit, interpretable knowledge that includes\ndomain-specific information from the cybersecurity scientific literature. One\nof the challenges in constructing a KG from scientific literature is the\nextraction of ontology from unstructured text. In this paper, we address this\ntopic and introduce a method for building a multi-modal KG by extracting\nstructured ontology from scientific papers. We demonstrate this concept in the\ncybersecurity domain. One modality of the KG represents observable information\nfrom the papers, such as the categories in which they were published or the\nauthors. The second modality uncovers latent (hidden) patterns of text\nextracted through hierarchical and semantic non-negative matrix factorization\n(NMF), such as named entities, topics or clusters, and keywords. We illustrate\nthis concept by consolidating more than two million scientific papers uploaded\nto arXiv into the cyber-domain, using hierarchical and semantic NMF, and by\nbuilding a cyber-domain-specific KG.\n","authors":["Ryan Barron","Maksim E. Eren","Manish Bhattarai","Nicholas Solovyev","Kim Rasmussen","Boian S. Alexandrov","Charles Nicholas","Cynthia Matuszek"],"pdf_url":"https://arxiv.org/pdf/2403.16222v1.pdf","comment":"Accepted at IEEE ISDFS"},{"id":"http://arxiv.org/abs/2403.16218v1","updated":"2024-03-24T16:18:27Z","published":"2024-03-24T16:18:27Z","title":"CoverUp: Coverage-Guided LLM-Based Test Generation","summary":"  This paper presents CoverUp, a novel system that drives the generation of\nhigh-coverage Python regression tests via a combination of coverage analysis\nand large-language models (LLMs). CoverUp iteratively improves coverage,\ninterleaving coverage analysis with dialogs with the LLM to focus its attention\non as yet uncovered lines and branches. The resulting test suites significantly\nimprove coverage over the current state of the art: compared to CodaMosa, a\nhybrid LLM / search-based software testing system, CoverUp substantially\nimproves coverage across the board. On a per-module basis, CoverUp achieves\nmedian line coverage of 81% (vs. 62%), branch coverage of 53% (vs. 35%) and\nline+branch coverage of 78% (vs. 55%). We show that CoverUp's iterative,\ncoverage-guided approach is crucial to its effectiveness, contributing to\nnearly half of its successes.\n","authors":["Juan Altmayer Pizzorno","Emery D. Berger"],"pdf_url":"https://arxiv.org/pdf/2403.16218v1.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2403.16210v1","updated":"2024-03-24T16:09:21Z","published":"2024-03-24T16:09:21Z","title":"Frankenstein: Generating Semantic-Compositional 3D Scenes in One\n  Tri-Plane","summary":"  We present Frankenstein, a diffusion-based framework that can generate\nsemantic-compositional 3D scenes in a single pass. Unlike existing methods that\noutput a single, unified 3D shape, Frankenstein simultaneously generates\nmultiple separated shapes, each corresponding to a semantically meaningful\npart. The 3D scene information is encoded in one single tri-plane tensor, from\nwhich multiple Singed Distance Function (SDF) fields can be decoded to\nrepresent the compositional shapes. During training, an auto-encoder compresses\ntri-planes into a latent space, and then the denoising diffusion process is\nemployed to approximate the distribution of the compositional scenes.\nFrankenstein demonstrates promising results in generating room interiors as\nwell as human avatars with automatically separated parts. The generated scenes\nfacilitate many downstream applications, such as part-wise re-texturing, object\nrearrangement in the room or avatar cloth re-targeting.\n","authors":["Han Yan","Yang Li","Zhennan Wu","Shenzhou Chen","Weixuan Sun","Taizhang Shang","Weizhe Liu","Tian Chen","Xiaqiang Dai","Chao Ma","Hongdong Li","Pan Ji"],"pdf_url":"https://arxiv.org/pdf/2403.16210v1.pdf","comment":"Video: https://youtu.be/lRn-HqyCrLI"},{"id":"http://arxiv.org/abs/2403.16209v1","updated":"2024-03-24T16:08:10Z","published":"2024-03-24T16:08:10Z","title":"Image Captioning in news report scenario","summary":"  Image captioning strives to generate pertinent captions for specified images,\nsituating itself at the crossroads of Computer Vision (CV) and Natural Language\nProcessing (NLP). This endeavor is of paramount importance with far-reaching\napplications in recommendation systems, news outlets, social media, and beyond.\nParticularly within the realm of news reporting, captions are expected to\nencompass detailed information, such as the identities of celebrities captured\nin the images. However, much of the existing body of work primarily centers\naround understanding scenes and actions. In this paper, we explore the realm of\nimage captioning specifically tailored for celebrity photographs, illustrating\nits broad potential for enhancing news industry practices. This exploration\naims to augment automated news content generation, thereby facilitating a more\nnuanced dissemination of information. Our endeavor shows a broader horizon,\nenriching the narrative in news reporting through a more intuitive image\ncaptioning framework.\n","authors":["Tianrui Liu","Qi Cai","Changxin Xu","Zhanxin Zhou","Jize Xiong","Yuxin Qiao","Tsungwei Yang"],"pdf_url":"https://arxiv.org/pdf/2403.16209v1.pdf","comment":"10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2403.16206v1","updated":"2024-03-24T15:59:47Z","published":"2024-03-24T15:59:47Z","title":"Rumor Detection with a novel graph neural network approach","summary":"  The wide spread of rumors on social media has caused a negative impact on\npeople's daily life, leading to potential panic, fear, and mental health\nproblems for the public. How to debunk rumors as early as possible remains a\nchallenging problem. Existing studies mainly leverage information propagation\nstructure to detect rumors, while very few works focus on correlation among\nusers that they may coordinate to spread rumors in order to gain large\npopularity. In this paper, we propose a new detection model, that jointly\nlearns both the representations of user correlation and information propagation\nto detect rumors on social media. Specifically, we leverage graph neural\nnetworks to learn the representations of user correlation from a bipartite\ngraph that describes the correlations between users and source tweets, and the\nrepresentations of information propagation with a tree structure. Then we\ncombine the learned representations from these two modules to classify the\nrumors. Since malicious users intend to subvert our model after deployment, we\nfurther develop a greedy attack scheme to analyze the cost of three adversarial\nattacks: graph attack, comment attack, and joint attack. Evaluation results on\ntwo public datasets illustrate that the proposed MODEL outperforms the\nstate-of-the-art rumor detection models. We also demonstrate our method\nperforms well for early rumor detection. Moreover, the proposed detection\nmethod is more robust to adversarial attacks compared to the best existing\nmethod. Importantly, we show that it requires a high cost for attackers to\nsubvert user correlation pattern, demonstrating the importance of considering\nuser correlation for rumor detection.\n","authors":["Tianrui Liu","Qi Cai","Changxin Xu","Zhanxin Zhou","Fanghao Ni","Yuxin Qiao","Tsungwei Yang"],"pdf_url":"https://arxiv.org/pdf/2403.16206v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2307.09985v3","updated":"2024-03-24T15:53:57Z","published":"2023-07-19T13:44:32Z","title":"Our Model Achieves Excellent Performance on MovieLens: What Does it\n  Mean?","summary":"  A typical benchmark dataset for recommender system (RecSys) evaluation\nconsists of user-item interactions generated on a platform within a time\nperiod. The interaction generation mechanism partially explains why a user\ninteracts with (e.g., like, purchase, rate) an item, and the context of when a\nparticular interaction happened. In this study, we conduct a meticulous\nanalysis of the MovieLens dataset and explain the potential impact of using the\ndataset for evaluating recommendation algorithms. We make a few main findings\nfrom our analysis. First, there are significant differences in user\ninteractions at the different stages when a user interacts with the MovieLens\nplatform. The early interactions largely define the user portrait which affects\nthe subsequent interactions. Second, user interactions are highly affected by\nthe candidate movies that are recommended by the platform's internal\nrecommendation algorithm(s). Third, changing the order of user interactions\nmakes it more difficult for sequential algorithms to capture the progressive\ninteraction process. We further discuss the discrepancy between the interaction\ngeneration mechanism that is employed by the MovieLens system and that of\ntypical real-world recommendation scenarios. In summary, the MovieLens platform\ndemonstrates an efficient and effective way of collecting user preferences to\naddress cold-starts. However, models that achieve excellent recommendation\naccuracy on the MovieLens dataset may not demonstrate superior performance in\npractice, for at least two kinds of differences: (i) the differences in the\ncontexts of user-item interaction generation, and (ii) the differences in user\nknowledge about the item collections. While results on MovieLens can be useful\nas a reference, they should not be solely relied upon as the primary\njustification for the effectiveness of a recommendation system model.\n","authors":["Yu-chen Fan","Yitong Ji","Jie Zhang","Aixin Sun"],"pdf_url":"https://arxiv.org/pdf/2307.09985v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16190v1","updated":"2024-03-24T15:14:44Z","published":"2024-03-24T15:14:44Z","title":"Logic-based Explanations for Linear Support Vector Classifiers with\n  Reject Option","summary":"  Support Vector Classifier (SVC) is a well-known Machine Learning (ML) model\nfor linear classification problems. It can be used in conjunction with a reject\noption strategy to reject instances that are hard to correctly classify and\ndelegate them to a specialist. This further increases the confidence of the\nmodel. Given this, obtaining an explanation of the cause of rejection is\nimportant to not blindly trust the obtained results. While most of the related\nwork has developed means to give such explanations for machine learning models,\nto the best of our knowledge none have done so for when reject option is\npresent. We propose a logic-based approach with formal guarantees on the\ncorrectness and minimality of explanations for linear SVCs with reject option.\nWe evaluate our approach by comparing it to Anchors, which is a heuristic\nalgorithm for generating explanations. Obtained results show that our proposed\nmethod gives shorter explanations with reduced time cost.\n","authors":["Francisco Mateus Rocha Filho","Thiago Alves Rocha","Reginaldo Pereira Fernandes Ribeiro","Ajalmar Rêgo da Rocha Neto"],"pdf_url":"https://arxiv.org/pdf/2403.16190v1.pdf","comment":"16 pages, submitted to BRACIS 2023 (Brazilian Conference on\n  Intelligent Systems), accepted version published in Intelligent Systems,\n  LNCS, vol 14195"},{"id":"http://arxiv.org/abs/2403.16178v1","updated":"2024-03-24T14:38:18Z","published":"2024-03-24T14:38:18Z","title":"Mixed-Initiative Human-Robot Teaming under Suboptimality with Online\n  Bayesian Adaptation","summary":"  For effective human-agent teaming, robots and other artificial intelligence\n(AI) agents must infer their human partner's abilities and behavioral response\npatterns and adapt accordingly. Most prior works make the unrealistic\nassumption that one or more teammates can act near-optimally. In real-world\ncollaboration, humans and autonomous agents can be suboptimal, especially when\neach only has partial domain knowledge. In this work, we develop computational\nmodeling and optimization techniques for enhancing the performance of\nsuboptimal human-agent teams, where the human and the agent have asymmetric\ncapabilities and act suboptimally due to incomplete environmental knowledge. We\nadopt an online Bayesian approach that enables a robot to infer people's\nwillingness to comply with its assistance in a sequential decision-making game.\nOur user studies show that user preferences and team performance indeed vary\nwith robot intervention styles, and our approach for mixed-initiative\ncollaborations enhances objective team performance ($p<.001$) and subjective\nmeasures, such as user's trust ($p<.001$) and perceived likeability of the\nrobot ($p<.001$).\n","authors":["Manisha Natarajan","Chunyue Xue","Sanne van Waveren","Karen Feigh","Matthew Gombolay"],"pdf_url":"https://arxiv.org/pdf/2403.16178v1.pdf","comment":"8 pages, 4 pages for supplementary"},{"id":"http://arxiv.org/abs/2403.16163v1","updated":"2024-03-24T14:08:24Z","published":"2024-03-24T14:08:24Z","title":"An Analytic Solution to Covariance Propagation in Neural Networks","summary":"  Uncertainty quantification of neural networks is critical to measuring the\nreliability and robustness of deep learning systems. However, this often\ninvolves costly or inaccurate sampling methods and approximations. This paper\npresents a sample-free moment propagation technique that propagates mean\nvectors and covariance matrices across a network to accurately characterize the\ninput-output distributions of neural networks. A key enabler of our technique\nis an analytic solution for the covariance of random variables passed through\nnonlinear activation functions, such as Heaviside, ReLU, and GELU. The wide\napplicability and merits of the proposed technique are shown in experiments\nanalyzing the input-output distributions of trained neural networks and\ntraining Bayesian neural networks.\n","authors":["Oren Wright","Yorie Nakahira","José M. F. Moura"],"pdf_url":"https://arxiv.org/pdf/2403.16163v1.pdf","comment":"Accepted to AISTATS 2024"},{"id":"http://arxiv.org/abs/2403.16162v1","updated":"2024-03-24T14:04:40Z","published":"2024-03-24T14:04:40Z","title":"Multi-Task Learning with Multi-Task Optimization","summary":"  Multi-task learning solves multiple correlated tasks. However, conflicts may\nexist between them. In such circumstances, a single solution can rarely\noptimize all the tasks, leading to performance trade-offs. To arrive at a set\nof optimized yet well-distributed models that collectively embody different\ntrade-offs in one algorithmic pass, this paper proposes to view Pareto\nmulti-task learning through the lens of multi-task optimization. Multi-task\nlearning is first cast as a multi-objective optimization problem, which is then\ndecomposed into a diverse set of unconstrained scalar-valued subproblems. These\nsubproblems are solved jointly using a novel multi-task gradient descent\nmethod, whose uniqueness lies in the iterative transfer of model parameters\namong the subproblems during the course of optimization. A theorem proving\nfaster convergence through the inclusion of such transfers is presented. We\ninvestigate the proposed multi-task learning with multi-task optimization for\nsolving various problem settings including image classification, scene\nunderstanding, and multi-target regression. Comprehensive experiments confirm\nthat the proposed method significantly advances the state-of-the-art in\ndiscovering sets of Pareto-optimized models. Notably, on the large image\ndataset we tested on, namely NYUv2, the hypervolume convergence achieved by our\nmethod was found to be nearly two times faster than the next-best among the\nstate-of-the-art.\n","authors":["Lu Bai","Abhishek Gupta","Yew-Soon Ong"],"pdf_url":"https://arxiv.org/pdf/2403.16162v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16153v1","updated":"2024-03-24T13:44:57Z","published":"2024-03-24T13:44:57Z","title":"One Masked Model is All You Need for Sensor Fault Detection, Isolation\n  and Accommodation","summary":"  Accurate and reliable sensor measurements are critical for ensuring the\nsafety and longevity of complex engineering systems such as wind turbines. In\nthis paper, we propose a novel framework for sensor fault detection, isolation,\nand accommodation (FDIA) using masked models and self-supervised learning. Our\nproposed approach is a general time series modeling approach that can be\napplied to any neural network (NN) model capable of sequence modeling, and\ncaptures the complex spatio-temporal relationships among different sensors.\nDuring training, the proposed masked approach creates a random mask, which acts\nlike a fault, for one or more sensors, making the training and inference task\nunified: finding the faulty sensors and correcting them. We validate our\nproposed technique on both a public dataset and a real-world dataset from GE\noffshore wind turbines, and demonstrate its effectiveness in detecting,\ndiagnosing and correcting sensor faults. The masked model not only simplifies\nthe overall FDIA pipeline, but also outperforms existing approaches. Our\nproposed technique has the potential to significantly improve the accuracy and\nreliability of sensor measurements in complex engineering systems in real-time,\nand could be applied to other types of sensors and engineering systems in the\nfuture. We believe that our proposed framework can contribute to the\ndevelopment of more efficient and effective FDIA techniques for a wide range of\napplications.\n","authors":["Yiwei Fu","Weizhong Yan"],"pdf_url":"https://arxiv.org/pdf/2403.16153v1.pdf","comment":"Accepted by the 2024 International Joint Conference on Neural\n  Networks (IJCNN 2024)"},{"id":"http://arxiv.org/abs/2403.16149v1","updated":"2024-03-24T13:43:43Z","published":"2024-03-24T13:43:43Z","title":"A Survey on Consumer IoT Traffic: Security and Privacy","summary":"  For the past few years, the Consumer Internet of Things (CIoT) has entered\npublic lives. While CIoT has improved the convenience of people's daily lives,\nit has also brought new security and privacy concerns. In this survey, we try\nto figure out what researchers can learn about the security and privacy of CIoT\nby traffic analysis, a popular method in the security community. From the\nsecurity and privacy perspective, this survey seeks out the new characteristics\nin CIoT traffic analysis, the state-of-the-art progress in CIoT traffic\nanalysis, and the challenges yet to be solved. We collected 310 papers from\nJanuary 2018 to December 2023 related to CIoT traffic analysis from the\nsecurity and privacy perspective and summarized the process of CIoT traffic\nanalysis in which the new characteristics of CIoT are identified. Then, we\ndetail existing works based on five application goals: device fingerprinting,\nuser activity inference, malicious traffic analysis, security analysis, and\nmeasurement. At last, we discuss the new challenges and future research\ndirections.\n","authors":["Yan Jia","Yuxin Song","Zihou Liu","Qingyin Tan","Fangming Wang","Yu Zhang","Zheli Liu"],"pdf_url":"https://arxiv.org/pdf/2403.16149v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.17548v3","updated":"2024-03-24T13:29:40Z","published":"2024-01-31T02:26:09Z","title":"Rethinking Channel Dependence for Multivariate Time Series Forecasting:\n  Learning from Leading Indicators","summary":"  Recently, channel-independent methods have achieved state-of-the-art\nperformance in multivariate time series (MTS) forecasting. Despite reducing\noverfitting risks, these methods miss potential opportunities in utilizing\nchannel dependence for accurate predictions. We argue that there exist locally\nstationary lead-lag relationships between variates, i.e., some lagged variates\nmay follow the leading indicators within a short time period. Exploiting such\nchannel dependence is beneficial since leading indicators offer advance\ninformation that can be used to reduce the forecasting difficulty of the lagged\nvariates. In this paper, we propose a new method named LIFT that first\nefficiently estimates leading indicators and their leading steps at each time\nstep and then judiciously allows the lagged variates to utilize the advance\ninformation from leading indicators. LIFT plays as a plugin that can be\nseamlessly collaborated with arbitrary time series forecasting methods.\nExtensive experiments on six real-world datasets demonstrate that LIFT improves\nthe state-of-the-art methods by 5.5% in average forecasting performance. Our\ncode is available at https://github.com/SJTU-Quant/LIFT.\n","authors":["Lifan Zhao","Yanyan Shen"],"pdf_url":"https://arxiv.org/pdf/2401.17548v3.pdf","comment":"Accepted to ICLR 2024"},{"id":"http://arxiv.org/abs/2403.16142v1","updated":"2024-03-24T13:28:27Z","published":"2024-03-24T13:28:27Z","title":"What Happens to a Dataset Transformed by a Projection-based Concept\n  Removal Method?","summary":"  We investigate the behavior of methods that use linear projections to remove\ninformation about a concept from a language representation, and we consider the\nquestion of what happens to a dataset transformed by such a method. A\ntheoretical analysis and experiments on real-world and synthetic data show that\nthese methods inject strong statistical dependencies into the transformed\ndatasets. After applying such a method, the representation space is highly\nstructured: in the transformed space, an instance tends to be located near\ninstances of the opposite label. As a consequence, the original labeling can in\nsome cases be reconstructed by applying an anti-clustering method.\n","authors":["Richard Johansson"],"pdf_url":"https://arxiv.org/pdf/2403.16142v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16135v1","updated":"2024-03-24T13:06:05Z","published":"2024-03-24T13:06:05Z","title":"Complementary Recommendation in E-commerce: Definition, Approaches, and\n  Future Directions","summary":"  In recent years, complementary recommendation has received extensive\nattention in the e-commerce domain. In this paper, we comprehensively summarize\nand compare 34 representative studies conducted between 2009 and 2024. Firstly,\nwe compare the data and methods used for modeling complementary relationships\nbetween products, including simple complementarity and more complex scenarios\nsuch as asymmetric complementarity, the coexistence of substitution and\ncomplementarity relationships between products, and varying degrees of\ncomplementarity between different pairs of products. Next, we classify and\ncompare the models based on the research problems of complementary\nrecommendation, such as diversity, personalization, and cold-start.\nFurthermore, we provide a comparative analysis of experimental results from\ndifferent studies conducted on the same dataset, which helps identify the\nstrengths and weaknesses of the research. Compared to previous surveys, this\npaper provides a more updated and comprehensive summary of the research,\ndiscusses future research directions, and contributes to the advancement of\nthis field.\n","authors":["Linyue Li","Zhijuan Du"],"pdf_url":"https://arxiv.org/pdf/2403.16135v1.pdf","comment":"20 pages,9 figures"},{"id":"http://arxiv.org/abs/2403.16133v1","updated":"2024-03-24T13:03:35Z","published":"2024-03-24T13:03:35Z","title":"SSHPool: The Separated Subgraph-based Hierarchical Pooling","summary":"  In this paper, we develop a novel local graph pooling method, namely the\nSeparated Subgraph-based Hierarchical Pooling (SSHPool), for graph\nclassification. To this end, we commence by assigning the nodes of a sample\ngraph into different clusters, resulting in a family of separated subgraphs. We\nindividually employ a local graph convolution units as the local structure to\nfurther compress each subgraph into a coarsened node, transforming the original\ngraph into a coarsened graph. Since these subgraphs are separated by different\nclusters and the structural information cannot be propagated between them, the\nlocal convolution operation can significantly avoid the over-smoothing problem\narising in most existing Graph Neural Networks (GNNs). By hierarchically\nperforming the proposed procedures on the resulting coarsened graph, the\nproposed SSHPool can effectively extract the hierarchical global feature of the\noriginal graph structure, encapsulating rich intrinsic structural\ncharacteristics. Furthermore, we develop an end-to-end GNN framework associated\nwith the proposed SSHPool module for graph classification. Experimental results\ndemonstrate the superior performance of the proposed model on real-world\ndatasets, significantly outperforming state-of-the-art GNN methods in terms of\nthe classification accuracies.\n","authors":["Zhuo Xu","Lixin Cui","Yue Wang","Hangyuan Du","Lu Bai","Edwin R. Hancock"],"pdf_url":"https://arxiv.org/pdf/2403.16133v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16130v1","updated":"2024-03-24T13:01:05Z","published":"2024-03-24T13:01:05Z","title":"AKBR: Learning Adaptive Kernel-based Representations for Graph\n  Classification","summary":"  In this paper, we propose a new model to learn Adaptive Kernel-based\nRepresentations (AKBR) for graph classification. Unlike state-of-the-art\nR-convolution graph kernels that are defined by merely counting any pair of\nisomorphic substructures between graphs and cannot provide an end-to-end\nlearning mechanism for the classifier, the proposed AKBR approach aims to\ndefine an end-to-end representation learning model to construct an adaptive\nkernel matrix for graphs. To this end, we commence by leveraging a novel\nfeature-channel attention mechanism to capture the interdependencies between\ndifferent substructure invariants of original graphs. The proposed AKBR model\ncan thus effectively identify the structural importance of different\nsubstructures, and compute the R-convolution kernel between pairwise graphs\nassociated with the more significant substructures specified by their\nstructural attentions. Since each row of the resulting kernel matrix can be\ntheoretically seen as the embedding vector of a sample graph, the proposed AKBR\nmodel is able to directly employ the resulting kernel matrix as the graph\nfeature matrix and input it into the classifier for classification (i.e., the\nSoftMax layer), naturally providing an end-to-end learning architecture between\nthe kernel computation as well as the classifier. Experimental results show\nthat the proposed AKBR model outperforms existing state-of-the-art graph\nkernels and deep learning methods on standard graph benchmarks.\n","authors":["Feifei Qian","Lixin Cui","Yue Wang","Hangyuan Du","Lu Bai","Edwin R. Hancock"],"pdf_url":"https://arxiv.org/pdf/2403.16130v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16127v1","updated":"2024-03-24T12:49:30Z","published":"2024-03-24T12:49:30Z","title":"WangchanLion and WangchanX MRC Eval","summary":"  This technical report describes the development of WangchanLion, an\ninstruction fine-tuned model focusing on Machine Reading Comprehension (MRC) in\nthe Thai language. Our model is based on SEA-LION and a collection of\ninstruction following datasets. To promote open research and reproducibility,\nwe publically release all training data, code, and the final model weights\nunder the Apache-2 license. To assess the contextual understanding capability,\nwe conducted extensive experimental studies using two Thai MRC datasets, XQuAD\nand Iapp_wiki_qa_squad. Experimental results demonstrate the model's ability to\ncomprehend the context and produce an answer faithful to the reference one in\n0-shot and 1-shot settings. In addition, our evaluation goes beyond the\ntraditional MRC. We propose a new evaluation scheme assessing the answer's\ncorrectness, helpfulness, conciseness, and contextuality. Evaluation results\nprovide insight into how we can improve our model in the future. Our code is\npublic at https://github.com/vistec-AI/WangchanLion.\n","authors":["Wannaphong Phatthiyaphaibun","Surapon Nonesung","Patomporn Payoungkhamdee","Peerat Limkonchotiwat","Can Udomcharoenchaikit","Ekapol Chuangsuwanich","Sarana Nutanong"],"pdf_url":"https://arxiv.org/pdf/2403.16127v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.05010v2","updated":"2024-03-24T12:32:06Z","published":"2024-01-10T08:56:02Z","title":"Less is More: A Closer Look at Semantic-based Few-Shot Learning","summary":"  Few-shot Learning aims to learn and distinguish new categories with a very\nlimited number of available images, presenting a significant challenge in the\nrealm of deep learning. Recent researchers have sought to leverage the\nadditional textual or linguistic information of these rare categories with a\npre-trained language model to facilitate learning, thus partially alleviating\nthe problem of insufficient supervision signals. However, the full potential of\nthe textual information and pre-trained language model have been underestimated\nin the few-shot learning till now, resulting in limited performance\nenhancements. To address this, we propose a simple but effective framework for\nfew-shot learning tasks, specifically designed to exploit the textual\ninformation and language model. In more detail, we explicitly exploit the\nzero-shot capability of the pre-trained language model with the learnable\nprompt. And we just add the visual feature with the textual feature for\ninference directly without the intricate designed fusion modules in previous\nworks. Additionally, we apply the self-ensemble and distillation to further\nenhance these components. Our extensive experiments conducted across four\nwidely used few-shot datasets demonstrate that our simple framework achieves\nimpressive results. Particularly noteworthy is its outstanding performance in\nthe 1-shot learning task, surpassing state-of-the-art methods by an average of\n3.0\\% in classification accuracy. \\footnote{We will make the source codes of\nthe proposed framework publicly available upon acceptance. }.\n","authors":["Chunpeng Zhou","Haishuai Wang","Xilu Yuan","Zhi Yu","Jiajun Bu"],"pdf_url":"https://arxiv.org/pdf/2401.05010v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.08118v2","updated":"2024-03-24T12:21:35Z","published":"2023-11-14T12:33:19Z","title":"Evaluating Neighbor Explainability for Graph Neural Networks","summary":"  Explainability in Graph Neural Networks (GNNs) is a new field growing in the\nlast few years. In this publication we address the problem of determining how\nimportant is each neighbor for the GNN when classifying a node and how to\nmeasure the performance for this specific task. To do this, various known\nexplainability methods are reformulated to get the neighbor importance and four\nnew metrics are presented. Our results show that there is almost no difference\nbetween the explanations provided by gradient-based techniques in the GNN\ndomain. In addition, many explainability techniques failed to identify\nimportant neighbors when GNNs without self-loops are used.\n","authors":["Oscar Llorente Gonzalez","Rana Fawzy","Jared Keown","Michal Horemuz","Péter Vaderna","Sándor Laki","Roland Kotroczó","Rita Csoma","János Márk Szalai-Gindl"],"pdf_url":"https://arxiv.org/pdf/2311.08118v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16116v1","updated":"2024-03-24T12:15:28Z","published":"2024-03-24T12:15:28Z","title":"Self-Supervised Multi-Frame Neural Scene Flow","summary":"  Neural Scene Flow Prior (NSFP) and Fast Neural Scene Flow (FNSF) have shown\nremarkable adaptability in the context of large out-of-distribution autonomous\ndriving. Despite their success, the underlying reasons for their astonishing\ngeneralization capabilities remain unclear. Our research addresses this gap by\nexamining the generalization capabilities of NSFP through the lens of uniform\nstability, revealing that its performance is inversely proportional to the\nnumber of input point clouds. This finding sheds light on NSFP's effectiveness\nin handling large-scale point cloud scene flow estimation tasks. Motivated by\nsuch theoretical insights, we further explore the improvement of scene flow\nestimation by leveraging historical point clouds across multiple frames, which\ninherently increases the number of point clouds. Consequently, we propose a\nsimple and effective method for multi-frame point cloud scene flow estimation,\nalong with a theoretical evaluation of its generalization abilities. Our\nanalysis confirms that the proposed method maintains a limited generalization\nerror, suggesting that adding multiple frames to the scene flow optimization\nprocess does not detract from its generalizability. Extensive experimental\nresults on large-scale autonomous driving Waymo Open and Argoverse lidar\ndatasets demonstrate that the proposed method achieves state-of-the-art\nperformance.\n","authors":["Dongrui Liu","Daqi Liu","Xueqian Li","Sihao Lin","Hongwei xie","Bing Wang","Xiaojun Chang","Lei Chu"],"pdf_url":"https://arxiv.org/pdf/2403.16116v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16112v1","updated":"2024-03-24T12:05:23Z","published":"2024-03-24T12:05:23Z","title":"Opportunities and challenges in the application of large artificial\n  intelligence models in radiology","summary":"  Influenced by ChatGPT, artificial intelligence (AI) large models have\nwitnessed a global upsurge in large model research and development. As people\nenjoy the convenience by this AI large model, more and more large models in\nsubdivided fields are gradually being proposed, especially large models in\nradiology imaging field. This article first introduces the development history\nof large models, technical details, workflow, working principles of multimodal\nlarge models and working principles of video generation large models. Secondly,\nwe summarize the latest research progress of AI large models in radiology\neducation, radiology report generation, applications of unimodal and multimodal\nradiology. Finally, this paper also summarizes some of the challenges of large\nAI models in radiology, with the aim of better promoting the rapid revolution\nin the field of radiography.\n","authors":["Liangrui Pan","Zhenyu Zhao","Ying Lu","Kewei Tang","Liyong Fu","Qingchun Liang","Shaoliang Peng"],"pdf_url":"https://arxiv.org/pdf/2403.16112v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.07942v2","updated":"2024-03-24T12:00:31Z","published":"2023-08-14T21:01:29Z","title":"Inductive Knowledge Graph Completion with GNNs and Rules: An Analysis","summary":"  The task of inductive knowledge graph completion requires models to learn\ninference patterns from a training graph, which can then be used to make\npredictions on a disjoint test graph. Rule-based methods seem like a natural\nfit for this task, but in practice they significantly underperform\nstate-of-the-art methods based on Graph Neural Networks (GNNs), such as NBFNet.\nWe hypothesise that the underperformance of rule-based methods is due to two\nfactors: (i) implausible entities are not ranked at all and (ii) only the most\ninformative path is taken into account when determining the confidence in a\ngiven link prediction answer. To analyse the impact of these factors, we study\na number of variants of a rule-based approach, which are specifically aimed at\naddressing the aforementioned issues. We find that the resulting models can\nachieve a performance which is close to that of NBFNet. Crucially, the\nconsidered variants only use a small fraction of the evidence that NBFNet\nrelies on, which means that they largely keep the interpretability advantage of\nrule-based methods. Moreover, we show that a further variant, which does look\nat the full KG, consistently outperforms NBFNet.\n","authors":["Akash Anil","Víctor Gutiérrez-Basulto","Yazmín Ibañéz-García","Steven Schockaert"],"pdf_url":"https://arxiv.org/pdf/2308.07942v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16108v1","updated":"2024-03-24T11:52:39Z","published":"2024-03-24T11:52:39Z","title":"A Transformer approach for Electricity Price Forecasting","summary":"  This paper presents a novel approach to electricity price forecasting (EPF)\nusing a pure Transformer model. As opposed to other alternatives, no other\nrecurrent network is used in combination to the attention mechanism. Hence,\nshowing that the attention layer is enough for capturing the temporal patterns.\nThe paper also provides fair comparison of the models using the open-source EPF\ntoolbox and provide the code to enhance reproducibility and transparency in EPF\nresearch. The results show that the Transformer model outperforms traditional\nmethods, offering a promising solution for reliable and sustainable power\nsystem operation.\n","authors":["Oscar Llorente Gonzalez","Jose Portela"],"pdf_url":"https://arxiv.org/pdf/2403.16108v1.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2310.11959v2","updated":"2024-03-24T11:50:28Z","published":"2023-10-18T13:39:07Z","title":"A Multi-Scale Decomposition MLP-Mixer for Time Series Analysis","summary":"  Time series data, including univariate and multivariate ones, are\ncharacterized by unique composition and complex multi-scale temporal\nvariations. They often require special consideration of decomposition and\nmulti-scale modeling to analyze. Existing deep learning methods on this best\nfit to univariate time series only, and have not sufficiently considered\nsub-series modeling and decomposition completeness. To address these\nchallenges, we propose MSD-Mixer, a Multi-Scale Decomposition MLP-Mixer, which\nlearns to explicitly decompose and represent the input time series in its\ndifferent layers. To handle the multi-scale temporal patterns and multivariate\ndependencies, we propose a novel temporal patching approach to model the time\nseries as multi-scale patches, and employ MLPs to capture intra- and\ninter-patch variations and channel-wise correlations. In addition, we propose a\nnovel loss function to constrain both the mean and the autocorrelation of the\ndecomposition residual for better decomposition completeness. Through extensive\nexperiments on various real-world datasets for five common time series analysis\ntasks, we demonstrate that MSD-Mixer consistently and significantly outperforms\nother state-of-the-art algorithms with better efficiency.\n","authors":["Shuhan Zhong","Sizhe Song","Weipeng Zhuo","Guanyao Li","Yang Liu","S. -H. Gary Chan"],"pdf_url":"https://arxiv.org/pdf/2310.11959v2.pdf","comment":"Accepted for VLDB 2024"},{"id":"http://arxiv.org/abs/2403.16101v1","updated":"2024-03-24T11:33:18Z","published":"2024-03-24T11:33:18Z","title":"Evaluating Fairness Metrics Across Borders from Human Perceptions","summary":"  Which fairness metrics are appropriately applicable in your contexts? There\nmay be instances of discordance regarding the perception of fairness, even when\nthe outcomes comply with established fairness metrics. Several surveys have\nbeen conducted to evaluate fairness metrics with human perceptions of fairness.\nHowever, these surveys were limited in scope, including only a few hundred\nparticipants within a single country. In this study, we conduct an\ninternational survey to evaluate the appropriateness of various fairness\nmetrics in decision-making scenarios. We collected responses from 1,000\nparticipants in each of China, France, Japan, and the United States, amassing a\ntotal of 4,000 responses, to analyze the preferences of fairness metrics. Our\nsurvey consists of three distinct scenarios paired with four fairness metrics,\nand each participant answers their preference for the fairness metric in each\ncase. This investigation explores the relationship between personal attributes\nand the choice of fairness metrics, uncovering a significant influence of\nnational context on these preferences.\n","authors":["Yuya Sasaki","Sohei Tokuno","Haruka Maeda","Osamu Sakura"],"pdf_url":"https://arxiv.org/pdf/2403.16101v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16100v1","updated":"2024-03-24T11:32:43Z","published":"2024-03-24T11:32:43Z","title":"Specifying Agent Ethics (Blue Sky Ideas)","summary":"  We consider the question of what properties a Machine Ethics system should\nhave. This question is complicated by the existence of ethical dilemmas with no\nagreed upon solution. We provide an example to motivate why we do not believe\nfalling back on the elicitation of values from stakeholders is sufficient to\nguarantee correctness of such systems. We go on to define two broad categories\nof ethical property that have arisen in our own work and present a challenge to\nthe community to approach this question in a more systematic way.\n","authors":["Louise A. Dennis","Michael Fisher"],"pdf_url":"https://arxiv.org/pdf/2403.16100v1.pdf","comment":"To appear in Coordination, Organizations, Institutions, Norms and\n  Ethics for Governance of Multi-Agent Systems 2024"},{"id":"http://arxiv.org/abs/2403.16097v1","updated":"2024-03-24T11:27:16Z","published":"2024-03-24T11:27:16Z","title":"Can Language Models Pretend Solvers? Logic Code Simulation with LLMs","summary":"  Transformer-based large language models (LLMs) have demonstrated significant\npotential in addressing logic problems. capitalizing on the great capabilities\nof LLMs for code-related activities, several frameworks leveraging logical\nsolvers for logic reasoning have been proposed recently. While existing\nresearch predominantly focuses on viewing LLMs as natural language logic\nsolvers or translators, their roles as logic code interpreters and executors\nhave received limited attention. This study delves into a novel aspect, namely\nlogic code simulation, which forces LLMs to emulate logical solvers in\npredicting the results of logical programs. To further investigate this novel\ntask, we formulate our three research questions: Can LLMs efficiently simulate\nthe outputs of logic codes? What strength arises along with logic code\nsimulation? And what pitfalls? To address these inquiries, we curate three\nnovel datasets tailored for the logic code simulation task and undertake\nthorough experiments to establish the baseline performance of LLMs in code\nsimulation. Subsequently, we introduce a pioneering LLM-based code simulation\ntechnique, Dual Chains of Logic (DCoL). This technique advocates a dual-path\nthinking approach for LLMs, which has demonstrated state-of-the-art performance\ncompared to other LLM prompt strategies, achieving a notable improvement in\naccuracy by 7.06% with GPT-4-Turbo.\n","authors":["Minyu Chen","Guoqiang Li","Ling-I Wu","Ruibang Liu","Yuxin Su","Xi Chang","Jianxin Xue"],"pdf_url":"https://arxiv.org/pdf/2403.16097v1.pdf","comment":"12 pages, 8 figures"},{"id":"http://arxiv.org/abs/2310.03059v6","updated":"2024-03-24T10:29:46Z","published":"2023-10-04T16:49:36Z","title":"Point-PEFT: Parameter-Efficient Fine-Tuning for 3D Pre-trained Models","summary":"  The popularity of pre-trained large models has revolutionized downstream\ntasks across diverse fields, such as language, vision, and multi-modality. To\nminimize the adaption cost for downstream tasks, many Parameter-Efficient\nFine-Tuning (PEFT) techniques are proposed for language and 2D image\npre-trained models. However, the specialized PEFT method for 3D pre-trained\nmodels is still under-explored. To this end, we introduce Point-PEFT, a novel\nframework for adapting point cloud pre-trained models with minimal learnable\nparameters. Specifically, for a pre-trained 3D model, we freeze most of its\nparameters, and only tune the newly added PEFT modules on downstream tasks,\nwhich consist of a Point-prior Prompt and a Geometry-aware Adapter. The\nPoint-prior Prompt adopts a set of learnable prompt tokens, for which we\npropose to construct a memory bank with domain-specific knowledge, and utilize\na parameter-free attention to enhance the prompt tokens. The Geometry-aware\nAdapter aims to aggregate point cloud features within spatial neighborhoods to\ncapture fine-grained geometric information through local interactions.\nExtensive experiments indicate that our Point-PEFT can achieve better\nperformance than the full fine-tuning on various downstream tasks, while using\nonly 5% of the trainable parameters, demonstrating the efficiency and\neffectiveness of our approach. Code is released at\nhttps://github.com/Ivan-Tang-3D/Point-PEFT.\n","authors":["Yiwen Tang","Ray Zhang","Zoey Guo","Dong Wang","Zhigang Wang","Bin Zhao","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2310.03059v6.pdf","comment":"The specialized PEFT framework for 3D pre-trained models, which\n  achieves competitive performance to full fine-tuning, and significantly\n  reduces the computational resources. Project page:\n  https://github.com/Ivan-Tang-3D/Point-PEFT"},{"id":"http://arxiv.org/abs/2309.11528v2","updated":"2024-03-24T10:27:10Z","published":"2023-09-20T08:11:58Z","title":"Learning Complete Topology-Aware Correlations Between Relations for\n  Inductive Link Prediction","summary":"  Inductive link prediction -- where entities during training and inference\nstages can be different -- has shown great potential for completing evolving\nknowledge graphs in an entity-independent manner. Many popular methods mainly\nfocus on modeling graph-level features, while the edge-level interactions --\nespecially the semantic correlations between relations -- have been less\nexplored. However, we notice a desirable property of semantic correlations\nbetween relations is that they are inherently edge-level and\nentity-independent. This implies the great potential of the semantic\ncorrelations for the entity-independent inductive link prediction task.\nInspired by this observation, we propose a novel subgraph-based method, namely\nTACO, to model Topology-Aware COrrelations between relations that are highly\ncorrelated to their topological structures within subgraphs. Specifically, we\nprove that semantic correlations between any two relations can be categorized\ninto seven topological patterns, and then proposes Relational Correlation\nNetwork (RCN) to learn the importance of each pattern. To further exploit the\npotential of RCN, we propose Complete Common Neighbor induced subgraph that can\neffectively preserve complete topological patterns within the subgraph.\nExtensive experiments demonstrate that TACO effectively unifies the graph-level\ninformation and edge-level interactions to jointly perform reasoning, leading\nto a superior performance over existing state-of-the-art methods for the\ninductive link prediction task.\n","authors":["Jie Wang","Hanzhu Chen","Qitan Lv","Zhihao Shi","Jiajun Chen","Huarui He","Hongtao Xie","Yongdong Zhang","Feng Wu"],"pdf_url":"https://arxiv.org/pdf/2309.11528v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2103.03642"},{"id":"http://arxiv.org/abs/2403.04369v3","updated":"2024-03-24T10:08:13Z","published":"2024-03-07T09:57:42Z","title":"From Graph to Word Bag: Introducing Domain Knowledge to Confusing Charge\n  Prediction","summary":"  Confusing charge prediction is a challenging task in legal AI, which involves\npredicting confusing charges based on fact descriptions. While existing charge\nprediction methods have shown impressive performance, they face significant\nchallenges when dealing with confusing charges, such as Snatch and Robbery. In\nthe legal domain, constituent elements play a pivotal role in distinguishing\nconfusing charges. Constituent elements are fundamental behaviors underlying\ncriminal punishment and have subtle distinctions among charges. In this paper,\nwe introduce a novel From Graph to Word Bag (FWGB) approach, which introduces\ndomain knowledge regarding constituent elements to guide the model in making\njudgments on confusing charges, much like a judge's reasoning process.\nSpecifically, we first construct a legal knowledge graph containing constituent\nelements to help select keywords for each charge, forming a word bag.\nSubsequently, to guide the model's attention towards the differentiating\ninformation for each charge within the context, we expand the attention\nmechanism and introduce a new loss function with attention supervision through\nwords in the word bag. We construct the confusing charges dataset from\nreal-world judicial documents. Experiments demonstrate the effectiveness of our\nmethod, especially in maintaining exceptional performance in imbalanced label\ndistributions.\n","authors":["Ang Li","Qiangchao Chen","Yiquan Wu","Ming Cai","Xiang Zhou","Fei Wu","Kun Kuang"],"pdf_url":"https://arxiv.org/pdf/2403.04369v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16081v1","updated":"2024-03-24T10:07:46Z","published":"2024-03-24T10:07:46Z","title":"The Interplay of Learning, Analytics, and Artificial Intelligence in\n  Education","summary":"  This paper presents a multi dimensional view of AI's role in learning and\neducation, emphasizing the intricate interplay between AI, analytics, and the\nlearning processes. Here, I challenge the prevalent narrow conceptualization of\nAI as stochastic tools, as exemplified in generative AI, and argue for the\nimportance of alternative conceptualisations of AI. I highlight the differences\nbetween human intelligence and artificial information processing, the cognitive\ndiversity inherent in AI algorithms, and posit that AI can also serve as an\ninstrument for understanding human learning. Early learning sciences and AI in\nEducation research, which saw AI as an analogy for human intelligence, have\ndiverged from this perspective, prompting a need to rekindle this connection.\nThe paper presents three unique conceptualizations of AI in education: the\nexternalization of human cognition, the internalization of AI models to\ninfluence human thought processes, and the extension of human cognition via\ntightly integrated human-AI systems. Examples from current research and\npractice are examined as instances of the three conceptualisations,\nhighlighting the potential value and limitations of each conceptualisation for\neducation, as well as the perils of overemphasis on externalising human\ncognition as exemplified in today's hype surrounding generative AI tools. The\npaper concludes with an advocacy for a broader educational approach that\nincludes educating people about AI and innovating educational systems to remain\nrelevant in an AI enabled world.\n","authors":["Mutlu Cukurova"],"pdf_url":"https://arxiv.org/pdf/2403.16081v1.pdf","comment":"20 pages, 7 figures, this paper is based on the keynote talk given by\n  the author at the ACM International Conference on Learning Analytics &\n  Knowledge (LAK) 2024 in Kyoto, Japan.\n  https://www.solaresearch.org/events/lak/lak24/keynotes/"},{"id":"http://arxiv.org/abs/2402.12928v4","updated":"2024-03-24T10:06:59Z","published":"2024-02-20T11:28:50Z","title":"A Literature Review of Literature Reviews in Pattern Analysis and\n  Machine Intelligence","summary":"  By consolidating scattered knowledge, the literature review provides a\ncomprehensive understanding of the investigated topic. However, reading,\nconducting, or peer-reviewing review papers generally demands a significant\ninvestment of time and effort from researchers. To improve efficiency, this\npaper aims to provide a thorough review of reviews in the PAMI field from\ndiverse perspectives. First, this paper proposes several article-level,\nfield-normalized, and large language model-empowered bibliometric indicators to\nevaluate reviews. To facilitate this, a meta-data database dubbed RiPAMI, and a\ntopic dataset are constructed. Second, based on these indicators, the study\npresents comparative analyses of representative reviews, unveiling the\ncharacteristics of publications across various fields, periods, and journals.\nThe newly emerging AI-generated literature reviews are also appraised, and the\nobserved differences suggest that most AI-generated reviews still lag behind\nhuman-authored reviews in multiple aspects. Third, we briefly provide a\nsubjective evaluation of representative PAMI reviews and introduce a paper\nstructure-based typology of literature reviews. This typology may improve the\nclarity and effectiveness for scholars in reading and writing reviews, while\nalso serving as a guide for AI systems in generating well-organized reviews.\nFinally, this work offers insights into the current challenges of literature\nreviews and envisions future directions for their development.\n","authors":["Penghai Zhao","Xin Zhang","Ming-Ming Cheng","Jian Yang","Xiang Li"],"pdf_url":"https://arxiv.org/pdf/2402.12928v4.pdf","comment":"IEEE version v1. [February 19, 2024] IEEE version v2 with typos\n  fixed. [February 23, 2024] IEEE version v3 with errors fixed. [February 29,\n  2024] IEEE version v4 with improved quaility. [February 29, 2024]"},{"id":"http://arxiv.org/abs/2304.07537v3","updated":"2024-03-24T09:42:39Z","published":"2023-04-15T11:48:18Z","title":"Gradient-less Federated Gradient Boosting Trees with Learnable Learning\n  Rates","summary":"  The privacy-sensitive nature of decentralized datasets and the robustness of\neXtreme Gradient Boosting (XGBoost) on tabular data raise the needs to train\nXGBoost in the context of federated learning (FL). Existing works on federated\nXGBoost in the horizontal setting rely on the sharing of gradients, which\ninduce per-node level communication frequency and serious privacy concerns. To\nalleviate these problems, we develop an innovative framework for horizontal\nfederated XGBoost which does not depend on the sharing of gradients and\nsimultaneously boosts privacy and communication efficiency by making the\nlearning rates of the aggregated tree ensembles learnable. We conduct extensive\nevaluations on various classification and regression datasets, showing our\napproach achieves performance comparable to the state-of-the-art method and\neffectively improves communication efficiency by lowering both communication\nrounds and communication overhead by factors ranging from 25x to 700x. Project\nPage: https://flower.ai/blog/2023-04-19-xgboost-with-flower/\n","authors":["Chenyang Ma","Xinchi Qiu","Daniel J. Beutel","Nicholas D. Lane"],"pdf_url":"https://arxiv.org/pdf/2304.07537v3.pdf","comment":"Accepted at the 3rd ACM Workshop on Machine Learning and Systems\n  (EuroMLSys), May 8th 2023, Rome, Italy"},{"id":"http://arxiv.org/abs/2403.16071v1","updated":"2024-03-24T09:18:21Z","published":"2024-03-24T09:18:21Z","title":"Landmark-Guided Cross-Speaker Lip Reading with Mutual Information\n  Regularization","summary":"  Lip reading, the process of interpreting silent speech from visual lip\nmovements, has gained rising attention for its wide range of realistic\napplications. Deep learning approaches greatly improve current lip reading\nsystems. However, lip reading in cross-speaker scenarios where the speaker\nidentity changes, poses a challenging problem due to inter-speaker variability.\nA well-trained lip reading system may perform poorly when handling a brand new\nspeaker. To learn a speaker-robust lip reading model, a key insight is to\nreduce visual variations across speakers, avoiding the model overfitting to\nspecific speakers. In this work, in view of both input visual clues and latent\nrepresentations based on a hybrid CTC/attention architecture, we propose to\nexploit the lip landmark-guided fine-grained visual clues instead of\nfrequently-used mouth-cropped images as input features, diminishing\nspeaker-specific appearance characteristics. Furthermore, a max-min mutual\ninformation regularization approach is proposed to capture speaker-insensitive\nlatent representations. Experimental evaluations on public lip reading datasets\ndemonstrate the effectiveness of the proposed approach under the intra-speaker\nand inter-speaker conditions.\n","authors":["Linzhi Wu","Xingyu Zhang","Yakun Zhang","Changyan Zheng","Tiejun Liu","Liang Xie","Ye Yan","Erwei Yin"],"pdf_url":"https://arxiv.org/pdf/2403.16071v1.pdf","comment":"To appear in LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2310.18340v2","updated":"2024-03-24T09:09:00Z","published":"2023-10-22T02:32:53Z","title":"UrbanCLIP: Learning Text-enhanced Urban Region Profiling with\n  Contrastive Language-Image Pretraining from the Web","summary":"  Urban region profiling from web-sourced data is of utmost importance for\nurban planning and sustainable development. We are witnessing a rising trend of\nLLMs for various fields, especially dealing with multi-modal data research such\nas vision-language learning, where the text modality serves as a supplement\ninformation for the image. Since textual modality has never been introduced\ninto modality combinations in urban region profiling, we aim to answer two\nfundamental questions in this paper: i) Can textual modality enhance urban\nregion profiling? ii) and if so, in what ways and with regard to which aspects?\nTo answer the questions, we leverage the power of Large Language Models (LLMs)\nand introduce the first-ever LLM-enhanced framework that integrates the\nknowledge of textual modality into urban imagery profiling, named LLM-enhanced\nUrban Region Profiling with Contrastive Language-Image Pretraining (UrbanCLIP).\nSpecifically, it first generates a detailed textual description for each\nsatellite image by an open-source Image-to-Text LLM. Then, the model is trained\non the image-text pairs, seamlessly unifying natural language supervision for\nurban visual representation learning, jointly with contrastive loss and\nlanguage modeling loss. Results on predicting three urban indicators in four\nmajor Chinese metropolises demonstrate its superior performance, with an\naverage improvement of 6.1% on R^2 compared to the state-of-the-art methods.\nOur code and the image-language dataset will be released upon paper\nnotification.\n","authors":["Yibo Yan","Haomin Wen","Siru Zhong","Wei Chen","Haodong Chen","Qingsong Wen","Roger Zimmermann","Yuxuan Liang"],"pdf_url":"https://arxiv.org/pdf/2310.18340v2.pdf","comment":"Accepted by The Web Conference 2024"},{"id":"http://arxiv.org/abs/2403.16067v1","updated":"2024-03-24T08:34:08Z","published":"2024-03-24T08:34:08Z","title":"Robust Diffusion Models for Adversarial Purification","summary":"  Diffusion models (DMs) based adversarial purification (AP) has shown to be\nthe most powerful alternative to adversarial training (AT). However, these\nmethods neglect the fact that pre-trained diffusion models themselves are not\nrobust to adversarial attacks as well. Additionally, the diffusion process can\neasily destroy semantic information and generate a high quality image but\ntotally different from the original input image after the reverse process,\nleading to degraded standard accuracy. To overcome these issues, a natural idea\nis to harness adversarial training strategy to retrain or fine-tune the\npre-trained diffusion model, which is computationally prohibitive. We propose a\nnovel robust reverse process with adversarial guidance, which is independent of\ngiven pre-trained DMs and avoids retraining or fine-tuning the DMs. This robust\nguidance can not only ensure to generate purified examples retaining more\nsemantic content but also mitigate the accuracy-robustness trade-off of DMs for\nthe first time, which also provides DM-based AP an efficient adaptive ability\nto new attacks. Extensive experiments are conducted to demonstrate that our\nmethod achieves the state-of-the-art results and exhibits generalization\nagainst different attacks.\n","authors":["Guang Lin","Zerui Tao","Jianhai Zhang","Toshihisa Tanaka","Qibin Zhao"],"pdf_url":"https://arxiv.org/pdf/2403.16067v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16066v1","updated":"2024-03-24T08:33:13Z","published":"2024-03-24T08:33:13Z","title":"A Temporal Graph Network Framework for Dynamic Recommendation","summary":"  Recommender systems, crucial for user engagement on platforms like e-commerce\nand streaming services, often lag behind users' evolving preferences due to\nstatic data reliance. After Temporal Graph Networks (TGNs) were proposed,\nvarious studies have shown that TGN can significantly improve situations where\nthe features of nodes and edges dynamically change over time. However, despite\nits promising capabilities, it has not been directly applied in recommender\nsystems to date. Our study bridges this gap by directly implementing Temporal\nGraph Networks (TGN) in recommender systems, a first in this field. Using\nreal-world datasets and a range of graph and history embedding methods, we show\nTGN's adaptability, confirming its effectiveness in dynamic recommendation\nscenarios.\n","authors":["Yejin Kim","Youngbin Lee","Vincent Yuan","Annika Lee","Yongjae Lee"],"pdf_url":"https://arxiv.org/pdf/2403.16066v1.pdf","comment":"Presented at the AAAI 2024 Workshop on Recommendation Ecosystems:\n  Modeling, Optimization and Incentive Design"},{"id":"http://arxiv.org/abs/2403.16056v1","updated":"2024-03-24T07:48:05Z","published":"2024-03-24T07:48:05Z","title":"Qibo: A Large Language Model for Traditional Chinese Medicine","summary":"  In the field of Artificial Intelligence, Large Language Models (LLMs) have\ndemonstrated significant advances in user intent understanding and response in\na number of specialized domains, including medicine, law, and finance. However,\nin the unique domain of traditional Chinese medicine (TCM), the performance\nenhancement of LLMs is challenged by the essential differences between its\ntheories and modern medicine, as well as the lack of specialized corpus\nresources. In this paper, we aim to construct and organize a professional\ncorpus in the field of TCM, to endow the large model with professional\nknowledge that is characteristic of TCM theory, and to successfully develop the\nQibo model based on LLaMA, which is the first LLM in the field of TCM to\nundergo a complete training process from pre-training to Supervised Fine-Tuning\n(SFT). Furthermore, we develop the Qibo-benchmark, a specialized tool for\nevaluating the performance of LLMs, which is a specialized tool for evaluating\nthe performance of LLMs in the TCM domain. This tool will provide an important\nbasis for quantifying and comparing the understanding and application\ncapabilities of different models in the field of traditional Chinese medicine,\nand provide guidance for future research directions and practical applications\nof intelligent assistants for traditional Chinese medicine. Finally, we\nconducted sufficient experiments to prove that Qibo has good performance in the\nfield of traditional Chinese medicine.\n","authors":["Heyi Zhang","Xin Wang","Zhaopeng Meng","Yongzhe Jia","Dawei Xu"],"pdf_url":"https://arxiv.org/pdf/2403.16056v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16043v1","updated":"2024-03-24T07:04:08Z","published":"2024-03-24T07:04:08Z","title":"Semantic Is Enough: Only Semantic Information For NeRF Reconstruction","summary":"  Recent research that combines implicit 3D representation with semantic\ninformation, like Semantic-NeRF, has proven that NeRF model could perform\nexcellently in rendering 3D structures with semantic labels. This research aims\nto extend the Semantic Neural Radiance Fields (Semantic-NeRF) model by focusing\nsolely on semantic output and removing the RGB output component. We reformulate\nthe model and its training procedure to leverage only the cross-entropy loss\nbetween the model semantic output and the ground truth semantic images,\nremoving the colour data traditionally used in the original Semantic-NeRF\napproach. We then conduct a series of identical experiments using the original\nand the modified Semantic-NeRF model. Our primary objective is to obverse the\nimpact of this modification on the model performance by Semantic-NeRF, focusing\non tasks such as scene understanding, object detection, and segmentation. The\nresults offer valuable insights into the new way of rendering the scenes and\nprovide an avenue for further research and development in semantic-focused 3D\nscene understanding.\n","authors":["Ruibo Wang","Song Zhang","Ping Huang","Donghai Zhang","Wei Yan"],"pdf_url":"https://arxiv.org/pdf/2403.16043v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16023v1","updated":"2024-03-24T05:55:39Z","published":"2024-03-24T05:55:39Z","title":"RPMArt: Towards Robust Perception and Manipulation for Articulated\n  Objects","summary":"  Articulated objects are commonly found in daily life. It is essential that\nrobots can exhibit robust perception and manipulation skills for articulated\nobjects in real-world robotic applications. However, existing methods for\narticulated objects insufficiently address noise in point clouds and struggle\nto bridge the gap between simulation and reality, thus limiting the practical\ndeployment in real-world scenarios. To tackle these challenges, we propose a\nframework towards Robust Perception and Manipulation for Articulated Objects\n(RPMArt), which learns to estimate the articulation parameters and manipulate\nthe articulation part from the noisy point cloud. Our primary contribution is a\nRobust Articulation Network (RoArtNet) that is able to predict both joint\nparameters and affordable points robustly by local feature learning and point\ntuple voting. Moreover, we introduce an articulation-aware classification\nscheme to enhance its ability for sim-to-real transfer. Finally, with the\nestimated affordable point and articulation joint constraint, the robot can\ngenerate robust actions to manipulate articulated objects. After learning only\nfrom synthetic data, RPMArt is able to transfer zero-shot to real-world\narticulated objects. Experimental results confirm our approach's effectiveness,\nwith our framework achieving state-of-the-art performance in both noise-added\nsimulation and real-world environments. The code and data will be open-sourced\nfor reproduction. More results are published on the project website at\nhttps://r-pmart.github.io .\n","authors":["Junbo Wang","Wenhai Liu","Qiaojun Yu","Yang You","Liu Liu","Weiming Wang","Cewu Lu"],"pdf_url":"https://arxiv.org/pdf/2403.16023v1.pdf","comment":"8 pages, 7 figures, submitted to 2024 IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS 2024), project website at\n  https://r-pmart.github.io"},{"id":"http://arxiv.org/abs/2403.16016v1","updated":"2024-03-24T05:26:55Z","published":"2024-03-24T05:26:55Z","title":"Fill in the ____ (a Diffusion-based Image Inpainting Pipeline)","summary":"  Image inpainting is the process of taking an image and generating lost or\nintentionally occluded portions. Inpainting has countless applications\nincluding restoring previously damaged pictures, restoring the quality of\nimages that have been degraded due to compression, and removing unwanted\nobjects/text. Modern inpainting techniques have shown remarkable ability in\ngenerating sensible completions for images with mask occlusions. In our paper,\nan overview of the progress of inpainting techniques will be provided, along\nwith identifying current leading approaches, focusing on their strengths and\nweaknesses. A critical gap in these existing models will be addressed, focusing\non the ability to prompt and control what exactly is generated. We will\nadditionally justify why we think this is the natural next progressive step\nthat inpainting models must take, and provide multiple approaches to\nimplementing this functionality. Finally, we will evaluate the results of our\napproaches by qualitatively checking whether they generate high-quality images\nthat correctly inpaint regions with the objects that they are instructed to\nproduce.\n","authors":["Eyoel Gebre","Krishna Saxena","Timothy Tran"],"pdf_url":"https://arxiv.org/pdf/2403.16016v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.15991v3","updated":"2024-03-24T04:45:03Z","published":"2023-08-30T12:24:30Z","title":"DRL-Based Trajectory Tracking for Motion-Related Modules in Autonomous\n  Driving","summary":"  Autonomous driving systems are always built on motion-related modules such as\nthe planner and the controller. An accurate and robust trajectory tracking\nmethod is indispensable for these motion-related modules as a primitive\nroutine. Current methods often make strong assumptions about the model such as\nthe context and the dynamics, which are not robust enough to deal with the\nchanging scenarios in a real-world system. In this paper, we propose a Deep\nReinforcement Learning (DRL)-based trajectory tracking method for the\nmotion-related modules in autonomous driving systems. The representation\nlearning ability of DL and the exploration nature of RL bring strong robustness\nand improve accuracy. Meanwhile, it enhances versatility by running the\ntrajectory tracking in a model-free and data-driven manner. Through extensive\nexperiments, we demonstrate both the efficiency and effectiveness of our method\ncompared to current methods. Code and documentation are released to facilitate\nboth further research and industrial deployment.\n","authors":["Yinda Xu","Lidong Yu"],"pdf_url":"https://arxiv.org/pdf/2308.15991v3.pdf","comment":"Technical report. Code:\n  https://github.com/MARMOTatZJU/drl-based-trajectory-tracking Documentation:\n  https://drl-based-trajectory-tracking.readthedocs.io"},{"id":"http://arxiv.org/abs/2403.16004v1","updated":"2024-03-24T04:23:43Z","published":"2024-03-24T04:23:43Z","title":"A Federated Parameter Aggregation Method for Node Classification Tasks\n  with Different Graph Network Structures","summary":"  Over the past few years, federated learning has become widely used in various\nclassical machine learning fields because of its collaborative ability to train\ndata from multiple sources without compromising privacy. However, in the area\nof graph neural networks, the nodes and network structures of graphs held by\nclients are different in many practical applications, and the aggregation\nmethod that directly shares model gradients cannot be directly applied to this\nscenario. Therefore, this work proposes a federated aggregation method FLGNN\napplied to various graph federation scenarios and investigates the aggregation\neffect of parameter sharing at each layer of the graph neural network model.\nThe effectiveness of the federated aggregation method FLGNN is verified by\nexperiments on real datasets. Additionally, for the privacy security of FLGNN,\nthis paper designs membership inference attack experiments and differential\nprivacy defense experiments. The results show that FLGNN performs good\nrobustness, and the success rate of privacy theft is further reduced by adding\ndifferential privacy defense methods.\n","authors":["Hao Song","Jiacheng Yao","Zhengxi Li","Shaocong Xu","Shibo Jin","Jiajun Zhou","Chenbo Fu","Qi Xuan","Shanqing Yu"],"pdf_url":"https://arxiv.org/pdf/2403.16004v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16003v1","updated":"2024-03-24T04:22:37Z","published":"2024-03-24T04:22:37Z","title":"Diverse Representation Embedding for Lifelong Person Re-Identification","summary":"  Lifelong Person Re-Identification (LReID) aims to continuously learn from\nsuccessive data streams, matching individuals across multiple cameras. The key\nchallenge for LReID is how to effectively preserve old knowledge while learning\nnew information incrementally. Task-level domain gaps and limited old task\ndatasets are key factors leading to catastrophic forgetting in ReLD, which are\noverlooked in existing methods. To alleviate this problem, we propose a novel\nDiverse Representation Embedding (DRE) framework for LReID. The proposed DRE\npreserves old knowledge while adapting to new information based on\ninstance-level and task-level layout. Concretely, an Adaptive Constraint Module\n(ACM) is proposed to implement integration and push away operations between\nmultiple representations, obtaining dense embedding subspace for each instance\nto improve matching ability on limited old task datasets. Based on the\nprocessed diverse representation, we interact knowledge between the adjustment\nmodel and the learner model through Knowledge Update (KU) and Knowledge\nPreservation (KP) strategies at the task-level layout, which reduce the\ntask-wise domain gap on both old and new tasks, and exploit diverse\nrepresentation of each instance in limited datasets from old tasks, improving\nmodel performance for extended periods. Extensive experiments were conducted on\neleven Re-ID datasets, including five seen datasets for training in order-1 and\norder-2 orders and six unseen datasets for inference. Compared to\nstate-of-the-art methods, our method achieves significantly improved\nperformance in holistic, large-scale, and occluded datasets.\n","authors":["Shiben Liu","Huijie Fan","Qiang Wang","Xiai Chen","Zhi Han","Yandong Tang"],"pdf_url":"https://arxiv.org/pdf/2403.16003v1.pdf","comment":"11 pages,7 Tables,3 Figures"},{"id":"http://arxiv.org/abs/2309.13339v3","updated":"2024-03-24T04:17:28Z","published":"2023-09-23T11:21:12Z","title":"Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models\n  through Logic","summary":"  Recent advancements in large language models have showcased their remarkable\ngeneralizability across various domains. However, their reasoning abilities\nstill have significant room for improvement, especially when confronted with\nscenarios requiring multi-step reasoning. Although large language models\npossess extensive knowledge, their reasoning often fails to effectively utilize\nthis knowledge to establish a coherent thinking paradigm. These models\nsometimes show hallucinations as their reasoning procedures are unconstrained\nby logical principles. Aiming at improving the zero-shot chain-of-thought\nreasoning ability of large language models, we propose LoT (Logical Thoughts),\na self-improvement prompting framework that leverages principles rooted in\nsymbolic logic, particularly Reductio ad Absurdum, to systematically verify and\nrectify the reasoning processes step by step. Experimental evaluations\nconducted on language tasks in diverse domains, including arithmetic,\ncommonsense, symbolic, causal inference, and social problems, demonstrate the\nefficacy of enhanced reasoning by logic. The implementation code for LoT can be\naccessed at: \\url{https://github.com/xf-zhao/LoT}.\n","authors":["Xufeng Zhao","Mengdi Li","Wenhao Lu","Cornelius Weber","Jae Hee Lee","Kun Chu","Stefan Wermter"],"pdf_url":"https://arxiv.org/pdf/2309.13339v3.pdf","comment":"Accepted in COLING 2024. Code see https://github.com/xf-zhao/LoT"},{"id":"http://arxiv.org/abs/2402.02023v2","updated":"2024-03-24T04:01:18Z","published":"2024-02-03T04:32:34Z","title":"Self-Supervised Contrastive Learning for Long-term Forecasting","summary":"  Long-term forecasting presents unique challenges due to the time and memory\ncomplexity of handling long sequences. Existing methods, which rely on sliding\nwindows to process long sequences, struggle to effectively capture long-term\nvariations that are partially caught within the short window (i.e.,\nouter-window variations). In this paper, we introduce a novel approach that\novercomes this limitation by employing contrastive learning and enhanced\ndecomposition architecture, specifically designed to focus on long-term\nvariations. To this end, our contrastive loss incorporates global\nautocorrelation held in the whole time series, which facilitates the\nconstruction of positive and negative pairs in a self-supervised manner. When\ncombined with our decomposition networks, our contrastive learning\nsignificantly improves long-term forecasting performance. Extensive experiments\ndemonstrate that our approach outperforms 14 baseline models in multiple\nexperiments over nine long-term benchmarks, especially in challenging scenarios\nthat require a significantly long output for forecasting. Source code is\navailable at\nhttps://github.com/junwoopark92/Self-Supervised-Contrastive-Forecsating.\n","authors":["Junwoo Park","Daehoon Gwak","Jaegul Choo","Edward Choi"],"pdf_url":"https://arxiv.org/pdf/2402.02023v2.pdf","comment":"Accepted at International Conference on Learning Representations\n  (ICLR) 2024"},{"id":"http://arxiv.org/abs/2403.15994v1","updated":"2024-03-24T03:10:39Z","published":"2024-03-24T03:10:39Z","title":"Multi-Scale Spatio-Temporal Graph Convolutional Network for Facial\n  Expression Spotting","summary":"  Facial expression spotting is a significant but challenging task in facial\nexpression analysis. The accuracy of expression spotting is affected not only\nby irrelevant facial movements but also by the difficulty of perceiving subtle\nmotions in micro-expressions. In this paper, we propose a Multi-Scale\nSpatio-Temporal Graph Convolutional Network (SpoT-GCN) for facial expression\nspotting. To extract more robust motion features, we track both short- and\nlong-term motion of facial muscles in compact sliding windows whose window\nlength adapts to the temporal receptive field of the network. This strategy,\ntermed the receptive field adaptive sliding window strategy, effectively\nmagnifies the motion features while alleviating the problem of severe head\nmovement. The subtle motion features are then converted to a facial graph\nrepresentation, whose spatio-temporal graph patterns are learned by a graph\nconvolutional network. This network learns both local and global features from\nmultiple scales of facial graph structures using our proposed facial local\ngraph pooling (FLGP). Furthermore, we introduce supervised contrastive learning\nto enhance the discriminative capability of our model for difficult-to-classify\nframes. The experimental results on the SAMM-LV and CAS(ME)^2 datasets\ndemonstrate that our method achieves state-of-the-art performance, particularly\nin micro-expression spotting. Ablation studies further verify the effectiveness\nof our proposed modules.\n","authors":["Yicheng Deng","Hideaki Hayashi","Hajime Nagahara"],"pdf_url":"https://arxiv.org/pdf/2403.15994v1.pdf","comment":"Accepted by FG2024"},{"id":"http://arxiv.org/abs/2403.15989v1","updated":"2024-03-24T02:54:46Z","published":"2024-03-24T02:54:46Z","title":"Knowledge-guided Machine Learning: Current Trends and Future Prospects","summary":"  This paper presents an overview of scientific modeling and discusses the\ncomplementary strengths and weaknesses of ML methods for scientific modeling in\ncomparison to process-based models. It also provides an introduction to the\ncurrent state of research in the emerging field of scientific knowledge-guided\nmachine learning (KGML) that aims to use both scientific knowledge and data in\nML frameworks to achieve better generalizability, scientific consistency, and\nexplainability of results. We discuss different facets of KGML research in\nterms of the type of scientific knowledge used, the form of knowledge-ML\nintegration explored, and the method for incorporating scientific knowledge in\nML. We also discuss some of the common categories of use cases in environmental\nsciences where KGML methods are being developed, using illustrative examples in\neach category.\n","authors":["Anuj Karpatne","Xiaowei Jia","Vipin Kumar"],"pdf_url":"https://arxiv.org/pdf/2403.15989v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.03695v2","updated":"2024-03-24T02:03:55Z","published":"2024-01-08T06:53:33Z","title":"A Large-Scale Empirical Study on Improving the Fairness of Image\n  Classification Models","summary":"  Fairness has been a critical issue that affects the adoption of deep learning\nmodels in real practice. To improve model fairness, many existing methods have\nbeen proposed and evaluated to be effective in their own contexts. However,\nthere is still no systematic evaluation among them for a comprehensive\ncomparison under the same context, which makes it hard to understand the\nperformance distinction among them, hindering the research progress and\npractical adoption of them. To fill this gap, this paper endeavours to conduct\nthe first large-scale empirical study to comprehensively compare the\nperformance of existing state-of-the-art fairness improving techniques.\nSpecifically, we target the widely-used application scenario of image\nclassification, and utilized three different datasets and five commonly-used\nperformance metrics to assess in total 13 methods from diverse categories. Our\nfindings reveal substantial variations in the performance of each method across\ndifferent datasets and sensitive attributes, indicating over-fitting on\nspecific datasets by many existing methods. Furthermore, different fairness\nevaluation metrics, due to their distinct focuses, yield significantly\ndifferent assessment results. Overall, we observe that pre-processing methods\nand in-processing methods outperform post-processing methods, with\npre-processing methods exhibiting the best performance. Our empirical study\noffers comprehensive recommendations for enhancing fairness in deep learning\nmodels. We approach the problem from multiple dimensions, aiming to provide a\nuniform evaluation platform and inspire researchers to explore more effective\nfairness solutions via a set of implications.\n","authors":["Junjie Yang","Jiajun Jiang","Zeyu Sun","Junjie Chen"],"pdf_url":"https://arxiv.org/pdf/2401.03695v2.pdf","comment":"Accepted by the 33rd ACM SIGSOFT International Symposium on Software\n  Testing and Analysis (ISSTA 2024). Please include ISSTA in any citations"},{"id":"http://arxiv.org/abs/2012.04132v4","updated":"2024-03-24T01:23:11Z","published":"2020-12-08T00:37:35Z","title":"A Number Sense as an Emergent Property of the Manipulating Brain","summary":"  The ability to understand and manipulate numbers and quantities emerges\nduring childhood, but the mechanism through which humans acquire and develop\nthis ability is still poorly understood. We explore this question through a\nmodel, assuming that the learner is able to pick up and place small objects\nfrom, and to, locations of its choosing, and will spontaneously engage in such\nundirected manipulation. We further assume that the learner's visual system\nwill monitor the changing arrangements of objects in the scene and will learn\nto predict the effects of each action by comparing perception with a\nsupervisory signal from the motor system. We model perception using standard\ndeep networks for feature extraction and classification, and gradient descent\nlearning. Our main finding is that, from learning the task of action\nprediction, an unexpected image representation emerges exhibiting regularities\nthat foreshadow the perception and representation of numbers and quantity.\nThese include distinct categories for zero and the first few natural numbers, a\nstrict ordering of the numbers, and a one-dimensional signal that correlates\nwith numerical quantity. As a result, our model acquires the ability to\nestimate numerosity, i.e. the number of objects in the scene, as well as\nsubitization, i.e. the ability to recognize at a glance the exact number of\nobjects in small scenes. Remarkably, subitization and numerosity estimation\nextrapolate to scenes containing many objects, far beyond the three objects\nused during training. We conclude that important aspects of a facility with\nnumbers and quantities may be learned with supervision from a simple\npre-training task. Our observations suggest that cross-modal learning is a\npowerful learning mechanism that may be harnessed in artificial intelligence.\n","authors":["Neehar Kondapaneni","Pietro Perona"],"pdf_url":"https://arxiv.org/pdf/2012.04132v4.pdf","comment":"16 pages, 5 figures, 15 supplemental figures"},{"id":"http://arxiv.org/abs/2401.06461v3","updated":"2024-03-24T01:20:49Z","published":"2024-01-12T09:15:20Z","title":"Between Lines of Code: Unraveling the Distinct Patterns of Machine and\n  Human Programmers","summary":"  Large language models have catalyzed an unprecedented wave in code\ngeneration. While achieving significant advances, they blur the distinctions\nbetween machine- and human-authored source code, causing integrity and\nauthenticity issues of software artifacts. Previous methods such as DetectGPT\nhave proven effective in discerning machine-generated texts, but they do not\nidentify and harness the unique patterns of machine-generated code. Thus, its\napplicability falters when applied to code. In this paper, we carefully study\nthe specific patterns that characterize machine- and human-authored code.\nThrough a rigorous analysis of code attributes such as lexical diversity,\nconciseness, and naturalness, we expose unique patterns inherent to each\nsource. We particularly notice that the syntactic segmentation of code is a\ncritical factor in identifying its provenance. Based on our findings, we\npropose DetectCodeGPT, a novel method for detecting machine-generated code,\nwhich improves DetectGPT by capturing the distinct stylized patterns of code.\nDiverging from conventional techniques that depend on external LLMs for\nperturbations, DetectCodeGPT perturbs the code corpus by strategically\ninserting spaces and newlines, ensuring both efficacy and efficiency.\nExperiment results show that our approach significantly outperforms\nstate-of-the-art techniques in detecting machine-generated code.\n","authors":["Yuling Shi","Hongyu Zhang","Chengcheng Wan","Xiaodong Gu"],"pdf_url":"https://arxiv.org/pdf/2401.06461v3.pdf","comment":"code available at https://github.com/YerbaPage/DetectCodeGPT"},{"id":"http://arxiv.org/abs/2403.15977v1","updated":"2024-03-24T01:20:08Z","published":"2024-03-24T01:20:08Z","title":"Towards Two-Stream Foveation-based Active Vision Learning","summary":"  Deep neural network (DNN) based machine perception frameworks process the\nentire input in a one-shot manner to provide answers to both \"what object is\nbeing observed\" and \"where it is located\". In contrast, the \"two-stream\nhypothesis\" from neuroscience explains the neural processing in the human\nvisual cortex as an active vision system that utilizes two separate regions of\nthe brain to answer the what and the where questions. In this work, we propose\na machine learning framework inspired by the \"two-stream hypothesis\" and\nexplore the potential benefits that it offers. Specifically, the proposed\nframework models the following mechanisms: 1) ventral (what) stream focusing on\nthe input regions perceived by the fovea part of an eye (foveation), 2) dorsal\n(where) stream providing visual guidance, and 3) iterative processing of the\ntwo streams to calibrate visual focus and process the sequence of focused image\npatches. The training of the proposed framework is accomplished by label-based\nDNN training for the ventral stream model and reinforcement learning for the\ndorsal stream model. We show that the two-stream foveation-based learning is\napplicable to the challenging task of weakly-supervised object localization\n(WSOL), where the training data is limited to the object class or its\nattributes. The framework is capable of both predicting the properties of an\nobject and successfully localizing it by predicting its bounding box. We also\nshow that, due to the independent nature of the two streams, the dorsal model\ncan be applied on its own to unseen images to localize objects from different\ndatasets.\n","authors":["Timur Ibrayev","Amitangshu Mukherjee","Sai Aparna Aketi","Kaushik Roy"],"pdf_url":"https://arxiv.org/pdf/2403.15977v1.pdf","comment":"18 pages, 14 figures, Under consideration at IEEE Transactions on\n  Cognitive and Developmental Systems"},{"id":"http://arxiv.org/abs/2403.15974v1","updated":"2024-03-24T00:46:40Z","published":"2024-03-24T00:46:40Z","title":"CBGT-Net: A Neuromimetic Architecture for Robust Classification of\n  Streaming Data","summary":"  This paper describes CBGT-Net, a neural network model inspired by the\ncortico-basal ganglia-thalamic (CBGT) circuits found in mammalian brains.\nUnlike traditional neural network models, which either generate an output for\neach provided input, or an output after a fixed sequence of inputs, the\nCBGT-Net learns to produce an output after a sufficient criteria for evidence\nis achieved from a stream of observed data. For each observation, the CBGT-Net\ngenerates a vector that explicitly represents the amount of evidence the\nobservation provides for each potential decision, accumulates the evidence over\ntime, and generates a decision when the accumulated evidence exceeds a\npre-defined threshold. We evaluate the proposed model on two image\nclassification tasks, where models need to predict image categories based on a\nstream of small patches extracted from the image. We show that the CBGT-Net\nprovides improved accuracy and robustness compared to models trained to\nclassify from a single patch, and models leveraging an LSTM layer to classify\nfrom a fixed sequence length of patches.\n","authors":["Shreya Sharma","Dana Hughes","Katia Sycara"],"pdf_url":"https://arxiv.org/pdf/2403.15974v1.pdf","comment":null}],"Optimization and Control":[{"id":"http://arxiv.org/abs/2403.16330v1","updated":"2024-03-24T23:36:42Z","published":"2024-03-24T23:36:42Z","title":"Algorithms of constrained uniform approximation","summary":"  We address the problem of the best uniform approximation of a continuous\nfunction on a convex domain. The approximation is by linear combinations of a\nfinite system of functions (not necessarily Chebyshev) under arbitrary linear\nconstraints. By modifying the concept of alternance and of the Remez iterative\nprocedure we present a method, which demonstrates its efficiency in numerical\nproblems. The linear rate of convergence is proved under some favourable\nassumptions. A special attention is paid to systems of complex exponents,\nGaussian functions, lacunar algebraic and trigonometric polynomials.\nApplications to signal processing, linear ODE, switching dynamical systems, and\nto Markov-Bernstein type inequalities are considered.\n","authors":["Vladimir Yu. Protasov","Rinat Kamalov"],"pdf_url":"https://arxiv.org/pdf/2403.16330v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16317v1","updated":"2024-03-24T22:42:40Z","published":"2024-03-24T22:42:40Z","title":"Optimization on a Finer Scale: Bounded Local Subgradient Variation\n  Perspective","summary":"  We initiate the study of nonsmooth optimization problems under bounded local\nsubgradient variation, which postulates bounded difference between\n(sub)gradients in small local regions around points, in either average or\nmaximum sense. The resulting class of objective functions encapsulates the\nclasses of objective functions traditionally studied in optimization, which are\ndefined based on either Lipschitz continuity of the objective or\nH\\\"{o}lder/Lipschitz continuity of its gradient. Further, the defined class\ncontains functions that are neither Lipschitz continuous nor have a H\\\"{o}lder\ncontinuous gradient. When restricted to the traditional classes of optimization\nproblems, the parameters defining the studied classes lead to more fine-grained\ncomplexity bounds, recovering traditional oracle complexity bounds in the worst\ncase but generally leading to lower oracle complexity for functions that are\nnot ``worst case.'' Some highlights of our results are that: (i) it is possible\nto obtain complexity results for both convex and nonconvex problems with the\n(local or global) Lipschitz constant being replaced by a constant of local\nsubgradient variation and (ii) mean width of the subdifferential set around the\noptima plays a role in the complexity of nonsmooth optimization, particularly\nin parallel settings. A consequence of (ii) is that for any error parameter\n$\\epsilon > 0$, parallel oracle complexity of nonsmooth Lipschitz convex\noptimization is lower than its sequential oracle complexity by a factor\n$\\tilde{\\Omega}\\big(\\frac{1}{\\epsilon}\\big)$ whenever the objective function is\npiecewise linear with polynomially many pieces in the input size. This is\nparticularly surprising as existing parallel complexity lower bounds are based\non such classes of functions. The seeming contradiction is resolved by\nconsidering the region in which the algorithm is allowed to query the\nobjective.\n","authors":["Jelena Diakonikolas","Cristóbal Guzmán"],"pdf_url":"https://arxiv.org/pdf/2403.16317v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.11858v2","updated":"2024-03-24T21:33:21Z","published":"2024-02-19T06:00:35Z","title":"Stochastic Hessian Fittings on Lie Groups","summary":"  This paper studies the fitting of Hessian or its inverse for stochastic\noptimizations using a Hessian fitting criterion from the preconditioned\nstochastic gradient descent (PSGD) method, which is intimately related to many\ncommonly used second order and adaptive gradient optimizers, e.g., BFGS,\nGaussian-Newton and natural gradient descent, AdaGrad, etc. Our analyses reveal\nthe efficiency and reliability differences among a wide range of preconditioner\nfitting methods, from closed-form to iterative solutions, using Hessian-vector\nproducts or stochastic gradients only, with Hessian fittings in the Euclidean\nspace, the manifold of symmetric positive definite (SPL) matrices, or a variety\nof Lie groups. The most intriguing discovery is that the Hessian fitting itself\nas an optimization problem is strongly convex under mild conditions on a\nspecific yet general enough Lie group. This discovery turns Hessian fitting\ninto a well behaved optimization problem, and facilitates the designs of highly\nefficient and elegant Lie group sparse preconditioner fitting methods for large\nscale stochastic optimizations.\n","authors":["Xi-Lin Li"],"pdf_url":"https://arxiv.org/pdf/2402.11858v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16302v1","updated":"2024-03-24T21:29:05Z","published":"2024-03-24T21:29:05Z","title":"Chance-Constrained Gaussian Mixture Steering to a Terminal Gaussian\n  Distribution","summary":"  We address the problem of finite-horizon control of a discrete-time linear\nsystem, where the initial state distribution follows a Gaussian mixture model,\nthe terminal state must follow a specified Gaussian distribution, and the state\nand control inputs must obey chance constraints. We show that, throughout the\ntime horizon, the state and control distributions are fully characterized by\nGaussian mixtures. We then formulate the cost, distributional terminal\nconstraint, and affine/2-norm chance constraints on the state and control, as\nconvex functions of the decision variables. This is leveraged to formulate the\nchance-constrained path planning problem as a single semidefinite programming\nproblem. A numerical example demonstrates the effectiveness of the proposed\nmethod.\n","authors":["Naoya Kumagai","Kenshiro Oguri"],"pdf_url":"https://arxiv.org/pdf/2403.16302v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16294v1","updated":"2024-03-24T21:00:23Z","published":"2024-03-24T21:00:23Z","title":"Unbiased Extremum Seeking Based on Lie Bracket Averaging","summary":"  Extremum seeking is an online, model-free optimization algorithm\ntraditionally known for its practical stability. This paper introduces an\nextremum seeking algorithm designed for unbiased convergence to the extremum\nasymptotically, allowing users to define the convergence rate. Unlike\nconventional extremum seeking approaches utilizing constant gains, our\nalgorithms employ time-varying parameters. These parameters reduce perturbation\namplitudes towards zero in an asymptotic manner, while incorporating\nasymptotically growing controller gains. The stability analysis is based on\nstate transformation, achieved through the multiplication of the input state by\nasymptotic growth function, and Lie bracket averaging applied to the\ntransformed system. The averaging ensures the practical stability of the\ntransformed system, which, in turn, leads to the asymptotic stability of the\noriginal system. Moreover, for strongly convex maps, we achieve exponentially\nfast convergence. The numerical simulations validate the feasibility of the\nintroduced designs.\n","authors":["Cemal Tugrul Yilmaz","Mamadou Diagne","Miroslav Krstic"],"pdf_url":"https://arxiv.org/pdf/2403.16294v1.pdf","comment":"Submitted to the 63rd IEEE Conference on Decision and Control (CDC),\n  2024"},{"id":"http://arxiv.org/abs/2403.16240v1","updated":"2024-03-24T17:12:13Z","published":"2024-03-24T17:12:13Z","title":"Low Rank Groupwise Deformations for Motion Tracking in Cardiac Cine MRI","summary":"  Diffeomorphic image registration is a commonly used method to deform one\nimage to resemble another. While warping a single image to another is useful,\nit can be advantageous to warp multiple images simultaneously, such as in\ntracking the motion of the heart across a sequence of images. In this paper,\nour objective is to propose a novel method capable of registering a group or\nsequence of images to a target image, resulting in registered images that\nappear identical and therefore have a low rank. Moreover, we aim for these\nregistered images to closely resemble the target image. Through experimental\nevidence, we will demonstrate our method's superior efficacy in producing\nlow-rank groupwise deformations compared to other state-of-the-art approaches.\n","authors":["Sean Rendell","Jinming Duan"],"pdf_url":"https://arxiv.org/pdf/2403.16240v1.pdf","comment":"A thesis submitted to the University of Birmingham for MSc Degree"},{"id":"http://arxiv.org/abs/2403.16232v1","updated":"2024-03-24T16:49:01Z","published":"2024-03-24T16:49:01Z","title":"Mean Field Game of Mutual Holding with common noise","summary":"  We consider the mean field game of cross--holding introduced in\n\\citeauthor*{DjeteTouzi} \\cite{DjeteTouzi} in the context where the equity\nvalue dynamics are affected by a common noise. In contrast with\n\\cite{DjeteTouzi}, the problem exhibits the standard paradigm of mean--variance\ntrade off. Our crucial observation is to search for equilibrium solutions of\nour mean field game among those models which satisfy an appropriate notion of\nno--arbitrage. Under this condition, it follows that the representative agent\noptimization step is reduced to a standard portfolio optimization problem with\nrandom endowment.\n","authors":["Leila Bassou","Mao Fabrice Djete","Nizar Touzi"],"pdf_url":"https://arxiv.org/pdf/2403.16232v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16223v1","updated":"2024-03-24T16:33:01Z","published":"2024-03-24T16:33:01Z","title":"A Coupled Optimization Framework for Correlated Equilibria in\n  Normal-Form Game","summary":"  In competitive multi-player interactions, simultaneous optimality is a key\nrequirement for establishing strategic equilibria. This property is explicit\nwhen the game-theoretic equilibrium is the simultaneously optimal solution of\ncoupled optimization problems. However, no such optimization problems exist for\nthe correlated equilibrium, a strategic equilibrium where the players can\ncorrelate their actions. We address the lack of a coupled optimization\nframework for the correlated equilibrium by introducing an {unnormalized game}\n-- an extension of normal-form games in which the player strategies are lifted\nto unnormalized measures over the joint actions. We show that the set of fully\nmixed generalized Nash equilibria of this unnormalized game is a subset of the\ncorrelated equilibrium of the normal-form game. Furthermore, we introduce an\nentropy regularization to the unnormalized game and prove that the\nentropy-regularized generalized Nash equilibrium is a sub-optimal correlated\nequilibrium of the normal form game where the degree of sub-optimality depends\non the magnitude of regularization. We prove that the entropy-regularized\nunnormalized game has a closed-form solution, and empirically verify its\ncomputational efficacy at approximating the correlated equilibrium of\nnormal-form games.\n","authors":["Sarah H. Q. Li","Yue Yu","Florian Dörfler","John Lygeros"],"pdf_url":"https://arxiv.org/pdf/2403.16223v1.pdf","comment":"8 pages, 2 figures"},{"id":"http://arxiv.org/abs/2403.16173v1","updated":"2024-03-24T14:30:13Z","published":"2024-03-24T14:30:13Z","title":"A robust optimization approach model for a multi-vaccine multi-echelon\n  supply chain","summary":"  This research investigates a multi-product, multi-echelon, and multi-period\nvaccine supply chain network model under uncertainty and quality inspection\nerrors. The objective function seeks optimizing the total cost of the supply\nchain. Moreover, the proposed model is formulated as a mixed integer linear\nprogramming problem under multiple sources of uncertain parameters including\ndemand, inspection errors, vaccine waste generated in healthcare centers, and\ndefective treatment rate of vaccine waste. To provide meaningful solutions that\nare robust against future fluctuation of parameters, the robust optimization\napproach is utilized to incorporate the decision maker risk attitude under\ndifferent type of uncertainty sets. Namely, box, polyhedral and combination of\ninterval polyhedral. The performance of the proposed model is demonstrated\nthrough an illustrative example. The results show the effect of different types\nof uncertainties on the overall objective function. Managerial insights and\nresearch implications in terms of vaccine supply chain is advised and future\nresearch directions are proposed.\n","authors":["Abderrahmen Bochenine","Ismail Almaraj"],"pdf_url":"https://arxiv.org/pdf/2403.16173v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16165v1","updated":"2024-03-24T14:10:12Z","published":"2024-03-24T14:10:12Z","title":"Input-to-State Stability of Newton Methods for Generalized Equations in\n  Nonlinear Optimization","summary":"  We show that Newton methods for generalized equations are input-to-state\nstable with respect to disturbances such as due to inexact computations. We\nthen use this result to obtain convergence and robustness of a multistep\nNewton-type method for multivariate generalized equations. We demonstrate the\nusefulness of the results with other applications to nonlinear optimization. In\nparticular, we provide a new proof for (robust) local convergence of the\naugmented Lagrangian method.\n","authors":["Torbjørn Cunis","Ilya Kolmanovsky"],"pdf_url":"https://arxiv.org/pdf/2403.16165v1.pdf","comment":"Submitted to 2024 Conference on Decision and Control"},{"id":"http://arxiv.org/abs/2403.16156v1","updated":"2024-03-24T13:48:47Z","published":"2024-03-24T13:48:47Z","title":"An instability result of Hamiltonian systems related to optimal swing-up\n  control of a pendulum","summary":"  This paper presents an instability result of Hamiltonian systems associated\nwith optimal swing-up control for a pendulum. The systems possess weak\n(higher-order) instability at the initial point of the swing-up control, the\nanalysis for which requires techniques from celestial mechanics. The obtained\nresult may have relationships with the previously obtained numerical studies\nfor the existence of multiple locally optimal solutions and the non-existence\nconjecture of the optimal control.\n","authors":["Noboru Sakamoto"],"pdf_url":"https://arxiv.org/pdf/2403.16156v1.pdf","comment":"Submitted for the IEEE Conference on Decision and Control 2024"},{"id":"http://arxiv.org/abs/2304.08705v4","updated":"2024-03-24T12:50:40Z","published":"2023-04-18T02:31:02Z","title":"The chain control set of discrete-time linear system on the affine\n  two-dimensional Lie group","summary":"  In this paper, we present conditions for the existence and uniqueness of\nchain control sets of discrete-time linear systems on the affine\ntwo-dimensional Lie group. More specifically, we prove that these chain control\nsets are given by the union of an infinite number of control sets with empty\ninteriors.\n","authors":["Thiago Cavalheiro","Alexandre Santana","João Cossich"],"pdf_url":"https://arxiv.org/pdf/2304.08705v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.05742v2","updated":"2024-03-24T12:31:55Z","published":"2023-02-11T16:48:31Z","title":"A single player and a mass of agents: a pursuit evasion-like game","summary":"  We study a finite-horizon differential game of pursuit-evasion like, between\na single player and a mass of agents. The player and the mass directly control\ntheir own evolution, which for the mass is given by a first order PDE of\ntransport equation type. Using also an adapted concept of non-anticipating\nstrategies, we derive an infinite dimensional Isaacs equation, and by dynamic\nprogramming techniques we prove that the value function is the unique viscosity\nsolution on a suitable invariant subset of a Hilbert space.\n","authors":["Fabio Bagagiolo","Rossana Capuani","Luciano Marzufero"],"pdf_url":"https://arxiv.org/pdf/2302.05742v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.13855v2","updated":"2024-03-24T12:05:47Z","published":"2023-09-25T03:47:32Z","title":"Adaptive Softassign via Hadamard-Equipped Sinkhorn","summary":"  Softassign is a pivotal method in graph matching and other learning tasks.\nMany softassign-based algorithms exhibit performance sensitivity to a parameter\nin the softassign. However, tuning the parameter is challenging and almost done\nempirically. This paper proposes an adaptive softassign method for graph\nmatching by analyzing the relationship between the objective score and the\nparameter. This method can automatically tune the parameter based on a given\nerror bound to guarantee accuracy. The Hadamard-Equipped Sinkhorn formulas\nintroduced in this study significantly enhance the efficiency and stability of\nthe adaptive softassign. Moreover, these formulas can also be used in optimal\ntransport problems. The resulting adaptive softassign graph matching algorithm\nenjoys significantly higher accuracy than previous state-of-the-art large graph\nmatching algorithms while maintaining comparable efficiency.\n","authors":["Binrui Shen","Qiang Niu","Shengxin Zhu"],"pdf_url":"https://arxiv.org/pdf/2309.13855v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03712v2","updated":"2024-03-24T11:53:43Z","published":"2023-06-06T14:21:57Z","title":"Exact controllability of incompressible ideal magnetohydrodynamics in\n  $2$D","summary":"  This work examines the controllability of planar incompressible ideal\nmagnetohydrodynamics (MHD). Interior controls are obtained for problems posed\nin doubly-connected regions; simply-connected configurations are driven by\nboundary controls. Up to now, only straight channels regulated at opposing\nwalls have been studied. Hence, the present program adds to the literature an\nexploration of interior controllability, extends the known boundary\ncontrollability results, and contributes ideas for treating general domains. To\ntransship obstacles stemming from the MHD coupling and the magnetic field\ntopology, a divide-and-control strategy is proposed. This leads to a family of\nnonlinear velocity-controlled sub-problems which are solved using J.-M. Coron's\nreturn method. The latter is here developed based on a reference trajectory in\nthe domain's first cohomology space.\n","authors":["Manuel Rissel"],"pdf_url":"https://arxiv.org/pdf/2306.03712v2.pdf","comment":"43 pages, 9 figures"},{"id":"http://arxiv.org/abs/2403.16077v1","updated":"2024-03-24T09:38:01Z","published":"2024-03-24T09:38:01Z","title":"On the Bailout Dividend Problem with Periodic Dividend Payments and\n  Fixed Transaction Costs","summary":"  We study the optimal bailout dividend problem with transaction costs for an\ninsurance company, where shareholder payouts align with the arrival times of an\nindependent Poisson process. In this scenario, the underlying risk model\nfollows a spectrally negative L\\'evy process. Our analysis confirms the\noptimality of a periodic $(b_{1},b_{2})$-barrier policy with classical\nreflection at zero. This strategy involves reducing the surplus to $b_1$ when\nit exceeds $b_{2}$ at the Poisson arrival times and pushes the surplus to 0\nwhenever it goes below zero.\n","authors":["Harold A. Moreno-Franco","Jose-Luis Pérez"],"pdf_url":"https://arxiv.org/pdf/2403.16077v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16070v1","updated":"2024-03-24T09:11:55Z","published":"2024-03-24T09:11:55Z","title":"Towards a MATLAB Toolbox to compute backstepping kernels using the power\n  series method","summary":"  In this paper, we extend our previous work on the power series method for\ncomputing backstepping kernels. Our first contribution is the development of\ninitial steps towards a MATLAB toolbox dedicated to backstepping kernel\ncomputation. This toolbox would exploit MATLAB's linear algebra and sparse\nmatrix manipulation features for enhanced efficiency; our initial findings show\nconsiderable improvements in computational speed with respect to the use of\nsymbolical software without loss of precision at high orders. Additionally, we\ntackle limitations observed in our earlier work, such as slow convergence (due\nto oscillatory behaviors) and non-converging series (due to loss of analiticity\nat some singular points). To overcome these challenges, we introduce a\ntechnique that mitigates this behaviour by computing the expansion at different\npoints, denoted as localized power series. This approach effectively navigates\naround singularities, and can also accelerates convergence by using more local\napproximations. Basic examples are provided to demonstrate these enhancements.\nAlthough this research is still ongoing, the significant potential and\nsimplicity of the method already establish the power series approach as a\nviable and versatile solution for solving backstepping kernel equations,\nbenefiting both novel and experienced practitioners in the field. We anticipate\nthat these developments will be particularly beneficial in training the\nrecently introduced neural operators that approximate backstepping kernels and\ngains.\n","authors":["Xin Lin","Rafael Vazquez","Miroslav Krstic"],"pdf_url":"https://arxiv.org/pdf/2403.16070v1.pdf","comment":"Preprint submitted to CDC 2024"},{"id":"http://arxiv.org/abs/2403.16059v1","updated":"2024-03-24T08:06:34Z","published":"2024-03-24T08:06:34Z","title":"Manifold Regularization Classification Model Based On Improved Diffusion\n  Map","summary":"  Manifold regularization model is a semi-supervised learning model that\nleverages the geometric structure of a dataset, comprising a small number of\nlabeled samples and a large number of unlabeled samples, to generate\nclassifiers. However, the original manifold norm limits the performance of\nmodels to local regions. To address this limitation, this paper proposes an\napproach to improve manifold regularization based on a label propagation model.\nWe initially enhance the probability transition matrix of the diffusion map\nalgorithm, which can be used to estimate the Neumann heat kernel, enabling it\nto accurately depict the label propagation process on the manifold. Using this\nmatrix, we establish a label propagation function on the dataset to describe\nthe distribution of labels at different time steps. Subsequently, we extend the\nlabel propagation function to the entire data manifold. We prove that the\nextended label propagation function converges to a stable distribution after a\nsufficiently long time and can be considered as a classifier. Building upon\nthis concept, we propose a viable improvement to the manifold regularization\nmodel and validate its superiority through experiments.\n","authors":["Hongfu Guo","Wencheng Zou","Zeyu Zhang","Shuishan Zhang","Ruitong Wang","Jintao Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.16059v1.pdf","comment":"20 pages, 24figures"},{"id":"http://arxiv.org/abs/2403.16058v1","updated":"2024-03-24T08:01:52Z","published":"2024-03-24T08:01:52Z","title":"Exponential mixing of constrained random dynamical systems via\n  controllability conditions","summary":"  We provide deterministic controllability conditions that imply exponential\nmixing properties for randomly forced constrained dynamical systems with\npossibly unbounded state space. As an application, new ergodicity results are\nobtained for non-smooth models in elasto-plasticity driven by various types of\nnoise, including white noise. It is thereby illustrated how tools from control\ntheory can be utilized to tackle regularity issues that commonly arise in the\nqualitative study of constrained systems.\n","authors":["Laurent Mertz","Vahagn Nersesyan","Manuel Rissel"],"pdf_url":"https://arxiv.org/pdf/2403.16058v1.pdf","comment":"27 pages, 1 figure"},{"id":"http://arxiv.org/abs/2208.07243v4","updated":"2024-03-24T07:48:18Z","published":"2022-08-15T14:57:26Z","title":"Exponential Concentration in Stochastic Approximation","summary":"  We analyze the behavior of stochastic approximation algorithms where\niterates, in expectation, progress towards an objective at each step. When\nprogress is proportional to the step size of the algorithm, we prove\nexponential concentration bounds. These tail-bounds contrast asymptotic\nnormality results, which are more frequently associated with stochastic\napproximation. The methods that we develop rely on a geometric ergodicity\nproof. This extends a result on Markov chains due to Hajek (1982) to the area\nof stochastic approximation algorithms. We apply our results to several\ndifferent Stochastic Approximation algorithms, specifically Projected\nStochastic Gradient Descent, Kiefer-Wolfowitz and Stochastic Frank-Wolfe\nalgorithms. When applicable, our results prove faster $O(1/t)$ and linear\nconvergence rates for Projected Stochastic Gradient Descent with a\nnon-vanishing gradient.\n","authors":["Kody Law","Neil Walton","Shangda Yang"],"pdf_url":"https://arxiv.org/pdf/2208.07243v4.pdf","comment":"35 pages, 11 Figures"},{"id":"http://arxiv.org/abs/2403.16046v1","updated":"2024-03-24T07:13:33Z","published":"2024-03-24T07:13:33Z","title":"Digital control of negative imaginary systems: a discrete-time hybrid\n  integrator-gain system approach","summary":"  A hybrid integrator-gain system (HIGS) is a control element that switches\nbetween an integrator and a gain, which overcomes some inherent limitations of\nlinear controllers. In this paper, we consider using discrete-time HIGS\ncontrollers for the digital control of negative imaginary (NI) systems. We show\nthat the discrete-time HIGS themselves are step-advanced negative imaginary\nsystems. For a minimal linear NI system, there always exists a HIGS controller\nthat can asymptotically stablize it. An illustrative example is provided, where\nwe use the proposed HIGS control method to stabilize a discrete-time\nmass-spring system.\n","authors":["Kanghong Shi","Ian R. Petersen"],"pdf_url":"https://arxiv.org/pdf/2403.16046v1.pdf","comment":"To appear in the 2024 European Control Conference. 7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2403.16029v1","updated":"2024-03-24T06:10:54Z","published":"2024-03-24T06:10:54Z","title":"Planning Charging Stations and Service Operations of Dockless Electric\n  Micromobility Systems","summary":"  Dockless electric micro-mobility services (e.g., shared e-scooters and\ne-bikes) have been increasingly popular in the recent decade, and a variety of\ncharging technologies have emerged for these services. The use of charging\nstations, to/from which service vehicles are transported by the riders for\ncharging, poses as a promising approach because it reduces the need for\ndedicated staff or contractors. However, unique challenges also arise, such as\nhow to incentivize riders to drop off vehicles at stations and how to\nefficiently utilize the vehicles being charged at the stations. This paper\nfocuses on dockless e-scooters as an example and develops a new spatial queuing\nnetwork model to capture the steady-state scooter service cycles, battery\nconsumption and charging processes, and the associated pricing and management\nmechanisms. Building upon this model, a system of closed-form equations is\nformulated and incorporated into a constrained nonlinear program to optimize\nthe deployment of the service fleet, the design of charging stations (i.e.,\nnumber, location, and capacity), user-based charging price promotions and\npriorities, and repositioning truck operations (i.e., headway and truck load).\nThe proposed queuing network model is found to match very well with agent-based\nsimulations. It is applied to a series of numerical experiments to draw\ninsights into the optimal designs and the system performance. The numerical\nresults reveal strong advantages of using charging stations for shared dockless\nelectric micro-mobility services as compared to state-of-the-art alternatives.\nThe proposed model can also be used to analyze other micromobility services and\nother charging approaches.\n","authors":["Yining Liu","Yanfeng Ouyang"],"pdf_url":"https://arxiv.org/pdf/2403.16029v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.00956v5","updated":"2024-03-24T05:01:56Z","published":"2022-08-01T16:07:22Z","title":"An adjoint-free algorithm for conditional nonlinear optimal\n  perturbations (CNOPs) via sampling","summary":"  In this paper, we propose a sampling algorithm based on state-of-the-art\nstatistical machine learning techniques to obtain conditional nonlinear optimal\nperturbations (CNOPs), which is different from traditional (deterministic)\noptimization methods.1 Specifically, the traditional approach is unavailable in\npractice, which requires numerically computing the gradient (first-order\ninformation) such that the computation cost is expensive, since it needs a\nlarge number of times to run numerical models. However, the sampling approach\ndirectly reduces the gradient to the objective function value (zeroth-order\ninformation), which also avoids using the adjoint technique that is unusable\nfor many atmosphere and ocean models and requires large amounts of storage. We\nshow an intuitive analysis for the sampling algorithm from the law of large\nnumbers and further present a Chernoff-type concentration inequality to\nrigorously characterize the degree to which the sample average\nprobabilistically approximates the exact gradient. The experiments are\nimplemented to obtain the CNOPs for two numerical models, the Burgers equation\nwith small viscosity and the Lorenz-96 model. We demonstrate the CNOPs obtained\nwith their spatial patterns, objective values, computation times, and nonlinear\nerror growth. Compared with the performance of the three approaches, all the\ncharacters for quantifying the CNOPs are nearly consistent, while the\ncomputation time using the sampling approach with fewer samples is much\nshorter. In other words, the new sampling algorithm shortens the computation\ntime to the utmost at the cost of losing little accuracy.\n","authors":["Bin Shi","Guodong Sun"],"pdf_url":"https://arxiv.org/pdf/2208.00956v5.pdf","comment":"20 pages, 6 figures, 4 tables"},{"id":"http://arxiv.org/abs/2403.16000v1","updated":"2024-03-24T04:04:05Z","published":"2024-03-24T04:04:05Z","title":"Stochastic maximum principle for weighted mean-field system with jump","summary":"  In this article, we consider a weighted mean-field control problem with\njump-diffusion as its state process. The main difficulty is from the\nnon-Lipschitz property of the coefficients. We overcome this difficulty by an\n$L_{p,q}$-estimate of the solution processes with a suitably chosen $p$ and\n$q$. Convex pertubation method combining with the aforementioned\n$L_{p,q}$-estimation method is utilized to derive the stochastic maximum\nprinciple for this control problem. A sufficient condition for the optimality\nis also given.\n","authors":["Yanyan Tang","Jie Xiong"],"pdf_url":"https://arxiv.org/pdf/2403.16000v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15998v1","updated":"2024-03-24T03:46:29Z","published":"2024-03-24T03:46:29Z","title":"Output Feedback Control of Suspended Sediment Load Entrainment in Water\n  Canals and Reservoirs","summary":"  This paper addresses the management of water flow in a rectangular open\nchannel, considering the dynamic nature of both the channel's bathymetry and\nthe suspended sediment particles caused by entrainment and deposition effects.\nThe control-oriented model under study is a set of coupled nonlinear partial\ndifferential equations (PDEs) describing conservation of mass and momentum\nwhile accounting for constitutive relations that govern sediment erosion and\ndeposition phenomena. The proposed boundary control problem presents a fresh\nperspective in water canal management and expands Saint-Venant Exner (SVE)\ncontrol frameworks by integrating dynamics related to the transport of fine\nparticles. After linearization, PDE backstepping design is employed to\nstabilize both the bathymetry, the water dynamics together with the\nconcentration of suspended sediment particles. Two underflow sluice gates are\nused for flow control at the upstream and downstream boundaries with only the\ndownstream component being actuated. An observer-based backstepping control\ndesign is carried out for the downstream gate using state measurement at the\nupstream gate to globally exponentially stabilize the linearized system to a\ndesired equilibrium point in $\\mathscr{L}^2$ sense. The stability analysis is\nperformed on the linearized model which is a system of four coupled PDEs, three\nof which are rightward convecting and one leftward. The proposed control design\nhas the potential to facilitate efficient reservoir flushing operations.\nConsistent simulation results are presented to illustrate the feasibility of\nthe designed control law.\n","authors":["Eranda Somathilake","Mamadou Diagne"],"pdf_url":"https://arxiv.org/pdf/2403.15998v1.pdf","comment":"10 pages, 8 figures"},{"id":"http://arxiv.org/abs/2207.02894v2","updated":"2024-03-24T03:31:23Z","published":"2022-07-06T18:14:59Z","title":"Learning Acceptability Criteria from Good and Bad Decisions: An Inverse\n  Optimization Approach","summary":"  Conventional inverse optimization inputs a solution and finds the parameters\nof an optimization model that render a given solution optimal. The literature\nmostly focuses on inferring the objective function in linear problems when\nacceptable solutions are provided as input. In this paper, we propose an\ninverse optimization model that inputs several accepted and rejected solutions\nand recovers the underlying convex optimization model that can be used to\ngenerate such solutions. The novelty of our model is three-fold: First, while\nmost literature focuses on inferring the objective function, we focus on\ninferring the feasible region. Second, our model can infer the constraints of\ngeneral convex optimization models. Third, the proposed model learns from\naccepted (good) and rejected (bad) observations in inferring the constraint\nset. The resulting inverse model is a mixed-integer nonlinear problem that is\ncomplex to solve. To mitigate the inverse problem complexity, we employ\nvariational inequalities and the theoretical properties of the solutions to\nderive a reduced formulation that retains the complexity of its forward\ncounterpart. We demonstrate that our inverse model can utilize a subset of past\ngood and bad treatment plans to infer planning criteria that can lead to nearly\nguaranteed clinically acceptable plans for future patients.\n","authors":["Houra Mahmoudzadeh","Kimia Ghobadi"],"pdf_url":"https://arxiv.org/pdf/2207.02894v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15988v1","updated":"2024-03-24T02:53:04Z","published":"2024-03-24T02:53:04Z","title":"Infinite dimensional open-loop linear quadratic stochastic optimal\n  control problems and related games","summary":"  We investigate the linear quadratic stochastic optimal control problems in\ninfinite dimension without Markovian restriction for coefficients. The\nnecessary and sufficient conditions for open-loop optimal controls are\npresented. We prove the Fr\\'echet differentiable of the cost functional with\nrespect to the control variable, and the Fr\\'echet derivatives are\ncharacterized in detail by operators derived from dual analysis, which are\nproven to be the stationary conditions. Transposition methods are adopted to\ndeal with the adjoint equations. As applications, we employ the results to\nstudy open-loop Nash equilibria for two-person stochastic differential games.\n","authors":["Guangdong Jing"],"pdf_url":"https://arxiv.org/pdf/2403.15988v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2311.00181v2","updated":"2024-03-24T01:13:59Z","published":"2023-10-31T22:59:23Z","title":"Best of Both Worlds Guarantees for Smoothed Online Quadratic\n  Optimization","summary":"  We study the smoothed online quadratic optimization (SOQO) problem where, at\neach round $t$, a player plays an action $x_t$ in response to a quadratic\nhitting cost and an additional squared $\\ell_2$-norm cost for switching\nactions. This problem class has strong connections to a wide range of\napplication domains including smart grid management, adaptive control, and data\ncenter management, where switching-efficient algorithms are highly sought\nafter. We study the SOQO problem in both adversarial and stochastic settings,\nand in this process, perform the first stochastic analysis of this class of\nproblems. We provide the online optimal algorithm when the minimizers of the\nhitting cost function evolve as a general stochastic process, which, for the\ncase of martingale process, takes the form of a distribution-agnostic dynamic\ninterpolation algorithm (LAI). Next, we present the stochastic-adversarial\ntrade-off by proving an $\\Omega(T)$ expected regret for the adversarial optimal\nalgorithm in the literature (ROBD) with respect to LAI and, a sub-optimal\ncompetitive ratio for LAI in the adversarial setting. Finally, we present a\nbest-of-both-worlds algorithm that obtains a robust adversarial performance\nwhile simultaneously achieving a near-optimal stochastic performance.\n","authors":["Neelkamal Bhuyan","Debankur Mukherjee","Adam Wierman"],"pdf_url":"https://arxiv.org/pdf/2311.00181v2.pdf","comment":"48 pages, 9 figures"}],"Systems and Control":[{"id":"http://arxiv.org/abs/2403.16313v1","updated":"2024-03-24T22:35:54Z","published":"2024-03-24T22:35:54Z","title":"Datasets of Great Britain Primary Substations Integrated with Household\n  Heating Information","summary":"  The growing demand for electrified heating, electrified transportation, and\npower-intensive data centres challenge distribution networks. If\nelectrification projects are carried out without considering electrical\ndistribution infrastructure, there could be unexpected blackouts and financial\nlosses. Datasets containing real-world distribution network information are\nrequired to address this. On the other hand, social data, such as household\nheating composition, are closely coupled with people's lives. Studying the\ncoupling between the energy system and society is important in promoting social\nwelfare. To fill these gaps, this paper introduces two datasets. The first is\nthe main dataset for the distribution networks in Great Britain (GB),\ncollecting information on firm capacity, peak demands, locations, and parent\ntransmission nodes (the Grid Supply Point, namely GSP) for all primary\nsubstations (PSs). PSs are a crucial part of the UK distribution network and\nare at the lowest voltage level (11 kV) with publicly available data for most\nUK Distribution Network Operators (DNOs). Substation firm capacity and peak\ndemand facilitate an understanding of the remaining room of the existing\nnetwork. The parent GSP information helps link the dataset of distribution\nnetworks to datasets of transmission networks. The second dataset extends the\nmain network dataset, linking each PS to information about the number of\nhouseholds that use different types of central heating recorded in census data.\nThe derivation of the second dataset is based on locations of PSs collected in\nthe main dataset with appropriate assumptions. The derivation process may also\nbe replicated to integrate other social datasets.\n","authors":["Yihong Zhou","Chaimaa Essayeh","Thomas Morstyn"],"pdf_url":"https://arxiv.org/pdf/2403.16313v1.pdf","comment":"Submitted to the journal \"Data in Brief\""},{"id":"http://arxiv.org/abs/2403.16307v1","updated":"2024-03-24T22:12:40Z","published":"2024-03-24T22:12:40Z","title":"ANN-Based Adaptive NMPC for Uranium Extraction-Scrubbing Operation in\n  Spent Nuclear Fuel Treatment Process","summary":"  This paper addresses the particularities in optimal control of the uranium\nextraction-scrubbing operation in the PUREX process. The control problem\nrequires optimally stabilizing the system at a desired solvent saturation\nlevel, guaranteeing constraints, disturbance rejection, and adapting to set\npoint variations. A qualified simulator named PAREX was developed by the French\nAlternative Energies and Atomic Energy Commission (CEA) to simulate\nliquid-liquid extraction operations in the PUREX process. However, since the\nmathematical model is complex and is described by a system of nonlinear, stiff,\nhigh-dimensional differential-algebraic equations (DAE), applying optimal\ncontrol methods will lead to a large-scale nonlinear programming problem with a\nhuge computational burden. The solution we propose in this work is to train a\nneural network to predict the process outputs using the measurement history.\nThis neural network architecture, which employs the long short-term memory\n(LSTM), linear regression and logistic regression networks, allows reducing the\nnumber of state variables, thus reducing the complexity of the optimization\nproblems in the control scheme. Furthermore, nonlinear model predictive control\n(NMPC) and moving horizon estimation (MHE) problems are developed and solved\nusing the PSO (Particle Swarm Optimization) algorithm. Simulation results show\nthat the proposed adaptive optimal control scheme satisfies the requirements of\nthe control problem and provides promise for experimental testing.\n","authors":["Duc-Tri Vo","Ionela Prodan","Laurent Lefèvre","Vincent Vanel","Sylvain Costenoble","Binh Dinh"],"pdf_url":"https://arxiv.org/pdf/2403.16307v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16306v1","updated":"2024-03-24T21:55:46Z","published":"2024-03-24T21:55:46Z","title":"Control-Coherent Koopman Modeling: A Physical Modeling Approach","summary":"  The modeling of nonlinear dynamics based on Koopman operator theory, which is\noriginally applicable only to autonomous systems with no control, is extended\nto non-autonomous control system without approximation to input matrix B.\nPrevailing methods using a least square estimate of the B matrix may result in\nan erroneous input matrix, misinforming the controller about the structure of\nthe input matrix in a lifted space. Here, a new method for constructing a\nKoopman model that comprises the exact input matrix B is presented. A set of\nstate variables are introduced so that the control inputs are linearly involved\nin the dynamics of actuators. With these variables, a lifted linear model with\nthe exact control matrix, called a Control-Coherent Koopman Model, is\nconstructed by superposing control input terms, which are linear in local\nactuator dynamics, to the Koopman operator of the associated autonomous\nnonlinear system. The proposed method is applied to multi degree-of-freedom\nrobotic arms and multi-cable manipulation systems. Model Predictive Control is\napplied to the former. It is demonstrated that the prevailing Dynamic Mode\nDecomposition with Control (DMDc) using an approximate control matrix B does\nnot provide a satisfactory result, while the Control-Coherent Koopman Model\nperforms well with the correct B matrix.\n","authors":["H. Harry Asada","Jose A. Solano-Castellanos"],"pdf_url":"https://arxiv.org/pdf/2403.16306v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16281v1","updated":"2024-03-24T20:07:07Z","published":"2024-03-24T20:07:07Z","title":"Semi-Automatic Line-System Provisioning with Integrated\n  Physical-Parameter-Aware Methodology: Field Verification and Operational\n  Feasibility","summary":"  We propose methods and an architecture to conduct measurements and optimize\nnewly installed optical fiber line systems semi-automatically using integrated\nphysics-aware technologies in a data center interconnection (DCI) transmission\nscenario. We demonstrate, for the first time, digital longitudinal monitoring\n(DLM) and optical line system (OLS) physical parameter calibration working\ntogether in real-time to extract physical link parameters for transmission\nperformance optimization. Our methodology has the following advantages over\ntraditional design: a minimized footprint at user sites, accurate estimation of\nthe necessary optical network characteristics via complementary telemetry\ntechnologies, and the capability to conduct all operation work remotely. The\nlast feature is crucial, as it enables remote operation to implement network\ndesign settings for immediate response to quality of transmission (QoT)\ndegradation and reversion in the case of unforeseen problems. We successfully\nperformed semi-automatic line system provisioning over field fiber networks\nfacilities at Duke University, Durham, NC. The tasks of parameter retrieval,\nequipment setting optimization, and system setup/provisioning were completed\nwithin 1 hour. The field operation was supervised by on-duty personnel who\ncould access the system remotely from different time zones. By comparing\nQ-factor estimates calculated from the extracted link parameters with measured\nresults from 400G transceivers, we confirmed that our methodology has a\nreduction in the QoT prediction errors (+-0.3 dB) over existing design (+-10.6\ndB).\n","authors":["Hideki Nishizawa","Giacomo Borraccini","Takeo Sasai","Yue-Kai Huang","Toru Mano","Kazuya Anazawa","Masatoshi Namiki","Soichiroh Usui","Tatsuya Matsumura","Yoshiaki Sone","Zehao Wang","Seiji Okamoto","Takeru Inoue","Ezra Ip","Andrea D'Amico","Tingjun Chen","Vittorio Curri","Ting Wang","Koji Asahi","Koichi Takasugi"],"pdf_url":"https://arxiv.org/pdf/2403.16281v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.15893v3","updated":"2024-03-24T19:34:34Z","published":"2024-02-24T20:01:15Z","title":"Concurrent Learning of Policy and Unknown Safety Constraints in\n  Reinforcement Learning","summary":"  Reinforcement learning (RL) has revolutionized decision-making across a wide\nrange of domains over the past few decades. Yet, deploying RL policies in\nreal-world scenarios presents the crucial challenge of ensuring safety.\nTraditional safe RL approaches have predominantly focused on incorporating\npredefined safety constraints into the policy learning process. However, this\nreliance on predefined safety constraints poses limitations in dynamic and\nunpredictable real-world settings where such constraints may not be available\nor sufficiently adaptable. Bridging this gap, we propose a novel approach that\nconcurrently learns a safe RL control policy and identifies the unknown safety\nconstraint parameters of a given environment. Initializing with a parametric\nsignal temporal logic (pSTL) safety specification and a small initial labeled\ndataset, we frame the problem as a bilevel optimization task, intricately\nintegrating constrained policy optimization, using a Lagrangian-variant of the\ntwin delayed deep deterministic policy gradient (TD3) algorithm, with Bayesian\noptimization for optimizing parameters for the given pSTL safety specification.\nThrough experimentation in comprehensive case studies, we validate the efficacy\nof this approach across varying forms of environmental constraints,\nconsistently yielding safe RL policies with high returns. Furthermore, our\nfindings indicate successful learning of STL safety constraint parameters,\nexhibiting a high degree of conformity with true environmental safety\nconstraints. The performance of our model closely mirrors that of an ideal\nscenario that possesses complete prior knowledge of safety constraints,\ndemonstrating its proficiency in accurately identifying environmental safety\nconstraints and learning safe policies that adhere to those constraints.\n","authors":["Lunet Yifru","Ali Baheri"],"pdf_url":"https://arxiv.org/pdf/2402.15893v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16262v1","updated":"2024-03-24T18:49:16Z","published":"2024-03-24T18:49:16Z","title":"HT-LIP Model based Robust Control of Quadrupedal Robot Locomotion under\n  Unknown Vertical Ground Motion","summary":"  This paper presents a hierarchical control framework that enables robust\nquadrupedal locomotion on a dynamic rigid surface (DRS) with general and\nunknown vertical motions. The key novelty of the framework lies in its higher\nlayer, which is a discrete-time, provably stabilizing footstep controller. The\nbasis of the footstep controller is a new hybrid, time-varying, linear inverted\npendulum (HT-LIP) model that is low-dimensional and accurately captures the\nessential robot dynamics during DRS locomotion. A new set of sufficient\nstability conditions are then derived to directly guide the controller design\nfor ensuring the asymptotic stability of the HT-LIP model under general,\nunknown, vertical DRS motions. Further, the footstep controller is cast as a\ncomputationally efficient quadratic program that incorporates the proposed\nHT-LIP model and stability conditions. The middle layer takes the desired\nfootstep locations generated by the higher layer as input to produce\nkinematically feasible full-body reference trajectories, which are then\naccurately tracked by a lower-layer torque controller. Hardware experiments on\na Unitree Go1 quadrupedal robot confirm the robustness of the proposed\nframework under various unknown, aperiodic, vertical DRS motions and\nuncertainties (e.g., slippery and uneven surfaces, solid and liquid loads, and\nsudden pushes).\n","authors":["Amir Iqbal","Sushant Veer","Christopher Niezrecki","Yan Gu"],"pdf_url":"https://arxiv.org/pdf/2403.16262v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16252v1","updated":"2024-03-24T18:10:30Z","published":"2024-03-24T18:10:30Z","title":"Legged Robot State Estimation within Non-inertial Environments","summary":"  This paper investigates the robot state estimation problem within a\nnon-inertial environment. The proposed state estimation approach relaxes the\ncommon assumption of static ground in the system modeling. The process and\nmeasurement models explicitly treat the movement of the non-inertial\nenvironments without requiring knowledge of its motion in the inertial frame or\nrelying on GPS or sensing environmental landmarks. Further, the proposed state\nestimator is formulated as an invariant extended Kalman filter (InEKF) with the\ndeterministic part of its process model obeying the group-affine property,\nleading to log-linear error dynamics. The observability analysis of the filter\nconfirms that the robot's pose (i.e., position and orientation) and velocity\nrelative to the non-inertial environment are observable. Hardware experiments\non a humanoid robot moving on a rotating and translating treadmill demonstrate\nthe high convergence rate and accuracy of the proposed InEKF even under\nsignificant treadmill pitch sway, as well as large estimation errors.\n","authors":["Zijian He","Sangli Teng","Tzu-Yuan Lin","Maani Ghaffari","Yan Gu"],"pdf_url":"https://arxiv.org/pdf/2403.16252v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16225v1","updated":"2024-03-24T16:36:12Z","published":"2024-03-24T16:36:12Z","title":"Bi-Level Control of Weaving Sections in Mixed Traffic Environments with\n  Connected and Automated Vehicles","summary":"  Connected and automated vehicles (CAVs) can be beneficial for improving the\noperation of highway bottlenecks such as weaving sections. This paper proposes\na bi-level control approach based on an upper-level deep reinforcement learning\ncontroller and a lower-level model predictive controller to coordinate the\nlane-changings of a mixed fleet of CAVs and human-driven vehicles (HVs) in\nweaving sections. The upper level represents a roadside controller that\ncollects vehicular information from the entire weaving section and determines\nthe control weights used in the lower-level controller. The lower level is\nimplemented within each CAV, which takes the control weights from the\nupper-level controller and generates the acceleration and steering angle for\nindividual CAVs based on the local situation. The lower-level controller\nfurther incorporates an HV trajectory predictor, which is capable of handling\nthe dynamic topology of vehicles in weaving scenarios with intensive mandatory\nlane changes. The case study inspired by a real weaving section in Basel,\nSwitzerland, shows that our method consistently outperforms state-of-the-art\nbenchmarks.\n","authors":["Longhao Yan","Jinhao Liang","Kaidi Yang"],"pdf_url":"https://arxiv.org/pdf/2403.16225v1.pdf","comment":"12 pages, 8 figures"},{"id":"http://arxiv.org/abs/2309.13755v3","updated":"2024-03-24T16:15:24Z","published":"2023-09-24T21:13:20Z","title":"Efficient Recursive Data-enabled Predictive Control (Extended Version)","summary":"  In the field of model predictive control, Data-enabled Predictive Control\n(DeePC) offers direct predictive control, bypassing traditional modeling.\nHowever, challenges emerge with increased computational demand due to recursive\ndata updates. This paper introduces a novel recursive updating algorithm for\nDeePC. It emphasizes the use of Singular Value Decomposition (SVD) for\nefficient low-dimensional transformations of DeePC in its general form, as well\nas a fast SVD update scheme. Importantly, our proposed algorithm is highly\nflexible due to its reliance on the general form of DeePC, which is\ndemonstrated to encompass various data-driven methods that utilize\nPseudoinverse and Hankel matrices. This is exemplified through a comparison to\nSubspace Predictive Control, where the algorithm achieves asymptotically\nconsistent prediction for stochastic linear time-invariant systems. Our\nproposed methodologies' efficacy is validated through simulation studies.\n","authors":["Jicheng Shi","Yingzhao Lian","Colin N. Jones"],"pdf_url":"https://arxiv.org/pdf/2309.13755v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16214v1","updated":"2024-03-24T16:13:27Z","published":"2024-03-24T16:13:27Z","title":"Efficient Reachable Sets on Lie Groups Using Lie Algebra Monotonicity\n  and Tangent Intervals","summary":"  In this paper, we efficiently compute overapproximated reachable sets for\ncontrol systems evolving on Lie groups, building off results from monotone\nsystems theory and geometric integration theory. We propose to consider\nintervals living in the Lie algebra, which through the exponential map,\ndescribe real sets on the Lie group. A local equivalence between the original\nsystem and a system evolving on the Lie algebra allows existing interval\nreachability techniques to apply in the tangent space. Using interval bounds of\nthe Baker-Campbell-Hausdorff formula, a Runge-Kutta-Munthe-Kaas reachability\nalgorithm is proposed, providing reachable set estimates for arbitrary time\nhorizons at little computational cost. The algorithm is demonstrated on through\nconsensus on a torus and attitude control on $SO(3)$.\n","authors":["Akash Harapanahalli","Samuel Coogan"],"pdf_url":"https://arxiv.org/pdf/2403.16214v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16170v1","updated":"2024-03-24T14:25:10Z","published":"2024-03-24T14:25:10Z","title":"Voltage Regulation in Polymer Electrolyte Fuel Cell Systems Using\n  Gaussian Process Model Predictive Control","summary":"  This study introduces a novel approach utilizing Gaussian process model\npredictive control (MPC) to stabilize the output voltage of a polymer\nelectrolyte fuel cell (PEFC) system by simultaneously regulating hydrogen and\nairflow rates. Two Gaussian process models are developed to capture PEFC\ndynamics, taking into account constraints including hydrogen pressure and input\nchange rates, thereby aiding in mitigating errors inherent to PEFC predictive\ncontrol. The dynamic performance of the physical model and Gaussian process MPC\nin constraint handling and system inputs is compared and analyzed. Simulation\noutcomes demonstrate that the proposed Gaussian process MPC effectively\nmaintains the voltage at the target 48 V while adhering to safety constraints,\neven amidst workload disturbances ranging from 110-120 A. In comparison to\ntraditional MPC using detailed system models, Gaussian process MPC exhibits a\n43\\% higher overshoot and 25\\% slower response time. Nonetheless, it offers the\nadvantage of not requiring the underlying true system model and needing less\nsystem information.\n","authors":["Xiufei Li","Miao Zhang","Yuanxin Qi","Miao Yang"],"pdf_url":"https://arxiv.org/pdf/2403.16170v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16165v1","updated":"2024-03-24T14:10:12Z","published":"2024-03-24T14:10:12Z","title":"Input-to-State Stability of Newton Methods for Generalized Equations in\n  Nonlinear Optimization","summary":"  We show that Newton methods for generalized equations are input-to-state\nstable with respect to disturbances such as due to inexact computations. We\nthen use this result to obtain convergence and robustness of a multistep\nNewton-type method for multivariate generalized equations. We demonstrate the\nusefulness of the results with other applications to nonlinear optimization. In\nparticular, we provide a new proof for (robust) local convergence of the\naugmented Lagrangian method.\n","authors":["Torbjørn Cunis","Ilya Kolmanovsky"],"pdf_url":"https://arxiv.org/pdf/2403.16165v1.pdf","comment":"Submitted to 2024 Conference on Decision and Control"},{"id":"http://arxiv.org/abs/2403.16136v1","updated":"2024-03-24T13:09:46Z","published":"2024-03-24T13:09:46Z","title":"Data-Driven Sliding Mode Control for Partially Unknown Nonlinear Systems","summary":"  This paper introduces a new design method for data-driven control of\nnonlinear systems with partially unknown dynamics and unknown bounded\ndisturbance. Since it is not possible to achieve exact nonlinearity\ncancellation in the presence of unknown disturbance, this paper adapts the idea\nof sliding mode control (SMC) to ensure system stability and robustness without\nassuming that the nonlinearity goes to zero faster than the state as in the\nexisting methods. The SMC consists of a data-dependent robust controller\nensuring the system state trajectory reach and remain on the sliding surface\nand a nominal controller solved from a data-dependent semidefinite program\n(SDP) ensuring robust stability of the state trajectory on the sliding surface.\nNumerical simulation results demonstrate effectiveness of the proposed\ndata-driven SMC and its superior in terms of robust stability over the existing\ndata-driven control that also uses approximate nonlinearity cancellation.\n","authors":["Jianglin Lan","Xianxian Zhao","Congcong Sun"],"pdf_url":"https://arxiv.org/pdf/2403.16136v1.pdf","comment":"Submitted to IEEE CDC 2024"},{"id":"http://arxiv.org/abs/2403.16132v1","updated":"2024-03-24T13:03:27Z","published":"2024-03-24T13:03:27Z","title":"Runtime Monitoring and Fault Detection for Neural Network-Controlled\n  Systems","summary":"  There is an emerging trend in applying deep learning methods to control\ncomplex nonlinear systems. This paper considers enhancing the runtime safety of\nnonlinear systems controlled by neural networks in the presence of disturbance\nand measurement noise. A robustly stable interval observer is designed to\ngenerate sound and precise lower and upper bounds for the neural network,\nnonlinear function, and system state. The obtained interval is utilised to\nmonitor the real-time system safety and detect faults in the system outputs or\nactuators. An adaptive cruise control vehicular system is simulated to\ndemonstrate effectiveness of the proposed design.\n","authors":["Jianglin Lan","Siyuan Zhan","Ron Patton","Xianxian Zhao"],"pdf_url":"https://arxiv.org/pdf/2403.16132v1.pdf","comment":"Accepted to SAFEPROCESS 2024"},{"id":"http://arxiv.org/abs/2403.16070v1","updated":"2024-03-24T09:11:55Z","published":"2024-03-24T09:11:55Z","title":"Towards a MATLAB Toolbox to compute backstepping kernels using the power\n  series method","summary":"  In this paper, we extend our previous work on the power series method for\ncomputing backstepping kernels. Our first contribution is the development of\ninitial steps towards a MATLAB toolbox dedicated to backstepping kernel\ncomputation. This toolbox would exploit MATLAB's linear algebra and sparse\nmatrix manipulation features for enhanced efficiency; our initial findings show\nconsiderable improvements in computational speed with respect to the use of\nsymbolical software without loss of precision at high orders. Additionally, we\ntackle limitations observed in our earlier work, such as slow convergence (due\nto oscillatory behaviors) and non-converging series (due to loss of analiticity\nat some singular points). To overcome these challenges, we introduce a\ntechnique that mitigates this behaviour by computing the expansion at different\npoints, denoted as localized power series. This approach effectively navigates\naround singularities, and can also accelerates convergence by using more local\napproximations. Basic examples are provided to demonstrate these enhancements.\nAlthough this research is still ongoing, the significant potential and\nsimplicity of the method already establish the power series approach as a\nviable and versatile solution for solving backstepping kernel equations,\nbenefiting both novel and experienced practitioners in the field. We anticipate\nthat these developments will be particularly beneficial in training the\nrecently introduced neural operators that approximate backstepping kernels and\ngains.\n","authors":["Xin Lin","Rafael Vazquez","Miroslav Krstic"],"pdf_url":"https://arxiv.org/pdf/2403.16070v1.pdf","comment":"Preprint submitted to CDC 2024"},{"id":"http://arxiv.org/abs/2403.16046v1","updated":"2024-03-24T07:13:33Z","published":"2024-03-24T07:13:33Z","title":"Digital control of negative imaginary systems: a discrete-time hybrid\n  integrator-gain system approach","summary":"  A hybrid integrator-gain system (HIGS) is a control element that switches\nbetween an integrator and a gain, which overcomes some inherent limitations of\nlinear controllers. In this paper, we consider using discrete-time HIGS\ncontrollers for the digital control of negative imaginary (NI) systems. We show\nthat the discrete-time HIGS themselves are step-advanced negative imaginary\nsystems. For a minimal linear NI system, there always exists a HIGS controller\nthat can asymptotically stablize it. An illustrative example is provided, where\nwe use the proposed HIGS control method to stabilize a discrete-time\nmass-spring system.\n","authors":["Kanghong Shi","Ian R. Petersen"],"pdf_url":"https://arxiv.org/pdf/2403.16046v1.pdf","comment":"To appear in the 2024 European Control Conference. 7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2403.16042v1","updated":"2024-03-24T07:04:07Z","published":"2024-03-24T07:04:07Z","title":"Force Controlled Printing for Material Extrusion Additive Manufacturing","summary":"  In material extrusion additive manufacturing, the extrusion process is\ncommonly controlled in a feed-forward fashion. The amount of material to be\nextruded at each printing location is pre-computed by a planning software. This\napproach is inherently unable to adapt the extrusion to external and unexpected\ndisturbances, and the quality of the results strongly depends on a number of\nmodeling and tuning parameters. To overcome these limitations, we propose the\nfirst framework for Force Controlled Printing for material extrusion additive\nmanufacturing. We utilize a custom-built extruder to measure the extrusion\nforce in real time, and use this quantity as feedback to continuously control\nthe material flow in closed-loop. We demonstrate the existence of a strong\ncorrelation between extrusion force and line width, which we exploit to deposit\nlines of desired width in a width range of 33 % up to 233 % of the nozzle\ndiameter. We also show how Force Controlled Printing outperforms conventional\nfeed-forward extrusion in print quality and disturbance rejection, while\nrequiring little tuning and automatically adapting to changes in the hardware\nsettings. With no adaptation, Force Controlled Printing can deposit lines of\ndesired width under severe disturbances in bed leveling, such as at layer\nheights ranging between 20 % and 200 % of the nominal height.\n","authors":["Xavier Guidetti","Nathan Mingard","Raul Cruz-Oliver","Yannick Nagel","Marvin Rueppel","Alisa Rupenyan","Efe C. Balta","John Lygeros"],"pdf_url":"https://arxiv.org/pdf/2403.16042v1.pdf","comment":"Preprint to be submitted to Elsevier Additive Manufacturing"},{"id":"http://arxiv.org/abs/2308.01562v3","updated":"2024-03-24T05:50:58Z","published":"2023-08-03T07:03:33Z","title":"Hierarchical Federated Learning in Wireless Networks: Pruning Tackles\n  Bandwidth Scarcity and System Heterogeneity","summary":"  While a practical wireless network has many tiers where end users do not\ndirectly communicate with the central server, the users' devices have limited\ncomputation and battery powers, and the serving base station (BS) has a fixed\nbandwidth. Owing to these practical constraints and system models, this paper\nleverages model pruning and proposes a pruning-enabled hierarchical federated\nlearning (PHFL) in heterogeneous networks (HetNets). We first derive an upper\nbound of the convergence rate that clearly demonstrates the impact of the model\npruning and wireless communications between the clients and the associated BS.\nThen we jointly optimize the model pruning ratio, central processing unit (CPU)\nfrequency and transmission power of the clients in order to minimize the\ncontrollable terms of the convergence bound under strict delay and energy\nconstraints. However, since the original problem is not convex, we perform\nsuccessive convex approximation (SCA) and jointly optimize the parameters for\nthe relaxed convex problem. Through extensive simulation, we validate the\neffectiveness of our proposed PHFL algorithm in terms of test accuracy, wall\nclock time, energy consumption and bandwidth requirement.\n","authors":["Md Ferdous Pervej","Richeng Jin","Huaiyu Dai"],"pdf_url":"https://arxiv.org/pdf/2308.01562v3.pdf","comment":"Accepted for publications in the IEEE Transactions on Wireless\n  Communications (TWC); \\copyright 2024 IEEE. Personal use of this material is\n  permitted. Permission from IEEE must be obtained for all other uses"},{"id":"http://arxiv.org/abs/2403.13609v2","updated":"2024-03-24T02:05:25Z","published":"2024-03-20T14:01:07Z","title":"3D Directed Formation Control with Global Shape Convergence using\n  Bispherical Coordinates","summary":"  In this paper, we present a novel 3D formation control scheme for directed\ngraphs in a leader-follower configuration, achieving (almost) global\nconvergence to the desired shape. Specifically, we introduce three controlled\nvariables representing bispherical coordinates that uniquely describe the\nformation in 3D. Acyclic triangulated directed graphs (a class of minimally\nacyclic persistent graphs) are used to model the inter-agent sensing topology,\nwhile the agents' dynamics are governed by single-integrator model. Our\nanalysis demonstrates that the proposed decentralized formation controller\nensures (almost) global asymptotic stability while avoiding potential shape\nambiguities in the final formation. Furthermore, the control laws are\nimplementable in arbitrarily oriented local coordinate frames of follower\nagents using only low-cost onboard vision sensors, making it suitable for\npractical applications. Finally, we validate our formation control approach by\na simulation study.\n","authors":["Omid Mirzaeedodangeh","Farhad Mehdifar","Dimos V. Dimarogonas"],"pdf_url":"https://arxiv.org/pdf/2403.13609v2.pdf","comment":"Submitted to ECC 2024"},{"id":"http://arxiv.org/abs/2403.15966v1","updated":"2024-03-24T00:04:23Z","published":"2024-03-24T00:04:23Z","title":"Fisher Information Approach for Masking the Sensing Plan: Applications\n  in Multifunction Radars","summary":"  How to design a Markov Decision Process (MDP) based radar controller that\nmakes small sacrifices in performance to mask its sensing plan from an\nadversary? The radar controller purposefully minimizes the Fisher information\nof its emissions so that an adversary cannot identify the controller's model\nparameters accurately. Unlike classical open loop statistical inference, where\nthe Fisher information serves as a lower bound for the achievable covariance,\nthis paper employs the Fisher information as a design constraint for a closed\nloop radar controller to mask its sensing plan. We analytically derive a\nclosed-form expression for the determinant of the Fisher Information Matrix\n(FIM) pertaining to the parameters of the MDP-based controller. Subsequently,\nwe constrain the MDP with respect to the determinant of the FIM. Numerical\nresults show that the introduction of minor perturbations to the MDP's\ntransition kernel and the total operation cost can reduce the Fisher\nInformation of the emissions. Consequently, this reduction amplifies the\nvariability in policy and transition kernel estimation errors, thwarting the\nadversary's accuracy in estimating the controller's sensing plan.\n","authors":["Shashwat Jain","Vikram Krishnamurthy","Muralidhar Rangaswamy","Bosung Kang","Sandeep Gogineni"],"pdf_url":"https://arxiv.org/pdf/2403.15966v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.07250v2","updated":"2024-03-24T03:33:39Z","published":"2022-05-15T10:27:49Z","title":"A cGAN Ensemble-based Uncertainty-aware Surrogate Model for Offline\n  Model-based Optimization in Industrial Control Problems","summary":"  This study focuses on two important problems related to applying offline\nmodel-based optimization to real-world industrial control problems. The first\nproblem is how to create a reliable probabilistic model that accurately\ncaptures the dynamics present in noisy industrial data. The second problem is\nhow to reliably optimize control parameters without actively collecting\nfeedback from industrial systems. Specifically, we introduce a novel cGAN\nensemble-based uncertainty-aware surrogate model for reliable offline\nmodel-based optimization in industrial control problems. The effectiveness of\nthe proposed method is demonstrated through extensive experiments conducted on\ntwo representative cases, namely a discrete control case and a continuous\ncontrol case. The results of these experiments show that our method outperforms\nseveral competitive baselines in the field of offline model-based optimization\nfor industrial control.\n","authors":["Cheng Feng"],"pdf_url":"https://arxiv.org/pdf/2205.07250v2.pdf","comment":"Accepted in IJCNN 2024"}]},"2024-03-23T00:00:00Z":{"Robotics":[{"id":"http://arxiv.org/abs/2403.15959v1","updated":"2024-03-23T23:36:26Z","published":"2024-03-23T23:36:26Z","title":"Risk-Calibrated Human-Robot Interaction via Set-Valued Intent Prediction","summary":"  Tasks where robots must cooperate with humans, such as navigating around a\ncluttered home or sorting everyday items, are challenging because they exhibit\na wide range of valid actions that lead to similar outcomes. Moreover,\nzero-shot cooperation between human-robot partners is an especially challenging\nproblem because it requires the robot to infer and adapt on the fly to a latent\nhuman intent, which could vary significantly from human to human. Recently,\ndeep learned motion prediction models have shown promising results in\npredicting human intent but are prone to being confidently incorrect. In this\nwork, we present Risk-Calibrated Interactive Planning (RCIP), which is a\nframework for measuring and calibrating risk associated with uncertain action\nselection in human-robot cooperation, with the fundamental idea that the robot\nshould ask for human clarification when the risk associated with the\nuncertainty in the human's intent cannot be controlled. RCIP builds on the\ntheory of set-valued risk calibration to provide a finite-sample statistical\nguarantee on the cumulative loss incurred by the robot while minimizing the\ncost of human clarification in complex multi-step settings. Our main insight is\nto frame the risk control problem as a sequence-level multi-hypothesis testing\nproblem, allowing efficient calibration using a low-dimensional parameter that\ncontrols a pre-trained risk-aware policy. Experiments across a variety of\nsimulated and real-world environments demonstrate RCIP's ability to predict and\nadapt to a diverse set of dynamic human intents.\n","authors":["Justin Lidard","Hang Pham","Ariel Bachman","Bryan Boateng","Anirudha Majumdar"],"pdf_url":"https://arxiv.org/pdf/2403.15959v1.pdf","comment":"Website with additional information, videos, and code:\n  https://risk-calibrated-planning.github.io/"},{"id":"http://arxiv.org/abs/2403.15941v1","updated":"2024-03-23T22:04:03Z","published":"2024-03-23T22:04:03Z","title":"Explore until Confident: Efficient Exploration for Embodied Question\n  Answering","summary":"  We consider the problem of Embodied Question Answering (EQA), which refers to\nsettings where an embodied agent such as a robot needs to actively explore an\nenvironment to gather information until it is confident about the answer to a\nquestion. In this work, we leverage the strong semantic reasoning capabilities\nof large vision-language models (VLMs) to efficiently explore and answer such\nquestions. However, there are two main challenges when using VLMs in EQA: they\ndo not have an internal memory for mapping the scene to be able to plan how to\nexplore over time, and their confidence can be miscalibrated and can cause the\nrobot to prematurely stop exploration or over-explore. We propose a method that\nfirst builds a semantic map of the scene based on depth information and via\nvisual prompting of a VLM - leveraging its vast knowledge of relevant regions\nof the scene for exploration. Next, we use conformal prediction to calibrate\nthe VLM's question answering confidence, allowing the robot to know when to\nstop exploration - leading to a more calibrated and efficient exploration\nstrategy. To test our framework in simulation, we also contribute a new EQA\ndataset with diverse, realistic human-robot scenarios and scenes built upon the\nHabitat-Matterport 3D Research Dataset (HM3D). Both simulated and real robot\nexperiments show our proposed approach improves the performance and efficiency\nover baselines that do no leverage VLM for exploration or do not calibrate its\nconfidence. Webpage with experiment videos and code:\nhttps://explore-eqa.github.io/\n","authors":["Allen Z. Ren","Jaden Clark","Anushri Dixit","Masha Itkina","Anirudha Majumdar","Dorsa Sadigh"],"pdf_url":"https://arxiv.org/pdf/2403.15941v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2309.04937v3","updated":"2024-03-23T21:09:19Z","published":"2023-09-10T05:45:36Z","title":"LONER: LiDAR Only Neural Representations for Real-Time SLAM","summary":"  This paper proposes LONER, the first real-time LiDAR SLAM algorithm that uses\na neural implicit scene representation. Existing implicit mapping methods for\nLiDAR show promising results in large-scale reconstruction, but either require\ngroundtruth poses or run slower than real-time. In contrast, LONER uses LiDAR\ndata to train an MLP to estimate a dense map in real-time, while simultaneously\nestimating the trajectory of the sensor. To achieve real-time performance, this\npaper proposes a novel information-theoretic loss function that accounts for\nthe fact that different regions of the map may be learned to varying degrees\nthroughout online training. The proposed method is evaluated qualitatively and\nquantitatively on two open-source datasets. This evaluation illustrates that\nthe proposed loss function converges faster and leads to more accurate geometry\nreconstruction than other loss functions used in depth-supervised neural\nimplicit frameworks. Finally, this paper shows that LONER estimates\ntrajectories competitively with state-of-the-art LiDAR SLAM methods, while also\nproducing dense maps competitive with existing real-time implicit mapping\nmethods that use groundtruth poses.\n","authors":["Seth Isaacson","Pou-Chun Kung","Mani Ramanagopal","Ram Vasudevan","Katherine A. Skinner"],"pdf_url":"https://arxiv.org/pdf/2309.04937v3.pdf","comment":"First two authors equally contributed. Webpage:\n  https://umautobots.github.io/loner"},{"id":"http://arxiv.org/abs/2309.08865v3","updated":"2024-03-23T20:33:45Z","published":"2023-09-16T04:01:34Z","title":"ARTEMIS: AI-driven Robotic Triage Labeling and Emergency Medical\n  Information System","summary":"  Mass casualty incidents (MCIs) pose a significant challenge to emergency\nmedical services by overwhelming available resources and personnel. Effective\nvictim assessment is the key to minimizing casualties during such a crisis. We\nintroduce ARTEMIS, an AI-driven Robotic Triage Labeling and Emergency Medical\nInformation System, to aid first responders in MCI events. It leverages speech\nprocessing, natural language processing, and deep learning to help with acuity\nclassification. This is deployed on a quadruped that performs victim\nlocalization and preliminary injury severity assessment. First responders\naccess victim information through a Graphical User Interface that is updated in\nreal-time. To validate our proposed algorithmic triage protocol, we used the\nUnitree Go1 quadruped. The robot identifies humans, interacts with them, gets\nvitals and information, and assigns an acuity label. Simulations of an MCI in\nsoftware and a controlled environment outdoors were conducted. The system\nachieved a triage-level classification precision of over 74% on average and 99%\nfor the most critical victims, i.e. level 1 acuity, outperforming\nstate-of-the-art deep learning-based triage labeling systems. In this paper, we\nshowcase the potential of human-robot interaction in assisting medical\npersonnel in MCI events.\n","authors":["Revanth Krishna Senthilkumaran","Mridu Prashanth","Hrishikesh Viswanath","Sathvika Kotha","Kshitij Tiwari","Aniket Bera"],"pdf_url":"https://arxiv.org/pdf/2309.08865v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.15852v4","updated":"2024-03-23T16:54:01Z","published":"2024-02-24T16:39:16Z","title":"NaVid: Video-based VLM Plans the Next Step for Vision-and-Language\n  Navigation","summary":"  Vision-and-Language Navigation (VLN) stands as a key research problem of\nEmbodied AI, aiming at enabling agents to navigate in unseen environments\nfollowing linguistic instructions. In this field, generalization is a\nlong-standing challenge, either to out-of-distribution scenes or from Sim to\nReal. In this paper, we propose NaVid, a video-based large vision language\nmodel (VLM), to mitigate such a generalization gap. NaVid makes the first\nendeavour to showcase the capability of VLMs to achieve state-of-the-art level\nnavigation performance without any maps, odometer and depth inputs. Following\nhuman instruction, NaVid only requires an on-the-fly video stream from a\nmonocular RGB camera equipped on the robot to output the next-step action. Our\nformulation mimics how humans navigate and naturally gets rid of the problems\nintroduced by odometer noises, and the Sim2Real gaps from map or depth inputs.\nMoreover, our video-based approach can effectively encode the historical\nobservations of robots as spatio-temporal contexts for decision-making and\ninstruction following. We train NaVid with 550k navigation samples collected\nfrom VLN-CE trajectories, including action-planning and instruction-reasoning\nsamples, along with 665k large-scale web data. Extensive experiments show that\nNaVid achieves SOTA performance in simulation environments and the real world,\ndemonstrating superior cross-dataset and Sim2Real transfer. We thus believe our\nproposed VLM approach plans the next step for not only the navigation agents\nbut also this research field.\n","authors":["Jiazhao Zhang","Kunyu Wang","Rongtao Xu","Gengze Zhou","Yicong Hong","Xiaomeng Fang","Qi Wu","Zhizheng Zhang","He Wang"],"pdf_url":"https://arxiv.org/pdf/2402.15852v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15870v1","updated":"2024-03-23T15:35:54Z","published":"2024-03-23T15:35:54Z","title":"iA$^*$: Imperative Learning-based A$^*$ Search for Pathfinding","summary":"  The pathfinding problem, which aims to identify a collision-free path between\ntwo points, is crucial for many applications, such as robot navigation and\nautonomous driving. Classic methods, such as A$^*$ search, perform well on\nsmall-scale maps but face difficulties scaling up. Conversely, data-driven\napproaches can improve pathfinding efficiency but require extensive data\nlabeling and lack theoretical guarantees, making it challenging for practical\napplications. To combine the strengths of the two methods, we utilize the\nimperative learning (IL) strategy and propose a novel self-supervised\npathfinding framework, termed imperative learning-based A$^*$ (iA$^*$).\nSpecifically, iA$^*$ is a bilevel optimization process where the lower-level\noptimization is dedicated to finding the optimal path by a differentiable A$^*$\nsearch module, and the upper-level optimization narrows down the search space\nto improve efficiency via setting suitable initial values from a data-driven\nmodel. Besides, the model within the upper-level optimization is a fully\nconvolutional network, trained by the calculated loss in the lower-level\noptimization. Thus, the framework avoids extensive data labeling and can be\napplied in diverse environments. Our comprehensive experiments demonstrate that\niA$^*$ surpasses both classical and data-driven methods in pathfinding\nefficiency and shows superior robustness among different tasks, validated with\npublic datasets and simulation environments.\n","authors":["Xiangyu Chen","Fan Yang","Chen Wang"],"pdf_url":"https://arxiv.org/pdf/2403.15870v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15857v1","updated":"2024-03-23T14:47:26Z","published":"2024-03-23T14:47:26Z","title":"Automated System-level Testing of Unmanned Aerial Systems","summary":"  Unmanned aerial systems (UAS) rely on various avionics systems that are\nsafety-critical and mission-critical. A major requirement of international\nsafety standards is to perform rigorous system-level testing of avionics\nsoftware systems. The current industrial practice is to manually create test\nscenarios, manually/automatically execute these scenarios using simulators, and\nmanually evaluate outcomes. The test scenarios typically consist of setting\ncertain flight or environment conditions and testing the system under test in\nthese settings. The state-of-the-art approaches for this purpose also require\nmanual test scenario development and evaluation. In this paper, we propose a\nnovel approach to automate the system-level testing of the UAS. The proposed\napproach (AITester) utilizes model-based testing and artificial intelligence\n(AI) techniques to automatically generate, execute, and evaluate various test\nscenarios. The test scenarios are generated on the fly, i.e., during test\nexecution based on the environmental context at runtime. The approach is\nsupported by a toolset. We empirically evaluate the proposed approach on two\ncore components of UAS, an autopilot system of an unmanned aerial vehicle (UAV)\nand cockpit display systems (CDS) of the ground control station (GCS). The\nresults show that the AITester effectively generates test scenarios causing\ndeviations from the expected behavior of the UAV autopilot and reveals\npotential flaws in the GCS-CDS.\n","authors":["Hassan Sartaj","Asmar Muqeet","Muhammad Zohaib Iqbal","Muhammad Uzair Khan"],"pdf_url":"https://arxiv.org/pdf/2403.15857v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.14552v2","updated":"2024-03-23T14:15:02Z","published":"2023-09-25T21:51:48Z","title":"Tactile Estimation of Extrinsic Contact Patch for Stable Placement","summary":"  Precise perception of contact interactions is essential for fine-grained\nmanipulation skills for robots. In this paper, we present the design of\nfeedback skills for robots that must learn to stack complex-shaped objects on\ntop of each other (see Fig.1). To design such a system, a robot should be able\nto reason about the stability of placement from very gentle contact\ninteractions. Our results demonstrate that it is possible to infer the\nstability of object placement based on tactile readings during contact\nformation between the object and its environment. In particular, we estimate\nthe contact patch between a grasped object and its environment using force and\ntactile observations to estimate the stability of the object during a contact\nformation. The contact patch could be used to estimate the stability of the\nobject upon release of the grasp. The proposed method is demonstrated in\nvarious pairs of objects that are used in a very popular board game.\n","authors":["Kei Ota","Devesh K. Jha","Krishna Murthy Jatavallabhula","Asako Kanezaki","Joshua B. Tenenbaum"],"pdf_url":"https://arxiv.org/pdf/2309.14552v2.pdf","comment":"Accepted at ICRA2024"},{"id":"http://arxiv.org/abs/2403.15834v1","updated":"2024-03-23T13:21:09Z","published":"2024-03-23T13:21:09Z","title":"ARO: Large Language Model Supervised Robotics Text2Skill Autonomous\n  Learning","summary":"  Robotics learning highly relies on human expertise and efforts, such as\ndemonstrations, design of reward functions in reinforcement learning,\nperformance evaluation using human feedback, etc. However, reliance on human\nassistance can lead to expensive learning costs and make skill learning\ndifficult to scale. In this work, we introduce the Large Language Model\nSupervised Robotics Text2Skill Autonomous Learning (ARO) framework, which aims\nto replace human participation in the robot skill learning process with\nlarge-scale language models that incorporate reward function design and\nperformance evaluation. We provide evidence that our approach enables fully\nautonomous robot skill learning, capable of completing partial tasks without\nhuman intervention. Furthermore, we also analyze the limitations of this\napproach in task understanding and optimization stability.\n","authors":["Yiwen Chen","Yuyao Ye","Ziyi Chen","Chuheng Zhang","Marcelo H. Ang"],"pdf_url":"https://arxiv.org/pdf/2403.15834v1.pdf","comment":"6 pages, 2 figures"},{"id":"http://arxiv.org/abs/2403.15826v1","updated":"2024-03-23T12:53:51Z","published":"2024-03-23T12:53:51Z","title":"Scaling Learning based Policy Optimization for Temporal Tasks via\n  Dropout","summary":"  This paper introduces a model-based approach for training feedback\ncontrollers for an autonomous agent operating in a highly nonlinear\nenvironment. We desire the trained policy to ensure that the agent satisfies\nspecific task objectives, expressed in discrete-time Signal Temporal Logic\n(DT-STL). One advantage for reformulation of a task via formal frameworks, like\nDT-STL, is that it permits quantitative satisfaction semantics. In other words,\ngiven a trajectory and a DT-STL formula, we can compute the robustness, which\ncan be interpreted as an approximate signed distance between the trajectory and\nthe set of trajectories satisfying the formula. We utilize feedback\ncontrollers, and we assume a feed forward neural network for learning these\nfeedback controllers. We show how this learning problem is similar to training\nrecurrent neural networks (RNNs), where the number of recurrent units is\nproportional to the temporal horizon of the agent's task objectives. This poses\na challenge: RNNs are susceptible to vanishing and exploding gradients, and\nna\\\"{i}ve gradient descent-based strategies to solve long-horizon task\nobjectives thus suffer from the same problems. To tackle this challenge, we\nintroduce a novel gradient approximation algorithm based on the idea of dropout\nor gradient sampling. We show that, the existing smooth semantics for\nrobustness are inefficient regarding gradient computation when the\nspecification becomes complex. To address this challenge, we propose a new\nsmooth semantics for DT-STL that under-approximates the robustness value and\nscales well for backpropagation over a complex specification. We show that our\ncontrol synthesis methodology, can be quite helpful for stochastic gradient\ndescent to converge with less numerical issues, enabling scalable\nbackpropagation over long time horizons and trajectories over high dimensional\nstate spaces.\n","authors":["Navid Hashemi","Bardh Hoxha","Danil Prokhorov","Georgios Fainekos","Jyotirmoy Deshmukh"],"pdf_url":"https://arxiv.org/pdf/2403.15826v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.14945v2","updated":"2024-03-23T12:39:14Z","published":"2023-09-26T14:00:25Z","title":"Integration of Large Language Models within Cognitive Architectures for\n  Autonomous Robots","summary":"  Symbolic reasoning systems have been used in cognitive architectures to\nprovide inference and planning capabilities. However, defining domains and\nproblems has proven difficult and prone to errors. Moreover, Large Language\nModels (LLMs) have emerged as tools to process natural language for different\ntasks. In this paper, we propose the use of LLMs to tackle these problems. This\nway, this paper proposes the integration of LLMs in the ROS 2-integrated\ncognitive architecture MERLIN2 for autonomous robots. Specifically, we present\nthe design, development and deployment of how to leverage the reasoning\ncapabilities of LLMs inside the deliberative processes of MERLIN2. As a result,\nthe deliberative system is updated from a PDDL-based planner system to a\nnatural language planning system. This proposal is evaluated quantitatively and\nqualitatively, measuring the impact of incorporating the LLMs in the cognitive\narchitecture. Results show that a classical approach achieves better\nperformance but the proposed solution provides an enhanced interaction through\nnatural language.\n","authors":["Miguel Á. González-Santamarta","Francisco J. Rodríguez-Lera","Ángel Manuel Guerrero-Higueras","Vicente Matellán-Olivera"],"pdf_url":"https://arxiv.org/pdf/2309.14945v2.pdf","comment":"8 pages, 6 figures, 2 tables, Submitted to IROS 2024"},{"id":"http://arxiv.org/abs/2403.15813v1","updated":"2024-03-23T12:00:00Z","published":"2024-03-23T12:00:00Z","title":"Learning Early Social Maneuvers for Enhanced Social Navigation","summary":"  Socially compliant navigation is an integral part of safety features in\nHuman-Robot Interaction. Traditional approaches to mobile navigation prioritize\nphysical aspects, such as efficiency, but social behaviors gain traction as\nrobots appear more in daily life. Recent techniques to improve the social\ncompliance of navigation often rely on predefined features or reward functions,\nintroducing assumptions about social human behavior. To address this\nlimitation, we propose a novel Learning from Demonstration (LfD) framework for\nsocial navigation that exclusively utilizes raw sensory data. Additionally, the\nproposed system contains mechanisms to consider the future paths of the\nsurrounding pedestrians, acknowledging the temporal aspect of the problem. The\nfinal product is expected to reduce the anxiety of people sharing their\nenvironment with a mobile robot, helping them trust that the robot is aware of\ntheir presence and will not harm them. As the framework is currently being\ndeveloped, we outline its components, present experimental results, and discuss\nfuture work towards realizing this framework.\n","authors":["Yigit Yıldırim","Mehmet Suzer","Emre Ugur"],"pdf_url":"https://arxiv.org/pdf/2403.15813v1.pdf","comment":"Submitted to the workshop of Robot Trust for Symbiotic Societies\n  (RTSS) at ICRA 2024 on March 23, 2024"},{"id":"http://arxiv.org/abs/2403.15812v1","updated":"2024-03-23T11:50:20Z","published":"2024-03-23T11:50:20Z","title":"The Impact of Evolutionary Computation on Robotic Design: A Case Study\n  with an Underactuated Hand Exoskeleton","summary":"  Robotic exoskeletons can enhance human strength and aid people with physical\ndisabilities. However, designing them to ensure safety and optimal performance\npresents significant challenges. Developing exoskeletons should incorporate\nspecific optimization algorithms to find the best design. This study\ninvestigates the potential of Evolutionary Computation (EC) methods in robotic\ndesign optimization, with an underactuated hand exoskeleton (U-HEx) used as a\ncase study. We propose improving the performance and usability of the U-HEx\ndesign, which was initially optimized using a naive brute-force approach, by\nintegrating EC techniques such as Genetic Algorithm and Big Bang-Big Crunch\nAlgorithm. Comparative analysis revealed that EC methods consistently yield\nmore precise and optimal solutions than brute force in a significantly shorter\ntime. This allowed us to improve the optimization by increasing the number of\nvariables in the design, which was impossible with naive methods. The results\nshow significant improvements in terms of the torque magnitude the device\ntransfers to the user, enhancing its efficiency. These findings underline the\nimportance of performing proper optimization while designing exoskeletons, as\nwell as providing a significant improvement to this specific robotic design.\n","authors":["Baris Akbas","Huseyin Taner Yuksel","Aleyna Soylemez","Mazhar Eid Zyada","Mine Sarac","Fabio Stroppa"],"pdf_url":"https://arxiv.org/pdf/2403.15812v1.pdf","comment":"6 pages (+ref), 4 figures, IEEE International Conference on Robotics\n  and Automation (ICRA) 2024"},{"id":"http://arxiv.org/abs/2403.15805v1","updated":"2024-03-23T11:30:44Z","published":"2024-03-23T11:30:44Z","title":"AirCrab: A Hybrid Aerial-Ground Manipulator with An Active Wheel","summary":"  Inspired by the behavior of birds, we present AirCrab, a hybrid aerial ground\nmanipulator (HAGM) with a single active wheel and a 3-degree of freedom (3-DoF)\nmanipulator. AirCrab leverages a single point of contact with the ground to\nreduce position drift and improve manipulation accuracy. The single active\nwheel enables locomotion on narrow surfaces without adding significant weight\nto the robot. To realize accurate attitude maintenance using propellers on the\nground, we design a control allocation method for AirCrab that prioritizes\nattitude control and dynamically adjusts the thrust input to reduce energy\nconsumption. Experiments verify the effectiveness of the proposed control\nmethod and the gain in manipulation accuracy with ground contact. A series of\noperations to complete the letters 'NTU' demonstrates the capability of the\nrobot to perform challenging hybrid aerial-ground manipulation missions.\n","authors":["Muqing Cao","Jiayan Zhao","Xinhang Xu","Lihua Xie"],"pdf_url":"https://arxiv.org/pdf/2403.15805v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14447v2","updated":"2024-03-23T11:26:38Z","published":"2024-03-21T14:53:50Z","title":"Exploring 3D Human Pose Estimation and Forecasting from the Robot's\n  Perspective: The HARPER Dataset","summary":"  We introduce HARPER, a novel dataset for 3D body pose estimation and forecast\nin dyadic interactions between users and Spot, the quadruped robot manufactured\nby Boston Dynamics. The key-novelty is the focus on the robot's perspective,\ni.e., on the data captured by the robot's sensors. These make 3D body pose\nanalysis challenging because being close to the ground captures humans only\npartially. The scenario underlying HARPER includes 15 actions, of which 10\ninvolve physical contact between the robot and users. The Corpus contains not\nonly the recordings of the built-in stereo cameras of Spot, but also those of a\n6-camera OptiTrack system (all recordings are synchronized). This leads to\nground-truth skeletal representations with a precision lower than a millimeter.\nIn addition, the Corpus includes reproducible benchmarks on 3D Human Pose\nEstimation, Human Pose Forecasting, and Collision Prediction, all based on\npublicly available baseline approaches. This enables future HARPER users to\nrigorously compare their results with those we provide in this work.\n","authors":["Andrea Avogaro","Andrea Toaiari","Federico Cunico","Xiangmin Xu","Haralambos Dafas","Alessandro Vinciarelli","Emma Li","Marco Cristani"],"pdf_url":"https://arxiv.org/pdf/2403.14447v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15798v1","updated":"2024-03-23T11:09:41Z","published":"2024-03-23T11:09:41Z","title":"Vid2Real HRI: Align video-based HRI study designs with real-world\n  settings","summary":"  HRI research using autonomous robots in real-world settings can produce\nresults with the highest ecological validity of any study modality, but many\ndifficulties limit such studies' feasibility and effectiveness. We propose\nVid2Real HRI, a research framework to maximize real-world insights offered by\nvideo-based studies. The Vid2Real HRI framework was used to design an online\nstudy using first-person videos of robots as real-world encounter surrogates.\nThe online study ($n = 385$) distinguished the within-subjects effects of four\nrobot behavioral conditions on perceived social intelligence and human\nwillingness to help the robot enter an exterior door. A real-world,\nbetween-subjects replication ($n = 26$) using two conditions confirmed the\nvalidity of the online study's findings and the sufficiency of the participant\nrecruitment target ($22$) based on a power analysis of online study results.\nThe Vid2Real HRI framework offers HRI researchers a principled way to take\nadvantage of the efficiency of video-based study modalities while generating\ndirectly transferable knowledge of real-world HRI. Code and data from the study\nare provided at https://vid2real.github.io/vid2realHRI\n","authors":["Elliott Hauser","Yao-Cheng Chan","Sadanand Modak","Joydeep Biswas","Justin Hart"],"pdf_url":"https://arxiv.org/pdf/2403.15798v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15791v1","updated":"2024-03-23T10:38:59Z","published":"2024-03-23T10:38:59Z","title":"DriveEnv-NeRF: Exploration of A NeRF-Based Autonomous Driving\n  Environment for Real-World Performance Validation","summary":"  In this study, we introduce the DriveEnv-NeRF framework, which leverages\nNeural Radiance Fields (NeRF) to enable the validation and faithful forecasting\nof the efficacy of autonomous driving agents in a targeted real-world scene.\nStandard simulator-based rendering often fails to accurately reflect real-world\nperformance due to the sim-to-real gap, which represents the disparity between\nvirtual simulations and real-world conditions. To mitigate this gap, we propose\na workflow for building a high-fidelity simulation environment of the targeted\nreal-world scene using NeRF. This approach is capable of rendering realistic\nimages from novel viewpoints and constructing 3D meshes for emulating\ncollisions. The validation of these capabilities through the comparison of\nsuccess rates in both simulated and real environments demonstrates the benefits\nof using DriveEnv-NeRF as a real-world performance indicator. Furthermore, the\nDriveEnv-NeRF framework can serve as a training environment for autonomous\ndriving agents under various lighting conditions. This approach enhances the\nrobustness of the agents and reduces performance degradation when deployed to\nthe target real scene, compared to agents fully trained using the standard\nsimulator rendering pipeline.\n","authors":["Mu-Yi Shen","Chia-Chi Hsu","Hao-Yu Hou","Yu-Chen Huang","Wei-Fang Sun","Chia-Che Chang","Yu-Lun Liu","Chun-Yi Lee"],"pdf_url":"https://arxiv.org/pdf/2403.15791v1.pdf","comment":"Project page: https://github.com/muyishen2040/DriveEnvNeRF"},{"id":"http://arxiv.org/abs/2403.15762v1","updated":"2024-03-23T08:26:20Z","published":"2024-03-23T08:26:20Z","title":"RicMonk: A Three-Link Brachiation Robot with Passive Grippers for\n  Energy-Efficient Brachiation","summary":"  This paper presents the design, analysis, and performance evaluation of\nRicMonk, a novel three-link brachiation robot equipped with passive hook-shaped\ngrippers. Brachiation, an agile and energy-efficient mode of locomotion\nobserved in primates, has inspired the development of RicMonk to explore\nversatile locomotion and maneuvers on ladder-like structures. The robot's\nanatomical resemblance to gibbons and the integration of a tail mechanism for\nenergy injection contribute to its unique capabilities. The paper discusses the\nuse of the Direct Collocation methodology for optimizing trajectories for the\nrobot's dynamic behaviors and stabilization of these trajectories using a\nTime-varying Linear Quadratic Regulator. With RicMonk we demonstrate\nbidirectional brachiation, and provide comparative analysis with its\npredecessor, AcroMonk - a two-link brachiation robot, to demonstrate that the\npresence of a passive tail helps improve energy efficiency. The system design,\ncontrollers, and software implementation are publicly available on GitHub and\nthe video demonstration of the experiments can be viewed YouTube.\n","authors":["Shourie S. Grama","Mahdi Javadi","Shivesh Kumar","Hossein Zamani Boroujeni","Frank Kirchner"],"pdf_url":"https://arxiv.org/pdf/2403.15762v1.pdf","comment":"Open sourced system design, controllers, software implementation can\n  be found at https://github.com/dfki-ric-underactuated-lab/ricmonk and a video\n  demonstrating the experiments performed with RicMonk can be found at\n  https://www.youtube.com/watch?v=hOuDQI7CD8w"},{"id":"http://arxiv.org/abs/2209.01426v2","updated":"2024-03-23T07:50:26Z","published":"2022-09-03T14:00:43Z","title":"Space Filling Curves for Coverage Path Planning with Online Obstacle\n  Avoidance","summary":"  The paper presents a strategy for robotic exploration problem using\nSpace-Filling curves (SFC). The strategy plans a path that avoids unknown\nobstacles while ensuring complete coverage of the free space in region of\ninterest. The region of interest is first tessellated, and the tiles/cells are\nconnected using a SFC pattern. A robot follows the SFC to explore the entire\narea. However, obstacles can block the systematic movement of the robot. We\novercome this problem by determining an alternate path online that avoids the\nblocked cells while ensuring all the accessible cells are visited at least\nonce. The proposed strategy chooses next waypoint based on the graph\nconnectivity of the cells and the obstacle encountered so far. It is online,\nexhaustive and works in situations demanding non-uniform coverage. The\ncompleteness of the strategy is proved and its desirable properties are\ndiscussed with examples.\n","authors":["Ashay Wakode","Arpita Sinha"],"pdf_url":"https://arxiv.org/pdf/2209.01426v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.05022v2","updated":"2024-03-23T06:58:58Z","published":"2023-10-08T05:48:30Z","title":"Fully Spiking Neural Network for Legged Robots","summary":"  In recent years, legged robots based on deep reinforcement learning have made\nremarkable progress. Quadruped robots have demonstrated the ability to complete\nchallenging tasks in complex environments and have been deployed in real-world\nscenarios to assist humans. Simultaneously, bipedal and humanoid robots have\nachieved breakthroughs in various demanding tasks. Current reinforcement\nlearning methods can utilize diverse robot bodies and historical information to\nperform actions. However, prior research has not emphasized the speed and\nenergy consumption of network inference, as well as the biological significance\nof the neural networks themselves. Most of the networks employed are\ntraditional artificial neural networks that utilize multilayer perceptrons\n(MLP). In this paper, we successfully apply a novel Spiking Neural Network\n(SNN) to process legged robots, achieving outstanding results across a range of\nsimulated terrains. SNN holds a natural advantage over traditional neural\nnetworks in terms of inference speed and energy consumption, and their\npulse-form processing of body perception signals offers improved biological\ninterpretability. Applying more biomimetic neural networks to legged robots can\nfurther reduce the heat dissipation and structural burden caused by the high\npower consumption of neural networks. To the best of our knowledge, this is the\nfirst work to implement SNN in legged robots.\n","authors":["Xiaoyang Jiang","Qiang Zhang","Jingkai Sun","Jiahang Cao","Jingtong Ma","Renjing Xu"],"pdf_url":"https://arxiv.org/pdf/2310.05022v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15716v1","updated":"2024-03-23T04:36:12Z","published":"2024-03-23T04:36:12Z","title":"Distributed Robust Learning based Formation Control of Mobile Robots\n  based on Bioinspired Neural Dynamics","summary":"  This paper addresses the challenges of distributed formation control in\nmultiple mobile robots, introducing a novel approach that enhances real-world\npracticability. We first introduce a distributed estimator using a variable\nstructure and cascaded design technique, eliminating the need for derivative\ninformation to improve the real time performance. Then, a kinematic tracking\ncontrol method is developed utilizing a bioinspired neural dynamic-based\napproach aimed at providing smooth control inputs and effectively resolving the\nspeed jump issue. Furthermore, to address the challenges for robots operating\nwith completely unknown dynamics and disturbances, a learning-based robust\ndynamic controller is developed. This controller provides real time parameter\nestimates while maintaining its robustness against disturbances. The overall\nstability of the proposed method is proved with rigorous mathematical analysis.\nAt last, multiple comprehensive simulation studies have shown the advantages\nand effectiveness of the proposed method.\n","authors":["Zhe Xu","Tao Yan","Simon X. Yang","S. Andrew Gadsden","Mohammad Biglarbegian"],"pdf_url":"https://arxiv.org/pdf/2403.15716v1.pdf","comment":"This paper is accepted by IEEE Transactions on Intelligent Vehicles"},{"id":"http://arxiv.org/abs/2403.15712v1","updated":"2024-03-23T04:18:49Z","published":"2024-03-23T04:18:49Z","title":"PNAS-MOT: Multi-Modal Object Tracking with Pareto Neural Architecture\n  Search","summary":"  Multiple object tracking is a critical task in autonomous driving. Existing\nworks primarily focus on the heuristic design of neural networks to obtain high\naccuracy. As tracking accuracy improves, however, neural networks become\nincreasingly complex, posing challenges for their practical application in real\ndriving scenarios due to the high level of latency. In this paper, we explore\nthe use of the neural architecture search (NAS) methods to search for efficient\narchitectures for tracking, aiming for low real-time latency while maintaining\nrelatively high accuracy. Another challenge for object tracking is the\nunreliability of a single sensor, therefore, we propose a multi-modal framework\nto improve the robustness. Experiments demonstrate that our algorithm can run\non edge devices within lower latency constraints, thus greatly reducing the\ncomputational requirements for multi-modal object tracking while keeping lower\nlatency.\n","authors":["Chensheng Peng","Zhaoyu Zeng","Jinling Gao","Jundong Zhou","Masayoshi Tomizuka","Xinbing Wang","Chenghu Zhou","Nanyang Ye"],"pdf_url":"https://arxiv.org/pdf/2403.15712v1.pdf","comment":"IEEE Robotics and Automation Letters 2024. Code is available at\n  https://github.com/PholyPeng/PNAS-MOT"},{"id":"http://arxiv.org/abs/2309.10062v2","updated":"2024-03-23T03:50:18Z","published":"2023-09-18T18:17:56Z","title":"SMART-LLM: Smart Multi-Agent Robot Task Planning using Large Language\n  Models","summary":"  In this work, we introduce SMART-LLM, an innovative framework designed for\nembodied multi-robot task planning. SMART-LLM: Smart Multi-Agent Robot Task\nPlanning using Large Language Models (LLMs), harnesses the power of LLMs to\nconvert high-level task instructions provided as input into a multi-robot task\nplan. It accomplishes this by executing a series of stages, including task\ndecomposition, coalition formation, and task allocation, all guided by\nprogrammatic LLM prompts within the few-shot prompting paradigm. We create a\nbenchmark dataset designed for validating the multi-robot task planning\nproblem, encompassing four distinct categories of high-level instructions that\nvary in task complexity. Our evaluation experiments span both simulation and\nreal-world scenarios, demonstrating that the proposed model can achieve\npromising results for generating multi-robot task plans. The experimental\nvideos, code, and datasets from the work can be found at\nhttps://sites.google.com/view/smart-llm/.\n","authors":["Shyam Sundar Kannan","Vishnunandan L. N. Venkatesh","Byung-Cheol Min"],"pdf_url":"https://arxiv.org/pdf/2309.10062v2.pdf","comment":"Submitted to IROS 2024"},{"id":"http://arxiv.org/abs/2312.14481v2","updated":"2024-03-23T03:13:35Z","published":"2023-12-22T07:17:51Z","title":"SurgicalPart-SAM: Part-to-Whole Collaborative Prompting for Surgical\n  Instrument Segmentation","summary":"  The Segment Anything Model (SAM) exhibits promise in generic object\nsegmentation and offers potential for various applications. Existing methods\nhave applied SAM to surgical instrument segmentation (SIS) by tuning SAM-based\nframeworks with surgical data. However, they fall short in two crucial aspects:\n(1) Straightforward model tuning with instrument masks treats each instrument\nas a single entity, neglecting their complex structures and fine-grained\ndetails; and (2) Instrument category-based prompts are not flexible and\ninformative enough to describe instrument structures. To address these\nproblems, in this paper, we investigate text promptable SIS and propose\nSurgicalPart-SAM (SP-SAM), a novel SAM efficient-tuning approach that\nexplicitly integrates instrument structure knowledge with SAM's generic\nknowledge, guided by expert knowledge on instrument part compositions.\nSpecifically, we achieve this by proposing (1) Collaborative Prompts that\ndescribe instrument structures via collaborating category-level and part-level\ntexts; (2) Cross-Modal Prompt Encoder that encodes text prompts jointly with\nvisual embeddings into discriminative part-level representations; and (3)\nPart-to-Whole Adaptive Fusion and Hierarchical Decoding that adaptively fuse\nthe part-level representations into a whole for accurate instrument\nsegmentation in surgical scenarios. Built upon them, SP-SAM acquires a better\ncapability to comprehend surgical instruments in terms of both overall\nstructure and part-level details. Extensive experiments on both the EndoVis2018\nand EndoVis2017 datasets demonstrate SP-SAM's state-of-the-art performance with\nminimal tunable parameters. The code will be available at\nhttps://github.com/wenxi-yue/SurgicalPart-SAM.\n","authors":["Wenxi Yue","Jing Zhang","Kun Hu","Qiuxia Wu","Zongyuan Ge","Yong Xia","Jiebo Luo","Zhiyong Wang"],"pdf_url":"https://arxiv.org/pdf/2312.14481v2.pdf","comment":"Technical Report. The source code will be released at\n  https://github.com/wenxi-yue/SurgicalPart-SAM"},{"id":"http://arxiv.org/abs/2403.15658v1","updated":"2024-03-23T00:39:05Z","published":"2024-03-23T00:39:05Z","title":"Data-Driven Predictive Control for Robust Exoskeleton Locomotion","summary":"  Exoskeleton locomotion must be robust while being adaptive to different users\nwith and without payloads. To address these challenges, this work introduces a\ndata-driven predictive control (DDPC) framework to synthesize walking gaits for\nlower-body exoskeletons, employing Hankel matrices and a state transition\nmatrix for its data-driven model. The proposed approach leverages DDPC through\na multi-layer architecture. At the top layer, DDPC serves as a planner\nemploying Hankel matrices and a state transition matrix to generate a\ndata-driven model that can learn and adapt to varying users and payloads. At\nthe lower layer, our method incorporates inverse kinematics and passivity-based\ncontrol to map the planned trajectory from DDPC into the full-order states of\nthe lower-body exoskeleton. We validate the effectiveness of this approach\nthrough numerical simulations and hardware experiments conducted on the\nAtalante lower-body exoskeleton with different payloads. Moreover, we conducted\na comparative analysis against the model predictive control (MPC) framework\nbased on the reduced-order linear inverted pendulum (LIP) model. Through this\ncomparison, the paper demonstrates that DDPC enables robust bipedal walking at\nvarious velocities while accounting for model uncertainties and unknown\nperturbations.\n","authors":["Kejun Li","Jeeseop Kim","Xiaobin Xiong","Kaveh Akbari Hamed","Yisong Yue","Aaron D. Ames"],"pdf_url":"https://arxiv.org/pdf/2403.15658v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.18847v2","updated":"2024-03-23T00:28:21Z","published":"2023-10-28T23:25:19Z","title":"Bird's Eye View Based Pretrained World model for Visual Navigation","summary":"  Sim2Real transfer has gained popularity because it helps transfer from\ninexpensive simulators to real world. This paper presents a novel system that\nfuses components in a traditional World Model into a robust system, trained\nentirely within a simulator, that Zero-Shot transfers to the real world. To\nfacilitate transfer, we use an intermediary representation that is based on\n\\textit{Bird's Eye View (BEV)} images. Thus, our robot learns to navigate in a\nsimulator by first learning to translate from complex \\textit{First-Person View\n(FPV)} based RGB images to BEV representations, then learning to navigate using\nthose representations. Later, when tested in the real world, the robot uses the\nperception model that translates FPV-based RGB images to embeddings that were\nlearned by the FPV to BEV translator and that can be used by the downstream\npolicy. The incorporation of state-checking modules using \\textit{Anchor\nimages} and Mixture Density LSTM not only interpolates uncertain and missing\nobservations but also enhances the robustness of the model in the real-world.\nWe trained the model using data from a Differential drive robot in the CARLA\nsimulator. Our methodology's effectiveness is shown through the deployment of\ntrained models onto a real-world Differential drive robot. Lastly we release a\ncomprehensive codebase, dataset and models for training and deployment\n(\\url{https://sites.google.com/view/value-explicit-pretraining}).\n","authors":["Kiran Lekkala","Chen Liu","Laurent Itti"],"pdf_url":"https://arxiv.org/pdf/2310.18847v2.pdf","comment":"Under Review at the IROS 2024; Accepted at NeurIPS 2023, Robot\n  Learning Workshop"}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2403.15962v1","updated":"2024-03-23T23:49:01Z","published":"2024-03-23T23:49:01Z","title":"Detection of Problem Gambling with Less Features Using Machine Learning\n  Methods","summary":"  Analytic features in gambling study are performed based on the amount of data\nmonitoring on user daily actions. While performing the detection of problem\ngambling, existing datasets provide relatively rich analytic features for\nbuilding machine learning based model. However, considering the complexity and\ncost of collecting the analytic features in real applications, conducting\nprecise detection with less features will tremendously reduce the cost of data\ncollection. In this study, we propose a deep neural networks PGN4 that performs\nwell when using limited analytic features. Through the experiment on two\ndatasets, we discover that PGN4 only experiences a mere performance drop when\ncutting 102 features to 5 features. Besides, we find the commonality within the\ntop 5 features from two datasets.\n","authors":["Yang Jiao","Gloria Wong-Padoongpatt","Mei Yang"],"pdf_url":"https://arxiv.org/pdf/2403.15962v1.pdf","comment":"6 pages, 5 tables, 1 figure"},{"id":"http://arxiv.org/abs/2403.15961v1","updated":"2024-03-23T23:48:41Z","published":"2024-03-23T23:48:41Z","title":"SAT Encoding of Partial Ordering Models for Graph Coloring Problems","summary":"  In this paper, we suggest new SAT encodings of the partial-ordering based ILP\nmodel for the graph coloring problem (GCP) and the bandwidth coloring problem\n(BCP). The GCP asks for the minimum number of colors that can be assigned to\nthe vertices of a given graph such that each two adjacent vertices get\ndifferent colors. The BCP is a generalization, where each edge has a weight\nthat enforces a minimal \"distance\" between the assigned colors, and the goal is\nto minimize the \"largest\" color used. For the widely studied GCP, we\nexperimentally compare our new SAT encoding to the state-of-the-art approaches\non the DIMACS benchmark set. Our evaluation confirms that this SAT encoding is\neffective for sparse graphs and even outperforms the state-of-the-art on some\nDIMACS instances. For the BCP, our theoretical analysis shows that the\npartial-ordering based SAT and ILP formulations have an asymptotically smaller\nsize than that of the classical assignment-based model. Our practical\nevaluation confirms not only a dominance compared to the assignment-based\nencodings but also to the state-of-the-art approaches on a set of benchmark\ninstances. Up to our knowledge, we have solved several open instances of the\nBCP from the literature for the first time.\n","authors":["Daniel Faber","Adalat Jabrayilov","Petra Mutzel"],"pdf_url":"https://arxiv.org/pdf/2403.15961v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15955v1","updated":"2024-03-23T23:22:54Z","published":"2024-03-23T23:22:54Z","title":"Finding needles in a haystack: A Black-Box Approach to Invisible\n  Watermark Detection","summary":"  In this paper, we propose WaterMark Detection (WMD), the first invisible\nwatermark detection method under a black-box and annotation-free setting. WMD\nis capable of detecting arbitrary watermarks within a given reference dataset\nusing a clean non-watermarked dataset as a reference, without relying on\nspecific decoding methods or prior knowledge of the watermarking techniques. We\ndevelop WMD using foundations of offset learning, where a clean non-watermarked\ndataset enables us to isolate the influence of only watermarked samples in the\nreference dataset. Our comprehensive evaluations demonstrate the effectiveness\nof WMD, significantly outperforming naive detection methods, which only yield\nAUC scores around 0.5. In contrast, WMD consistently achieves impressive\ndetection AUC scores, surpassing 0.9 in most single-watermark datasets and\nexceeding 0.7 in more challenging multi-watermark scenarios across diverse\ndatasets and watermarking methods. As invisible watermarks become increasingly\nprevalent, while specific decoding techniques remain undisclosed, our approach\nprovides a versatile solution and establishes a path toward increasing\naccountability, transparency, and trust in our digital visual content.\n","authors":["Minzhou Pan","Zhengting Wang","Xin Dong","Vikash Sehwag","Lingjuan Lyu","Xue Lin"],"pdf_url":"https://arxiv.org/pdf/2403.15955v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15953v1","updated":"2024-03-23T23:14:37Z","published":"2024-03-23T23:14:37Z","title":"Understanding The Effectiveness of Lossy Compression in Machine Learning\n  Training Sets","summary":"  Learning and Artificial Intelligence (ML/AI) techniques have become\nincreasingly prevalent in high performance computing (HPC). However, these\nmethods depend on vast volumes of floating point data for training and\nvalidation which need methods to share the data on a wide area network (WAN) or\nto transfer it from edge devices to data centers. Data compression can be a\nsolution to these problems, but an in-depth understanding of how lossy\ncompression affects model quality is needed. Prior work largely considers a\nsingle application or compression method. We designed a systematic methodology\nfor evaluating data reduction techniques for ML/AI, and we use it to perform a\nvery comprehensive evaluation with 17 data reduction methods on 7 ML/AI\napplications to show modern lossy compression methods can achieve a 50-100x\ncompression ratio improvement for a 1% or less loss in quality. We identify\ncritical insights that guide the future use and design of lossy compressors for\nML/AI.\n","authors":["Robert Underwood","Jon C. Calhoun","Sheng Di","Franck Cappello"],"pdf_url":"https://arxiv.org/pdf/2403.15953v1.pdf","comment":"12 pages, 4 figures"},{"id":"http://arxiv.org/abs/1909.03820v2","updated":"2024-03-23T22:14:50Z","published":"2019-09-09T12:57:29Z","title":"Learning Concepts Definable in First-Order Logic with Counting","summary":"  We study Boolean classification problems over relational background\nstructures in the logical framework introduced by Grohe and Tur\\'an (TOCS\n2004). It is known (Grohe and Ritzert, LICS 2017) that classifiers definable in\nfirst-order logic over structures of polylogarithmic degree can be learned in\nsublinear time, where the degree of the structure and the running time are\nmeasured in terms of the size of the structure. We generalise the results to\nthe first-order logic with counting FOCN, which was introduced by Kuske and\nSchweikardt (LICS 2017) as an expressive logic generalising various other\ncounting logics. Specifically, we prove that classifiers definable in FOCN over\nclasses of structures of polylogarithmic degree can be consistently learned in\nsublinear time. This can be seen as a first step towards extending the learning\nframework to include numerical aspects of machine learning. We extend the\nresult to agnostic probably approximately correct (PAC) learning for classes of\nstructures of degree at most $(\\log \\log n)^c$ for some constant $c$. Moreover,\nwe show that bounding the degree is crucial to obtain sublinear-time learning\nalgorithms. That is, we prove that, for structures of unbounded degree,\nlearning is not possible in sublinear time, even for classifiers definable in\nplain first-order logic.\n","authors":["Steffen van Bergerem"],"pdf_url":"https://arxiv.org/pdf/1909.03820v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15944v1","updated":"2024-03-23T22:14:38Z","published":"2024-03-23T22:14:38Z","title":"Adaptive Super Resolution For One-Shot Talking-Head Generation","summary":"  The one-shot talking-head generation learns to synthesize a talking-head\nvideo with one source portrait image under the driving of same or different\nidentity video. Usually these methods require plane-based pixel transformations\nvia Jacobin matrices or facial image warps for novel poses generation. The\nconstraints of using a single image source and pixel displacements often\ncompromise the clarity of the synthesized images. Some methods try to improve\nthe quality of synthesized videos by introducing additional super-resolution\nmodules, but this will undoubtedly increase computational consumption and\ndestroy the original data distribution. In this work, we propose an adaptive\nhigh-quality talking-head video generation method, which synthesizes\nhigh-resolution video without additional pre-trained modules. Specifically,\ninspired by existing super-resolution methods, we down-sample the one-shot\nsource image, and then adaptively reconstruct high-frequency details via an\nencoder-decoder module, resulting in enhanced video clarity. Our method\nconsistently improves the quality of generated videos through a straightforward\nyet effective strategy, substantiated by quantitative and qualitative\nevaluations. The code and demo video are available on:\n\\url{https://github.com/Songluchuan/AdaSR-TalkingHead/}.\n","authors":["Luchuan Song","Pinxin Liu","Guojun Yin","Chenliang Xu"],"pdf_url":"https://arxiv.org/pdf/2403.15944v1.pdf","comment":"5 pages, 3 figures"}],"Optimization and Control":[{"id":"http://arxiv.org/abs/2403.15959v1","updated":"2024-03-23T23:36:26Z","published":"2024-03-23T23:36:26Z","title":"Risk-Calibrated Human-Robot Interaction via Set-Valued Intent Prediction","summary":"  Tasks where robots must cooperate with humans, such as navigating around a\ncluttered home or sorting everyday items, are challenging because they exhibit\na wide range of valid actions that lead to similar outcomes. Moreover,\nzero-shot cooperation between human-robot partners is an especially challenging\nproblem because it requires the robot to infer and adapt on the fly to a latent\nhuman intent, which could vary significantly from human to human. Recently,\ndeep learned motion prediction models have shown promising results in\npredicting human intent but are prone to being confidently incorrect. In this\nwork, we present Risk-Calibrated Interactive Planning (RCIP), which is a\nframework for measuring and calibrating risk associated with uncertain action\nselection in human-robot cooperation, with the fundamental idea that the robot\nshould ask for human clarification when the risk associated with the\nuncertainty in the human's intent cannot be controlled. RCIP builds on the\ntheory of set-valued risk calibration to provide a finite-sample statistical\nguarantee on the cumulative loss incurred by the robot while minimizing the\ncost of human clarification in complex multi-step settings. Our main insight is\nto frame the risk control problem as a sequence-level multi-hypothesis testing\nproblem, allowing efficient calibration using a low-dimensional parameter that\ncontrols a pre-trained risk-aware policy. Experiments across a variety of\nsimulated and real-world environments demonstrate RCIP's ability to predict and\nadapt to a diverse set of dynamic human intents.\n","authors":["Justin Lidard","Hang Pham","Ariel Bachman","Bryan Boateng","Anirudha Majumdar"],"pdf_url":"https://arxiv.org/pdf/2403.15959v1.pdf","comment":"Website with additional information, videos, and code:\n  https://risk-calibrated-planning.github.io/"},{"id":"http://arxiv.org/abs/2403.15957v1","updated":"2024-03-23T23:26:19Z","published":"2024-03-23T23:26:19Z","title":"Putting all eggs in one basket: some insights from a correlation\n  inequality","summary":"  We give examples of situations -- stochastic production, military tactics,\ncorporate merger -- where it is beneficial to concentrate risk rather than to\ndiversify it, that is, to put all eggs in one basket. Our examples admit a dual\ninterpretation: as optimal strategies of a single player (the `principal') or,\nalternatively, as dominant strategies in a non-cooperative game with multiple\nplayers (the `agents').\n  The key mathematical result can be formulated in terms of a convolution\nstructure on the set of increasing functions on a Boolean lattice (the lattice\nof subsets of a finite set). This generalizes the well-known Harris inequality\nfrom statistical physics and discrete mathematics; we give a simple\nself-contained proof of this result, and prove a further generalization based\non the game-theoretic approach.\n","authors":["Pradeep Dubey","Siddhartha Sahi","Guanyang Wang"],"pdf_url":"https://arxiv.org/pdf/2403.15957v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2403.15915v1","updated":"2024-03-23T19:02:42Z","published":"2024-03-23T19:02:42Z","title":"Michell Truss and From 1-beam to k-beam","summary":"  This paper generalizes the Michell Truss problem and Gangbo's paper from\n1-dimension to higher dimensions using geometric measure theory.\n  Given an elastic surface $S$ made of $(k-1)$-beams under an equilibriated\nsystem $F$ of external forces, then we ask the following two questions:\n  1. What are the necessary and sufficient conditions for the existence of an\nelastic body made of $k$-beams whose forces on the surface balance $F$ and\nwhose surfaces consist of $S$.\n  2. What is an optimal design so that the total cost is a minimum?\n  We've solved the existence question completely; and research is still in\nprogress for the minimal question. In particular when $k=1$, it involves a\nsystem of beams joining a given finite collection of pointed forces. It was\nfirst introduced by A. Michell in 1904, then used in mechanical engineering,\nand recently popularized in many pure mathematics works by W. Gangbo, Prager,\nand others. Here we are going to generalize them to higher dimensional cases.\nWe have already found the minimal solutions in terms of the flat chain complex\nand vector-valued currents. Right now we are studying the Calibration theory\nfor future directions. I appreciate the discussion with Prof. Robert Hardt!\n","authors":["Chengcheng Yang"],"pdf_url":"https://arxiv.org/pdf/2403.15915v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15913v1","updated":"2024-03-23T18:59:55Z","published":"2024-03-23T18:59:55Z","title":"GPU-accelerated nonlinear model predictive control with ExaModels and\n  MadNLP","summary":"  We investigate the potential of Graphics Processing Units (GPUs) to solve\nlarge-scale nonlinear model predictive control (NMPC) problems. We accelerate\nthe solution of the constrained nonlinear programs in the NMPC algorithm using\nthe GPU-accelerated automatic differentiation tool ExaModels with the\ninterior-point solver MadNLP. The sparse linear systems formulated in the\ninterior-point method is solved on the GPU using a hybrid solver combining an\niterative method with a sparse Cholesky factorization, which harness the newly\nreleased NVIDIA cuDSS solver. Our results on the classical distillation column\ninstance show that despite a significant pre-processing time, the hybrid solver\nallows to reduce the time per iteration by a factor of 25 for the largest\ninstance.\n","authors":["François Pacaud","Sungho Shin"],"pdf_url":"https://arxiv.org/pdf/2403.15913v1.pdf","comment":"6 pages, 1 figure, 2 tables"},{"id":"http://arxiv.org/abs/2103.15130v5","updated":"2024-03-23T18:51:38Z","published":"2021-03-28T13:42:07Z","title":"Consensus-Based Optimization Methods Converge Globally","summary":"  In this paper we study consensus-based optimization (CBO), which is a\nmulti-agent metaheuristic derivative-free optimization method that can globally\nminimize nonconvex nonsmooth functions and is amenable to theoretical analysis.\nBased on an experimentally supported intuition that, on average, CBO performs a\ngradient descent of the squared Euclidean distance to the global minimizer, we\ndevise a novel technique for proving the convergence to the global minimizer in\nmean-field law for a rich class of objective functions. The result unveils\ninternal mechanisms of CBO that are responsible for the success of the method.\nIn particular, we prove that CBO performs a convexification of a large class of\noptimization problems as the number of optimizing agents goes to infinity.\nFurthermore, we improve prior analyses by requiring mild assumptions about the\ninitialization of the method and by covering objectives that are merely locally\nLipschitz continuous. As a core component of this analysis, we establish a\nquantitative nonasymptotic Laplace principle, which may be of independent\ninterest. From the result of CBO convergence in mean-field law, it becomes\napparent that the hardness of any global optimization problem is necessarily\nencoded in the rate of the mean-field approximation, for which we provide a\nnovel probabilistic quantitative estimate. The combination of these results\nallows to obtain probabilistic global convergence guarantees of the numerical\nCBO method.\n","authors":["Massimo Fornasier","Timo Klock","Konstantin Riedl"],"pdf_url":"https://arxiv.org/pdf/2103.15130v5.pdf","comment":"41 pages, 3 figures"},{"id":"http://arxiv.org/abs/2401.10240v2","updated":"2024-03-23T17:41:12Z","published":"2023-11-28T17:15:07Z","title":"Policy Evaluation in Distributional LQR (Extended Version)","summary":"  Distributional reinforcement learning (DRL) enhances the understanding of the\neffects of the randomness in the environment by letting agents learn the\ndistribution of a random return, rather than its expected value as in standard\nreinforcement learning. Meanwhile, a challenge in DRL is that the policy\nevaluation typically relies on the representation of the return distribution,\nwhich needs to be carefully designed. In this paper, we address this challenge\nfor the special class of DRL problems that rely on a discounted linear\nquadratic regulator (LQR), which we call \\emph{distributional LQR}.\nSpecifically, we provide a closed-form expression for the distribution of the\nrandom return, which is applicable for all types of exogenous disturbance as\nlong as it is independent and identically distributed (i.i.d.). We show that\nthe variance of the random return is bounded if the fourth moment of the\nexogenous disturbance is bounded. Furthermore, we investigate the sensitivity\nof the return distribution to model perturbations. While the proposed exact\nreturn distribution consists of infinitely many random variables, we show that\nthis distribution can be well approximated by a finite number of random\nvariables. The associated approximation error can be analytically bounded under\nmild assumptions. When the model is unknown, we propose a model-free approach\nfor estimating the return distribution, supported by sample complexity\nguarantees. Finally, we extend our approach to partially observable linear\nsystems. Numerical experiments are provided to illustrate the theoretical\nresults.\n","authors":["Zifan Wang","Yulong Gao","Siyi Wang","Michael M. Zavlanos","Alessandro Abate","Karl H. Johansson"],"pdf_url":"https://arxiv.org/pdf/2401.10240v2.pdf","comment":"This draft is an extension to our previous work\n  https://proceedings.mlr.press/v211/wang23c/wang23c.pdf. arXiv admin note:\n  text overlap with arXiv:2303.13657"},{"id":"http://arxiv.org/abs/2303.10599v2","updated":"2024-03-23T13:26:31Z","published":"2023-03-19T08:29:49Z","title":"Convergence Analysis of Stochastic Gradient Descent with MCMC Estimators","summary":"  Understanding stochastic gradient descent (SGD) and its variants is essential\nfor machine learning. However, most of the preceding analyses are conducted\nunder amenable conditions such as unbiased gradient estimator and bounded\nobjective functions, which does not encompass many sophisticated applications,\nsuch as variational Monte Carlo, entropy-regularized reinforcement learning and\nvariational inference. In this paper, we consider the SGD algorithm that employ\nthe Markov Chain Monte Carlo (MCMC) estimator to compute the gradient, called\nMCMC-SGD. Since MCMC reduces the sampling complexity significantly, it is an\nasymptotically convergent biased estimator in practice. Moreover, by\nincorporating a general class of unbounded functions, it is much more difficult\nto analyze the MCMC sampling error. Therefore, we assume that the function is\nsub-exponential and use the Bernstein inequality for non-stationary Markov\nchains to derive error bounds of the MCMC estimator. Consequently, MCMC-SGD is\nproven to have a first order convergence rate $O(\\log K/\\sqrt{n K})$ with $K$\niterations and a sample size $n$. It partially explains how MCMC influences the\nbehavior of SGD. Furthermore, we verify the correlated negative curvature\ncondition under reasonable assumptions. It is shown that MCMC-SGD escapes from\nsaddle points and reaches $(\\epsilon,\\epsilon^{1/4})$ approximate second order\nstationary points or $\\epsilon^{1/2}$-variance points at least\n$O(\\epsilon^{-11/2}\\log^{2}(1/\\epsilon) )$ steps with high probability. Our\nanalysis unveils the convergence pattern of MCMC-SGD across a broad class of\nstochastic optimization problems, and interprets the convergence phenomena\nobserved in practical applications.\n","authors":["Tianyou Li","Fan Chen","Huajie Chen","Zaiwen Wen"],"pdf_url":"https://arxiv.org/pdf/2303.10599v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15804v1","updated":"2024-03-23T11:30:09Z","published":"2024-03-23T11:30:09Z","title":"Semi-on-Demand Hybrid Transit Route Design with Shared Autonomous\n  Mobility Services","summary":"  This study examines the route design of a semi-on-demand hybrid route\ndirectional service in the public transit network, offering on-demand flexible\nroute service in low-density areas and fixed route service in higher-density\nareas with Shared Autonomous Mobility Service (SAMS). The study develops\nanalytically tractable cost expressions that capture access, waiting, and\nriding costs for users, and distance-based operating and time-based vehicle\ncosts for operators. Two formulations are presented for strategic and tactical\ndecisions in flexible route portion, fleet size, headway, and vehicle size\noptimization, enabling the determination of route types between fixed, hybrid,\nand flexible routes based on demand, cost, and operational parameters. The\npractical applications and benefits of semi-on-demand feeders are demonstrated\nwith numerical examples and a large-scale case study in the Chicago\nmetropolitan area. Findings reveal scenarios in which flexible route portions\nserving passengers located further away reduce total costs, particularly user\ncosts. Lower operating costs in lower-demand areas favor more flexible routes,\nwhereas higher demand densities favor more traditional line-based operations.\nOn two studied lines, a current cost forecast favors smaller vehicles with\nflexible routes, but operating constraints and higher operating costs would\nfavor bigger vehicles with hybrid routes. The study provides an analytical tool\nto design SAMS as directional services and transit feeders, and tractable\ncontinuous approximation formulations for future research in transit network\ndesign.\n","authors":["Max T. M. Ng","Florian Dandl","Hani S. Mahmassani","Klaus Bogenberger"],"pdf_url":"https://arxiv.org/pdf/2403.15804v1.pdf","comment":"24 pages, 12 figures, the previous version presented at the 103rd\n  Transportation Research Board Annual Meeting, Washington, D.C"},{"id":"http://arxiv.org/abs/2311.03326v2","updated":"2024-03-23T11:05:53Z","published":"2023-11-06T18:22:18Z","title":"Non-convex potential games for finding global solutions to sensor\n  network localization","summary":"  Sensor network localization (SNL) problems require determining the physical\ncoordinates of all sensors in a network. This process relies on the global\ncoordinates of anchors and the available measurements between non-anchor and\nanchor nodes. Attributed to the intrinsic non-convexity, obtaining a globally\noptimal solution to SNL is challenging, as well as implementing corresponding\nalgorithms. In this paper, we formulate a non-convex multi-player potential\ngame for a generic SNL problem to investigate the identification condition of\nthe global Nash equilibrium (NE) therein, where the global NE represents the\nglobal solution of SNL. We employ canonical duality theory to transform the\nnon-convex game into a complementary dual problem. Then we develop a\nconjugation-based algorithm to compute the stationary points of the\ncomplementary dual problem. On this basis, we show an identification condition\nof the global NE: the stationary point of the proposed algorithm satisfies a\nduality relation. Finally, simulation results are provided to validate the\neffectiveness of the theoretical results.\n","authors":["Gehui Xu","Guanpu Chen","Yiguang Hong","Baris Fidan","Thomas Parisini","Karl H. Johansson"],"pdf_url":"https://arxiv.org/pdf/2311.03326v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15783v1","updated":"2024-03-23T10:04:06Z","published":"2024-03-23T10:04:06Z","title":"Divergence conforming DG method for the optimal control of the Oseen\n  equation with variable viscosity","summary":"  This study introduces the divergence-conforming discontinuous Galerkin finite\nelement method (DGFEM) for numerically approximating optimal control problems\nwith distributed constraints, specifically those governed by stationary\ngeneralized Oseen equations. We provide optimal a priori error estimates in\nenergy norms for such problems using the divergence-conforming DGFEM approach.\nMoreover, we thoroughly analyze $L^2$ error estimates for scenarios dominated\nby diffusion and convection. Additionally, we establish the new reliable and\nefficient a posteriori error estimators for the optimal control of the Oseen\nequation with variable viscosity. Theoretical findings are validated through\nnumerical experiments conducted in both two and three dimensions.\n","authors":["Harpal Singh","Arbaz Khan"],"pdf_url":"https://arxiv.org/pdf/2403.15783v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15749v1","updated":"2024-03-23T07:34:18Z","published":"2024-03-23T07:34:18Z","title":"Horoballs and the subgradient method","summary":"  To explore convex optimization on Hadamard spaces, we consider an iteration\nin the style of a subgradient algorithm. Traditionally, such methods assume\nthat the underlying spaces are manifolds and that the objectives are\ngeodesically convex: the methods are described using tangent spaces and\nexponential maps. By contrast, our iteration applies in a general Hadamard\nspace, is framed in the underlying space itself, and relies instead on\nhorospherical convexity of the objective level sets. For this restricted class\nof objectives, we prove a complexity result of the usual form. Notably, the\ncomplexity does not depend on a lower bound on the space curvature.\n","authors":["Adrian S. Lewis","Genaro Lopez-Acedo","Adriana Nicolae"],"pdf_url":"https://arxiv.org/pdf/2403.15749v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15745v1","updated":"2024-03-23T07:19:10Z","published":"2024-03-23T07:19:10Z","title":"Fast Consensus Topology Design via Minimizing Laplacian Energy","summary":"  This paper characterizes the graphical properties of an optimal topology with\nminimal Laplacian energy under the constraint of fixed numbers of vertices and\nedges, and devises an algorithm to construct such connected optimal graphs.\nThese constructed graphs possess maximum vertex and edge connectivity, and more\nimportantly, exhibit large algebraic connectivity of an optimal order provided\nthey are not sparse. These properties guarantee fast and resilient consensus\nprocesses over these graphs.\n","authors":["Susie Lu","Ji Liu"],"pdf_url":"https://arxiv.org/pdf/2403.15745v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15738v1","updated":"2024-03-23T06:06:06Z","published":"2024-03-23T06:06:06Z","title":"Optimal Hospital Capacity Management During Demand Surges","summary":"  Effective hospital capacity management is pivotal for enhancing patient care\nquality, operational efficiency, and healthcare system resilience, notably\nduring demand spikes like those seen in the COVID-19 pandemic. However,\ndevising optimal capacity strategies is complicated by fluctuating demand,\nconflicting objectives, and multifaceted practical constraints. This study\npresents a data-driven framework to optimize capacity management decisions\nwithin hospital systems during surge events. Two key decisions are optimized\nover a tactical planning horizon: allocating dedicated capacity to surge\npatients and transferring incoming patients between emergency departments (EDs)\nof hospitals to better distribute demand. The optimization models are\nformulated as robust mixed-integer linear programs, enabling efficient\ncomputation of optimal decisions that are robust against demand uncertainty.\nThe models incorporate practical constraints and costs, including setup times\nand costs for adding surge capacity, restrictions on ED patient transfers, and\nrelative costs of different decisions that reflect impacts on care quality and\noperational efficiency. The methodology is evaluated retrospectively in a\nhospital system during the height of the COVID-19 pandemic to demonstrate the\npotential impact of the recommended decisions. The results show that optimally\nallocating beds and transferring just 30 patients over a 63 day period around\nthe peak, less than one transfer every two days, could have reduced the need\nfor surge capacity in the hospital system by approximately 98%. Overall, this\nwork introduces a practical tool to transform capacity management\ndecision-making, enabling proactive planning and the use of data-driven\nrecommendations to improve outcomes.\n","authors":["Felix Parker","Fardin Ganjkhanloo","Diego A. Martínez","Kimia Ghobadi"],"pdf_url":"https://arxiv.org/pdf/2403.15738v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15710v1","updated":"2024-03-23T04:10:53Z","published":"2024-03-23T04:10:53Z","title":"Properties for transposition solutions to operator-valued BSEEs, and\n  applications to robust second order necessary conditions for controlled SEEs","summary":"  This article is concerned with the second order necessary conditions for the\nstochastic optimal control problem of stochastic evolution equation with model\nuncertainty when the traditional Pontryagin-type maximum principle holds\ntrivially and do not provide any information depicting the optimal control. The\ndiffusion term of the state equation is allowed to be control dependent with\nconvex control constraints. Transposition method is adopted to deal with the\nadjoint operator-valued backward stochastic evolution equations, especially the\ncorrection terms. Besides, weak convergence arguments are performed to obtain\nthe optimal uncertainty measure, among which the regularities of the state\nprocesses, variational processes, and adjoint processes (in the transposition\nsense) are carefully characterized. Malliavin calculus is applied to pave the\nway for Lebesgue differentiation theorem to deduce the pointwise robust\noptimality conditions.\n","authors":["Guangdong Jing"],"pdf_url":"https://arxiv.org/pdf/2403.15710v1.pdf","comment":"40 pages"},{"id":"http://arxiv.org/abs/2403.15703v1","updated":"2024-03-23T03:52:54Z","published":"2024-03-23T03:52:54Z","title":"Robust pointwise second order necessary conditions for singular\n  stochastic optimal control with model uncertainty","summary":"  We study the singular stochastic optimal control problem with model\nuncertainty, where the necessary conditions determined by the corresponding\nmaximum principle are trivial. Robust integral form and pointwise second order\nnecessary optimality conditions under certain compactness conditions are\nderived. Both the drift and diffusion terms are control dependent but the\ncontrol region are assumed to be convex. The convex variational method is\nemployed, because linear structure is essential in deriving the weak limit of\nuncertainty measures. Other main technical ingredients in obtaining the\nintegral type conditions are compact analysis and minimax theorem, while for\nthe pointwise ones it is Clark-Ocone formula and Lebesgue differentiation type\ntheorem. Besides, a compendious example is given to illustrate the motivation\nand effectiveness of the results.\n","authors":["Guangdong Jing"],"pdf_url":"https://arxiv.org/pdf/2403.15703v1.pdf","comment":"36 pages"},{"id":"http://arxiv.org/abs/2403.15702v1","updated":"2024-03-23T03:49:39Z","published":"2024-03-23T03:49:39Z","title":"Causal Tracking of Distributions in Wasserstein Space: A Model\n  Predictive Control Scheme","summary":"  We consider the problem of optimal swarm tracking which can be formulated as\na tracking problem for distributions in the Wasserstein metric. Optimal control\nsolutions to this problem are non-causal and require knowing the\ntime-trajectory of the distribution to be tracked in advance. We propose a\nscheme where these non-causal solutions can be used together with a predictive\nmodel for the reference to achieve causal tracking control of a priori-unknown\nreferences. We develop the resulting model-predictive control scheme in the\nsimple case where the reference is predicted to be constant-in-time. A\ncomputational algorithm based on particle methods and discrete optimal mass\ntransport is presented, and numerical simulations are provided for various\nclasses of reference signals. The results demonstrate that the proposed control\nalgorithm achieves reasonable performance even when using simple predictive\nmodels.\n","authors":["Max Emerick","Jared Jonas","Bassam Bamieh"],"pdf_url":"https://arxiv.org/pdf/2403.15702v1.pdf","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2403.14028v2","updated":"2024-03-23T02:29:44Z","published":"2024-03-20T22:56:11Z","title":"Performance-Guaranteed Solutions for Multi-Agent Optimal Coverage\n  Problems using Submodularity, Curvature, and Greedy Algorithms","summary":"  We consider a class of multi-agent optimal coverage problems in which the\ngoal is to determine the optimal placement of a group of agents in a given\nmission space so that they maximize a coverage objective that represents a\nblend of individual and collaborative event detection capabilities. This class\nof problems is extremely challenging due to the non-convex nature of the\nmission space and of the coverage objective. With this motivation, greedy\nalgorithms are often used as means of getting feasible coverage solutions\nefficiently. Even though such greedy solutions are suboptimal, the\nsubmodularity (diminishing returns) property of the coverage objective can be\nexploited to provide performance bound guarantees. Moreover, we show that\nimproved performance bound guarantees (beyond the standard (1-1/e) performance\nbound) can be established using various curvature measures of the coverage\nproblem. In particular, we provide a brief review of all existing popular\napplicable curvature measures, including a recent curvature measure that we\nproposed, and discuss their effectiveness and computational complexity, in the\ncontext of optimal coverage problems. We also propose novel computationally\nefficient techniques to estimate some curvature measures. Finally, we provide\nseveral numerical results to support our findings and propose several potential\nfuture research directions.\n","authors":["Shirantha Welikala","Christos G. Cassandras"],"pdf_url":"https://arxiv.org/pdf/2403.14028v2.pdf","comment":"Will be submitted to CDC 2024"},{"id":"http://arxiv.org/abs/2309.09574v2","updated":"2024-03-23T02:16:40Z","published":"2023-09-18T08:33:23Z","title":"Latent assimilation with implicit neural representations for unknown\n  dynamics","summary":"  Data assimilation is crucial in a wide range of applications, but it often\nfaces challenges such as high computational costs due to data dimensionality\nand incomplete understanding of underlying mechanisms. To address these\nchallenges, this study presents a novel assimilation framework, termed Latent\nAssimilation with Implicit Neural Representations (LAINR). By introducing\nSpherical Implicit Neural Representations (SINR) along with a data-driven\nuncertainty estimator of the trained neural networks, LAINR enhances efficiency\nin assimilation process. Experimental results indicate that LAINR holds certain\nadvantage over existing methods based on AutoEncoders, both in terms of\naccuracy and efficiency.\n","authors":["Zhuoyuan Li","Bin Dong","Pingwen Zhang"],"pdf_url":"https://arxiv.org/pdf/2309.09574v2.pdf","comment":"40 pages"},{"id":"http://arxiv.org/abs/2403.15678v1","updated":"2024-03-23T02:04:43Z","published":"2024-03-23T02:04:43Z","title":"Conservative Surrogate Models for Optimization with the Active Subspace\n  Method","summary":"  We are interested in building low-dimensional surrogate models to reduce\noptimization costs, while having theoretical guarantees that the optimum will\nsatisfy the constraints of the full-size model, by making conservative\napproximations. The surrogate model is constructed using a Gaussian process\nregression (GPR). To ensure conservativeness, two new approaches are proposed:\nthe first one using bootstrapping, and the second one using concentration\ninequalities. Those two techniques are based on a stochastic argument and thus\nwill only enforce conservativeness up to a user-defined probability threshold.\nThe method has applications in the context of optimization using the active\nsubspace method for dimensionality reduction of the objective function and the\nconstraints, addressing recorded issues about constraint violations. The\nresulting algorithms are tested on a toy optimization problem in thermal\ndesign.\n","authors":["Philippe-André Luneau"],"pdf_url":"https://arxiv.org/pdf/2403.15678v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15669v1","updated":"2024-03-23T01:34:44Z","published":"2024-03-23T01:34:44Z","title":"Review of Large-Scale Simulation Optimization","summary":"  Large-scale simulation optimization (SO) problems encompass both large-scale\nranking-and-selection problems and high-dimensional discrete or continuous SO\nproblems, presenting significant challenges to existing SO theories and\nalgorithms. This paper begins by providing illustrative examples that highlight\nthe differences between large-scale SO problems and those of a more moderate\nscale. Subsequently, it reviews several widely employed techniques for\naddressing large-scale SO problems, such as divide and conquer, dimension\nreduction, and gradient-based algorithms. Additionally, the paper examines\nparallelization techniques leveraging widely accessible parallel computing\nenvironments to facilitate the resolution of large-scale SO problems.\n","authors":["Weiwei Fan","L. Jeff Hong","Guangxin Jiang","Jun Luo"],"pdf_url":"https://arxiv.org/pdf/2403.15669v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15656v1","updated":"2024-03-23T00:23:16Z","published":"2024-03-23T00:23:16Z","title":"Constraint Preconditioning and Parameter Selection for a First-Order\n  Primal-Dual Method applied to Model Predictive Control","summary":"  Many techniques for real-time trajectory optimization and control require the\nsolution of optimization problems at high frequencies. However,\nill-conditioning in the optimization problem can significantly reduce the speed\nof first-order primal-dual optimization algorithms. We introduce a\npreconditioning technique and step-size heuristic for Proportional-Integral\nProjected Gradient (PIPG), a first-order primal-dual algorithm. The\npreconditioning technique, based on the QR factorization, aims to reduce the\ncondition number of the KKT matrix associated with the optimization problem.\nOur step-size selection heuristic chooses step-sizes to minimize the upper\nbound on the convergence of the primal-dual gap for the optimization problem.\nThese algorithms are tested on two model predictive control problem examples\nand show a solve-time reduction of at least 3.6x.\n","authors":["Govind M. Chari","Yue Yu","Behçet Açıkmeşe"],"pdf_url":"https://arxiv.org/pdf/2403.15656v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15654v1","updated":"2024-03-23T00:01:34Z","published":"2024-03-23T00:01:34Z","title":"The Effectiveness of Local Updates for Decentralized Learning under Data\n  Heterogeneity","summary":"  We revisit two fundamental decentralized optimization methods, Decentralized\nGradient Tracking (DGT) and Decentralized Gradient Descent (DGD), with multiple\nlocal updates. We consider two settings and demonstrate that incorporating $K >\n1$ local update steps can reduce communication complexity. Specifically, for\n$\\mu$-strongly convex and $L$-smooth loss functions, we proved that local DGT\nachieves communication complexity $\\tilde{\\mathcal{O}} \\Big(\\frac{L}{\\mu K} +\n\\frac{\\delta}{\\mu (1 - \\rho)} + \\frac{\\rho }{(1 - \\rho)^2} \\cdot \\frac{L+\n\\delta}{\\mu}\\Big)$, where $\\rho$ measures the network connectivity and $\\delta$\nmeasures the second-order heterogeneity of the local loss. Our result reveals\nthe tradeoff between communication and computation and shows increasing $K$ can\neffectively reduce communication costs when the data heterogeneity is low and\nthe network is well-connected. We then consider the over-parameterization\nregime where the local losses share the same minimums, we proved that employing\nlocal updates in DGD, even without gradient correction, can yield a similar\neffect as DGT in reducing communication complexity. Numerical experiments\nvalidate our theoretical results.\n","authors":["Tongle Wu","Ying Sun"],"pdf_url":"https://arxiv.org/pdf/2403.15654v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15928v1","updated":"2024-03-23T20:22:30Z","published":"2024-03-23T20:22:30Z","title":"Safe Reinforcement Learning for Constrained Markov Decision Processes\n  with Stochastic Stopping Time","summary":"  In this paper, we present an online reinforcement learning algorithm for\nconstrained Markov decision processes with a safety constraint. Despite the\nnecessary attention of the scientific community, considering stochastic\nstopping time, the problem of learning optimal policy without violating safety\nconstraints during the learning phase is yet to be addressed. To this end, we\npropose an algorithm based on linear programming that does not require a\nprocess model. We show that the learned policy is safe with high confidence. We\nalso propose a method to compute a safe baseline policy, which is central in\ndeveloping algorithms that do not violate the safety constraints. Finally, we\nprovide simulation results to show the efficacy of the proposed algorithm.\nFurther, we demonstrate that efficient exploration can be achieved by defining\na subset of the state-space called proxy set.\n","authors":["Abhijit Mazumdar","Rafal Wisniewski","Manuela L. Bujorianu"],"pdf_url":"https://arxiv.org/pdf/2403.15928v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15907v1","updated":"2024-03-23T18:31:18Z","published":"2024-03-23T18:31:18Z","title":"Balancing art and money in pursuit of a Kelly-type optimality","summary":"  We introduce and study a mathematical model of an art collector. In our\nmodel, the collector is a rational agent whose actions in the art market are\ndriven by two competing long-term objectives, namely sustainable financial\nhealth and maintaining the collection. Mathematically, our model is a\ntwo-dimensional random linear dynamical system with transformation matrix of a\npeculiar type. In some examples we are able to show that within the Kelly-type\noptimization paradigm, that is optimizing the system's Lyapunov exponent over a\nset of policy parameters, the dilemma ``art or money\" can be successfully\nresolved, namely the optimal policy creates a coexistence equilibrium where the\nvalue of both is increasing over the time.\n","authors":["Reza Rastegar","Alex Roitershtein","Vadim Roytershteyn","Vijay Seetharam"],"pdf_url":"https://arxiv.org/pdf/2403.15907v1.pdf","comment":null}],"Systems and Control":[{"id":"http://arxiv.org/abs/2403.15959v1","updated":"2024-03-23T23:36:26Z","published":"2024-03-23T23:36:26Z","title":"Risk-Calibrated Human-Robot Interaction via Set-Valued Intent Prediction","summary":"  Tasks where robots must cooperate with humans, such as navigating around a\ncluttered home or sorting everyday items, are challenging because they exhibit\na wide range of valid actions that lead to similar outcomes. Moreover,\nzero-shot cooperation between human-robot partners is an especially challenging\nproblem because it requires the robot to infer and adapt on the fly to a latent\nhuman intent, which could vary significantly from human to human. Recently,\ndeep learned motion prediction models have shown promising results in\npredicting human intent but are prone to being confidently incorrect. In this\nwork, we present Risk-Calibrated Interactive Planning (RCIP), which is a\nframework for measuring and calibrating risk associated with uncertain action\nselection in human-robot cooperation, with the fundamental idea that the robot\nshould ask for human clarification when the risk associated with the\nuncertainty in the human's intent cannot be controlled. RCIP builds on the\ntheory of set-valued risk calibration to provide a finite-sample statistical\nguarantee on the cumulative loss incurred by the robot while minimizing the\ncost of human clarification in complex multi-step settings. Our main insight is\nto frame the risk control problem as a sequence-level multi-hypothesis testing\nproblem, allowing efficient calibration using a low-dimensional parameter that\ncontrols a pre-trained risk-aware policy. Experiments across a variety of\nsimulated and real-world environments demonstrate RCIP's ability to predict and\nadapt to a diverse set of dynamic human intents.\n","authors":["Justin Lidard","Hang Pham","Ariel Bachman","Bryan Boateng","Anirudha Majumdar"],"pdf_url":"https://arxiv.org/pdf/2403.15959v1.pdf","comment":"Website with additional information, videos, and code:\n  https://risk-calibrated-planning.github.io/"},{"id":"http://arxiv.org/abs/2403.15958v1","updated":"2024-03-23T23:27:37Z","published":"2024-03-23T23:27:37Z","title":"Convection-Enabled Boundary Control of a 2D Channel Flow","summary":"  We consider the incompressible Navier-Stokes equations in a two-dimensional\nchannel. The tangential and normal velocities are assumed to be periodic in the\nstreamwise (horizontal) direction. Moreover, we consider no-slip boundary\nconditions on the tangential velocity at the top and bottom walls of the\nchannel, and normal velocity actuation at the top and bottom walls. For an\narbitrarily large Reynolds number, we design the boundary control inputs to\nachieve global exponential stabilization, in the L2 sense, of a chosen\nparabolic Poiseuille profile. Moreover, we design the control inputs such that\nthey have zero mean, but non-zero cubic mean. The zero-mean property is to\nensure that the conservation of mass constraint is verified. The non-zero cubic\nmean property is the key to exploiting the stabilizing effect of nonlinear\nconvection and achieving global stabilization independently of the size of the\nReynolds number. This paper is not only the first work where a closed-form\nfeedback law is proposed for global stabilization of parabolic Poiseuille\nprofiles for arbitrary Reynolds number but is also the first generalization of\nthe Cardano-Lyapunov formula, designed initially to stabilize scalar-valued\nconvective PDEs, to a vector-valued convective PDE with a divergence-free\nconstraint on the state.\n","authors":["Mohamed Camil Belhadjoudja","Miroslav Krstic","Emmanuel Witrant"],"pdf_url":"https://arxiv.org/pdf/2403.15958v1.pdf","comment":"Submitted to the 63rd IEEE Conference on Decision and Control (CDC\n  2024)"},{"id":"http://arxiv.org/abs/2403.15924v1","updated":"2024-03-23T20:05:34Z","published":"2024-03-23T20:05:34Z","title":"Perception and Control of Surfing in Virtual Reality using a 6-DoF\n  Motion Platform","summary":"  The paper presents a system for simulating surfing in Virtual Reality (VR),\nemphasizing the recreation of aquatic motions and user-initiated propulsive\nforces using a 6-Degree of Freedom (DoF) motion platform. We present an\nalgorithmic approach to accurately render surfboard kinematics and interactive\npaddling dynamics, validated through experimental evaluation with \\(N=17\\)\nparticipants. Results indicate that the system effectively reproduces various\nacceleration levels, the perception of which is independent of users' body\nposture. We additionally found that the presence of ocean ripples amplifies the\nperception of acceleration. This system aims to enhance the realism and\ninteractivity of VR surfing, laying a foundation for future advancements in\nsurf therapy and interactive aquatic VR experiences.\n","authors":["Premankur Banerjee","Jason Cherin","Jayati Upadhyay","Jason Kutch","Heather Culbertson"],"pdf_url":"https://arxiv.org/pdf/2403.15924v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.00263v2","updated":"2024-03-23T16:52:29Z","published":"2023-04-01T08:56:46Z","title":"On the impact of regularization in data-driven predictive control","summary":"  Model predictive control (MPC) is a control strategy widely used in\nindustrial applications. However, its implementation typically requires a\nmathematical model of the system being controlled, which can be a\ntime-consuming and expensive task. Data-driven predictive control (DDPC)\nmethods offer an alternative approach that does not require an explicit\nmathematical model, but instead optimize the control policy directly from data.\nIn this paper, we study the impact of two different regularization penalties on\nthe closed-loop performance of a recently introduced data-driven method called\n$\\gamma$-DDPC. Moreover, we discuss the tuning of the related coefficients in\ndifferent data and noise scenarios, to provide some guidelines for the end\nuser.\n","authors":["Valentina Breschi","Alessandro Chiuso","Marco Fabris","Simone Formentin"],"pdf_url":"https://arxiv.org/pdf/2304.00263v2.pdf","comment":"7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2403.15883v1","updated":"2024-03-23T16:35:33Z","published":"2024-03-23T16:35:33Z","title":"From Raw Data to Safety: Reducing Conservatism by Set Expansion","summary":"  In response to safety concerns associated with learning-based algorithms,\nsafety filters have been proposed as a modular technique. Generally, these\nfilters heavily rely on the system's model, which is contradictory if they are\nintended to enhance a data-driven or end-to-end learning solution. This paper\nextends our previous work, a purely Data-Driven Safety Filter (DDSF) based on\nWillems' lemma, to an extremely short-sighted and non-conservative solution.\nSpecifically, we propose online and offline sample-based methods to expand the\nsafe set of DDSF and reduce its conservatism. Since this method is defined in\nan input-output framework, it can systematically handle both unknown and\ntime-delay LTI systems using only one single batch of data. To evaluate its\nperformance, we apply the proposed method to a time-delay system under various\nsettings. The simulation results validate the effectiveness of the set\nexpansion algorithm in generating a notably large input-output safe set,\nresulting in safety filters that are not conservative, even with an extremely\nshort prediction horizon.\n","authors":["Mohammad Bajelani","Klaske van Heusden"],"pdf_url":"https://arxiv.org/pdf/2403.15883v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.05261v2","updated":"2024-03-23T16:03:03Z","published":"2023-10-08T18:50:32Z","title":"Time-Varying Soft-Maximum Control Barrier Functions for Safety in an A\n  Priori Unknown Environment","summary":"  This paper presents a time-varying soft-maximum composite control barrier\nfunction (CBF) that can be used to ensure safety in an a priori unknown\nenvironment, where local perception information regarding the safe set is\nperiodically obtained. We consider the scenario where the periodically obtained\nperception feedback can be used to construct a local CBF that models a local\nsubset of the unknown safe set. Then, we use a novel smooth time-varying\nsoft-maximum function to compose the N most recently obtained local CBFs into a\nsingle CBF. This composite CBF models an approximate union of the N most\nrecently obtained local subsets of the safe set. Notably, this composite CBF\ncan have arbitrary relative degree r. Next, this composite CBF is used as a\nrth-order CBF constraint in a real-time optimization to determine a control\nthat minimizes a quadratic cost while guaranteeing that the state stays in a\ntime-varying subset of the unknown safe set. We also present an application of\nthe time-varying soft-maximum composite CBF method to a nonholonomic ground\nrobot with nonnegligible inertia. In this application, we present a simple\napproach to generate the local CBFs from the periodically obtained perception\ndata.\n","authors":["Amirsaeid Safari","Jesse B. Hoagg"],"pdf_url":"https://arxiv.org/pdf/2310.05261v2.pdf","comment":"2024 American Control Conference (ACC)"},{"id":"http://arxiv.org/abs/2402.17038v2","updated":"2024-03-23T15:43:50Z","published":"2024-02-26T21:44:23Z","title":"Hybrid Feedback Control for Global and Optimal Safe Navigation","summary":"  We propose a hybrid feedback control strategy that safely steers a point-mass\nrobot to a target location optimally from all initial conditions in the\nn-dimensional Euclidean space with a single spherical obstacle. The robot moves\nstraight to the target when it has a clear line-of-sight to the target\nlocation. Otherwise, it engages in an optimal obstacle avoidance maneuver via\nthe shortest path inside the cone enclosing the obstacle and having the robot's\nposition as a vertex. The switching strategy that avoids the undesired\nequilibria, leading to global asymptotic stability (GAS) of the target\nlocation, relies on using two appropriately designed virtual destinations,\nensuring control continuity and shortest path generation. Simulation results\nillustrating the effectiveness of the proposed approach are presented.\n","authors":["Ishak Cheniouni","Soulaimane Berkane","Abdelhamid Tayebi"],"pdf_url":"https://arxiv.org/pdf/2402.17038v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15854v1","updated":"2024-03-23T14:16:38Z","published":"2024-03-23T14:16:38Z","title":"A Modular Safety Filter for Safety-Certified Cyber-Physical Systems","summary":"  Nowadays, many control systems are networked and embed communication and\ncomputation capabilities. Such control architectures are prone to cyber attacks\non the cyberinfrastructure. Consequently, there is an impellent need to develop\nsolutions to preserve the plant's safety against potential attacks. To ensure\nsafety, this paper introduces a modular safety filter approach that is\neffective for a variety of cyber-attack types. This solution can be implemented\nin combination with existing control and detection algorithms, effectively\nseparating safety from performance. The safety filter does not require\ninformation on the reliability of the received command or the feature of the\nused anomaly detector. It can be implemented in conjunction with\nhigh-performance, resilient controllers, to achieve both high performance\nduring normal operation and safety during an attack. As an illustrative\nexample, we have shown the effectiveness of the proposed design considering a\nmulti-agent formation task involving 20 mobile robots. The simulation results\ntestify that the safety filter operates effectively during false data injection\nand intelligent attacks.\n","authors":["Mohammad Bajelani","Walter Lucia","Klaske van Heusden"],"pdf_url":"https://arxiv.org/pdf/2403.15854v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.05764v2","updated":"2024-03-23T14:08:17Z","published":"2023-12-10T05:03:10Z","title":"Synthesis of Temporally-Robust Policies for Signal Temporal Logic Tasks\n  using Reinforcement Learning","summary":"  This paper investigates the problem of designing control policies that\nsatisfy high-level specifications described by signal temporal logic (STL) in\nunknown, stochastic environments. While many existing works concentrate on\noptimizing the spatial robustness of a system, our work takes a step further by\nalso considering temporal robustness as a critical metric to quantify the\ntolerance of time uncertainty in STL. To this end, we formulate two relevant\ncontrol objectives to enhance the temporal robustness of the synthesized\npolicies. The first objective is to maximize the probability of being\ntemporally robust for a given threshold. The second objective is to maximize\nthe worst-case spatial robustness value within a bounded time shift. We use\nreinforcement learning to solve both control synthesis problems for unknown\nsystems. Specifically, we approximate both control objectives in a way that\nenables us to apply the standard Q-learning algorithm. Theoretical bounds in\nterms of the approximations are also derived. We present case studies to\ndemonstrate the feasibility of our approach.\n","authors":["Siqi Wang","Shaoyuan Li","Li Yin","Xiang Yin"],"pdf_url":"https://arxiv.org/pdf/2312.05764v2.pdf","comment":"Accepted to ICRA 2024"},{"id":"http://arxiv.org/abs/2403.15828v1","updated":"2024-03-23T13:01:26Z","published":"2024-03-23T13:01:26Z","title":"TJCCT: A Two-timescale Approach for UAV-assisted Mobile Edge Computing","summary":"  Unmanned aerial vehicle (UAV)-assisted mobile edge computing (MEC) is\nemerging as a promising paradigm to provide aerial-terrestrial computing\nservices in close proximity to mobile devices (MDs). However, meeting the\ndemands of computation-intensive and delay-sensitive tasks for MDs poses\nseveral challenges, including the demand-supply contradiction between MDs and\nMEC servers, the demand-supply heterogeneity between MDs and MEC servers, the\ntrajectory control requirements on energy efficiency and timeliness, and the\ndifferent time-scale dynamics of the network. To address these issues, we first\npresent a hierarchical architecture by incorporating terrestrial-aerial\ncomputing capabilities and leveraging UAV flexibility. Furthermore, we\nformulate a joint computing resource allocation, computation offloading, and\ntrajectory control problem to maximize the system utility. Since the problem is\na non-convex and NP-hard mixed integer nonlinear programming (MINLP), we\npropose a two-timescale joint computing resource allocation, computation\noffloading, and trajectory control (TJCCT) approach for solving the problem. In\nthe short timescale, we propose a price-incentive model for on-demand computing\nresource allocation and a matching mechanism-based method for computation\noffloading. In the long timescale, we propose a convex optimization-based\nmethod for UAV trajectory control. Besides, we theoretically prove the\nstability, optimality, and polynomial complexity of TJCCT. Extended simulation\nresults demonstrate that the proposed TJCCT outperforms the comparative\nalgorithms in terms of the system utility, average processing rate, average\ncompletion delay, and average completion ratio.\n","authors":["Zemin Sun","Geng Sun","Qingqing Wu","Long He","Shuang Liang","Hongyang Pan","Dusit Niyato","Chau Yuen","Victor C. M. Leung"],"pdf_url":"https://arxiv.org/pdf/2403.15828v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15826v1","updated":"2024-03-23T12:53:51Z","published":"2024-03-23T12:53:51Z","title":"Scaling Learning based Policy Optimization for Temporal Tasks via\n  Dropout","summary":"  This paper introduces a model-based approach for training feedback\ncontrollers for an autonomous agent operating in a highly nonlinear\nenvironment. We desire the trained policy to ensure that the agent satisfies\nspecific task objectives, expressed in discrete-time Signal Temporal Logic\n(DT-STL). One advantage for reformulation of a task via formal frameworks, like\nDT-STL, is that it permits quantitative satisfaction semantics. In other words,\ngiven a trajectory and a DT-STL formula, we can compute the robustness, which\ncan be interpreted as an approximate signed distance between the trajectory and\nthe set of trajectories satisfying the formula. We utilize feedback\ncontrollers, and we assume a feed forward neural network for learning these\nfeedback controllers. We show how this learning problem is similar to training\nrecurrent neural networks (RNNs), where the number of recurrent units is\nproportional to the temporal horizon of the agent's task objectives. This poses\na challenge: RNNs are susceptible to vanishing and exploding gradients, and\nna\\\"{i}ve gradient descent-based strategies to solve long-horizon task\nobjectives thus suffer from the same problems. To tackle this challenge, we\nintroduce a novel gradient approximation algorithm based on the idea of dropout\nor gradient sampling. We show that, the existing smooth semantics for\nrobustness are inefficient regarding gradient computation when the\nspecification becomes complex. To address this challenge, we propose a new\nsmooth semantics for DT-STL that under-approximates the robustness value and\nscales well for backpropagation over a complex specification. We show that our\ncontrol synthesis methodology, can be quite helpful for stochastic gradient\ndescent to converge with less numerical issues, enabling scalable\nbackpropagation over long time horizons and trajectories over high dimensional\nstate spaces.\n","authors":["Navid Hashemi","Bardh Hoxha","Danil Prokhorov","Georgios Fainekos","Jyotirmoy Deshmukh"],"pdf_url":"https://arxiv.org/pdf/2403.15826v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15804v1","updated":"2024-03-23T11:30:09Z","published":"2024-03-23T11:30:09Z","title":"Semi-on-Demand Hybrid Transit Route Design with Shared Autonomous\n  Mobility Services","summary":"  This study examines the route design of a semi-on-demand hybrid route\ndirectional service in the public transit network, offering on-demand flexible\nroute service in low-density areas and fixed route service in higher-density\nareas with Shared Autonomous Mobility Service (SAMS). The study develops\nanalytically tractable cost expressions that capture access, waiting, and\nriding costs for users, and distance-based operating and time-based vehicle\ncosts for operators. Two formulations are presented for strategic and tactical\ndecisions in flexible route portion, fleet size, headway, and vehicle size\noptimization, enabling the determination of route types between fixed, hybrid,\nand flexible routes based on demand, cost, and operational parameters. The\npractical applications and benefits of semi-on-demand feeders are demonstrated\nwith numerical examples and a large-scale case study in the Chicago\nmetropolitan area. Findings reveal scenarios in which flexible route portions\nserving passengers located further away reduce total costs, particularly user\ncosts. Lower operating costs in lower-demand areas favor more flexible routes,\nwhereas higher demand densities favor more traditional line-based operations.\nOn two studied lines, a current cost forecast favors smaller vehicles with\nflexible routes, but operating constraints and higher operating costs would\nfavor bigger vehicles with hybrid routes. The study provides an analytical tool\nto design SAMS as directional services and transit feeders, and tractable\ncontinuous approximation formulations for future research in transit network\ndesign.\n","authors":["Max T. M. Ng","Florian Dandl","Hani S. Mahmassani","Klaus Bogenberger"],"pdf_url":"https://arxiv.org/pdf/2403.15804v1.pdf","comment":"24 pages, 12 figures, the previous version presented at the 103rd\n  Transportation Research Board Annual Meeting, Washington, D.C"},{"id":"http://arxiv.org/abs/2403.15780v1","updated":"2024-03-23T09:32:23Z","published":"2024-03-23T09:32:23Z","title":"A Fairness-Oriented Reinforcement Learning Approach for the Operation\n  and Control of Shared Micromobility Services","summary":"  As Machine Learning systems become increasingly popular across diverse\napplication domains, including those with direct human implications, the\nimperative of equity and algorithmic fairness has risen to prominence in the\nArtificial Intelligence community. On the other hand, in the context of Shared\nMicromobility Systems, the exploration of fairness-oriented approaches remains\nlimited. Addressing this gap, we introduce a pioneering investigation into the\nbalance between performance optimization and algorithmic fairness in the\noperation and control of Shared Micromobility Services. Our study leverages the\nQ-Learning algorithm in Reinforcement Learning, benefiting from its convergence\nguarantees to ensure the robustness of our proposed approach. Notably, our\nmethodology stands out for its ability to achieve equitable outcomes, as\nmeasured by the Gini index, across different station categories--central,\nperipheral, and remote. Through strategic rebalancing of vehicle distribution,\nour approach aims to maximize operator performance while simultaneously\nupholding fairness principles for users. In addition to theoretical insights,\nwe substantiate our findings with a case study or simulation based on synthetic\ndata, validating the efficacy of our approach. This paper underscores the\ncritical importance of fairness considerations in shaping control strategies\nfor Shared Micromobility Services, offering a pragmatic framework for enhancing\nequity in urban transportation systems.\n","authors":["Luca Vittorio Piron","Matteo Cederle","Marina Ceccon","Federico Chiariotti","Alessandro Fabris","Marco Fabris","Gian Antonio Susto"],"pdf_url":"https://arxiv.org/pdf/2403.15780v1.pdf","comment":"8 pages, 4 figures, submitted to the 63rd Conference on Decision and\n  Control, Dec. 16-19, 2024, Milan, Italy"},{"id":"http://arxiv.org/abs/2403.15771v1","updated":"2024-03-23T08:58:31Z","published":"2024-03-23T08:58:31Z","title":"Small Noise Analysis of Non-Parametric Closed-Loop Identification","summary":"  We revisit the problem of non-parametric closed-loop identification in\nfrequency domain; we give a brief survey of the literature and provide a small\nnoise analysis of the direct, indirect, and joint input-output methods when two\nindependent experiments with identical excitation are used. The analysis is\nasymptotic in the noise variance (i.e., as the standard deviation of the\ninnovations $\\sigma \\to 0$), for a finite data record of length $N$. We\nhighlight the relationship between the estimators accuracy and the loop shape\nvia asymptotic variance expressions given in terms of the sensitivity function.\nThe results are illustrated using a numerical simulation example.\n","authors":["Mohamed Abdalmoaty","Roy S. Smith"],"pdf_url":"https://arxiv.org/pdf/2403.15771v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15743v1","updated":"2024-03-23T07:14:27Z","published":"2024-03-23T07:14:27Z","title":"A Comparative Study of Artificial Potential Fields and Safety Filters","summary":"  In this paper, we have demonstrated that the controllers designed by a\nclassical motion planning tool, namely artificial potential fields (APFs), can\nbe derived from a recently prevalent approach: control barrier function\nquadratic program (CBF-QP) safety filters. By integrating APF information into\nthe CBF-QP framework, we establish a bridge between these two methodologies.\nSpecifically, this is achieved by employing the attractive potential field as a\ncontrol Lyapunov function (CLF) to guide the design of the nominal controller,\nand then the repulsive potential field serves as a reciprocal CBF (RCBF) to\ndefine a CBF-QP safety filter. Building on this integration, we extend the\ndesign of the CBF-QP safety filter to accommodate a more general class of\ndynamical models featuring a control-affine structure. This extension yields a\nspecial CBF-QP safety filter and a general APF solution suitable for\ncontrol-affine dynamical models. Through a reach-avoid navigation example, we\nshowcase the efficacy of the developed approaches.\n","authors":["Ming Li","Zhiyong Sun"],"pdf_url":"https://arxiv.org/pdf/2403.15743v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11542v2","updated":"2024-03-23T05:54:01Z","published":"2024-03-18T07:51:32Z","title":"Topology Data Analysis-based Error Detection for Semantic Image\n  Transmission with Incremental Knowledge-based HARQ","summary":"  Semantic communication (SemCom) aims to achieve high fidelity information\ndelivery under low communication consumption by only guaranteeing semantic\naccuracy. Nevertheless, semantic communication still suffers from unexpected\nchannel volatility and thus developing a re-transmission mechanism (e.g.,\nhybrid automatic repeat request [HARQ]) is indispensable. In that regard,\ninstead of discarding previously transmitted information, the incremental\nknowledge-based HARQ (IK-HARQ) is deemed as a more effective mechanism that\ncould sufficiently utilize the information semantics. However, considering the\npossible existence of semantic ambiguity in image transmission, a simple\nbit-level cyclic redundancy check (CRC) might compromise the performance of\nIK-HARQ. Therefore, it emerges a strong incentive to revolutionize the CRC\nmechanism, so as to reap the benefits of both SemCom and HARQ. In this paper,\nbuilt on top of swin transformer-based joint source-channel coding (JSCC) and\nIK-HARQ, we propose a semantic image transmission framework SC-TDA-HARQ. In\nparticular, different from the conventional CRC, we introduce a topological\ndata analysis (TDA)-based error detection method, which capably digs out the\ninner topological and geometric information of images, so as to capture\nsemantic information and determine the necessity for re-transmission. Extensive\nnumerical results validate the effectiveness and efficiency of the proposed\nSC-TDA-HARQ framework, especially under the limited bandwidth condition, and\nmanifest the superiority of TDA-based error detection method in image\ntransmission.\n","authors":["Fei Ni","Rongpeng Li","Zhifeng Zhao","Honggang Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.11542v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15716v1","updated":"2024-03-23T04:36:12Z","published":"2024-03-23T04:36:12Z","title":"Distributed Robust Learning based Formation Control of Mobile Robots\n  based on Bioinspired Neural Dynamics","summary":"  This paper addresses the challenges of distributed formation control in\nmultiple mobile robots, introducing a novel approach that enhances real-world\npracticability. We first introduce a distributed estimator using a variable\nstructure and cascaded design technique, eliminating the need for derivative\ninformation to improve the real time performance. Then, a kinematic tracking\ncontrol method is developed utilizing a bioinspired neural dynamic-based\napproach aimed at providing smooth control inputs and effectively resolving the\nspeed jump issue. Furthermore, to address the challenges for robots operating\nwith completely unknown dynamics and disturbances, a learning-based robust\ndynamic controller is developed. This controller provides real time parameter\nestimates while maintaining its robustness against disturbances. The overall\nstability of the proposed method is proved with rigorous mathematical analysis.\nAt last, multiple comprehensive simulation studies have shown the advantages\nand effectiveness of the proposed method.\n","authors":["Zhe Xu","Tao Yan","Simon X. Yang","S. Andrew Gadsden","Mohammad Biglarbegian"],"pdf_url":"https://arxiv.org/pdf/2403.15716v1.pdf","comment":"This paper is accepted by IEEE Transactions on Intelligent Vehicles"},{"id":"http://arxiv.org/abs/2403.15702v1","updated":"2024-03-23T03:49:39Z","published":"2024-03-23T03:49:39Z","title":"Causal Tracking of Distributions in Wasserstein Space: A Model\n  Predictive Control Scheme","summary":"  We consider the problem of optimal swarm tracking which can be formulated as\na tracking problem for distributions in the Wasserstein metric. Optimal control\nsolutions to this problem are non-causal and require knowing the\ntime-trajectory of the distribution to be tracked in advance. We propose a\nscheme where these non-causal solutions can be used together with a predictive\nmodel for the reference to achieve causal tracking control of a priori-unknown\nreferences. We develop the resulting model-predictive control scheme in the\nsimple case where the reference is predicted to be constant-in-time. A\ncomputational algorithm based on particle methods and discrete optimal mass\ntransport is presented, and numerical simulations are provided for various\nclasses of reference signals. The results demonstrate that the proposed control\nalgorithm achieves reasonable performance even when using simple predictive\nmodels.\n","authors":["Max Emerick","Jared Jonas","Bassam Bamieh"],"pdf_url":"https://arxiv.org/pdf/2403.15702v1.pdf","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2403.15700v1","updated":"2024-03-23T03:36:15Z","published":"2024-03-23T03:36:15Z","title":"Improved Soft-k-Means Clustering Algorithm for Balancing Energy\n  Consumption in Wireless Sensor Networks","summary":"  Energy load balancing is an essential issue in designing wireless sensor\nnetworks (WSNs). Clustering techniques are utilized as energy-efficient methods\nto balance the network energy and prolong its lifetime. In this paper, we\npropose an improved soft-k-means (IS-k-means) clustering algorithm to balance\nthe energy consumption of nodes in WSNs. First, we use the idea of ``clustering\nby fast search and find of density peaks'' (CFSFDP) and kernel density\nestimation (KDE) to improve the selection of the initial cluster centers of the\nsoft k-means clustering algorithm. Then, we utilize the flexibility of the\nsoft-k-means and reassign member nodes considering their membership\nprobabilities at the boundary of clusters to balance the number of nodes per\ncluster. Furthermore, the concept of multi-cluster heads is employed to balance\nthe energy consumption within clusters. {Extensive simulation results under\ndifferent network scenarios demonstrate that for small-scale WSNs with\nsingle-hop transmission}, the proposed algorithm can postpone the first node\ndeath, the half of nodes death, and the last node death on average when\ncompared to various clustering algorithms from the literature.\n","authors":["Botao Zhu","Ebrahim Bedeer","Ha H. Nguyen","Robert Barton","Jerome Henry"],"pdf_url":"https://arxiv.org/pdf/2403.15700v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15697v1","updated":"2024-03-23T03:19:42Z","published":"2024-03-23T03:19:42Z","title":"Passivity-based Attack Identification and Mitigation with\n  Event-triggered Observer Feedback and Switching Controller","summary":"  This paper addresses the problem of output consensus in linear passive\nmulti-agent systems under a False Data Injection (FDI) attack, considering the\nunavailability of complete state information. Our formulation relies on an\nevent-based cryptographic authentication scheme for sensor integrity and\nconsiders FDI attacks at the actuator end, inspired by their practical nature\nand usages. For secure consensus, we propose (i) a passivity-based approach for\ndetecting FDI attacks on the system and (ii) a Zeno-free event-triggered\nobserver-based switching controller, which switches between the normal and the\ndefense modes following an attack detection. We show that the closed-loop\nsystem achieves practical consensus under the controller's action in the\ndefense mode. Simulation examples are provided to support the theoretical\nfindings.\n","authors":["Pushkal Purohit","Anoop Jain"],"pdf_url":"https://arxiv.org/pdf/2403.15697v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01983v2","updated":"2024-03-23T03:13:32Z","published":"2023-02-03T20:07:14Z","title":"Hybrid path-lifting algorithm and Equivalence of Stability results for\n  MRP-based control strategies","summary":"  The modified Rodrigues parameters (MRP) consist of two numerically different\ntriplets that, by switching between them, yield a minimal globally non-singular\nattitude description with advantageous properties. The MRP space results from\nthe Alexandroff compactification of the three-dimensional Euclidean space and\nis a double cover of $\\mathrm{SO(3)}$. By capitalizing on instrumental\nproperties of the covering map, this paper proposes a novel hybrid dynamic\npath-lifting mechanism to unambiguously and robustly extract the MRP from the\nattitude space. This hybrid solution allows applying an MRP-based feedback\ncontroller to the attitude dynamics in the base space while preserving its\nasymptotic and exponential stability properties. Furthermore, by profiting from\nthe distinct characteristics of the MRP, the resulting interconnection is\nimpervious to the unwinding phenomenon. The design and validation of an\nMRP-based controller exemplify the application of the proposed algorithm\nalongside the novel results for equivalence of stability between spaces. The\nsolution renders the attitude space tracking dynamics robustly globally\nexponentially stable, demonstrating the potential of this novel methodology.\n","authors":["Luís Martins","Carlos Cardeira","Paulo Oliveira"],"pdf_url":"https://arxiv.org/pdf/2302.01983v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15687v1","updated":"2024-03-23T02:31:37Z","published":"2024-03-23T02:31:37Z","title":"Motion Planning for Identification of Linear Classifiers","summary":"  A given region in 2-D Euclidean space is divided by a unknown linear\nclassifier in to two sets each carrying a label. The objective of an agent with\nknown dynamics traversing the region is to identify the true classifier while\npaying a control cost across its trajectory. We consider two scenarios: (i) the\nagent is able to measure the true label perfectly; (ii) the observed label is\nthe true label multiplied by noise. We present the following: (i) the\nclassifier identification problem formulated as a control problem; (ii)\ngeometric interpretation of the control problem resulting in one step modified\ncontrol problems; (iii) control algorithms that result in data sets which are\nused to identify the true classifier with accuracy; (iv) convergence of\nestimated classifier to the true classifier when the observed label is not\ncorrupted by noise; (iv) numerical example demonstrating the utility of the\ncontrol algorithms.\n","authors":["Aneesh Raghavan","Karl Henrik Johansson"],"pdf_url":"https://arxiv.org/pdf/2403.15687v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14028v2","updated":"2024-03-23T02:29:44Z","published":"2024-03-20T22:56:11Z","title":"Performance-Guaranteed Solutions for Multi-Agent Optimal Coverage\n  Problems using Submodularity, Curvature, and Greedy Algorithms","summary":"  We consider a class of multi-agent optimal coverage problems in which the\ngoal is to determine the optimal placement of a group of agents in a given\nmission space so that they maximize a coverage objective that represents a\nblend of individual and collaborative event detection capabilities. This class\nof problems is extremely challenging due to the non-convex nature of the\nmission space and of the coverage objective. With this motivation, greedy\nalgorithms are often used as means of getting feasible coverage solutions\nefficiently. Even though such greedy solutions are suboptimal, the\nsubmodularity (diminishing returns) property of the coverage objective can be\nexploited to provide performance bound guarantees. Moreover, we show that\nimproved performance bound guarantees (beyond the standard (1-1/e) performance\nbound) can be established using various curvature measures of the coverage\nproblem. In particular, we provide a brief review of all existing popular\napplicable curvature measures, including a recent curvature measure that we\nproposed, and discuss their effectiveness and computational complexity, in the\ncontext of optimal coverage problems. We also propose novel computationally\nefficient techniques to estimate some curvature measures. Finally, we provide\nseveral numerical results to support our findings and propose several potential\nfuture research directions.\n","authors":["Shirantha Welikala","Christos G. Cassandras"],"pdf_url":"https://arxiv.org/pdf/2403.14028v2.pdf","comment":"Will be submitted to CDC 2024"},{"id":"http://arxiv.org/abs/2403.15683v1","updated":"2024-03-23T02:15:06Z","published":"2024-03-23T02:15:06Z","title":"On the role of network structure in learning to coordinate with bounded\n  rationality","summary":"  Many socioeconomic phenomena, such as technology adoption, collaborative\nproblem-solving, and content engagement, involve a collection of agents\ncoordinating to take a common action, aligning their decisions to maximize\ntheir individual goals. We consider a model for networked interactions where\nagents learn to coordinate their binary actions under a strict bound on their\nrationality. We first prove that our model is a potential game and that the\noptimal action profile is always to achieve perfect alignment at one of the two\npossible actions, regardless of the network structure. Using a stochastic\nlearning algorithm known as Log Linear Learning, where agents have the same\nfinite rationality parameter, we show that the probability of agents\nsuccessfully agreeing on the correct decision is monotonically increasing in\nthe number of network links. Therefore, more connectivity improves the accuracy\nof collective decision-making, as predicted by the phenomenon known as Wisdom\nof Crowds. Finally, we show that for a fixed number of links, a regular network\nmaximizes the probability of success. We conclude that when using a network of\nirrational agents, promoting more homogeneous connectivity improves the\naccuracy of collective decision-making.\n","authors":["Yifei Zhang","Marcos M. Vasconcelos"],"pdf_url":"https://arxiv.org/pdf/2403.15683v1.pdf","comment":"Submitted to 2024 IEEE Conference on Decision and Control"},{"id":"http://arxiv.org/abs/2403.15674v1","updated":"2024-03-23T01:40:52Z","published":"2024-03-23T01:40:52Z","title":"Safe and Stable Formation Control with Distributed Multi-Agents Using\n  Adaptive Control and Control Barrier Functions","summary":"  This manuscript considers the problem of ensuring stability and safety during\nformation control with distributed multi-agent systems in the presence of\nparametric uncertainty in the dynamics and limited communication. We propose an\nintegrative approach that combines Control Barrier Functions, Adaptive Control,\nand connected graphs. A reference model is designed so as to ensure a safe and\nstable formation control strategy. This is combined with a provably correct\nadaptive control design that includes a use of a CBF-based safety filter that\nsuitably generates safe reference commands, and employs error-based relaxation\n(EBR) of Nagumo's Invariance Theorem. Together, it is shown to lead to a\nguarantee of boundedness, formation control, and forward invariance. Numerical\nexamples are provided to support the theoretical derivations.\n","authors":["Jose A. Solano-Castellanos","Anuradha Annaswamy"],"pdf_url":"https://arxiv.org/pdf/2403.15674v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15671v1","updated":"2024-03-23T01:39:18Z","published":"2024-03-23T01:39:18Z","title":"Real-Time Reconfiguration and Connectivity Maintenance for AUVs Network\n  Under External Disturbances using Distributed Nonlinear Model Predictive\n  Control","summary":"  Advancements in underwater vehicle technology have significantly expanded the\npotential scope for deploying autonomous or remotely operated underwater\nvehicles in novel practical applications. However, the efficiency and\nmaneuverability of these vehicles remain critical challenges, particularly in\nthe dynamic aquatic environment. In this work, we propose a novel control\nscheme for creating multi-agent distributed formation control with limited\ncommunication between individual agents. In addition, the formation of the\nmulti-agent can be reconfigured in real-time and the network connectivity can\nbe maintained. The proposed use case for this scheme includes creating\nunderwater mobile communication networks that can adapt to environmental or\nnetwork conditions to maintain the quality of communication links for\nlong-range exploration, seabed monitoring, or underwater infrastructure\ninspection. This work introduces a novel Distributed Nonlinear Model Predictive\nControl (DNMPC) strategy, integrating Control Lyapunov Functions (CLF) and\nControl Barrier Functions (CBF) with a relaxed decay rate, specifically\ntailored for 6-DOF underwater robotics. The effectiveness of our proposed DNMPC\nscheme was demonstrated through rigorous MATLAB simulations for trajectory\ntracking and formation reconfiguration in a dynamic environment. Our findings,\nsupported by tests conducted using Software In The Loop (SITL) simulation,\nconfirm the approach's applicability in real-time scenarios.\n","authors":["Nhat Minh Nguyen","Stephen McIlvanna","Jack Close","Mien Van"],"pdf_url":"https://arxiv.org/pdf/2403.15671v1.pdf","comment":null}]},"2024-03-26T00:00:00Z":{"Robotics":[{"id":"http://arxiv.org/abs/2403.17933v1","updated":"2024-03-26T17:58:29Z","published":"2024-03-26T17:58:29Z","title":"SLEDGE: Synthesizing Simulation Environments for Driving Agents with\n  Generative Models","summary":"  SLEDGE is the first generative simulator for vehicle motion planning trained\non real-world driving logs. Its core component is a learned model that is able\nto generate agent bounding boxes and lane graphs. The model's outputs serve as\nan initial state for traffic simulation. The unique properties of the entities\nto be generated for SLEDGE, such as their connectivity and variable count per\nscene, render the naive application of most modern generative models to this\ntask non-trivial. Therefore, together with a systematic study of existing lane\ngraph representations, we introduce a novel raster-to-vector autoencoder\n(RVAE). It encodes agents and the lane graph into distinct channels in a\nrasterized latent map. This facilitates both lane-conditioned agent generation\nand combined generation of lanes and agents with a Diffusion Transformer. Using\ngenerated entities in SLEDGE enables greater control over the simulation, e.g.\nupsampling turns or increasing traffic density. Further, SLEDGE can support\n500m long routes, a capability not found in existing data-driven simulators\nlike nuPlan. It presents new challenges for planning algorithms, evidenced by\nfailure rates of over 40% for PDM, the winner of the 2023 nuPlan challenge,\nwhen tested on hard routes and dense traffic generated by our model. Compared\nto nuPlan, SLEDGE requires 500$\\times$ less storage to set up (<4GB), making it\na more accessible option and helping with democratizing future research in this\nfield.\n","authors":["Kashyap Chitta","Daniel Dauner","Andreas Geiger"],"pdf_url":"https://arxiv.org/pdf/2403.17933v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17917v1","updated":"2024-03-26T17:54:05Z","published":"2024-03-26T17:54:05Z","title":"Multi-Agent Clarity-Aware Dynamic Coverage with Gaussian Processes","summary":"  This paper presents two algorithms for multi-agent dynamic coverage in\nspatiotemporal environments, where the coverage algorithms are informed by the\nmethod of data assimilation. In particular, we show that by considering the\ninformation assimilation algorithm, here a Numerical Gaussian Process Kalman\nFilter, the influence of measurements taken at one position on the uncertainty\nof the estimate at another location can be computed. We use this relationship\nto propose new coverage algorithms. Furthermore, we show that the controllers\nnaturally extend to the multi-agent context, allowing for a distributed-control\ncentral-information paradigm for multi-agent coverage. Finally, we demonstrate\nthe algorithms through a realistic simulation of a team of UAVs collecting wind\ndata over a region in Austria.\n","authors":["Devansh R. Agrawal","Dimitra Panagou"],"pdf_url":"https://arxiv.org/pdf/2403.17917v1.pdf","comment":"8 pages, 2 figures, submitted to CDC 2024"},{"id":"http://arxiv.org/abs/2403.17916v1","updated":"2024-03-26T17:53:27Z","published":"2024-03-26T17:53:27Z","title":"CMP: Cooperative Motion Prediction with Multi-Agent Communication","summary":"  The confluence of the advancement of Autonomous Vehicles (AVs) and the\nmaturity of Vehicle-to-Everything (V2X) communication has enabled the\ncapability of cooperative connected and automated vehicles (CAVs). Building on\ntop of cooperative perception, this paper explores the feasibility and\neffectiveness of cooperative motion prediction. Our method, CMP, takes LiDAR\nsignals as input to enhance tracking and prediction capabilities. Unlike\nprevious work that focuses separately on either cooperative perception or\nmotion prediction, our framework, to the best of our knowledge, is the first to\naddress the unified problem where CAVs share information in both perception and\nprediction modules. Incorporated into our design is the unique capability to\ntolerate realistic V2X bandwidth limitations and transmission delays, while\ndealing with bulky perception representations. We also propose a prediction\naggregation module, which unifies the predictions obtained by different CAVs\nand generates the final prediction. Through extensive experiments and ablation\nstudies, we demonstrate the effectiveness of our method in cooperative\nperception, tracking, and motion prediction tasks. In particular, CMP reduces\nthe average prediction error by 17.2\\% with fewer missing detections compared\nwith the no cooperation setting. Our work marks a significant step forward in\nthe cooperative capabilities of CAVs, showcasing enhanced performance in\ncomplex scenarios.\n","authors":["Zhuoyuan Wu","Yuping Wang","Hengbo Ma","Zhaowei Li","Hang Qiu","Jiachen Li"],"pdf_url":"https://arxiv.org/pdf/2403.17916v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.03773v3","updated":"2024-03-26T17:17:39Z","published":"2023-04-04T21:49:02Z","title":"Safe Explicable Planning","summary":"  Human expectations arise from their understanding of others and the world. In\nthe context of human-AI interaction, this understanding may not align with\nreality, leading to the AI agent failing to meet expectations and compromising\nteam performance. Explicable planning, introduced as a method to bridge this\ngap, aims to reconcile human expectations with the agent's optimal behavior,\nfacilitating interpretable decision-making. However, an unresolved critical\nissue is ensuring safety in explicable planning, as it could result in\nexplicable behaviors that are unsafe. To address this, we propose Safe\nExplicable Planning (SEP), which extends the prior work to support the\nspecification of a safety bound. The goal of SEP is to find behaviors that\nalign with human expectations while adhering to the specified safety criterion.\nOur approach generalizes the consideration of multiple objectives stemming from\nmultiple models rather than a single model, yielding a Pareto set of safe\nexplicable policies. We present both an exact method, guaranteeing finding the\nPareto set, and a more efficient greedy method that finds one of the policies\nin the Pareto set. Additionally, we offer approximate solutions based on state\naggregation to improve scalability. We provide formal proofs that validate the\ndesired theoretical properties of these methods. Evaluation through simulations\nand physical robot experiments confirms the effectiveness of our approach for\nsafe explicable planning.\n","authors":["Akkamahadevi Hanni","Andrew Boateng","Yu Zhang"],"pdf_url":"https://arxiv.org/pdf/2304.03773v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17849v1","updated":"2024-03-26T16:38:12Z","published":"2024-03-26T16:38:12Z","title":"Multi Agent Pathfinding for Noise Restricted Hybrid Fuel Unmanned Aerial\n  Vehicles","summary":"  Multi Agent Path Finding (MAPF) seeks the optimal set of paths for multiple\nagents from respective start to goal locations such that no paths conflict. We\naddress the MAPF problem for a fleet of hybrid-fuel unmanned aerial vehicles\nwhich are subject to location-dependent noise restrictions. We solve this\nproblem by searching a constraint tree for which the subproblem at each node is\na set of shortest path problems subject to the noise and fuel constraints and\nconflict zone avoidance. A labeling algorithm is presented to solve this\nsubproblem, including the conflict zones which are treated as dynamic\nobstacles. We present the experimental results of the algorithms for various\ngraph sizes and number of agents.\n","authors":["Drew Scott","Satyanarayana G. Manyam","David W. Casbeer","Manish Kumar","Isaac E. Weintraub"],"pdf_url":"https://arxiv.org/pdf/2403.17849v1.pdf","comment":"6 pages, 7 figures"},{"id":"http://arxiv.org/abs/2403.17846v1","updated":"2024-03-26T16:36:43Z","published":"2024-03-26T16:36:43Z","title":"Hierarchical Open-Vocabulary 3D Scene Graphs for Language-Grounded Robot\n  Navigation","summary":"  Recent open-vocabulary robot mapping methods enrich dense geometric maps with\npre-trained visual-language features. While these maps allow for the prediction\nof point-wise saliency maps when queried for a certain language concept,\nlarge-scale environments and abstract queries beyond the object level still\npose a considerable hurdle, ultimately limiting language-grounded robotic\nnavigation. In this work, we present HOV-SG, a hierarchical open-vocabulary 3D\nscene graph mapping approach for language-grounded robot navigation. Leveraging\nopen-vocabulary vision foundation models, we first obtain state-of-the-art\nopen-vocabulary segment-level maps in 3D and subsequently construct a 3D scene\ngraph hierarchy consisting of floor, room, and object concepts, each enriched\nwith open-vocabulary features. Our approach is able to represent multi-story\nbuildings and allows robotic traversal of those using a cross-floor Voronoi\ngraph. HOV-SG is evaluated on three distinct datasets and surpasses previous\nbaselines in open-vocabulary semantic accuracy on the object, room, and floor\nlevel while producing a 75% reduction in representation size compared to dense\nopen-vocabulary maps. In order to prove the efficacy and generalization\ncapabilities of HOV-SG, we showcase successful long-horizon\nlanguage-conditioned robot navigation within real-world multi-storage\nenvironments. We provide code and trial video data at http://hovsg.github.io/.\n","authors":["Abdelrhman Werby","Chenguang Huang","Martin Büchner","Abhinav Valada","Wolfram Burgard"],"pdf_url":"https://arxiv.org/pdf/2403.17846v1.pdf","comment":"Code and video are available at http://hovsg.github.io/"},{"id":"http://arxiv.org/abs/2309.02937v2","updated":"2024-03-26T15:51:49Z","published":"2023-09-06T12:04:24Z","title":"Resilient source seeking with robot swarms","summary":"  We present a solution for locating the source, or maximum, of an unknown\nscalar field using a swarm of mobile robots. Unlike relying on the traditional\ngradient information, the swarm determines an ascending direction to approach\nthe source with arbitrary precision. The ascending direction is calculated from\nmeasurements of the field strength at the robot locations and their relative\npositions concerning the centroid. Rather than focusing on individual robots,\nwe focus the analysis on the density of robots per unit area to guarantee a\nmore resilient swarm, i.e., the functionality remains even if individuals go\nmissing or are misplaced during the mission. We reinforce the robustness of the\nalgorithm by providing sufficient conditions for the swarm shape so that the\nascending direction is almost parallel to the gradient. The swarm can respond\nto an unexpected environment by morphing its shape and exploiting the existence\nof multiple ascending directions. Finally, we validate our approach numerically\nwith hundreds of robots. The fact that a large number of robots always\ncalculate an ascending direction compensates for the loss of individuals and\nmitigates issues arising from the actuator and sensor noises.\n","authors":["Antonio Acuaviva","Jesus Bautista","Weijia Yao","Juan Jimenez","Hector Garcia de Marina"],"pdf_url":"https://arxiv.org/pdf/2309.02937v2.pdf","comment":"7 pages, submitted to CDC 2024"},{"id":"http://arxiv.org/abs/2403.17805v1","updated":"2024-03-26T15:42:04Z","published":"2024-03-26T15:42:04Z","title":"Scenario-Based Curriculum Generation for Multi-Agent Autonomous Driving","summary":"  The automated generation of diverse and complex training scenarios has been\nan important ingredient in many complex learning tasks. Especially in\nreal-world application domains, such as autonomous driving, auto-curriculum\ngeneration is considered vital for obtaining robust and general policies.\nHowever, crafting traffic scenarios with multiple, heterogeneous agents is\ntypically considered as a tedious and time-consuming task, especially in more\ncomplex simulation environments. In our work, we introduce MATS-Gym, a\nMulti-Agent Traffic Scenario framework to train agents in CARLA, a\nhigh-fidelity driving simulator. MATS-Gym is a multi-agent training framework\nfor autonomous driving that uses partial scenario specifications to generate\ntraffic scenarios with variable numbers of agents. This paper unifies various\nexisting approaches to traffic scenario description into a single training\nframework and demonstrates how it can be integrated with techniques from\nunsupervised environment design to automate the generation of adaptive\nauto-curricula. The code is available at\nhttps://github.com/AutonomousDrivingExaminer/mats-gym.\n","authors":["Axel Brunnbauer","Luigi Berducci","Peter Priller","Dejan Nickovic","Radu Grosu"],"pdf_url":"https://arxiv.org/pdf/2403.17805v1.pdf","comment":"7 Pages, Under Review"},{"id":"http://arxiv.org/abs/2403.17788v1","updated":"2024-03-26T15:20:56Z","published":"2024-03-26T15:20:56Z","title":"System Calibration of a Field Phenotyping Robot with Multiple\n  High-Precision Profile Laser Scanners","summary":"  The creation of precise and high-resolution crop point clouds in agricultural\nfields has become a key challenge for high-throughput phenotyping applications.\nThis work implements a novel calibration method to calibrate the laser scanning\nsystem of an agricultural field robot consisting of two industrial-grade laser\nscanners used for high-precise 3D crop point cloud creation. The calibration\nmethod optimizes the transformation between the scanner origins and the robot\npose by minimizing 3D point omnivariances within the point cloud. Moreover, we\npresent a novel factor graph-based pose estimation method that fuses total\nstation prism measurements with IMU and GNSS heading information for\nhigh-precise pose determination during calibration. The root-mean-square error\nof the distances to a georeferenced ground truth point cloud results in 0.8 cm\nafter parameter optimization. Furthermore, our results show the importance of a\nreference point cloud in the calibration method needed to estimate the vertical\ntranslation of the calibration. Challenges arise due to non-static parameters\nwhile the robot moves, indicated by systematic deviations to a ground truth\nterrestrial laser scan.\n","authors":["Felix Esser","Gereon Tombrink","Andre Cornelißen","Lasse Klingbeil","Heiner Kuhlmann"],"pdf_url":"https://arxiv.org/pdf/2403.17788v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17779v1","updated":"2024-03-26T15:12:46Z","published":"2024-03-26T15:12:46Z","title":"Optical Flow Based Detection and Tracking of Moving Objects for\n  Autonomous Vehicles","summary":"  Accurate velocity estimation of surrounding moving objects and their\ntrajectories are critical elements of perception systems in\nAutomated/Autonomous Vehicles (AVs) with a direct impact on their safety. These\nare non-trivial problems due to the diverse types and sizes of such objects and\ntheir dynamic and random behaviour. Recent point cloud based solutions often\nuse Iterative Closest Point (ICP) techniques, which are known to have certain\nlimitations. For example, their computational costs are high due to their\niterative nature, and their estimation error often deteriorates as the relative\nvelocities of the target objects increase (>2 m/sec). Motivated by such\nshortcomings, this paper first proposes a novel Detection and Tracking of\nMoving Objects (DATMO) for AVs based on an optical flow technique, which is\nproven to be computationally efficient and highly accurate for such problems.\n\\textcolor{black}{This is achieved by representing the driving scenario as a\nvector field and applying vector calculus theories to ensure spatiotemporal\ncontinuity.} We also report the results of a comprehensive performance\nevaluation of the proposed DATMO technique, carried out in this study using\nsynthetic and real-world data. The results of this study demonstrate the\nsuperiority of the proposed technique, compared to the DATMO techniques in the\nliterature, in terms of estimation accuracy and processing time in a wide range\nof relative velocities of moving objects. Finally, we evaluate and discuss the\nsensitivity of the estimation error of the proposed DATMO technique to various\nsystem and environmental parameters, as well as the relative velocities of the\nmoving objects.\n","authors":["MReza Alipour Sormoli","Mehrdad Dianati","Sajjad Mozaffari","Roger woodman"],"pdf_url":"https://arxiv.org/pdf/2403.17779v1.pdf","comment":"This manuscript has been accepted as a regular paper in Transactions\n  on Intelligent Transportation Systems (DOI: 10.1109/TITS.2024.3382495)"},{"id":"http://arxiv.org/abs/2403.17774v1","updated":"2024-03-26T15:07:27Z","published":"2024-03-26T15:07:27Z","title":"LiDAR-Based Crop Row Detection Algorithm for Over-Canopy Autonomous\n  Navigation in Agriculture Fields","summary":"  Autonomous navigation is crucial for various robotics applications in\nagriculture. However, many existing methods depend on RTK-GPS systems, which\nare expensive and susceptible to poor signal coverage. This paper introduces a\nstate-of-the-art LiDAR-based navigation system that can achieve over-canopy\nautonomous navigation in row-crop fields, even when the canopy fully blocks the\ninterrow spacing. Our crop row detection algorithm can detect crop rows across\ndiverse scenarios, encompassing various crop types, growth stages, weed\npresence, and discontinuities within the crop rows. Without utilizing the\nglobal localization of the robot, our navigation system can perform autonomous\nnavigation in these challenging scenarios, detect the end of the crop rows, and\nnavigate to the next crop row autonomously, providing a crop-agnostic approach\nto navigate the whole row-crop field. This navigation system has undergone\ntests in various simulated agricultural fields, achieving an average of\n$2.98cm$ autonomous driving accuracy without human intervention on the custom\nAmiga robot. In addition, the qualitative results of our crop row detection\nalgorithm from the actual soybean fields validate our LiDAR-based crop row\ndetection algorithm's potential for practical agricultural applications.\n","authors":["Ruiji Liu","Francisco Yandun","George Kantor"],"pdf_url":"https://arxiv.org/pdf/2403.17774v1.pdf","comment":"7 pages, 9 figures, submitted to IROS 2024"},{"id":"http://arxiv.org/abs/2311.15030v2","updated":"2024-03-26T14:33:51Z","published":"2023-11-25T13:51:14Z","title":"Tuning-free Quasi-stiffness Control Framework of a Powered Transfemoral\n  Prosthesis for Task-adaptive Walking","summary":"  Impedance-based control represents a prevalent strategy in the development of\npowered transfemoral prostheses. However, creating a task-adaptive, tuning-free\ncontroller that effectively generalizes across diverse locomotion modes and\nterrain conditions continues to be a significant challenge. This letter\nproposes a tuning-free and task-adaptive quasi-stiffness control framework for\npowered prostheses that generalizes across various walking tasks, including the\ntorque-angle relationship reconstruction part and the quasi-stiffness\ncontroller design part. A Gaussian Process Regression (GPR) model is introduced\nto predict the target features of the human joint angle and torque in a new\ntask. Subsequently, a Kernelized Movement Primitives (KMP) is employed to\nreconstruct the torque-angle relationship of the new task from multiple human\nreference trajectories and estimated target features. Based on the torque-angle\nrelationship of the new task, a quasi-stiffness control approach is designed\nfor a powered prosthesis. Finally, the proposed framework is validated through\npractical examples, including varying speeds and inclines walking tasks.\nNotably, the proposed framework not only aligns with but frequently surpasses\nthe performance of a benchmark finite state machine impedance controller\n(FSMIC) without necessitating manual impedance tuning and has the potential to\nexpand to variable walking tasks in daily life for the transfemoral amputees.\n","authors":["Teng Ma","Shucong Yin","Zhimin Hou","Binxin Huang","Haoyong Yu","Chenglong Fu"],"pdf_url":"https://arxiv.org/pdf/2311.15030v2.pdf","comment":"8 pages, 10 figures. This work has been submitted to the IEEE-RAL for\n  possible publication"},{"id":"http://arxiv.org/abs/2311.01885v2","updated":"2024-03-26T12:59:44Z","published":"2023-11-03T12:54:05Z","title":"Domain Randomization via Entropy Maximization","summary":"  Varying dynamics parameters in simulation is a popular Domain Randomization\n(DR) approach for overcoming the reality gap in Reinforcement Learning (RL).\nNevertheless, DR heavily hinges on the choice of the sampling distribution of\nthe dynamics parameters, since high variability is crucial to regularize the\nagent's behavior but notoriously leads to overly conservative policies when\nrandomizing excessively. In this paper, we propose a novel approach to address\nsim-to-real transfer, which automatically shapes dynamics distributions during\ntraining in simulation without requiring real-world data. We introduce DOmain\nRAndomization via Entropy MaximizatiON (DORAEMON), a constrained optimization\nproblem that directly maximizes the entropy of the training distribution while\nretaining generalization capabilities. In achieving this, DORAEMON gradually\nincreases the diversity of sampled dynamics parameters as long as the\nprobability of success of the current policy is sufficiently high. We\nempirically validate the consistent benefits of DORAEMON in obtaining highly\nadaptive and generalizable policies, i.e. solving the task at hand across the\nwidest range of dynamics parameters, as opposed to representative baselines\nfrom the DR literature. Notably, we also demonstrate the Sim2Real applicability\nof DORAEMON through its successful zero-shot transfer in a robotic manipulation\nsetup under unknown real-world parameters.\n","authors":["Gabriele Tiboni","Pascal Klink","Jan Peters","Tatiana Tommasi","Carlo D'Eramo","Georgia Chalvatzaki"],"pdf_url":"https://arxiv.org/pdf/2311.01885v2.pdf","comment":"Published as a conference paper at ICLR 2024. Project website at\n  https://gabrieletiboni.github.io/doraemon/"},{"id":"http://arxiv.org/abs/2403.17667v1","updated":"2024-03-26T12:57:05Z","published":"2024-03-26T12:57:05Z","title":"Learning Goal-Directed Object Pushing in Cluttered Scenes with\n  Location-Based Attention","summary":"  Non-prehensile planar pushing is a challenging task due to its underactuated\nnature with hybrid-dynamics, where a robot needs to reason about an object's\nlong-term behaviour and contact-switching, while being robust to contact\nuncertainty. The presence of clutter in the environment further complicates\nthis task, introducing the need to include more sophisticated spatial analysis\nto avoid collisions. Building upon prior work on reinforcement learning (RL)\nwith multimodal categorical exploration for planar pushing, in this paper we\nincorporate location-based attention to enable robust navigation through\nclutter. Unlike previous RL literature addressing this obstacle avoidance\npushing task, our framework requires no predefined global paths and considers\nthe target orientation of the manipulated object. Our results demonstrate that\nthe learned policies successfully navigate through a wide range of complex\nobstacle configurations, including dynamic obstacles, with smooth motions,\nachieving the desired target object pose. We also validate the transferability\nof the learned policies to robotic hardware using the KUKA iiwa robot arm.\n","authors":["Nils Dengler","Juan Del Aguila Ferrandis","João Moura","Sethu Vijayakumar","Maren Bennewitz"],"pdf_url":"https://arxiv.org/pdf/2403.17667v1.pdf","comment":"Submitted to IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS)"},{"id":"http://arxiv.org/abs/2402.03246v5","updated":"2024-03-26T12:35:03Z","published":"2024-02-05T18:03:53Z","title":"SGS-SLAM: Semantic Gaussian Splatting For Neural Dense SLAM","summary":"  We present SGS-SLAM, the first semantic visual SLAM system based on Gaussian\nSplatting. It incorporates appearance, geometry, and semantic features through\nmulti-channel optimization, addressing the oversmoothing limitations of neural\nimplicit SLAM systems in high-quality rendering, scene understanding, and\nobject-level geometry. We introduce a unique semantic feature loss that\neffectively compensates for the shortcomings of traditional depth and color\nlosses in object optimization. Through a semantic-guided keyframe selection\nstrategy, we prevent erroneous reconstructions caused by cumulative errors.\nExtensive experiments demonstrate that SGS-SLAM delivers state-of-the-art\nperformance in camera pose estimation, map reconstruction, precise semantic\nsegmentation, and object-level geometric accuracy, while ensuring real-time\nrendering capabilities.\n","authors":["Mingrui Li","Shuhong Liu","Heng Zhou","Guohao Zhu","Na Cheng","Tianchen Deng","Hongyu Wang"],"pdf_url":"https://arxiv.org/pdf/2402.03246v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17633v1","updated":"2024-03-26T12:08:14Z","published":"2024-03-26T12:08:14Z","title":"UADA3D: Unsupervised Adversarial Domain Adaptation for 3D Object\n  Detection with Sparse LiDAR and Large Domain Gaps","summary":"  In this study, we address a gap in existing unsupervised domain adaptation\napproaches on LiDAR-based 3D object detection, which have predominantly\nconcentrated on adapting between established, high-density autonomous driving\ndatasets. We focus on sparser point clouds, capturing scenarios from different\nperspectives: not just from vehicles on the road but also from mobile robots on\nsidewalks, which encounter significantly different environmental conditions and\nsensor configurations. We introduce Unsupervised Adversarial Domain Adaptation\nfor 3D Object Detection (UADA3D). UADA3D does not depend on pre-trained source\nmodels or teacher-student architectures. Instead, it uses an adversarial\napproach to directly learn domain-invariant features. We demonstrate its\nefficacy in various adaptation scenarios, showing significant improvements in\nboth self-driving car and mobile robot domains. Our code is open-source and\nwill be available soon.\n","authors":["Maciej K Wozniak","Mattias Hansson","Marko Thiel","Patric Jensfelt"],"pdf_url":"https://arxiv.org/pdf/2403.17633v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.01598v3","updated":"2024-03-26T11:54:40Z","published":"2023-06-02T15:09:19Z","title":"Towards Source-free Domain Adaptive Semantic Segmentation via\n  Importance-aware and Prototype-contrast Learning","summary":"  Domain adaptive semantic segmentation enables robust pixel-wise understanding\nin real-world driving scenes. Source-free domain adaptation, as a more\npractical technique, addresses the concerns of data privacy and storage\nlimitations in typical unsupervised domain adaptation methods, making it\nespecially relevant in the context of intelligent vehicles. It utilizes a\nwell-trained source model and unlabeled target data to achieve adaptation in\nthe target domain. However, in the absence of source data and target labels,\ncurrent solutions cannot sufficiently reduce the impact of domain shift and\nfully leverage the information from the target data. In this paper, we propose\nan end-to-end source-free domain adaptation semantic segmentation method via\nImportance-Aware and Prototype-Contrast (IAPC) learning. The proposed IAPC\nframework effectively extracts domain-invariant knowledge from the well-trained\nsource model and learns domain-specific knowledge from the unlabeled target\ndomain. Specifically, considering the problem of domain shift in the prediction\nof the target domain by the source model, we put forward an importance-aware\nmechanism for the biased target prediction probability distribution to extract\ndomain-invariant knowledge from the source model. We further introduce a\nprototype-contrast strategy, which includes a prototype-symmetric cross-entropy\nloss and a prototype-enhanced cross-entropy loss, to learn target intra-domain\nknowledge without relying on labels. A comprehensive variety of experiments on\ntwo domain adaptive semantic segmentation benchmarks demonstrates that the\nproposed end-to-end IAPC solution outperforms existing state-of-the-art\nmethods. The source code is publicly available at\nhttps://github.com/yihong-97/Source-free-IAPC.\n","authors":["Yihong Cao","Hui Zhang","Xiao Lu","Zheng Xiao","Kailun Yang","Yaonan Wang"],"pdf_url":"https://arxiv.org/pdf/2306.01598v3.pdf","comment":"Accepted to IEEE Transactions on Intelligent Vehicles (T-IV). The\n  source code is publicly available at\n  https://github.com/yihong-97/Source-free-IAPC"},{"id":"http://arxiv.org/abs/2403.17622v1","updated":"2024-03-26T11:51:58Z","published":"2024-03-26T11:51:58Z","title":"Online Tree Reconstruction and Forest Inventory on a Mobile Robotic\n  System","summary":"  Terrestrial laser scanning (TLS) is the standard technique used to create\naccurate point clouds for digital forest inventories. However, the measurement\nprocess is demanding, requiring up to two days per hectare for data collection,\nsignificant data storage, as well as resource-heavy post-processing of 3D data.\nIn this work, we present a real-time mapping and analysis system that enables\nonline generation of forest inventories using mobile laser scanners that can be\nmounted e.g. on mobile robots. Given incrementally created and locally accurate\nsubmaps-data payloads-our approach extracts tree candidates using a custom,\nVoronoi-inspired clustering algorithm. Tree candidates are reconstructed using\nan adapted Hough algorithm, which enables robust modeling of the tree stem.\nFurther, we explicitly incorporate the incremental nature of the data\ncollection by consistently updating the database using a pose graph LiDAR SLAM\nsystem. This enables us to refine our estimates of the tree traits if an area\nis revisited later during a mission. We demonstrate competitive accuracy to TLS\nor manual measurements using laser scanners that we mounted on backpacks or\nmobile robots operating in conifer, broad-leaf and mixed forests. Our results\nachieve RMSE of 1.93 cm, a bias of 0.65 cm and a standard deviation of 1.81 cm\n(averaged across these sequences)-with no post-processing required after the\nmission is complete.\n","authors":["Leonard Freißmuth","Matias Mattamala","Nived Chebrolu","Simon Schaefer","Stefan Leutenegger","Maurice Fallon"],"pdf_url":"https://arxiv.org/pdf/2403.17622v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.02021v5","updated":"2024-03-26T11:41:36Z","published":"2022-09-05T15:41:13Z","title":"When Robotics Meets Wireless Communications: An Introductory Tutorial","summary":"  The importance of ground Mobile Robots (MRs) and Unmanned Aerial Vehicles\n(UAVs) within the research community, industry, and society is growing fast.\nMany of these agents are nowadays equipped with communication systems that are,\nin some cases, essential to successfully achieve certain tasks. In this\ncontext, we have begun to witness the development of a new interdisciplinary\nresearch field at the intersection of robotics and communications. This\nresearch field has been boosted by the intention of integrating UAVs within the\n5G and 6G communication networks. This research will undoubtedly lead to many\nimportant applications in the near future. Nevertheless, one of the main\nobstacles to the development of this research area is that most researchers\naddress these problems by oversimplifying either the robotics or the\ncommunications aspect. This impedes the ability of reaching the full potential\nof this new interdisciplinary research area. In this tutorial, we present some\nof the modelling tools necessary to address problems involving both robotics\nand communication from an interdisciplinary perspective. As an illustrative\nexample of such problems, we focus in this tutorial on the issue of\ncommunication-aware trajectory planning.\n","authors":["Daniel Bonilla Licea","Mounir Ghogho","Martin Saska"],"pdf_url":"https://arxiv.org/pdf/2209.02021v5.pdf","comment":"35 pages, 192 references"},{"id":"http://arxiv.org/abs/2403.17606v1","updated":"2024-03-26T11:38:19Z","published":"2024-03-26T11:38:19Z","title":"Interactive Identification of Granular Materials using Force\n  Measurements","summary":"  The ability to identify granular materials facilitates the emergence of\nvarious new applications in robotics, ranging from cooking at home to truck\nloading at mining sites. However, granular material identification remains a\nchallenging and underexplored area. In this work, we present a novel\ninteractive material identification framework that enables robots to identify a\nwide range of granular materials using only a force-torque sensor for\nperception. Our framework, comprising interactive exploration, feature\nextraction, and classification stages, prioritizes simplicity and transparency\nfor seamless integration into various manipulation pipelines. We evaluate the\nproposed approach through extensive experiments with a real-world dataset\ncomprising 11 granular materials, which we also make publicly available.\nAdditionally, we conducted a comprehensive qualitative analysis of the dataset\nto offer deeper insights into its nature, aiding future development. Our\nresults show that the proposed method is capable of accurately identifying a\nwide range of granular materials solely relying on force measurements obtained\nfrom direct interaction with the materials. Code and dataset are available at:\nhttps://irobotics.aalto.fi/indentify_granular/.\n","authors":["Samuli Hynninen","Tran Nguyen Le","Ville Kyrki"],"pdf_url":"https://arxiv.org/pdf/2403.17606v1.pdf","comment":"Submitted to 2024 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2024)"},{"id":"http://arxiv.org/abs/2403.13518v2","updated":"2024-03-26T11:16:47Z","published":"2024-03-20T11:38:30Z","title":"Motion Generation from Fine-grained Textual Descriptions","summary":"  The task of text2motion is to generate human motion sequences from given\ntextual descriptions, where the model explores diverse mappings from natural\nlanguage instructions to human body movements. While most existing works are\nconfined to coarse-grained motion descriptions, e.g., \"A man squats.\",\nfine-grained descriptions specifying movements of relevant body parts are\nbarely explored. Models trained with coarse-grained texts may not be able to\nlearn mappings from fine-grained motion-related words to motion primitives,\nresulting in the failure to generate motions from unseen descriptions. In this\npaper, we build a large-scale language-motion dataset specializing in\nfine-grained textual descriptions, FineHumanML3D, by feeding GPT-3.5-turbo with\nstep-by-step instructions with pseudo-code compulsory checks. Accordingly, we\ndesign a new text2motion model, FineMotionDiffuse, making full use of\nfine-grained textual information. Our quantitative evaluation shows that\nFineMotionDiffuse trained on FineHumanML3D improves FID by a large margin of\n0.38, compared with competitive baselines. According to the qualitative\nevaluation and case study, our model outperforms MotionDiffuse in generating\nspatially or chronologically composite motions, by learning the implicit\nmappings from fine-grained descriptions to the corresponding basic motions. We\nrelease our data at https://github.com/KunhangL/finemotiondiffuse.\n","authors":["Kunhang Li","Yansong Feng"],"pdf_url":"https://arxiv.org/pdf/2403.13518v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17565v1","updated":"2024-03-26T10:19:04Z","published":"2024-03-26T10:19:04Z","title":"Aerial Robots Carrying Flexible Cables: Dynamic Shape Optimal Control\n  via Spectral Method Model","summary":"  In this work, we present a model-based optimal boundary control design for an\naerial robotic system composed of a quadrotor carrying a flexible cable. The\nwhole system is modeled by partial differential equations (PDEs) combined with\nboundary conditions described by ordinary differential equations (ODEs). The\nproper orthogonal decomposition (POD) method is adopted to project the original\ninfinite-dimensional system on a subspace spanned by orthogonal basis\nfunctions. Based on the reduced order model, nonlinear model predictive control\n(NMPC) is implemented online to realize shape trajectory tracking of the\nflexible cable in an optimal predictive fashion. The proposed reduced modeling\nand optimal control paradigms are numerically verified against an accurate\nhigh-dimensional FDM-based model in different scenarios and the controller's\nsuperior performance is shown compared to an optimally tuned PID controller.\n","authors":["Yaolei Shen","Chiara Gabellieri","Antonio Franchi"],"pdf_url":"https://arxiv.org/pdf/2403.17565v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17551v1","updated":"2024-03-26T09:58:27Z","published":"2024-03-26T09:58:27Z","title":"Time-Optimal Flight with Safety Constraints and Data-driven Dynamics","summary":"  Time-optimal quadrotor flight is an extremely challenging problem due to the\nlimited control authority encountered at the limit of handling. Model\nPredictive Contouring Control (MPCC) has emerged as a leading model-based\napproach for time optimization problems such as drone racing. However, the\nstandard MPCC formulation used in quadrotor racing introduces the notion of the\ngates directly in the cost function, creating a multi-objective optimization\nthat continuously trades off between maximizing progress and tracking the path\naccurately. This paper introduces three key components that enhance the MPCC\napproach for drone racing. First and foremost, we provide safety guarantees in\nthe form of a constraint and terminal set. The safety set is designed as a\nspatial constraint which prevents gate collisions while allowing for\ntime-optimization only in the cost function. Second, we augment the existing\nfirst principles dynamics with a residual term that captures complex\naerodynamic effects and thrust forces learned directly from real world data.\nThird, we use Trust Region Bayesian Optimization (TuRBO), a state of the art\nglobal Bayesian Optimization algorithm, to tune the hyperparameters of the MPC\ncontroller given a sparse reward based on lap time minimization. The proposed\napproach achieves similar lap times to the best state-of-the-art RL and\noutperforms the best time-optimal controller while satisfying constraints. In\nboth simulation and real-world, our approach consistently prevents gate crashes\nwith 100\\% success rate, while pushing the quadrotor to its physical limit\nreaching speeds of more than 80km/h.\n","authors":["Maria Krinner","Angel Romero","Leonard Bauersfeld","Melanie Zeilinger","Andrea Carron","Davide Scaramuzza"],"pdf_url":"https://arxiv.org/pdf/2403.17551v1.pdf","comment":"12 pages, 7 figures"},{"id":"http://arxiv.org/abs/2403.17550v1","updated":"2024-03-26T09:58:06Z","published":"2024-03-26T09:58:06Z","title":"DeepMIF: Deep Monotonic Implicit Fields for Large-Scale LiDAR 3D Mapping","summary":"  Recently, significant progress has been achieved in sensing real large-scale\noutdoor 3D environments, particularly by using modern acquisition equipment\nsuch as LiDAR sensors. Unfortunately, they are fundamentally limited in their\nability to produce dense, complete 3D scenes. To address this issue, recent\nlearning-based methods integrate neural implicit representations and\noptimizable feature grids to approximate surfaces of 3D scenes. However,\nnaively fitting samples along raw LiDAR rays leads to noisy 3D mapping results\ndue to the nature of sparse, conflicting LiDAR measurements. Instead, in this\nwork we depart from fitting LiDAR data exactly, instead letting the network\noptimize a non-metric monotonic implicit field defined in 3D space. To fit our\nfield, we design a learning system integrating a monotonicity loss that enables\noptimizing neural monotonic fields and leverages recent progress in large-scale\n3D mapping. Our algorithm achieves high-quality dense 3D mapping performance as\ncaptured by multiple quantitative and perceptual measures and visual results\nobtained for Mai City, Newer College, and KITTI benchmarks. The code of our\napproach will be made publicly available.\n","authors":["Kutay Yılmaz","Matthias Nießner","Anastasiia Kornilova","Alexey Artemov"],"pdf_url":"https://arxiv.org/pdf/2403.17550v1.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2110.07953v2","updated":"2024-03-26T09:52:36Z","published":"2021-10-15T09:12:44Z","title":"Attention-based Estimation and Prediction of Human Intent to augment\n  Haptic Glove aided Control of Robotic Hand","summary":"  The letter focuses on Haptic Glove (HG) based control of a Robotic Hand (RH)\nexecuting in-hand manipulation of certain objects of interest. The high\ndimensional motion signals in HG and RH possess intrinsic variability of\nkinematics resulting in difficulty to establish a direct mapping of the motion\nsignals from HG onto the RH. An estimation mechanism is proposed to quantify\nthe motion signal acquired from the human controller in relation to the\nintended goal pose of the object being held by the robotic hand. A control\nalgorithm is presented to transform the synthesized intent at the RH and allow\nrelocation of the object to the expected goal pose. The lag in synthesis of the\nintent in the presence of communication delay leads to a requirement of\npredicting the estimated intent. We leverage an attention-based convolutional\nneural network encoder to predict the trajectory of intent for a certain\nlookahead to compensate for the delays. The proposed methodology is evaluated\nacross objects of different shapes, mass, and materials. We present a\ncomparative performance of the estimation and prediction mechanisms on\n5G-driven real-world robotic setup against benchmark methodologies. The\ntest-MSE in prediction of human intent is reported to yield ~ 97.3 -98.7%\nimprovement of accuracy in comparison to LSTM-based benchmark\n","authors":["Muneeb Ahmed","Rajesh Kumar","Qaim Abbas","Brejesh Lall","Arzad A. Kherani","Sudipto Mukherjee"],"pdf_url":"https://arxiv.org/pdf/2110.07953v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17531v1","updated":"2024-03-26T09:36:26Z","published":"2024-03-26T09:36:26Z","title":"Design and Preliminary Evaluation of a Torso Stabiliser for Individuals\n  with Spinal Cord Injury","summary":"  Spinal cord injuries (SCIs) generally result in sensory and mobility\nimpairments, with torso instability being particularly debilitating. Existing\ntorso stabilisers are often rigid and restrictive. This paper presents an early\ninvestigation into a non-restrictive 1 degree-of-freedom (DoF) mechanical torso\nstabiliser inspired by devices such as centrifugal clutches and seat-belt\nmechanisms. Firstly, the paper presents a motion-capture (MoCap) and\nOpenSim-based kinematic analysis of the cable-based system to understand\nrequisite device characteristics. The simulated evaluation resulted in the\ncable-based device to require 55-60cm of unrestricted travel, and to lock at a\nthreshold cable velocity of 80-100cm/sec. Next, the developed 1-DoF device is\nintroduced. The proposed mechanical device is transparent during activities of\ndaily living, and transitions to compliant blocking when incipient fall is\ndetected. Prototype behaviour was then validated using a MoCap-based kinematic\nanalysis to verify non-restrictive movement, reliable transition to blocking,\nand compliance of the blocking.\n","authors":["Rejin John Varghese","Man-Yan Tong","Isabella Szczech","Peter Bryan","Dario Farina","Etienne Burdet"],"pdf_url":"https://arxiv.org/pdf/2403.17531v1.pdf","comment":"4 pages, 4 figures, 10 references. Submitted to IEEE EMBC 2024\n  conference"},{"id":"http://arxiv.org/abs/2403.16291v2","updated":"2024-03-26T09:23:07Z","published":"2024-03-24T20:43:29Z","title":"Guessing human intentions to avoid dangerous situations in caregiving\n  robots","summary":"  For robots to interact socially, they must interpret human intentions and\nanticipate their potential outcomes accurately. This is particularly important\nfor social robots designed for human care, which may face potentially dangerous\nsituations for people, such as unseen obstacles in their way, that should be\navoided. This paper explores the Artificial Theory of Mind (ATM) approach to\ninferring and interpreting human intentions. We propose an algorithm that\ndetects risky situations for humans, selecting a robot action that removes the\ndanger in real time. We use the simulation-based approach to ATM and adopt the\n'like-me' policy to assign intentions and actions to people. Using this\nstrategy, the robot can detect and act with a high rate of success under\ntime-constrained situations. The algorithm has been implemented as part of an\nexisting robotics cognitive architecture and tested in simulation scenarios.\nThree experiments have been conducted to test the implementation's robustness,\nprecision and real-time response, including a simulated scenario, a\nhuman-in-the-loop hybrid configuration and a real-world scenario.\n","authors":["Noé Zapata","Gerardo Pérez","Lucas Bonilla","Pedro Núñez","Pilar Bachiller","Pablo Bustos"],"pdf_url":"https://arxiv.org/pdf/2403.16291v2.pdf","comment":"8 pages, 6 figures. Submitted to IROS2024. For associated mpeg file\n  see https://youtu.be/87UEB8P97KY"},{"id":"http://arxiv.org/abs/2011.07529v3","updated":"2024-03-26T08:54:31Z","published":"2020-11-15T13:40:21Z","title":"Full Attitude Intelligent Controller Design of a Heliquad under Complete\n  Failure of an Actuator","summary":"  In this paper, we design a reliable Heliquad and develop an intelligent\ncontroller to handle one actuators complete failure. Heliquad is a multi-copter\nsimilar to Quadcopter, with four actuators diagonally symmetric from the\ncenter. Each actuator has two control inputs; the first input changes the\npropeller blades collective pitch (also called variable pitch), and the other\ninput changes the rotation speed. For reliable operation and high torque\ncharacteristic requirement for yaw control, a cambered airfoil is used to\ndesign propeller blades. A neural network-based control allocation is designed\nto provide complete control authority even under a complete loss of one\nactuator. Nonlinear quaternion based outer loop position control, with\nproportional-derivative inner loop for attitude control and neural\nnetwork-based control allocation is used in controller design. The proposed\ncontroller and Heliquad designs performance is evaluated using a\nsoftware-in-loop simulation to track the position reference command under\nfailure. The results clearly indicate that the Heliquad with an intelligent\ncontroller provides necessary tracking performance even under a complete loss\nof one actuator.\n","authors":["Eeshan Kulkarni","Suresh Sundaram"],"pdf_url":"https://arxiv.org/pdf/2011.07529v3.pdf","comment":"7 pages, For video go to\n  https://indianinstituteofscience-my.sharepoint.com/:v:/g/personal/eeshank_iisc_ac_in/EcMg2uTtE91AsHDejNkb6YMBNckaXGjeh_YMzDV6sAHZAQ?e=DrRqmN"},{"id":"http://arxiv.org/abs/2403.11384v3","updated":"2024-03-26T08:40:12Z","published":"2024-03-18T00:22:30Z","title":"Towards Massive Interaction with Generalist Robotics: A Systematic\n  Review of XR-enabled Remote Human-Robot Interaction Systems","summary":"  The rising interest of generalist robots seek to create robots with\nversatility to handle multiple tasks in a variety of environments, and human\nwill interact with such robots through immersive interfaces. In the context of\nhuman-robot interaction (HRI), this survey provides an exhaustive review of the\napplications of extended reality (XR) technologies in the field of remote HRI.\nWe developed a systematic search strategy based on the PRISMA methodology. From\nthe initial 2,561 articles selected, 100 research papers that met our inclusion\ncriteria were included. We categorized and summarized the domain in detail,\ndelving into XR technologies, including augmented reality (AR), virtual reality\n(VR), and mixed reality (MR), and their applications in facilitating intuitive\nand effective remote control and interaction with robotic systems. The survey\nhighlights existing articles on the application of XR technologies, user\nexperience enhancement, and various interaction designs for XR in remote HRI,\nproviding insights into current trends and future directions. We also\nidentified potential gaps and opportunities for future research to improve\nremote HRI systems through XR technology to guide and inform future XR and\nrobotics research.\n","authors":["Xian Wang","Luyao Shen","Lik-Hang Lee"],"pdf_url":"https://arxiv.org/pdf/2403.11384v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.02444v2","updated":"2024-03-26T08:13:01Z","published":"2023-04-05T14:02:53Z","title":"Autonomous Hook-Based Grasping and Transportation with Quadcopters","summary":"  Payload grasping and transportation with quadcopters is an active research\narea that has rapidly developed over the last decade. To grasp a payload\nwithout human interaction, most state-of-the-art approaches apply robotic arms\nthat are attached to the quadcopter body. However, due to the large weight and\npower consumption of these aerial manipulators, their agility and flight time\nare limited. This paper proposes a motion control and planning method for\ntransportation with a lightweight, passive manipulator structure that consists\nof a hook attached to a quadrotor using a 1 DoF revolute joint. To perform\npayload grasping, transportation, and release, first, time-optimal reference\ntrajectories are designed through specific waypoints to ensure the fast and\nreliable execution of the tasks. Then, a two-stage motion control approach is\ndeveloped based on a robust geometric controller for precise and reliable\nreference tracking and a linear--quadratic payload regulator for rapid setpoint\nstabilization of the payload swing. Furthermore, stability of the closed-loop\nsystem is mathematically proven to give safety guarantee for its operation. The\nproposed control architecture and design are evaluated in a high-fidelity\nphysical simulator, and also in real flight experiments, using a custom-made\nquadrotor--hook manipulator platform.\n","authors":["Péter Antal","Tamás Péni","Roland Tóth"],"pdf_url":"https://arxiv.org/pdf/2304.02444v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.07658v3","updated":"2024-03-26T08:01:29Z","published":"2024-01-15T13:00:35Z","title":"Robustness Evaluation of Localization Techniques for Autonomous Racing","summary":"  This work introduces SynPF, an MCL-based algorithm tailored for high-speed\nracing environments. Benchmarked against Cartographer, a state-of-the-art\npose-graph SLAM algorithm, SynPF leverages synergies from previous\nparticle-filtering methods and synthesizes them for the high-performance racing\ndomain. Our extensive in-field evaluations reveal that while Cartographer\nexcels under nominal conditions, it struggles when subjected to wheel-slip, a\ncommon phenomenon in a racing scenario due to varying grip levels and\naggressive driving behaviour. Conversely, SynPF demonstrates robustness in\nthese challenging conditions and a low-latency computation time of 1.25 ms on\non-board computers without a GPU. Using the F1TENTH platform, a 1:10 scaled\nautonomous racing vehicle, this work not only highlights the vulnerabilities of\nexisting algorithms in high-speed scenarios, tested up until 7.6 m/s, but also\nemphasizes the potential of SynPF as a viable alternative, especially in\ndeteriorating odometry conditions.\n","authors":["Tian Yi Lim","Edoardo Ghignone","Nicolas Baumann","Michele Magno"],"pdf_url":"https://arxiv.org/pdf/2401.07658v3.pdf","comment":"Accepted at the Design, Automation and Test in Europe Conference 2024\n  as an extended abstract"},{"id":"http://arxiv.org/abs/2403.17459v1","updated":"2024-03-26T07:47:52Z","published":"2024-03-26T07:47:52Z","title":"High-Power, Flexible, Robust Hand: Development of Musculoskeletal Hand\n  Using Machined Springs and Realization of Self-Weight Supporting Motion with\n  Humanoid","summary":"  Human can not only support their body during standing or walking, but also\nsupport them by hand, so that they can dangle a bar and others. But most\nhumanoid robots support their body only in the foot and they use their hand\njust to manipulate objects because their hands are too weak to support their\nbody. Strong hands are supposed to enable humanoid robots to act in much\nbroader scene. Therefore, we developed new life-size five-fingered hand that\ncan support the body of life-size humanoid robot. It is tendon-driven and\nunderactuated hand and actuators in forearms produce large gripping force. This\nhand has flexible joints using machined springs, which can be designed\nintegrally with the attachment. Thus, it has both structural strength and\nimpact resistance in spite of small size. As other characteristics, this hand\nhas force sensors to measure external force and the fingers can be flexed along\nobjects though the number of actuators to flex fingers is less than that of\nfingers. We installed the developed hand on musculoskeletal humanoid \"Kengoro\"\nand achieved two self-weight supporting motions: push-up motion and dangling\nmotion.\n","authors":["Shogo Makino","Kento Kawaharazuka","Masaya Kawamura","Yuki Asano","Kei Okada","Masayuki Inaba"],"pdf_url":"https://arxiv.org/pdf/2403.17459v1.pdf","comment":"accepted at IROS2017"},{"id":"http://arxiv.org/abs/2403.17452v1","updated":"2024-03-26T07:33:53Z","published":"2024-03-26T07:33:53Z","title":"Five-fingered Hand with Wide Range of Thumb Using Combination of\n  Machined Springs and Variable Stiffness Joints","summary":"  Human hands can not only grasp objects of various shape and size and\nmanipulate them in hands but also exert such a large gripping force that they\ncan support the body in the situations such as dangling a bar and climbing a\nladder. On the other hand, it is difficult for most robot hands to manage both.\nTherefore in this paper we developed the hand which can grasp various objects\nand exert large gripping force. To develop such hand, we focused on the thumb\nCM joint with wide range of motion and the MP joints of four fingers with the\nDOF of abduction and adduction. Based on the hand with large gripping force and\nflexibility using machined spring, we applied above mentioned joint mechanism\nto the hand. The thumb CM joint has wide range of motion because of the\ncombination of three machined springs and MP joints of four fingers have\nvariable rigidity mechanism instead of driving each joint independently in\norder to move joint in limited space and by limited actuators. Using the\ndeveloped hand, we achieved the grasping of various objects, supporting a large\nload and several motions with an arm.\n","authors":["Shogo Makino","Kento Kawaharazuka","Ayaka Fujii","Masaya Kawamura","Tasuku Makabe","Moritaka Onitsuka","Yuki Asano","Kei Okada","Koji Kawasaki","Masayuki Inaba"],"pdf_url":"https://arxiv.org/pdf/2403.17452v1.pdf","comment":"accepted at IROS2018"},{"id":"http://arxiv.org/abs/2403.17448v1","updated":"2024-03-26T07:26:27Z","published":"2024-03-26T07:26:27Z","title":"Adaptive Line-Of-Sight guidance law based on vector fields path\n  following for underactuated unmanned surface vehicle","summary":"  The focus of this paper is to develop a methodology that enables an unmanned\nsurface vehicle (USV) to efficiently track a planned path. The introduction of\na vector field-based adaptive line-of-sight guidance law (VFALOS) for accurate\ntrajectory tracking and minimizing the overshoot response time during USV\ntracking of curved paths improves the overall line-of-sight (LOS) guidance\nmethod. These improvements contribute to faster convergence to the desired\npath, reduce oscillations, and can mitigate the effects of persistent external\ndisturbances. It is shown that the proposed guidance law exhibits k-exponential\nstability when converging to the desired path consisting of straight and curved\nlines. The results in the paper show that the proposed method effectively\nimproves the accuracy of the USV tracking the desired path while ensuring the\nsafety of the USV work.\n","authors":["Jie Qi","Ronghua Wang","Nailong Wu","Yuxin Fan","Jigang Wang"],"pdf_url":"https://arxiv.org/pdf/2403.17448v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17441v1","updated":"2024-03-26T07:19:06Z","published":"2024-03-26T07:19:06Z","title":"Adaptive LiDAR-Radar Fusion for Outdoor Odometry Across Dense Smoke\n  Conditions","summary":"  Robust odometry estimation in perceptually degraded environments represents a\nkey challenge in the field of robotics. In this paper, we propose a LiDAR-radar\nfusion method for robust odometry for adverse environment with LiDAR\ndegeneracy. By comparing the LiDAR point cloud with the radar static point\ncloud obtained through preprocessing module, it is possible to identify\ninstances of LiDAR degeneracy to overcome perceptual limits. We demonstrate the\neffectiveness of our method in challenging conditions such as dense smoke,\nshowcasing its ability to reliably estimate odometry and identify/remove\ndynamic points prone to LiDAR degeneracy.\n","authors":["Chiyun Noh","Ayoung Kim"],"pdf_url":"https://arxiv.org/pdf/2403.17441v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.11011v2","updated":"2024-03-26T07:03:18Z","published":"2023-09-20T02:26:41Z","title":"OCC-VO: Dense Mapping via 3D Occupancy-Based Visual Odometry for\n  Autonomous Driving","summary":"  Visual Odometry (VO) plays a pivotal role in autonomous systems, with a\nprincipal challenge being the lack of depth information in camera images. This\npaper introduces OCC-VO, a novel framework that capitalizes on recent advances\nin deep learning to transform 2D camera images into 3D semantic occupancy,\nthereby circumventing the traditional need for concurrent estimation of ego\nposes and landmark locations. Within this framework, we utilize the TPV-Former\nto convert surround view cameras' images into 3D semantic occupancy. Addressing\nthe challenges presented by this transformation, we have specifically tailored\na pose estimation and mapping algorithm that incorporates Semantic Label\nFilter, Dynamic Object Filter, and finally, utilizes Voxel PFilter for\nmaintaining a consistent global semantic map. Evaluations on the Occ3D-nuScenes\nnot only showcase a 20.6% improvement in Success Ratio and a 29.6% enhancement\nin trajectory accuracy against ORB-SLAM3, but also emphasize our ability to\nconstruct a comprehensive map. Our implementation is open-sourced and available\nat: https://github.com/USTCLH/OCC-VO.\n","authors":["Heng Li","Yifan Duan","Xinran Zhang","Haiyi Liu","Jianmin Ji","Yanyong Zhang"],"pdf_url":"https://arxiv.org/pdf/2309.11011v2.pdf","comment":"7pages, 3 figures"},{"id":"http://arxiv.org/abs/2308.01557v2","updated":"2024-03-26T06:50:43Z","published":"2023-08-03T06:36:21Z","title":"Motion Planning Diffusion: Learning and Planning of Robot Motions with\n  Diffusion Models","summary":"  Learning priors on trajectory distributions can help accelerate robot motion\nplanning optimization. Given previously successful plans, learning trajectory\ngenerative models as priors for a new planning problem is highly desirable.\nPrior works propose several ways on utilizing this prior to bootstrapping the\nmotion planning problem. Either sampling the prior for initializations or using\nthe prior distribution in a maximum-a-posterior formulation for trajectory\noptimization. In this work, we propose learning diffusion models as priors. We\nthen can sample directly from the posterior trajectory distribution conditioned\non task goals, by leveraging the inverse denoising process of diffusion models.\nFurthermore, diffusion has been recently shown to effectively encode data\nmultimodality in high-dimensional settings, which is particularly well-suited\nfor large trajectory dataset. To demonstrate our method efficacy, we compare\nour proposed method - Motion Planning Diffusion - against several baselines in\nsimulated planar robot and 7-dof robot arm manipulator environments. To assess\nthe generalization capabilities of our method, we test it in environments with\npreviously unseen obstacles. Our experiments show that diffusion models are\nstrong priors to encode high-dimensional trajectory distributions of robot\nmotions.\n","authors":["Joao Carvalho","An T. Le","Mark Baierl","Dorothea Koert","Jan Peters"],"pdf_url":"https://arxiv.org/pdf/2308.01557v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17417v1","updated":"2024-03-26T06:14:58Z","published":"2024-03-26T06:14:58Z","title":"Cyclic pursuit formation control for arbitrary desired shapes","summary":"  A multi-agent system comprises numerous agents that autonomously make\ndecisions to collectively accomplish tasks, drawing significant attention for\ntheir wide-ranging applications. Within this context, formation control emerges\nas a prominent task, wherein agents collaboratively shape and maneuver while\npreserving formation integrity. Our focus centers on cyclic pursuit, a method\nfacilitating the formation of circles, ellipses, and figure-eights under the\nassumption that agents can only perceive the relative positions of those\npreceding them. However, this method's scope has been restricted to these\nspecific shapes, leaving the feasibility of forming other shapes uncertain. In\nresponse, our study proposes a novel method based on cyclic pursuit capable of\nforming a broader array of shapes, enabling agents to individually shape while\npursuing preceding agents, thereby extending the repertoire of achievable\nformations. We present two scenarios concerning the information available to\nagents and devise formation control methods tailored to each scenario. Through\nextensive simulations, we demonstrate the efficacy of our proposed method in\nforming multiple shapes, including those represented as Fourier series, thereby\nunderscoring the versatility and effectiveness of our approach.\n","authors":["Anna Fujioka","Masaki Ogura","Naoki Wakamiya"],"pdf_url":"https://arxiv.org/pdf/2403.17417v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17392v1","updated":"2024-03-26T05:23:12Z","published":"2024-03-26T05:23:12Z","title":"Natural-artificial hybrid swarm: Cyborg-insect group navigation in\n  unknown obstructed soft terrain","summary":"  Navigating multi-robot systems in complex terrains has always been a\nchallenging task. This is due to the inherent limitations of traditional robots\nin collision avoidance, adaptation to unknown environments, and sustained\nenergy efficiency. In order to overcome these limitations, this research\nproposes a solution by integrating living insects with miniature electronic\ncontrollers to enable robotic-like programmable control, and proposing a novel\ncontrol algorithm for swarming. Although these creatures, called cyborg\ninsects, have the ability to instinctively avoid collisions with neighbors and\nobstacles while adapting to complex terrains, there is a lack of literature on\nthe control of multi-cyborg systems. This research gap is due to the difficulty\nin coordinating the movements of a cyborg system under the presence of insects'\ninherent individual variability in their reactions to control input. In\nresponse to this issue, we propose a novel swarm navigation algorithm\naddressing these challenges. The effectiveness of the algorithm is demonstrated\nthrough an experimental validation in which a cyborg swarm was successfully\nnavigated through an unknown sandy field with obstacles and hills. This\nresearch contributes to the domain of swarm robotics and showcases the\npotential of integrating biological organisms with robotics and control theory\nto create more intelligent autonomous systems with real-world applications.\n","authors":["Yang Bai","Phuoc Thanh Tran Ngoc","Huu Duoc Nguyen","Duc Long Le","Quang Huy Ha","Kazuki Kai","Yu Xiang See To","Yaosheng Deng","Jie Song","Naoki Wakamiya","Hirotaka Sato","Masaki Ogura"],"pdf_url":"https://arxiv.org/pdf/2403.17392v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17367v1","updated":"2024-03-26T04:05:01Z","published":"2024-03-26T04:05:01Z","title":"RoboDuet: A Framework Affording Mobile-Manipulation and Cross-Embodiment","summary":"  Combining the mobility of legged robots with the manipulation skills of arms\nhas the potential to significantly expand the operational range and enhance the\ncapabilities of robotic systems in performing various mobile manipulation\ntasks. Existing approaches are confined to imprecise six degrees of freedom\n(DoF) manipulation and possess a limited arm workspace. In this paper, we\npropose a novel framework, RoboDuet, which employs two collaborative policies\nto realize locomotion and manipulation simultaneously, achieving whole-body\ncontrol through interactions between each other. Surprisingly, going beyond the\nlarge-range pose tracking, we find that the two-policy framework may enable\ncross-embodiment deployment such as using different quadrupedal robots or other\narms. Our experiments demonstrate that the policies trained through RoboDuet\ncan accomplish stable gaits, agile 6D end-effector pose tracking, and zero-shot\nexchange of legged robots, and can be deployed in the real world to perform\nvarious mobile manipulation tasks. Our project page with demo videos is at\nhttps://locomanip-duet.github.io .\n","authors":["Guoping Pan","Qingwei Ben","Zhecheng Yuan","Guangqi Jiang","Yandong Ji","Jiangmiao Pang","Houde Liu","Huazhe Xu"],"pdf_url":"https://arxiv.org/pdf/2403.17367v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17353v1","updated":"2024-03-26T03:32:45Z","published":"2024-03-26T03:32:45Z","title":"Multi-Objective Trajectory Planning with Dual-Encoder","summary":"  Time-jerk optimal trajectory planning is crucial in advancing robotic arms'\nperformance in dynamic tasks. Traditional methods rely on solving complex\nnonlinear programming problems, bringing significant delays in generating\noptimized trajectories. In this paper, we propose a two-stage approach to\naccelerate time-jerk optimal trajectory planning. Firstly, we introduce a\ndual-encoder based transformer model to establish a good preliminary\ntrajectory. This trajectory is subsequently refined through sequential\nquadratic programming to improve its optimality and robustness. Our approach\noutperforms the state-of-the-art by up to 79.72\\% in reducing trajectory\nplanning time. Compared with existing methods, our method shrinks the\noptimality gap with the objective function value decreasing by up to 29.9\\%.\n","authors":["Beibei Zhang","Tian Xiang","Chentao Mao","Yuhua Zheng","Shuai Li","Haoyi Niu","Xiangming Xi","Wenyuan Bai","Feng Gao"],"pdf_url":"https://arxiv.org/pdf/2403.17353v1.pdf","comment":"6 pages, 7 figures, conference"},{"id":"http://arxiv.org/abs/2403.17347v1","updated":"2024-03-26T03:15:14Z","published":"2024-03-26T03:15:14Z","title":"Unified Path and Gait Planning for Safe Bipedal Robot Navigation","summary":"  Safe path and gait planning are essential for bipedal robots to navigate\ncomplex real-world environments. The prevailing approaches often plan the path\nand gait separately in a hierarchical fashion, potentially resulting in unsafe\nmovements due to neglecting the physical constraints of walking robots. A\nsafety-critical path must not only avoid obstacles but also ensure that the\nrobot's gaits are subject to its dynamic and kinematic constraints. This work\npresents a novel approach that unifies path planning and gait planning via a\nModel Predictive Control (MPC) using the Linear Inverted Pendulum (LIP) model\nrepresenting bipedal locomotion. This approach considers environmental\nconstraints, such as obstacles, and the robot's kinematics and dynamics\nconstraints. By using discrete-time Control Barrier Functions for obstacle\navoidance, our approach generates the next foot landing position, ensuring\nrobust walking gaits and a safe navigation path within clustered environments.\nWe validated our proposed approach in simulation using a Digit robot in 20\nrandomly created environments. The results demonstrate improved performance in\nterms of safety and robustness when compared to hierarchical path and gait\nplanning frameworks.\n","authors":["Chengyang Peng","Victor Paredes","Ayonga Hereid"],"pdf_url":"https://arxiv.org/pdf/2403.17347v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2403.17320v1","updated":"2024-03-26T02:02:35Z","published":"2024-03-26T02:02:35Z","title":"Leveraging Symmetry in RL-based Legged Locomotion Control","summary":"  Model-free reinforcement learning is a promising approach for autonomously\nsolving challenging robotics control problems, but faces exploration difficulty\nwithout information of the robot's kinematics and dynamics morphology. The\nunder-exploration of multiple modalities with symmetric states leads to\nbehaviors that are often unnatural and sub-optimal. This issue becomes\nparticularly pronounced in the context of robotic systems with morphological\nsymmetries, such as legged robots for which the resulting asymmetric and\naperiodic behaviors compromise performance, robustness, and transferability to\nreal hardware. To mitigate this challenge, we can leverage symmetry to guide\nand improve the exploration in policy learning via equivariance/invariance\nconstraints. In this paper, we investigate the efficacy of two approaches to\nincorporate symmetry: modifying the network architectures to be strictly\nequivariant/invariant, and leveraging data augmentation to approximate\nequivariant/invariant actor-critics. We implement the methods on challenging\nloco-manipulation and bipedal locomotion tasks and compare with an\nunconstrained baseline. We find that the strictly equivariant policy\nconsistently outperforms other methods in sample efficiency and task\nperformance in simulation. In addition, symmetry-incorporated approaches\nexhibit better gait quality, higher robustness and can be deployed zero-shot in\nreal-world experiments.\n","authors":["Zhi Su","Xiaoyu Huang","Daniel Ordoñez-Apraez","Yunfei Li","Zhongyu Li","Qiayuan Liao","Giulio Turrisi","Massimiliano Pontil","Claudio Semini","Yi Wu","Koushil Sreenath"],"pdf_url":"https://arxiv.org/pdf/2403.17320v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04225v2","updated":"2024-03-26T00:37:21Z","published":"2023-03-07T20:34:33Z","title":"Feeling Optimistic? Ambiguity Attitudes for Online Decision Making","summary":"  Due to the complexity of many decision making problems, tree search\nalgorithms often have inadequate information to produce accurate transition\nmodels. Robust methods, designed to make safe decisions when faced with these\nuncertainties, often overlook the impact expressions of uncertainty have on how\nthe decision is made. This work introduces the Ambiguity Attitude Graph Search\n(AAGS), advocating for more precise representation of ambiguities (uncertainty\nfrom a set of plausible models) in decision making. Additionally, AAGS allows\nusers to adjust their ambiguity attitude (or preference), promoting exploration\nand improving users' ability to control how an agent should respond when faced\nwith a set of valid alternatives. Simulation in a dynamic sailing environment\nshows how highly stochastic environments can lead robust methods to fail.\nResults further demonstrate how adjusting ambiguity attitudes better fulfills\nobjectives while mitigating this failure mode of robust approaches. Because\nthis approach is a generalization of the robust framework, these results\nfurther demonstrate how algorithms focused on ambiguity have applicability\nbeyond safety-critical systems.\n","authors":["Jared J. Beard","R. Michael Butts","Yu Gu"],"pdf_url":"https://arxiv.org/pdf/2303.04225v2.pdf","comment":"6 pages, 5 figures, 2 algorithms. Submitted to the 2024 IEEE/RSJ\n  International Conference on Intelligent Robots and Systems in Abu Dhabi, UAE\n  (Oct 14-18, 2024)"},{"id":"http://arxiv.org/abs/2403.17288v1","updated":"2024-03-26T00:35:06Z","published":"2024-03-26T00:35:06Z","title":"Sparse-Graph-Enabled Formation Planning for Large-Scale Aerial Swarms","summary":"  The formation trajectory planning using complete graphs to model\ncollaborative constraints becomes computationally intractable as the number of\ndrones increases due to the curse of dimensionality. To tackle this issue, this\npaper presents a sparse graph construction method for formation planning to\nrealize better efficiency-performance trade-off. Firstly, a sparsification\nmechanism for complete graphs is designed to ensure the global rigidity of\nsparsified graphs, which is a necessary condition for uniquely corresponding to\na geometric shape. Secondly, a good sparse graph is constructed to preserve the\nmain structural feature of complete graphs sufficiently. Since the graph-based\nformation constraint is described by Laplacian matrix, the sparse graph\nconstruction problem is equivalent to submatrix selection, which has\ncombinatorial time complexity and needs a scoring metric. Via comparative\nsimulations, the Max-Trace matrix-revealing metric shows the promising\nperformance. The sparse graph is integrated into the formation planning.\nSimulation results with 72 drones in complex environments demonstrate that when\npreserving 30\\% connection edges, our method has comparative formation error\nand recovery performance w.r.t. complete graphs. Meanwhile, the planning\nefficiency is improved by approximate an order of magnitude. Benchmark\ncomparisons and ablation studies are conducted to fully validate the merits of\nour method.\n","authors":["Yuan Zhou","Lun Quan","Chao Xu","Guangtong Xu","Fei Gao"],"pdf_url":"https://arxiv.org/pdf/2403.17288v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18149v1","updated":"2024-03-26T23:17:05Z","published":"2024-03-26T23:17:05Z","title":"Code Generation for Conic Model-Predictive Control on Microcontrollers\n  with TinyMPC","summary":"  Conic constraints appear in many important control applications like legged\nlocomotion, robotic manipulation, and autonomous rocket landing. However,\ncurrent solvers for conic optimization problems have relatively heavy\ncomputational demands in terms of both floating-point operations and memory\nfootprint, making them impractical for use on small embedded devices. We extend\nTinyMPC, an open-source, high-speed solver targeting low-power embedded control\napplications, to handle second-order cone constraints. We also present\ncode-generation software to enable deployment of TinyMPC on a variety of\nmicrocontrollers. We benchmark our generated code against state-of-the-art\nembedded QP and SOCP solvers, demonstrating a two-order-of-magnitude speed\nincrease over ECOS while consuming less memory. Finally, we demonstrate\nTinyMPC's efficacy on the Crazyflie, a lightweight, resource-constrained\nquadrotor with fast dynamics. TinyMPC and its code-generation tools are\npublicly available at https://tinympc.org.\n","authors":["Sam Schoedel","Khai Nguyen","Elakhya Nedumaran","Brian Plancher","Zachary Manchester"],"pdf_url":"https://arxiv.org/pdf/2403.18149v1.pdf","comment":"Submitted to CDC, 2024. First two authors contributed equally"},{"id":"http://arxiv.org/abs/2403.18145v1","updated":"2024-03-26T23:10:41Z","published":"2024-03-26T23:10:41Z","title":"A Real-Time Rescheduling Algorithm for Multi-robot Plan Execution","summary":"  One area of research in multi-agent path finding is to determine how\nreplanning can be efficiently achieved in the case of agents being delayed\nduring execution. One option is to reschedule the passing order of agents,\ni.e., the sequence in which agents visit the same location. In response, we\npropose Switchable-Edge Search (SES), an A*-style algorithm designed to find\noptimal passing orders. We prove the optimality of SES and evaluate its\nefficiency via simulations. The best variant of SES takes less than 1 second\nfor small- and medium-sized problems and runs up to 4 times faster than\nbaselines for large-sized problems.\n","authors":["Ying Feng","Adittyo Paul","Zhe Chen","Jiaoyang Li"],"pdf_url":"https://arxiv.org/pdf/2403.18145v1.pdf","comment":"ICAPS 2024"},{"id":"http://arxiv.org/abs/2403.16967v2","updated":"2024-03-26T22:00:27Z","published":"2024-03-25T17:26:08Z","title":"Visual Whole-Body Control for Legged Loco-Manipulation","summary":"  We study the problem of mobile manipulation using legged robots equipped with\nan arm, namely legged loco-manipulation. The robot legs, while usually utilized\nfor mobility, offer an opportunity to amplify the manipulation capabilities by\nconducting whole-body control. That is, the robot can control the legs and the\narm at the same time to extend its workspace. We propose a framework that can\nconduct the whole-body control autonomously with visual observations. Our\napproach, namely Visual Whole-Body Control(VBC), is composed of a low-level\npolicy using all degrees of freedom to track the end-effector manipulator\nposition and a high-level policy proposing the end-effector position based on\nvisual inputs. We train both levels of policies in simulation and perform\nSim2Real transfer for real robot deployment. We perform extensive experiments\nand show significant improvements over baselines in picking up diverse objects\nin different configurations (heights, locations, orientations) and\nenvironments. Project page: https://wholebody-b1.github.io\n","authors":["Minghuan Liu","Zixuan Chen","Xuxin Cheng","Yandong Ji","Ruihan Yang","Xiaolong Wang"],"pdf_url":"https://arxiv.org/pdf/2403.16967v2.pdf","comment":"The first two authors contribute equally. Project page:\n  https://wholebody-b1.github.io"},{"id":"http://arxiv.org/abs/2311.02749v3","updated":"2024-03-26T21:42:34Z","published":"2023-11-05T19:59:36Z","title":"Fast Point Cloud to Mesh Reconstruction for Deformable Object Tracking","summary":"  The world around us is full of soft objects we perceive and deform with\ndexterous hand movements. For a robotic hand to control soft objects, it has to\nacquire online state feedback of the deforming object. While RGB-D cameras can\ncollect occluded point clouds at a rate of 30Hz, this does not represent a\ncontinuously trackable object surface. Hence, in this work, we developed a\nmethod that takes as input a template mesh which is the mesh of an object in\nits non-deformed state and a deformed point cloud of the same object, and then\nshapes the template mesh such that it matches the deformed point cloud. The\nreconstruction of meshes from point clouds has long been studied in the field\nof Computer graphics under 3D reconstruction and 4D reconstruction, however,\nboth lack the speed and generalizability needed for robotics applications. Our\nmodel is designed using a point cloud auto-encoder and a Real-NVP architecture.\nOur trained model can perform mesh reconstruction and tracking at a rate of\n58Hz on a template mesh of 3000 vertices and a deformed point cloud of 5000\npoints and is generalizable to the deformations of six different object\ncategories which are assumed to be made of soft material in our experiments\n(scissors, hammer, foam brick, cleanser bottle, orange, and dice). The object\nmeshes are taken from the YCB benchmark dataset. An instance of a downstream\napplication can be the control algorithm for a robotic hand that requires\nonline feedback from the state of the manipulated object which would allow\nonline grasp adaptation in a closed-loop manner. Furthermore, the tracking\ncapacity of our method can help in the system identification of deforming\nobjects in a marker-free approach. In future work, we will extend our trained\nmodel to generalize beyond six object categories and additionally to real-world\ndeforming point clouds.\n","authors":["Elham Amin Mansour","Hehui Zheng","Robert K. Katzschmann"],"pdf_url":"https://arxiv.org/pdf/2311.02749v3.pdf","comment":"8 pages with appendix,16 figures"},{"id":"http://arxiv.org/abs/2302.08463v3","updated":"2024-03-26T21:33:23Z","published":"2023-02-16T18:14:13Z","title":"Dynamic Grasping with a Learned Meta-Controller","summary":"  Grasping moving objects is a challenging task that requires multiple\nsubmodules such as object pose predictor, arm motion planner, etc. Each\nsubmodule operates under its own set of meta-parameters. For example, how far\nthe pose predictor should look into the future (i.e., look-ahead time) and the\nmaximum amount of time the motion planner can spend planning a motion (i.e.,\ntime budget). Many previous works assign fixed values to these parameters;\nhowever, at different moments within a single episode of dynamic grasping, the\noptimal values should vary depending on the current scene. In this work, we\npropose a dynamic grasping pipeline with a meta-controller that controls the\nlook-ahead time and time budget dynamically. We learn the meta-controller\nthrough reinforcement learning with a sparse reward. Our experiments show the\nmeta-controller improves the grasping success rate (up to 28% in the most\ncluttered environment) and reduces grasping time, compared to the strongest\nbaseline. Our meta-controller learns to reason about the reachable workspace\nand maintain the predicted pose within the reachable region. In addition, it\nassigns a small but sufficient time budget for the motion planner. Our method\ncan handle different objects, trajectories, and obstacles. Despite being\ntrained only with 3-6 random cuboidal obstacles, our meta-controller\ngeneralizes well to 7-9 obstacles and more realistic out-of-domain household\nsetups with unseen obstacle shapes.\n","authors":["Yinsen Jia","Jingxi Xu","Dinesh Jayaraman","Shuran Song"],"pdf_url":"https://arxiv.org/pdf/2302.08463v3.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2312.02126v2","updated":"2024-03-26T21:20:57Z","published":"2023-12-04T18:53:24Z","title":"SplaTAM: Splat, Track & Map 3D Gaussians for Dense RGB-D SLAM","summary":"  Dense simultaneous localization and mapping (SLAM) is crucial for robotics\nand augmented reality applications. However, current methods are often hampered\nby the non-volumetric or implicit way they represent a scene. This work\nintroduces SplaTAM, an approach that, for the first time, leverages explicit\nvolumetric representations, i.e., 3D Gaussians, to enable high-fidelity\nreconstruction from a single unposed RGB-D camera, surpassing the capabilities\nof existing methods. SplaTAM employs a simple online tracking and mapping\nsystem tailored to the underlying Gaussian representation. It utilizes a\nsilhouette mask to elegantly capture the presence of scene density. This\ncombination enables several benefits over prior representations, including fast\nrendering and dense optimization, quickly determining if areas have been\npreviously mapped, and structured map expansion by adding more Gaussians.\nExtensive experiments show that SplaTAM achieves up to 2x superior performance\nin camera pose estimation, map construction, and novel-view synthesis over\nexisting methods, paving the way for more immersive high-fidelity SLAM\napplications.\n","authors":["Nikhil Keetha","Jay Karhade","Krishna Murthy Jatavallabhula","Gengshan Yang","Sebastian Scherer","Deva Ramanan","Jonathon Luiten"],"pdf_url":"https://arxiv.org/pdf/2312.02126v2.pdf","comment":"CVPR 2024. Website: https://spla-tam.github.io/"},{"id":"http://arxiv.org/abs/2403.18096v1","updated":"2024-03-26T20:41:35Z","published":"2024-03-26T20:41:35Z","title":"Efficient Multi-Band Temporal Video Filter for Reducing Human-Robot\n  Interaction","summary":"  Although mobile robots have on-board sensors to perform navigation, their\nefficiency in completing paths can be enhanced by planning to avoid human\ninteraction. Infrastructure cameras can capture human activity continuously for\nthe purpose of compiling activity analytics to choose efficient times and\nroutes. We describe a cascade temporal filtering method to efficiently extract\nshort- and long-term activity in two time dimensions, isochronal and\nchronological, for use in global path planning and local navigation\nrespectively. The temporal filter has application either independently, or, if\nobject recognition is also required, it can be used as a pre-filter to perform\nactivity-gating of the more computationally expensive neural network\nprocessing. For a testbed 32-camera network, we show how this hybrid approach\ncan achieve over 8 times improvement in frames per second throughput and 6.5\ntimes reduction of system power use. We also show how the cost map of static\nobjects in the ROS robot software development framework is augmented with\ndynamic regions determined from the temporal filter.\n","authors":["Lawrence O'Gorman"],"pdf_url":"https://arxiv.org/pdf/2403.18096v1.pdf","comment":"15 pages, 5 figures, 4 tables"},{"id":"http://arxiv.org/abs/2403.18066v1","updated":"2024-03-26T19:35:22Z","published":"2024-03-26T19:35:22Z","title":"Path Integral Control with Rollout Clustering and Dynamic Obstacles","summary":"  Model Predictive Path Integral (MPPI) control has proven to be a powerful\ntool for the control of uncertain systems (such as systems subject to\ndisturbances and systems with unmodeled dynamics). One important limitation of\nthe baseline MPPI algorithm is that it does not utilize simulated trajectories\nto their fullest extent. For one, it assumes that the average of all\ntrajectories weighted by their performance index will be a safe trajectory. In\nthis paper, multiple examples are shown where the previous assumption does not\nhold, and a trajectory clustering technique is presented that reduces the\nchances of the weighted average crossing in an unsafe region. Secondly, MPPI\ndoes not account for dynamic obstacles, so the authors put forward a novel cost\nfunction that accounts for dynamic obstacles without adding significant\ncomputation time to the overall algorithm. The novel contributions proposed in\nthis paper were evaluated with extensive simulations to demonstrate\nimprovements upon the state-of-the-art MPPI techniques.\n","authors":["Steven Patrick","Efstathios Bakolas"],"pdf_url":"https://arxiv.org/pdf/2403.18066v1.pdf","comment":"8 pages, 5 figures, extended version of ACC 2024 submission"},{"id":"http://arxiv.org/abs/2403.18062v1","updated":"2024-03-26T19:26:53Z","published":"2024-03-26T19:26:53Z","title":"ShapeGrasp: Zero-Shot Task-Oriented Grasping with Large Language Models\n  through Geometric Decomposition","summary":"  Task-oriented grasping of unfamiliar objects is a necessary skill for robots\nin dynamic in-home environments. Inspired by the human capability to grasp such\nobjects through intuition about their shape and structure, we present a novel\nzero-shot task-oriented grasping method leveraging a geometric decomposition of\nthe target object into simple, convex shapes that we represent in a graph\nstructure, including geometric attributes and spatial relationships. Our\napproach employs minimal essential information - the object's name and the\nintended task - to facilitate zero-shot task-oriented grasping. We utilize the\ncommonsense reasoning capabilities of large language models to dynamically\nassign semantic meaning to each decomposed part and subsequently reason over\nthe utility of each part for the intended task. Through extensive experiments\non a real-world robotics platform, we demonstrate that our grasping approach's\ndecomposition and reasoning pipeline is capable of selecting the correct part\nin 92% of the cases and successfully grasping the object in 82% of the tasks we\nevaluate. Additional videos, experiments, code, and data are available on our\nproject website: https://shapegrasp.github.io/.\n","authors":["Samuel Li","Sarthak Bhagat","Joseph Campbell","Yaqi Xie","Woojun Kim","Katia Sycara","Simon Stepputtis"],"pdf_url":"https://arxiv.org/pdf/2403.18062v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2312.08344v2","updated":"2024-03-26T19:25:53Z","published":"2023-12-13T18:28:09Z","title":"FoundationPose: Unified 6D Pose Estimation and Tracking of Novel Objects","summary":"  We present FoundationPose, a unified foundation model for 6D object pose\nestimation and tracking, supporting both model-based and model-free setups. Our\napproach can be instantly applied at test-time to a novel object without\nfine-tuning, as long as its CAD model is given, or a small number of reference\nimages are captured. We bridge the gap between these two setups with a neural\nimplicit representation that allows for effective novel view synthesis, keeping\nthe downstream pose estimation modules invariant under the same unified\nframework. Strong generalizability is achieved via large-scale synthetic\ntraining, aided by a large language model (LLM), a novel transformer-based\narchitecture, and contrastive learning formulation. Extensive evaluation on\nmultiple public datasets involving challenging scenarios and objects indicate\nour unified approach outperforms existing methods specialized for each task by\na large margin. In addition, it even achieves comparable results to\ninstance-level methods despite the reduced assumptions. Project page:\nhttps://nvlabs.github.io/FoundationPose/\n","authors":["Bowen Wen","Wei Yang","Jan Kautz","Stan Birchfield"],"pdf_url":"https://arxiv.org/pdf/2312.08344v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18041v1","updated":"2024-03-26T18:52:50Z","published":"2024-03-26T18:52:50Z","title":"Learning Piecewise Residuals of Control Barrier Functions for Safety of\n  Switching Systems using Multi-Output Gaussian Processes","summary":"  Control barrier functions (CBFs) have recently been introduced as a\nsystematic tool to ensure safety by establishing set invariance. When combined\nwith a control Lyapunov function (CLF), they form a safety-critical control\nmechanism. However, the effectiveness of CBFs and CLFs is closely tied to the\nsystem model. In practice, model uncertainty can jeopardize safety and\nstability guarantees and may lead to undesirable performance. In this paper, we\ndevelop a safe learning-based control strategy for switching systems in the\nface of uncertainty. We focus on the case that a nominal model is available for\na true underlying switching system. This uncertainty results in piecewise\nresiduals for each switching surface, impacting the CLF and CBF constraints. We\nintroduce a batch multi-output Gaussian process (MOGP) framework to approximate\nthese piecewise residuals, thereby mitigating the adverse effects of\nuncertainty. A particular structure of the covariance function enables us to\nconvert the MOGP-based chance constraints CLF and CBF into second-order cone\nconstraints, which leads to a convex optimization. We analyze the feasibility\nof the resulting optimization and provide the necessary and sufficient\nconditions for feasibility. The effectiveness of the proposed strategy is\nvalidated through a simulation of a switching adaptive cruise control system.\n","authors":["Mohammad Aali","Jun Liu"],"pdf_url":"https://arxiv.org/pdf/2403.18041v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2403.09573"},{"id":"http://arxiv.org/abs/2403.18033v1","updated":"2024-03-26T18:39:38Z","published":"2024-03-26T18:39:38Z","title":"SpectralWaste Dataset: Multimodal Data for Waste Sorting Automation","summary":"  The increase in non-biodegradable waste is a worldwide concern. Recycling\nfacilities play a crucial role, but their automation is hindered by the complex\ncharacteristics of waste recycling lines like clutter or object deformation. In\naddition, the lack of publicly available labeled data for these environments\nmakes developing robust perception systems challenging. Our work explores the\nbenefits of multimodal perception for object segmentation in real waste\nmanagement scenarios. First, we present SpectralWaste, the first dataset\ncollected from an operational plastic waste sorting facility that provides\nsynchronized hyperspectral and conventional RGB images. This dataset contains\nlabels for several categories of objects that commonly appear in sorting plants\nand need to be detected and separated from the main trash flow for several\nreasons, such as security in the management line or reuse. Additionally, we\npropose a pipeline employing different object segmentation architectures and\nevaluate the alternatives on our dataset, conducting an extensive analysis for\nboth multimodal and unimodal alternatives. Our evaluation pays special\nattention to efficiency and suitability for real-time processing and\ndemonstrates how HSI can bring a boost to RGB-only perception in these\nrealistic industrial settings without much computational overhead.\n","authors":["Sara Casao","Fernando Peña","Alberto Sabater","Rosa Castillón","Darío Suárez","Eduardo Montijano","Ana C. Murillo"],"pdf_url":"https://arxiv.org/pdf/2403.18033v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18021v1","updated":"2024-03-26T18:13:20Z","published":"2024-03-26T18:13:20Z","title":"A Study on the Use of Simulation in Synthesizing Path-Following Control\n  Policies for Autonomous Ground Robots","summary":"  We report results obtained and insights gained while answering the following\nquestion: how effective is it to use a simulator to establish path following\ncontrol policies for an autonomous ground robot? While the quality of the\nsimulator conditions the answer to this question, we found that for the\nsimulation platform used herein, producing four control policies for path\nplanning was straightforward once a digital twin of the controlled robot was\navailable. The control policies established in simulation and subsequently\ndemonstrated in the real world are PID control, MPC, and two neural network\n(NN) based controllers. Training the two NN controllers via imitation learning\nwas accomplished expeditiously using seven simple maneuvers: follow three\ncircles clockwise, follow the same circles counter-clockwise, and drive\nstraight. A test randomization process that employs random micro-simulations is\nused to rank the ``goodness'' of the four control policies. The policy ranking\nnoted in simulation correlates well with the ranking observed when the control\npolicies were tested in the real world. The simulation platform used is\npublicly available and BSD3-released as open source; a public Docker image is\navailable for reproducibility studies. It contains a dynamics engine, a sensor\nsimulator, a ROS2 bridge, and a ROS2 autonomy stack the latter employed both in\nthe simulator and the real world experiments.\n","authors":["Harry Zhang","Stefan Caldararu","Aaron Young","Alexis Ruiz","Huzaifa Unjhawala","Ishaan Mahajan","Sriram Ashokkumar","Nevindu Batagoda","Zhenhao Zhou","Luning Bakke","Dan Negrut"],"pdf_url":"https://arxiv.org/pdf/2403.18021v1.pdf","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2403.18015v1","updated":"2024-03-26T18:04:10Z","published":"2024-03-26T18:04:10Z","title":"A Constructive Method for Designing Safe Multirate Controllers for\n  Differentially-Flat Systems","summary":"  We present a multi-rate control architecture that leverages fundamental\nproperties of differential flatness to synthesize controllers for\nsafety-critical nonlinear dynamical systems. We propose a two-layer\narchitecture, where the high-level generates reference trajectories using a\nlinear Model Predictive Controller, and the low-level tracks this reference\nusing a feedback controller. The novelty lies in how we couple these layers, to\nachieve formal guarantees on recursive feasibility of the MPC problem, and\nsafety of the nonlinear system. Furthermore, using differential flatness, we\nprovide a constructive means to synthesize the multi-rate controller, thereby\nremoving the need to search for suitable Lyapunov or barrier functions, or to\napproximately linearize/discretize nonlinear dynamics. We show the synthesized\ncontroller is a convex optimization problem, making it amenable to real-time\nimplementations. The method is demonstrated experimentally on a ground rover\nand a quadruped robotic system.\n","authors":["Devansh R. Agrawal","Hardik Parwana","Ryan K. Cosner","Ugo Rosolia","Aaron D. Ames","Dimitra Panagou"],"pdf_url":"https://arxiv.org/pdf/2403.18015v1.pdf","comment":"6 pages, 3 figures, accepted at IEEE Control Systems Letters 2021"}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2403.08763v3","updated":"2024-03-26T17:58:48Z","published":"2024-03-13T17:58:57Z","title":"Simple and Scalable Strategies to Continually Pre-train Large Language\n  Models","summary":"  Large language models (LLMs) are routinely pre-trained on billions of tokens,\nonly to start the process over again once new data becomes available. A much\nmore efficient solution is to continually pre-train these models, saving\nsignificant compute compared to re-training. However, the distribution shift\ninduced by new data typically results in degraded performance on previous data\nor poor adaptation to the new data. In this work, we show that a simple and\nscalable combination of learning rate (LR) re-warming, LR re-decaying, and\nreplay of previous data is sufficient to match the performance of fully\nre-training from scratch on all available data, as measured by the final loss\nand the average score on several language model (LM) evaluation benchmarks.\nSpecifically, we show this for a weak but realistic distribution shift between\ntwo commonly used LLM pre-training datasets (English$\\rightarrow$English) and a\nstronger distribution shift (English$\\rightarrow$German) at the $405$M\nparameter model scale with large dataset sizes (hundreds of billions of\ntokens). Selecting the weak but realistic shift for larger-scale experiments,\nwe also find that our continual learning strategies match the re-training\nbaseline for a 10B parameter LLM. Our results demonstrate that LLMs can be\nsuccessfully updated via simple and scalable continual learning strategies,\nmatching the re-training baseline using only a fraction of the compute.\nFinally, inspired by previous work, we propose alternatives to the cosine\nlearning rate schedule that help circumvent forgetting induced by LR re-warming\nand that are not bound to a fixed token budget.\n","authors":["Adam Ibrahim","Benjamin Thérien","Kshitij Gupta","Mats L. Richter","Quentin Anthony","Timothée Lesort","Eugene Belilovsky","Irina Rish"],"pdf_url":"https://arxiv.org/pdf/2403.08763v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17933v1","updated":"2024-03-26T17:58:29Z","published":"2024-03-26T17:58:29Z","title":"SLEDGE: Synthesizing Simulation Environments for Driving Agents with\n  Generative Models","summary":"  SLEDGE is the first generative simulator for vehicle motion planning trained\non real-world driving logs. Its core component is a learned model that is able\nto generate agent bounding boxes and lane graphs. The model's outputs serve as\nan initial state for traffic simulation. The unique properties of the entities\nto be generated for SLEDGE, such as their connectivity and variable count per\nscene, render the naive application of most modern generative models to this\ntask non-trivial. Therefore, together with a systematic study of existing lane\ngraph representations, we introduce a novel raster-to-vector autoencoder\n(RVAE). It encodes agents and the lane graph into distinct channels in a\nrasterized latent map. This facilitates both lane-conditioned agent generation\nand combined generation of lanes and agents with a Diffusion Transformer. Using\ngenerated entities in SLEDGE enables greater control over the simulation, e.g.\nupsampling turns or increasing traffic density. Further, SLEDGE can support\n500m long routes, a capability not found in existing data-driven simulators\nlike nuPlan. It presents new challenges for planning algorithms, evidenced by\nfailure rates of over 40% for PDM, the winner of the 2023 nuPlan challenge,\nwhen tested on hard routes and dense traffic generated by our model. Compared\nto nuPlan, SLEDGE requires 500$\\times$ less storage to set up (<4GB), making it\na more accessible option and helping with democratizing future research in this\nfield.\n","authors":["Kashyap Chitta","Daniel Dauner","Andreas Geiger"],"pdf_url":"https://arxiv.org/pdf/2403.17933v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17927v1","updated":"2024-03-26T17:57:57Z","published":"2024-03-26T17:57:57Z","title":"MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution","summary":"  In software evolution, resolving the emergent issues within GitHub\nrepositories is a complex challenge that involves not only the incorporation of\nnew code but also the maintenance of existing functionalities. Large Language\nModels (LLMs) have shown promise in code generation and understanding but face\ndifficulties in code change, particularly at the repository level. To overcome\nthese challenges, we empirically study the reason why LLMs mostly fail to\nresolve GitHub issues and analyze some impact factors. Motivated by the\nempirical findings, we propose a novel LLM-based Multi-Agent framework for\nGitHub Issue reSolution, MAGIS, consisting of four kinds of agents customized\nfor the software evolution: Manager, Repository Custodian, Developer, and\nQuality Assurance Engineer agents. This framework leverages the collaboration\nof various agents in the planning and coding process to unlock the potential of\nLLMs to resolve GitHub issues. In experiments, we employ the SWE-bench\nbenchmark to compare MAGIS with popular LLMs, including GPT-3.5, GPT-4, and\nClaude-2. MAGIS can resolve 13.94% GitHub issues, which significantly\noutperforms the baselines. Specifically, MAGIS achieves an eight-fold increase\nin resolved ratio over the direct application of GPT-4, the based LLM of our\nmethod. We also analyze the factors for improving GitHub issue resolution\nrates, such as line location, task allocation, etc.\n","authors":["Wei Tao","Yucheng Zhou","Wenqiang Zhang","Yu Cheng"],"pdf_url":"https://arxiv.org/pdf/2403.17927v1.pdf","comment":"work in progress"},{"id":"http://arxiv.org/abs/2403.17924v1","updated":"2024-03-26T17:57:05Z","published":"2024-03-26T17:57:05Z","title":"AID: Attention Interpolation of Text-to-Image Diffusion","summary":"  Conditional diffusion models can create unseen images in various settings,\naiding image interpolation. Interpolation in latent spaces is well-studied, but\ninterpolation with specific conditions like text or poses is less understood.\nSimple approaches, such as linear interpolation in the space of conditions,\noften result in images that lack consistency, smoothness, and fidelity. To that\nend, we introduce a novel training-free technique named Attention Interpolation\nvia Diffusion (AID). Our key contributions include 1) proposing an inner/outer\ninterpolated attention layer; 2) fusing the interpolated attention with\nself-attention to boost fidelity; and 3) applying beta distribution to\nselection to increase smoothness. We also present a variant, Prompt-guided\nAttention Interpolation via Diffusion (PAID), that considers interpolation as a\ncondition-dependent generative process. This method enables the creation of new\nimages with greater consistency, smoothness, and efficiency, and offers control\nover the exact path of interpolation. Our approach demonstrates effectiveness\nfor conceptual and spatial interpolation. Code and demo are available at\nhttps://github.com/QY-H00/attention-interpolation-diffusion.\n","authors":["Qiyuan He","Jinghao Wang","Ziwei Liu","Angela Yao"],"pdf_url":"https://arxiv.org/pdf/2403.17924v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17919v1","updated":"2024-03-26T17:55:02Z","published":"2024-03-26T17:55:02Z","title":"LISA: Layerwise Importance Sampling for Memory-Efficient Large Language\n  Model Fine-Tuning","summary":"  The machine learning community has witnessed impressive advancements since\nthe first appearance of large language models (LLMs), yet their huge memory\nconsumption has become a major roadblock to large-scale training. Parameter\nEfficient Fine-Tuning techniques such as Low-Rank Adaptation (LoRA) have been\nproposed to alleviate this problem, but their performance still fails to match\nfull parameter training in most large-scale fine-tuning settings. Attempting to\ncomplement this deficiency, we investigate layerwise properties of LoRA on\nfine-tuning tasks and observe an uncommon skewness of weight norms across\ndifferent layers. Utilizing this key observation, a surprisingly simple\ntraining strategy is discovered, which outperforms both LoRA and full parameter\ntraining in a wide range of settings with memory costs as low as LoRA. We name\nit Layerwise Importance Sampled AdamW (LISA), a promising alternative for LoRA,\nwhich applies the idea of importance sampling to different layers in LLMs and\nrandomly freeze most middle layers during optimization. Experimental results\nshow that with similar or less GPU memory consumption, LISA surpasses LoRA or\neven full parameter tuning in downstream fine-tuning tasks, where LISA\nconsistently outperforms LoRA by over $11\\%$-$37\\%$ in terms of MT-Bench\nscores. On large models, specifically LLaMA-2-70B, LISA achieves on-par or\nbetter performance than LoRA on MT-Bench, GSM8K, and PubMedQA, demonstrating\nits effectiveness across different domains.\n","authors":["Rui Pan","Xiang Liu","Shizhe Diao","Renjie Pi","Jipeng Zhang","Chi Han","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.17919v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17918v1","updated":"2024-03-26T17:54:15Z","published":"2024-03-26T17:54:15Z","title":"AgentStudio: A Toolkit for Building General Virtual Agents","summary":"  Creating autonomous virtual agents capable of using arbitrary software on any\ndigital device remains a major challenge for artificial intelligence. Two key\nobstacles hinder progress: insufficient infrastructure for building virtual\nagents in real-world environments, and the need for in-the-wild evaluation of\nfundamental agent abilities. To address this, we introduce AgentStudio, an\nonline, realistic, and multimodal toolkit that covers the entire lifecycle of\nagent development. This includes environment setups, data collection, agent\nevaluation, and visualization. The observation and action spaces are highly\ngeneric, supporting both function calling and human-computer interfaces. This\nversatility is further enhanced by AgentStudio's graphical user interfaces,\nwhich allow efficient development of datasets and benchmarks in real-world\nsettings. To illustrate, we introduce a visual grounding dataset and a\nreal-world benchmark suite, both created with our graphical interfaces.\nFurthermore, we present several actionable insights derived from AgentStudio,\ne.g., general visual grounding, open-ended tool creation, learning from videos,\netc. We have open-sourced the environments, datasets, benchmarks, and\ninterfaces to promote research towards developing general virtual agents for\nthe future.\n","authors":["Longtao Zheng","Zhiyuan Huang","Zhenghai Xue","Xinrun Wang","Bo An","Shuicheng Yan"],"pdf_url":"https://arxiv.org/pdf/2403.17918v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17916v1","updated":"2024-03-26T17:53:27Z","published":"2024-03-26T17:53:27Z","title":"CMP: Cooperative Motion Prediction with Multi-Agent Communication","summary":"  The confluence of the advancement of Autonomous Vehicles (AVs) and the\nmaturity of Vehicle-to-Everything (V2X) communication has enabled the\ncapability of cooperative connected and automated vehicles (CAVs). Building on\ntop of cooperative perception, this paper explores the feasibility and\neffectiveness of cooperative motion prediction. Our method, CMP, takes LiDAR\nsignals as input to enhance tracking and prediction capabilities. Unlike\nprevious work that focuses separately on either cooperative perception or\nmotion prediction, our framework, to the best of our knowledge, is the first to\naddress the unified problem where CAVs share information in both perception and\nprediction modules. Incorporated into our design is the unique capability to\ntolerate realistic V2X bandwidth limitations and transmission delays, while\ndealing with bulky perception representations. We also propose a prediction\naggregation module, which unifies the predictions obtained by different CAVs\nand generates the final prediction. Through extensive experiments and ablation\nstudies, we demonstrate the effectiveness of our method in cooperative\nperception, tracking, and motion prediction tasks. In particular, CMP reduces\nthe average prediction error by 17.2\\% with fewer missing detections compared\nwith the no cooperation setting. Our work marks a significant step forward in\nthe cooperative capabilities of CAVs, showcasing enhanced performance in\ncomplex scenarios.\n","authors":["Zhuoyuan Wu","Yuping Wang","Hengbo Ma","Zhaowei Li","Hang Qiu","Jiachen Li"],"pdf_url":"https://arxiv.org/pdf/2403.17916v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17914v1","updated":"2024-03-26T17:51:06Z","published":"2024-03-26T17:51:06Z","title":"Hierarchical Multi-label Classification for Fine-level Event Extraction\n  from Aviation Accident Reports","summary":"  A large volume of accident reports is recorded in the aviation domain, which\ngreatly values improving aviation safety. To better use those reports, we need\nto understand the most important events or impact factors according to the\naccident reports. However, the increasing number of accident reports requires\nlarge efforts from domain experts to label those reports. In order to make the\nlabeling process more efficient, many researchers have started developing\nalgorithms to identify the underlying events from accident reports\nautomatically. This article argues that we can identify the events more\naccurately by leveraging the event taxonomy. More specifically, we consider the\nproblem a hierarchical classification task where we first identify the\ncoarse-level information and then predict the fine-level information. We\nachieve this hierarchical classification process by incorporating a novel\nhierarchical attention module into BERT. To further utilize the information\nfrom event taxonomy, we regularize the proposed model according to the\nrelationship and distribution among labels. The effectiveness of our framework\nis evaluated with the data collected by National Transportation Safety Board\n(NTSB). It has been shown that fine-level prediction accuracy is highly\nimproved, and the regularization term can be beneficial to the rare event\nidentification problem.\n","authors":["Xinyu Zhao","Hao Yan","Yongming Liu"],"pdf_url":"https://arxiv.org/pdf/2403.17914v1.pdf","comment":"Accepted in INFORMS Journal of Data Science"},{"id":"http://arxiv.org/abs/2307.16897v2","updated":"2024-03-26T17:40:47Z","published":"2023-07-31T17:59:48Z","title":"DiVa-360: The Dynamic Visual Dataset for Immersive Neural Fields","summary":"  Advances in neural fields are enabling high-fidelity capture of the shape and\nappearance of dynamic 3D scenes. However, their capabilities lag behind those\noffered by conventional representations such as 2D videos because of\nalgorithmic challenges and the lack of large-scale multi-view real-world\ndatasets. We address the dataset limitation with DiVa-360, a real-world 360\ndynamic visual dataset that contains synchronized high-resolution and\nlong-duration multi-view video sequences of table-scale scenes captured using a\ncustomized low-cost system with 53 cameras. It contains 21 object-centric\nsequences categorized by different motion types, 25 intricate hand-object\ninteraction sequences, and 8 long-duration sequences for a total of 17.4 M\nimage frames. In addition, we provide foreground-background segmentation masks,\nsynchronized audio, and text descriptions. We benchmark the state-of-the-art\ndynamic neural field methods on DiVa-360 and provide insights about existing\nmethods and future challenges on long-duration neural field capture.\n","authors":["Cheng-You Lu","Peisen Zhou","Angela Xing","Chandradeep Pokhariya","Arnab Dey","Ishaan Shah","Rugved Mavidipalli","Dylan Hu","Andrew Comport","Kefan Chen","Srinath Sridhar"],"pdf_url":"https://arxiv.org/pdf/2307.16897v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17891v1","updated":"2024-03-26T17:22:29Z","published":"2024-03-26T17:22:29Z","title":"Image-based Novel Fault Detection with Deep Learning Classifiers using\n  Hierarchical Labels","summary":"  One important characteristic of modern fault classification systems is the\nability to flag the system when faced with previously unseen fault types. This\nwork considers the unknown fault detection capabilities of deep neural\nnetwork-based fault classifiers. Specifically, we propose a methodology on how,\nwhen available, labels regarding the fault taxonomy can be used to increase\nunknown fault detection performance without sacrificing model performance. To\nachieve this, we propose to utilize soft label techniques to improve the\nstate-of-the-art deep novel fault detection techniques during the training\nprocess and novel hierarchically consistent detection statistics for online\nnovel fault detection. Finally, we demonstrated increased detection performance\non novel fault detection in inspection images from the hot steel rolling\nprocess, with results well replicated across multiple scenarios and baseline\ndetection methods.\n","authors":["Nurettin Sergin","Jiayu Huang","Tzyy-Shuh Chang","Hao Yan"],"pdf_url":"https://arxiv.org/pdf/2403.17891v1.pdf","comment":"Accepted in IISE Transaction"},{"id":"http://arxiv.org/abs/2403.04202v3","updated":"2024-03-26T17:18:33Z","published":"2024-03-07T04:12:24Z","title":"Dynamics of Moral Behavior in Heterogeneous Populations of Learning\n  Agents","summary":"  Growing concerns about safety and alignment of AI systems highlight the\nimportance of embedding moral capabilities in artificial agents. A promising\nsolution is the use of learning from experience, i.e., Reinforcement Learning.\nIn multi-agent (social) environments, complex population-level phenomena may\nemerge from interactions between individual learning agents. Many of the\nexisting studies rely on simulated social dilemma environments to study the\ninteractions of independent learning agents. However, they tend to ignore the\nmoral heterogeneity that is likely to be present in societies of agents in\npractice. For example, at different points in time a single learning agent may\nface opponents who are consequentialist (i.e., caring about maximizing some\noutcome over time) or norm-based (i.e., focusing on conforming to a specific\nnorm here and now). The extent to which agents' co-development may be impacted\nby such moral heterogeneity in populations is not well understood. In this\npaper, we present a study of the learning dynamics of morally heterogeneous\npopulations interacting in a social dilemma setting. Using a Prisoner's Dilemma\nenvironment with a partner selection mechanism, we investigate the extent to\nwhich the prevalence of diverse moral agents in populations affects individual\nagents' learning behaviors and emergent population-level outcomes. We observe\nseveral types of non-trivial interactions between pro-social and anti-social\nagents, and find that certain classes of moral agents are able to steer selfish\nagents towards more cooperative behavior.\n","authors":["Elizaveta Tennant","Stephen Hailes","Mirco Musolesi"],"pdf_url":"https://arxiv.org/pdf/2403.04202v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.03773v3","updated":"2024-03-26T17:17:39Z","published":"2023-04-04T21:49:02Z","title":"Safe Explicable Planning","summary":"  Human expectations arise from their understanding of others and the world. In\nthe context of human-AI interaction, this understanding may not align with\nreality, leading to the AI agent failing to meet expectations and compromising\nteam performance. Explicable planning, introduced as a method to bridge this\ngap, aims to reconcile human expectations with the agent's optimal behavior,\nfacilitating interpretable decision-making. However, an unresolved critical\nissue is ensuring safety in explicable planning, as it could result in\nexplicable behaviors that are unsafe. To address this, we propose Safe\nExplicable Planning (SEP), which extends the prior work to support the\nspecification of a safety bound. The goal of SEP is to find behaviors that\nalign with human expectations while adhering to the specified safety criterion.\nOur approach generalizes the consideration of multiple objectives stemming from\nmultiple models rather than a single model, yielding a Pareto set of safe\nexplicable policies. We present both an exact method, guaranteeing finding the\nPareto set, and a more efficient greedy method that finds one of the policies\nin the Pareto set. Additionally, we offer approximate solutions based on state\naggregation to improve scalability. We provide formal proofs that validate the\ndesired theoretical properties of these methods. Evaluation through simulations\nand physical robot experiments confirms the effectiveness of our approach for\nsafe explicable planning.\n","authors":["Akkamahadevi Hanni","Andrew Boateng","Yu Zhang"],"pdf_url":"https://arxiv.org/pdf/2304.03773v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17873v1","updated":"2024-03-26T17:02:42Z","published":"2024-03-26T17:02:42Z","title":"Addressing Social Misattributions of Large Language Models: An\n  HCXAI-based Approach","summary":"  Human-centered explainable AI (HCXAI) advocates for the integration of social\naspects into AI explanations. Central to the HCXAI discourse is the Social\nTransparency (ST) framework, which aims to make the socio-organizational\ncontext of AI systems accessible to their users. In this work, we suggest\nextending the ST framework to address the risks of social misattributions in\nLarge Language Models (LLMs), particularly in sensitive areas like mental\nhealth. In fact LLMs, which are remarkably capable of simulating roles and\npersonas, may lead to mismatches between designers' intentions and users'\nperceptions of social attributes, risking to promote emotional manipulation and\ndangerous behaviors, cases of epistemic injustice, and unwarranted trust. To\naddress these issues, we propose enhancing the ST framework with a fifth\n'W-question' to clarify the specific social attributions assigned to LLMs by\nits designers and users. This addition aims to bridge the gap between LLM\ncapabilities and user perceptions, promoting the ethically responsible\ndevelopment and use of LLM-based technology.\n","authors":["Andrea Ferrario","Alberto Termine","Alessandro Facchini"],"pdf_url":"https://arxiv.org/pdf/2403.17873v1.pdf","comment":"Extended version of the manuscript accepted for the ACM CHI Workshop\n  on Human-Centered Explainable AI 2024 (HCXAI24)"},{"id":"http://arxiv.org/abs/2401.06795v2","updated":"2024-03-26T16:44:34Z","published":"2024-01-08T18:42:55Z","title":"AI and Generative AI for Research Discovery and Summarization","summary":"  AI and generative AI tools, including chatbots like ChatGPT that rely on\nlarge language models (LLMs), have burst onto the scene this year, creating\nincredible opportunities to increase work productivity and improve our lives.\nStatisticians and data scientists have begun experiencing the benefits from the\navailability of these tools in numerous ways, such as the generation of\nprogramming code from text prompts to analyze data or fit statistical models.\nOne area that these tools can make a substantial impact is in research\ndiscovery and summarization. Standalone tools and plugins to chatbots are being\ndeveloped that allow researchers to more quickly find relevant literature than\npre-2023 search tools. Furthermore, generative AI tools have improved to the\npoint where they can summarize and extract the key points from research\narticles in succinct language. Finally, chatbots based on highly parameterized\nLLMs can be used to simulate abductive reasoning, which provides researchers\nthe ability to make connections among related technical topics, which can also\nbe used for research discovery. We review the developments in AI and generative\nAI for research discovery and summarization, and propose directions where these\ntypes of tools are likely to head in the future that may be of interest to\nstatistician and data scientists.\n","authors":["Mark Glickman","Yi Zhang"],"pdf_url":"https://arxiv.org/pdf/2401.06795v2.pdf","comment":"29 pages, 9 figures"},{"id":"http://arxiv.org/abs/2403.17847v1","updated":"2024-03-26T16:36:50Z","published":"2024-03-26T16:36:50Z","title":"Climate Downscaling: A Deep-Learning Based Super-resolution Model of\n  Precipitation Data with Attention Block and Skip Connections","summary":"  Human activities accelerate consumption of fossil fuels and produce\ngreenhouse gases, resulting in urgent issues today: global warming and the\nclimate change. These indirectly cause severe natural disasters, plenty of\nlives suffering and huge losses of agricultural properties. To mitigate impacts\non our lands, scientists are developing renewable, reusable, and clean energies\nand climatologists are trying to predict the extremes. Meanwhile, governments\nare publicizing resource-saving policies for a more eco-friendly society and\narousing environment awareness. One of the most influencing factors is the\nprecipitation, bringing condensed water vapor onto lands. Water resources are\nthe most significant but basic needs in society, not only supporting our\nlivings, but also economics. In Taiwan, although the average annual\nprecipitation is up to 2,500 millimeter (mm), the water allocation for each\nperson is lower than the global average due to drastically geographical\nelevation changes and uneven distribution through the year. Thus, it is crucial\nto track and predict the rainfall to make the most use of it and to prevent the\nfloods. However, climate models have limited resolution and require intensive\ncomputational power for local-scale use. Therefore, we proposed a deep\nconvolutional neural network with skip connections, attention blocks, and\nauxiliary data concatenation, in order to downscale the low-resolution\nprecipitation data into high-resolution one. Eventually, we compare with other\nclimate downscaling methods and show better performance in metrics of Mean\nAbsolute Error (MAE), Root Mean Square Error (RMSE), Pearson Correlation,\nstructural similarity index (SSIM), and forecast indicators.\n","authors":["Chia-Hao Chiang","Zheng-Han Huang","Liwen Liu","Hsin-Chien Liang","Yi-Chi Wang","Wan-Ling Tseng","Chao Wang","Che-Ta Chen","Ko-Chih Wang"],"pdf_url":"https://arxiv.org/pdf/2403.17847v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17846v1","updated":"2024-03-26T16:36:43Z","published":"2024-03-26T16:36:43Z","title":"Hierarchical Open-Vocabulary 3D Scene Graphs for Language-Grounded Robot\n  Navigation","summary":"  Recent open-vocabulary robot mapping methods enrich dense geometric maps with\npre-trained visual-language features. While these maps allow for the prediction\nof point-wise saliency maps when queried for a certain language concept,\nlarge-scale environments and abstract queries beyond the object level still\npose a considerable hurdle, ultimately limiting language-grounded robotic\nnavigation. In this work, we present HOV-SG, a hierarchical open-vocabulary 3D\nscene graph mapping approach for language-grounded robot navigation. Leveraging\nopen-vocabulary vision foundation models, we first obtain state-of-the-art\nopen-vocabulary segment-level maps in 3D and subsequently construct a 3D scene\ngraph hierarchy consisting of floor, room, and object concepts, each enriched\nwith open-vocabulary features. Our approach is able to represent multi-story\nbuildings and allows robotic traversal of those using a cross-floor Voronoi\ngraph. HOV-SG is evaluated on three distinct datasets and surpasses previous\nbaselines in open-vocabulary semantic accuracy on the object, room, and floor\nlevel while producing a 75% reduction in representation size compared to dense\nopen-vocabulary maps. In order to prove the efficacy and generalization\ncapabilities of HOV-SG, we showcase successful long-horizon\nlanguage-conditioned robot navigation within real-world multi-storage\nenvironments. We provide code and trial video data at http://hovsg.github.io/.\n","authors":["Abdelrhman Werby","Chenguang Huang","Martin Büchner","Abhinav Valada","Wolfram Burgard"],"pdf_url":"https://arxiv.org/pdf/2403.17846v1.pdf","comment":"Code and video are available at http://hovsg.github.io/"},{"id":"http://arxiv.org/abs/2403.17839v1","updated":"2024-03-26T16:27:37Z","published":"2024-03-26T16:27:37Z","title":"ReMamber: Referring Image Segmentation with Mamba Twister","summary":"  Referring Image Segmentation (RIS) leveraging transformers has achieved great\nsuccess on the interpretation of complex visual-language tasks. However, the\nquadratic computation cost makes it resource-consuming in capturing long-range\nvisual-language dependencies. Fortunately, Mamba addresses this with efficient\nlinear complexity in processing. However, directly applying Mamba to\nmulti-modal interactions presents challenges, primarily due to inadequate\nchannel interactions for the effective fusion of multi-modal data. In this\npaper, we propose ReMamber, a novel RIS architecture that integrates the power\nof Mamba with a multi-modal Mamba Twister block. The Mamba Twister explicitly\nmodels image-text interaction, and fuses textual and visual features through\nits unique channel and spatial twisting mechanism. We achieve the\nstate-of-the-art on three challenging benchmarks. Moreover, we conduct thorough\nanalyses of ReMamber and discuss other fusion designs using Mamba. These\nprovide valuable perspectives for future research.\n","authors":["Yuhuan Yang","Chaofan Ma","Jiangchao Yao","Zhun Zhong","Ya Zhang","Yanfeng Wang"],"pdf_url":"https://arxiv.org/pdf/2403.17839v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.03123v2","updated":"2024-03-26T16:22:54Z","published":"2023-04-13T16:01:28Z","title":"ChatGPT Needs SPADE (Sustainability, PrivAcy, Digital divide, and\n  Ethics) Evaluation: A Review","summary":"  ChatGPT is another large language model (LLM) vastly available for the\nconsumers on their devices but due to its performance and ability to converse\neffectively, it has gained a huge popularity amongst research as well as\nindustrial community. Recently, many studies have been published to show the\neffectiveness, efficiency, integration, and sentiments of chatGPT and other\nLLMs. In contrast, this study focuses on the important aspects that are mostly\noverlooked, i.e. sustainability, privacy, digital divide, and ethics and\nsuggests that not only chatGPT but every subsequent entry in the category of\nconversational bots should undergo Sustainability, PrivAcy, Digital divide, and\nEthics (SPADE) evaluation. This paper discusses in detail the issues and\nconcerns raised over chatGPT in line with aforementioned characteristics. We\nalso discuss the recent EU AI Act briefly in accordance with the SPADE\nevaluation. We support our hypothesis by some preliminary data collection and\nvisualizations along with hypothesized facts. We also suggest mitigations and\nrecommendations for each of the concerns. Furthermore, we also suggest some\npolicies and recommendations for AI policy act, if designed by the governments.\n","authors":["Sunder Ali Khowaja","Parus Khuwaja","Kapal Dev","Weizheng Wang","Lewis Nkenyereye"],"pdf_url":"https://arxiv.org/pdf/2305.03123v2.pdf","comment":"29 pages, 8 figures, 4 tables"},{"id":"http://arxiv.org/abs/2403.17827v1","updated":"2024-03-26T16:06:42Z","published":"2024-03-26T16:06:42Z","title":"DiffH2O: Diffusion-Based Synthesis of Hand-Object Interactions from\n  Textual Descriptions","summary":"  Generating natural hand-object interactions in 3D is challenging as the\nresulting hand and object motions are expected to be physically plausible and\nsemantically meaningful. Furthermore, generalization to unseen objects is\nhindered by the limited scale of available hand-object interaction datasets. We\npropose DiffH2O, a novel method to synthesize realistic, one or two-handed\nobject interactions from provided text prompts and geometry of the object. The\nmethod introduces three techniques that enable effective learning from limited\ndata. First, we decompose the task into a grasping stage and a text-based\ninteraction stage and use separate diffusion models for each. In the grasping\nstage, the model only generates hand motions, whereas in the interaction phase\nboth hand and object poses are synthesized. Second, we propose a compact\nrepresentation that tightly couples hand and object poses. Third, we propose\ntwo different guidance schemes to allow more control of the generated motions:\ngrasp guidance and detailed textual guidance. Grasp guidance takes a single\ntarget grasping pose and guides the diffusion model to reach this grasp at the\nend of the grasping stage, which provides control over the grasping pose. Given\na grasping motion from this stage, multiple different actions can be prompted\nin the interaction phase. For textual guidance, we contribute comprehensive\ntext descriptions to the GRAB dataset and show that they enable our method to\nhave more fine-grained control over hand-object interactions. Our quantitative\nand qualitative evaluation demonstrates that the proposed method outperforms\nbaseline methods and leads to natural hand-object motions. Moreover, we\ndemonstrate the practicality of our framework by utilizing a hand pose estimate\nfrom an off-the-shelf pose estimator for guidance, and then sampling multiple\ndifferent actions in the interaction stage.\n","authors":["Sammy Christen","Shreyas Hampali","Fadime Sener","Edoardo Remelli","Tomas Hodan","Eric Sauser","Shugao Ma","Bugra Tekin"],"pdf_url":"https://arxiv.org/pdf/2403.17827v1.pdf","comment":"Project Page: https://diffh2o.github.io/"},{"id":"http://arxiv.org/abs/2403.17826v1","updated":"2024-03-26T16:06:33Z","published":"2024-03-26T16:06:33Z","title":"On the Computational Complexity of Stackelberg Planning and\n  Meta-Operator Verification: Technical Report","summary":"  Stackelberg planning is a recently introduced single-turn two-player\nadversarial planning model, where two players are acting in a joint classical\nplanning task, the objective of the first player being hampering the second\nplayer from achieving its goal. This places the Stackelberg planning problem\nsomewhere between classical planning and general combinatorial two-player\ngames. But, where exactly? All investigations of Stackelberg planning so far\nfocused on practical aspects. We close this gap by conducting the first\ntheoretical complexity analysis of Stackelberg planning. We show that in\ngeneral Stackelberg planning is actually no harder than classical planning.\nUnder a polynomial plan-length restriction, however, Stackelberg planning is a\nlevel higher up in the polynomial complexity hierarchy, suggesting that\ncompilations into classical planning come with a worst-case exponential\nplan-length increase. In attempts to identify tractable fragments, we further\nstudy its complexity under various planning task restrictions, showing that\nStackelberg planning remains intractable where classical planning is not. We\nfinally inspect the complexity of meta-operator verification, a problem that\nhas been recently connected to Stackelberg planning.\n","authors":["Gregor Behnke","Marcel Steinmetz"],"pdf_url":"https://arxiv.org/pdf/2403.17826v1.pdf","comment":"Presented at ICAPS24"},{"id":"http://arxiv.org/abs/2403.14077v2","updated":"2024-03-26T16:02:36Z","published":"2024-03-21T01:57:30Z","title":"Can ChatGPT Detect DeepFakes? A Study of Using Multimodal Large Language\n  Models for Media Forensics","summary":"  DeepFakes, which refer to AI-generated media content, have become an\nincreasing concern due to their use as a means for disinformation. Detecting\nDeepFakes is currently solved with programmed machine learning algorithms. In\nthis work, we investigate the capabilities of multimodal large language models\n(LLMs) in DeepFake detection. We conducted qualitative and quantitative\nexperiments to demonstrate multimodal LLMs and show that they can expose\nAI-generated images through careful experimental design and prompt engineering.\nThis is interesting, considering that LLMs are not inherently tailored for\nmedia forensic tasks, and the process does not require programming. We discuss\nthe limitations of multimodal LLMs for these tasks and suggest possible\nimprovements.\n","authors":["Shan Jia","Reilin Lyu","Kangran Zhao","Yize Chen","Zhiyuan Yan","Yan Ju","Chuanbo Hu","Xin Li","Baoyuan Wu","Siwei Lyu"],"pdf_url":"https://arxiv.org/pdf/2403.14077v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15964v2","updated":"2024-03-26T15:58:26Z","published":"2023-11-27T16:07:37Z","title":"Efficient Pre-training for Localized Instruction Generation of Videos","summary":"  Procedural videos show step-by-step demonstrations of tasks like recipe\npreparation. Understanding such videos is challenging, involving the precise\nlocalization of steps and the generation of textual instructions. Manually\nannotating steps and writing instructions is costly, which limits the size of\ncurrent datasets and hinders effective learning. Leveraging large but noisy\nvideo-transcript datasets for pre-training can boost performance, but demands\nsignificant computational resources. Furthermore, transcripts contain\nirrelevant content and exhibit style variation compared to instructions written\nby human annotators. To mitigate both issues, we propose a technique,\nSieve-&-Swap, to automatically curate a smaller dataset: (i) Sieve filters\nirrelevant transcripts and (ii) Swap enhances the quality of the text\ninstruction by automatically replacing the transcripts with human-written\ninstructions from a text-only recipe dataset. The curated dataset, three orders\nof magnitude smaller than current web-scale datasets, enables efficient\ntraining of large-scale models with competitive performance. We complement our\nSieve-\\&-Swap approach with a Procedure Transformer (ProcX) for end-to-end step\nlocalization and instruction generation for procedural videos. When this model\nis pre-trained on our curated dataset, it achieves state-of-the-art performance\nin zero-shot and finetuning settings on YouCook2 and Tasty, while using a\nfraction of the computational resources.\n","authors":["Anil Batra","Davide Moltisanti","Laura Sevilla-Lara","Marcus Rohrbach","Frank Keller"],"pdf_url":"https://arxiv.org/pdf/2311.15964v2.pdf","comment":"This version has some missing experiments and elaborative technical\n  details"},{"id":"http://arxiv.org/abs/2403.17819v1","updated":"2024-03-26T15:54:48Z","published":"2024-03-26T15:54:48Z","title":"Accelerating Radio Spectrum Regulation Workflows with Large Language\n  Models (LLMs)","summary":"  Wireless spectrum regulation is a complex and demanding process due to the\nrapid pace of technological progress, increasing demand for spectrum, and a\nmultitude of stakeholders with potentially conflicting interests, alongside\nsignificant economic implications. To navigate this, regulators must engage\neffectively with all parties, keep pace with global technology trends, conduct\ntechnical evaluations, issue licenses in a timely manner, and comply with\nvarious legal and policy frameworks.\n  In light of these challenges, this paper demonstrates example applications of\nLarge Language Models (LLMs) to expedite spectrum regulatory processes. We\nexplore various roles that LLMs can play in this context while identifying some\nof the challenges to address. The paper also offers practical case studies and\ninsights, with appropriate experiments, highlighting the transformative\npotential of LLMs in spectrum management.\n","authors":["Amir Ghasemi","Paul Guinand"],"pdf_url":"https://arxiv.org/pdf/2403.17819v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17814v1","updated":"2024-03-26T15:52:36Z","published":"2024-03-26T15:52:36Z","title":"D-PAD: Deep-Shallow Multi-Frequency Patterns Disentangling for Time\n  Series Forecasting","summary":"  In time series forecasting, effectively disentangling intricate temporal\npatterns is crucial. While recent works endeavor to combine decomposition\ntechniques with deep learning, multiple frequencies may still be mixed in the\ndecomposed components, e.g., trend and seasonal. Furthermore, frequency domain\nanalysis methods, e.g., Fourier and wavelet transforms, have limitations in\nresolution in the time domain and adaptability. In this paper, we propose\nD-PAD, a deep-shallow multi-frequency patterns disentangling neural network for\ntime series forecasting. Specifically, a multi-component decomposing (MCD)\nblock is introduced to decompose the series into components with different\nfrequency ranges, corresponding to the \"shallow\" aspect. A\ndecomposition-reconstruction-decomposition (D-R-D) module is proposed to\nprogressively extract the information of frequencies mixed in the components,\ncorresponding to the \"deep\" aspect. After that, an interaction and fusion (IF)\nmodule is used to further analyze the components. Extensive experiments on\nseven real-world datasets demonstrate that D-PAD achieves the state-of-the-art\nperformance, outperforming the best baseline by an average of 9.48% and 7.15%\nin MSE and MAE, respectively.\n","authors":["Xiaobing Yuan","Ling Chen"],"pdf_url":"https://arxiv.org/pdf/2403.17814v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.12261v2","updated":"2024-03-26T15:52:06Z","published":"2024-01-22T00:37:01Z","title":"Analyzing the Quality Attributes of AI Vision Models in Open\n  Repositories Under Adversarial Attacks","summary":"  As AI models rapidly evolve, they are frequently released to open\nrepositories, such as HuggingFace. It is essential to perform quality assurance\nvalidation on these models before integrating them into the production\ndevelopment lifecycle. In addition to evaluating efficiency in terms of\nbalanced accuracy and computing costs, adversarial attacks are potential\nthreats to the robustness and explainability of AI models. Meanwhile, XAI\napplies algorithms that approximate inputs to outputs post-hoc to identify the\ncontributing features. Adversarial perturbations may also degrade the utility\nof XAI explanations that require further investigation. In this paper, we\npresent an integrated process designed for downstream evaluation tasks,\nincluding validating AI model accuracy, evaluating robustness with benchmark\nperturbations, comparing explanation utility, and assessing overhead. We\ndemonstrate an evaluation scenario involving six computer vision models, which\ninclude CNN-based, Transformer-based, and hybrid architectures, three types of\nperturbations, and five XAI methods, resulting in ninety unique combinations.\nThe process reveals the explanation utility among the XAI methods in terms of\nthe identified key areas responding to the adversarial perturbation. The\nprocess produces aggregated results that illustrate multiple attributes of each\nAI model.\n","authors":["Zerui Wang","Yan Liu"],"pdf_url":"https://arxiv.org/pdf/2401.12261v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.11911v4","updated":"2024-03-26T15:47:14Z","published":"2024-01-22T12:54:04Z","title":"Blinded by Generated Contexts: How Language Models Merge Generated and\n  Retrieved Contexts for Open-Domain QA?","summary":"  While auxiliary information has become a key to enhancing Large Language\nModels (LLMs), relatively little is known about how LLMs merge these contexts,\nspecifically contexts generated by LLMs and those retrieved from external\nsources. To investigate this, we formulate a systematic framework to identify\nwhether LLMs' responses, derived from the integration of generated and\nretrieved contexts, are attributed to either generated or retrieved contexts.\nTo easily trace the origin of the response, we construct datasets with\nconflicting contexts, i.e., each question is paired with both generated and\nretrieved contexts, yet only one of them contains the correct answer. Our\nexperiments reveal a significant bias in several LLMs (GPT-4/3.5 and Llama2) to\nfavor generated contexts, even when they provide incorrect information. We\nfurther identify two key factors contributing to this bias: i) contexts\ngenerated by LLMs typically show greater similarity to the questions,\nincreasing their likelihood of being selected; ii) the segmentation process\nused in retrieved contexts disrupts their completeness, thereby hindering their\nfull utilization in LLMs. Our analysis enhances the understanding of how LLMs\nmerge diverse contexts, offering valuable insights for advancing current\naugmentation methods for LLMs.\n","authors":["Hexiang Tan","Fei Sun","Wanli Yang","Yuanzhuo Wang","Qi Cao","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2401.11911v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03788v4","updated":"2024-03-26T15:41:28Z","published":"2023-02-07T22:56:58Z","title":"Toward a Theory of Causation for Interpreting Neural Code Models","summary":"  Neural Language Models of Code, or Neural Code Models (NCMs), are rapidly\nprogressing from research prototypes to commercial developer tools. As such,\nunderstanding the capabilities and limitations of such models is becoming\ncritical. However, the abilities of these models are typically measured using\nautomated metrics that often only reveal a portion of their real-world\nperformance. While, in general, the performance of NCMs appears promising,\ncurrently much is unknown about how such models arrive at decisions. To this\nend, this paper introduces $do_{code}$, a post hoc interpretability method\nspecific to NCMs that is capable of explaining model predictions. $do_{code}$\nis based upon causal inference to enable programming language-oriented\nexplanations. While the theoretical underpinnings of $do_{code}$ are extensible\nto exploring different model properties, we provide a concrete instantiation\nthat aims to mitigate the impact of spurious correlations by grounding\nexplanations of model behavior in properties of programming languages. To\ndemonstrate the practical benefit of $do_{code}$, we illustrate the insights\nthat our framework can provide by performing a case study on two popular deep\nlearning architectures and ten NCMs. The results of this case study illustrate\nthat our studied NCMs are sensitive to changes in code syntax. All our NCMs,\nexcept for the BERT-like model, statistically learn to predict tokens related\nto blocks of code (\\eg brackets, parenthesis, semicolon) with less confounding\nbias as compared to other programming language constructs. These insights\ndemonstrate the potential of $do_{code}$ as a useful method to detect and\nfacilitate the elimination of confounding bias in NCMs.\n","authors":["David N. Palacio","Alejandro Velasco","Nathan Cooper","Alvaro Rodriguez","Kevin Moran","Denys Poshyvanyk"],"pdf_url":"https://arxiv.org/pdf/2302.03788v4.pdf","comment":"Accepted to appear in IEEE Transactions on Software Engineering"},{"id":"http://arxiv.org/abs/2403.16222v2","updated":"2024-03-26T15:28:27Z","published":"2024-03-24T16:30:05Z","title":"Cyber-Security Knowledge Graph Generation by Hierarchical Nonnegative\n  Matrix Factorization","summary":"  Much of human knowledge in cybersecurity is encapsulated within the\never-growing volume of scientific papers. As this textual data continues to\nexpand, the importance of document organization methods becomes increasingly\ncrucial for extracting actionable insights hidden within large text datasets.\nKnowledge Graphs (KGs) serve as a means to store factual information in a\nstructured manner, providing explicit, interpretable knowledge that includes\ndomain-specific information from the cybersecurity scientific literature. One\nof the challenges in constructing a KG from scientific literature is the\nextraction of ontology from unstructured text. In this paper, we address this\ntopic and introduce a method for building a multi-modal KG by extracting\nstructured ontology from scientific papers. We demonstrate this concept in the\ncybersecurity domain. One modality of the KG represents observable information\nfrom the papers, such as the categories in which they were published or the\nauthors. The second modality uncovers latent (hidden) patterns of text\nextracted through hierarchical and semantic non-negative matrix factorization\n(NMF), such as named entities, topics or clusters, and keywords. We illustrate\nthis concept by consolidating more than two million scientific papers uploaded\nto arXiv into the cyber-domain, using hierarchical and semantic NMF, and by\nbuilding a cyber-domain-specific KG.\n","authors":["Ryan Barron","Maksim E. Eren","Manish Bhattarai","Selma Wanna","Nicholas Solovyev","Kim Rasmussen","Boian S. Alexandrov","Charles Nicholas","Cynthia Matuszek"],"pdf_url":"https://arxiv.org/pdf/2403.16222v2.pdf","comment":"Accepted at IEEE ISDFS"},{"id":"http://arxiv.org/abs/2403.01748v2","updated":"2024-03-26T15:26:21Z","published":"2024-03-04T05:55:01Z","title":"Decode Neural signal as Speech","summary":"  Decoding language from brain dynamics is an important open direction in the\nrealm of brain-computer interface (BCI), especially considering the rapid\ngrowth of large language models. Compared to invasive-based signals which\nrequire electrode implantation surgery, non-invasive neural signals (e.g. EEG,\nMEG) have attracted increasing attention considering their safety and\ngenerality. However, the exploration is not adequate in three aspects: 1)\nprevious methods mainly focus on EEG but none of the previous works address\nthis problem on MEG with better signal quality; 2) prior works have\npredominantly used ``teacher-forcing\" during generative decoding, which is\nimpractical; 3) prior works are mostly ``BART-based\" not fully auto-regressive,\nwhich performs better in other sequence tasks. In this paper, we explore the\nbrain-to-text translation of MEG signals in a speech-decoding formation. Here\nwe are the first to investigate a cross-attention-based ``whisper\" model for\ngenerating text directly from MEG signals without teacher forcing. Our model\nachieves impressive BLEU-1 scores of 60.30 and 52.89 without pretraining \\&\nteacher-forcing on two major datasets (\\textit{GWilliams} and\n\\textit{Schoffelen}). This paper conducts a comprehensive review to understand\nhow speech decoding formation performs on the neural decoding tasks, including\npretraining initialization, training \\& evaluation set splitting, augmentation,\nand scaling law.\n","authors":["Yiqian Yang","Yiqun Duan","Qiang Zhang","Renjing Xu","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2403.01748v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17787v1","updated":"2024-03-26T15:20:49Z","published":"2024-03-26T15:20:49Z","title":"Evaluating the Efficacy of Prompt-Engineered Large Multimodal Models\n  Versus Fine-Tuned Vision Transformers in Image-Based Security Applications","summary":"  The success of Large Language Models (LLMs) has led to a parallel rise in the\ndevelopment of Large Multimodal Models (LMMs), such as Gemini-pro, which have\nbegun to transform a variety of applications. These sophisticated multimodal\nmodels are designed to interpret and analyze complex data, integrating both\ntextual and visual information on a scale previously unattainable, opening new\navenues for a range of applications. This paper investigates the applicability\nand effectiveness of prompt-engineered Gemini-pro LMMs versus fine-tuned Vision\nTransformer (ViT) models in addressing critical security challenges. We focus\non two distinct tasks: a visually evident task of detecting simple triggers,\nsuch as small squares in images, indicative of potential backdoors, and a\nnon-visually evident task of malware classification through visual\nrepresentations. Our results highlight a significant divergence in performance,\nwith Gemini-pro falling short in accuracy and reliability when compared to\nfine-tuned ViT models. The ViT models, on the other hand, demonstrate\nexceptional accuracy, achieving near-perfect performance on both tasks. This\nstudy not only showcases the strengths and limitations of prompt-engineered\nLMMs in cybersecurity applications but also emphasizes the unmatched efficacy\nof fine-tuned ViT models for precise and dependable tasks.\n","authors":["Fouad Trad","Ali Chehab"],"pdf_url":"https://arxiv.org/pdf/2403.17787v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16760v2","updated":"2024-03-26T15:17:51Z","published":"2024-03-25T13:39:33Z","title":"As Good As A Coin Toss: Human detection of AI-generated images, videos,\n  audio, and audiovisual stimuli","summary":"  As synthetic media becomes progressively more realistic and barriers to using\nit continue to lower, the technology has been increasingly utilized for\nmalicious purposes, from financial fraud to nonconsensual pornography. Today,\nthe principal defense against being misled by synthetic media relies on the\nability of the human observer to visually and auditorily discern between real\nand fake. However, it remains unclear just how vulnerable people actually are\nto deceptive synthetic media in the course of their day to day lives. We\nconducted a perceptual study with 1276 participants to assess how accurate\npeople were at distinguishing synthetic images, audio only, video only, and\naudiovisual stimuli from authentic. To reflect the circumstances under which\npeople would likely encounter synthetic media in the wild, testing conditions\nand stimuli emulated a typical online platform, while all synthetic media used\nin the survey was sourced from publicly accessible generative AI technology.\n  We find that overall, participants struggled to meaningfully discern between\nsynthetic and authentic content. We also find that detection performance\nworsens when the stimuli contains synthetic content as compared to authentic\ncontent, images featuring human faces as compared to non face objects, a single\nmodality as compared to multimodal stimuli, mixed authenticity as compared to\nbeing fully synthetic for audiovisual stimuli, and features foreign languages\nas compared to languages the observer is fluent in. Finally, we also find that\nprior knowledge of synthetic media does not meaningfully impact their detection\nperformance. Collectively, these results indicate that people are highly\nsusceptible to being tricked by synthetic media in their daily lives and that\nhuman perceptual detection capabilities can no longer be relied upon as an\neffective counterdefense.\n","authors":["Di Cooke","Abigail Edwards","Sophia Barkoff","Kathryn Kelly"],"pdf_url":"https://arxiv.org/pdf/2403.16760v2.pdf","comment":"For study pre-registration, see https://osf.io/fnhr3"},{"id":"http://arxiv.org/abs/2403.17784v1","updated":"2024-03-26T15:16:14Z","published":"2024-03-26T15:16:14Z","title":"SciCapenter: Supporting Caption Composition for Scientific Figures with\n  Machine-Generated Captions and Ratings","summary":"  Crafting effective captions for figures is important. Readers heavily depend\non these captions to grasp the figure's message. However, despite a\nwell-developed set of AI technologies for figures and captions, these have\nrarely been tested for usefulness in aiding caption writing. This paper\nintroduces SciCapenter, an interactive system that puts together cutting-edge\nAI technologies for scientific figure captions to aid caption composition.\nSciCapenter generates a variety of captions for each figure in a scholarly\narticle, providing scores and a comprehensive checklist to assess caption\nquality across multiple critical aspects, such as helpfulness, OCR mention, key\ntakeaways, and visual properties reference. Users can directly edit captions in\nSciCapenter, resubmit for revised evaluations, and iteratively refine them. A\nuser study with Ph.D. students indicates that SciCapenter significantly lowers\nthe cognitive load of caption writing. Participants' feedback further offers\nvaluable design insights for future systems aiming to enhance caption writing.\n","authors":["Ting-Yao Hsu","Chieh-Yang Huang","Shih-Hong Huang","Ryan Rossi","Sungchul Kim","Tong Yu","C. Lee Giles","Ting-Hao K. Huang"],"pdf_url":"https://arxiv.org/pdf/2403.17784v1.pdf","comment":"CHI EA '24: Extended Abstracts of the 2024 CHI Conference on Human\n  Factors in Computing Systems"},{"id":"http://arxiv.org/abs/2306.15909v4","updated":"2024-03-26T15:13:20Z","published":"2023-06-28T04:16:16Z","title":"RL$^3$: Boosting Meta Reinforcement Learning via RL inside RL$^2$","summary":"  Meta reinforcement learning (meta-RL) methods such as RL$^2$ have emerged as\npromising approaches for learning data-efficient RL algorithms tailored to a\ngiven task distribution. However, they show poor asymptotic performance and\nstruggle with out-of-distribution tasks because they rely on sequence models,\nsuch as recurrent neural networks or transformers, to process experiences\nrather than summarize them using general-purpose RL components such as value\nfunctions. In contrast, traditional RL algorithms are data-inefficient as they\ndo not use domain knowledge, but they do converge to an optimal policy in the\nlimit. We propose RL$^3$, a principled hybrid approach that incorporates\naction-values, learned per task through traditional RL, in the inputs to\nmeta-RL. We show that RL$^3$ earns greater cumulative reward in the long term,\ncompared to RL$^2$, while maintaining data-efficiency in the short term, and\ngeneralizes better to out-of-distribution tasks. Experiments are conducted on\nboth custom and benchmark discrete domains from the meta-RL literature that\nexhibit a range of short-term, long-term, and complex dependencies.\n","authors":["Abhinav Bhatia","Samer B. Nashed","Shlomo Zilberstein"],"pdf_url":"https://arxiv.org/pdf/2306.15909v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.12243v4","updated":"2024-03-26T15:12:19Z","published":"2023-08-23T16:42:27Z","title":"Multi-Objective Optimization for Sparse Deep Multi-Task Learning","summary":"  Different conflicting optimization criteria arise naturally in various Deep\nLearning scenarios. These can address different main tasks (i.e., in the\nsetting of Multi-Task Learning), but also main and secondary tasks such as loss\nminimization versus sparsity. The usual approach is a simple weighting of the\ncriteria, which formally only works in the convex setting. In this paper, we\npresent a Multi-Objective Optimization algorithm using a modified Weighted\nChebyshev scalarization for training Deep Neural Networks (DNNs) with respect\nto several tasks. By employing this scalarization technique, the algorithm can\nidentify all optimal solutions of the original problem while reducing its\ncomplexity to a sequence of single-objective problems. The simplified problems\nare then solved using an Augmented Lagrangian method, enabling the use of\npopular optimization techniques such as Adam and Stochastic Gradient Descent,\nwhile efficaciously handling constraints. Our work aims to address the\n(economical and also ecological) sustainability issue of DNN models, with a\nparticular focus on Deep Multi-Task models, which are typically designed with a\nvery large number of weights to perform equally well on multiple tasks. Through\nexperiments conducted on two Machine Learning datasets, we demonstrate the\npossibility of adaptively sparsifying the model during training without\nsignificantly impacting its performance, if we are willing to apply\ntask-specific adaptations to the network weights. Code is available at\nhttps://github.com/salomonhotegni/MDMTN\n","authors":["S. S. Hotegni","M. Berkemeier","S. Peitz"],"pdf_url":"https://arxiv.org/pdf/2308.12243v4.pdf","comment":"12 pages, 7 figures"},{"id":"http://arxiv.org/abs/2403.17778v1","updated":"2024-03-26T15:11:18Z","published":"2024-03-26T15:11:18Z","title":"Towards a FAIR Documentation of Workflows and Models in Applied\n  Mathematics","summary":"  Modeling-Simulation-Optimization workflows play a fundamental role in applied\nmathematics. The Mathematical Research Data Initiative, MaRDI, responded to\nthis by developing a FAIR and machine-interpretable template for a\ncomprehensive documentation of such workflows. MaRDMO, a Plugin for the\nResearch Data Management Organiser, enables scientists from diverse fields to\ndocument and publish their workflows on the MaRDI Portal seamlessly using the\nMaRDI template. Central to these workflows are mathematical models. MaRDI\naddresses them with the MathModDB ontology, offering a structured formal model\ndescription. Here, we showcase the interaction between MaRDMO and the MathModDB\nKnowledge Graph through an algebraic modeling workflow from the Digital\nHumanities. This demonstration underscores the versatility of both services\nbeyond their original numerical domain.\n","authors":["Marco Reidelbach","Björn Schembera","Marcus Weber"],"pdf_url":"https://arxiv.org/pdf/2403.17778v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17768v1","updated":"2024-03-26T14:54:48Z","published":"2024-03-26T14:54:48Z","title":"SciNews: From Scholarly Complexities to Public Narratives -- A Dataset\n  for Scientific News Report Generation","summary":"  Scientific news reports serve as a bridge, adeptly translating complex\nresearch articles into reports that resonate with the broader public. The\nautomated generation of such narratives enhances the accessibility of scholarly\ninsights. In this paper, we present a new corpus to facilitate this paradigm\ndevelopment. Our corpus comprises a parallel compilation of academic\npublications and their corresponding scientific news reports across nine\ndisciplines. To demonstrate the utility and reliability of our dataset, we\nconduct an extensive analysis, highlighting the divergences in readability and\nbrevity between scientific news narratives and academic manuscripts. We\nbenchmark our dataset employing state-of-the-art text generation models. The\nevaluation process involves both automatic and human evaluation, which lays the\ngroundwork for future explorations into the automated generation of scientific\nnews reports. The dataset and code related to this work are available at\nhttps://dongqi.me/projects/SciNews.\n","authors":["Dongqi Pu","Yifan Wang","Jia Loy","Vera Demberg"],"pdf_url":"https://arxiv.org/pdf/2403.17768v1.pdf","comment":"LREC-COLING 2024 Main Conference Paper"},{"id":"http://arxiv.org/abs/2403.15585v2","updated":"2024-03-26T14:51:57Z","published":"2024-03-22T19:19:51Z","title":"MedPromptX: Grounded Multimodal Prompting for Chest X-ray Diagnosis","summary":"  Chest X-ray images are commonly used for predicting acute and chronic\ncardiopulmonary conditions, but efforts to integrate them with structured\nclinical data face challenges due to incomplete electronic health records\n(EHR). This paper introduces \\textbf{MedPromptX}, the first model to integrate\nmultimodal large language models (MLLMs), few-shot prompting (FP) and visual\ngrounding (VG) to combine imagery with EHR data for chest X-ray diagnosis. A\npre-trained MLLM is utilized to complement the missing EHR information,\nproviding a comprehensive understanding of patients' medical history.\nAdditionally, FP reduces the necessity for extensive training of MLLMs while\neffectively tackling the issue of hallucination. Nevertheless, the process of\ndetermining the optimal number of few-shot examples and selecting high-quality\ncandidates can be burdensome, yet it profoundly influences model performance.\nHence, we propose a new technique that dynamically refines few-shot data for\nreal-time adjustment to new patient scenarios. Moreover, VG aids in focusing\nthe model's attention on relevant regions of interest in X-ray images,\nenhancing the identification of abnormalities. We release MedPromptX-VQA, a new\nin-context visual question answering dataset encompassing interleaved image and\nEHR data derived from MIMIC-IV and MIMIC-CXR databases. Results demonstrate the\nSOTA performance of MedPromptX, achieving an 11% improvement in F1-score\ncompared to the baselines. Code and data are available at\nhttps://github.com/BioMedIA-MBZUAI/MedPromptX\n","authors":["Mai A. Shaaban","Adnan Khan","Mohammad Yaqub"],"pdf_url":"https://arxiv.org/pdf/2403.15585v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11996v2","updated":"2024-03-26T14:46:04Z","published":"2024-03-18T17:30:27Z","title":"Accelerating Scientific Discovery with Generative Knowledge Extraction,\n  Graph-Based Representation, and Multimodal Intelligent Graph Reasoning","summary":"  Leveraging generative Artificial Intelligence (AI), we have transformed a\ndataset comprising 1,000 scientific papers into an ontological knowledge graph.\nThrough an in-depth structural analysis, we have calculated node degrees,\nidentified communities and connectivities, and evaluated clustering\ncoefficients and betweenness centrality of pivotal nodes, uncovering\nfascinating knowledge architectures. The graph has an inherently scale-free\nnature, is highly connected, and can be used for graph reasoning by taking\nadvantage of transitive and isomorphic properties that reveal unprecedented\ninterdisciplinary relationships that can be used to answer queries, identify\ngaps in knowledge, propose never-before-seen material designs, and predict\nmaterial behaviors. We compute deep node embeddings for combinatorial node\nsimilarity ranking for use in a path sampling strategy links dissimilar\nconcepts that have previously not been related. One comparison revealed\nstructural parallels between biological materials and Beethoven's 9th Symphony,\nhighlighting shared patterns of complexity through isomorphic mapping. In\nanother example, the algorithm proposed a hierarchical mycelium-based composite\nbased on integrating path sampling with principles extracted from Kandinsky's\n'Composition VII' painting. The resulting material integrates an innovative set\nof concepts that include a balance of chaos/order, adjustable porosity,\nmechanical strength, and complex patterned chemical functionalization. We\nuncover other isomorphisms across science, technology and art, revealing a\nnuanced ontology of immanence that reveal a context-dependent heterarchical\ninterplay of constituents. Graph-based generative AI achieves a far higher\ndegree of novelty, explorative capacity, and technical detail, than\nconventional approaches and establishes a widely useful framework for\ninnovation by revealing hidden connections.\n","authors":["Markus J. Buehler"],"pdf_url":"https://arxiv.org/pdf/2403.11996v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17755v1","updated":"2024-03-26T14:44:51Z","published":"2024-03-26T14:44:51Z","title":"DataCook: Crafting Anti-Adversarial Examples for Healthcare Data\n  Copyright Protection","summary":"  In the realm of healthcare, the challenges of copyright protection and\nunauthorized third-party misuse are increasingly significant. Traditional\nmethods for data copyright protection are applied prior to data distribution,\nimplying that models trained on these data become uncontrollable. This paper\nintroduces a novel approach, named DataCook, designed to safeguard the\ncopyright of healthcare data during the deployment phase. DataCook operates by\n\"cooking\" the raw data before distribution, enabling the development of models\nthat perform normally on this processed data. However, during the deployment\nphase, the original test data must be also \"cooked\" through DataCook to ensure\nnormal model performance. This process grants copyright holders control over\nauthorization during the deployment phase. The mechanism behind DataCook is by\ncrafting anti-adversarial examples (AntiAdv), which are designed to enhance\nmodel confidence, as opposed to standard adversarial examples (Adv) that aim to\nconfuse models. Similar to Adv, AntiAdv introduces imperceptible perturbations,\nensuring that the data processed by DataCook remains easily understandable. We\nconducted extensive experiments on MedMNIST datasets, encompassing both 2D/3D\ndata and the high-resolution variants. The outcomes indicate that DataCook\neffectively meets its objectives, preventing models trained on AntiAdv from\nanalyzing unauthorized data effectively, without compromising the validity and\naccuracy of the data in legitimate scenarios. Code and data are available at\nhttps://github.com/MedMNIST/DataCook.\n","authors":["Sihan Shang","Jiancheng Yang","Zhenglong Sun","Pascal Fua"],"pdf_url":"https://arxiv.org/pdf/2403.17755v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.06247v2","updated":"2024-03-26T14:42:21Z","published":"2024-03-10T16:11:17Z","title":"Text-Guided Variational Image Generation for Industrial Anomaly\n  Detection and Segmentation","summary":"  We propose a text-guided variational image generation method to address the\nchallenge of getting clean data for anomaly detection in industrial\nmanufacturing. Our method utilizes text information about the target object,\nlearned from extensive text library documents, to generate non-defective data\nimages resembling the input image. The proposed framework ensures that the\ngenerated non-defective images align with anticipated distributions derived\nfrom textual and image-based knowledge, ensuring stability and generality.\nExperimental results demonstrate the effectiveness of our approach, surpassing\nprevious methods even with limited non-defective data. Our approach is\nvalidated through generalization tests across four baseline models and three\ndistinct datasets. We present an additional analysis to enhance the\neffectiveness of anomaly detection models by utilizing the generated images.\n","authors":["Mingyu Lee","Jongwon Choi"],"pdf_url":"https://arxiv.org/pdf/2403.06247v2.pdf","comment":"18 pages, Accepted to CVPR 2024"},{"id":"http://arxiv.org/abs/2310.02129v4","updated":"2024-03-26T14:38:23Z","published":"2023-10-03T15:10:46Z","title":"Unveiling the Pitfalls of Knowledge Editing for Large Language Models","summary":"  As the cost associated with fine-tuning Large Language Models (LLMs)\ncontinues to rise, recent research efforts have pivoted towards developing\nmethodologies to edit implicit knowledge embedded within LLMs. Yet, there's\nstill a dark cloud lingering overhead -- will knowledge editing trigger\nbutterfly effect? since it is still unclear whether knowledge editing might\nintroduce side effects that pose potential risks or not. This paper pioneers\nthe investigation into the potential pitfalls associated with knowledge editing\nfor LLMs. To achieve this, we introduce new benchmark datasets and propose\ninnovative evaluation metrics. Our results underline two pivotal concerns: (1)\nKnowledge Conflict: Editing groups of facts that logically clash can magnify\nthe inherent inconsistencies in LLMs-a facet neglected by previous methods. (2)\nKnowledge Distortion: Altering parameters with the aim of editing factual\nknowledge can irrevocably warp the innate knowledge structure of LLMs.\nExperimental results vividly demonstrate that knowledge editing might\ninadvertently cast a shadow of unintended consequences on LLMs, which warrant\nattention and efforts for future works. Code and data are available at\nhttps://github.com/zjunlp/PitfallsKnowledgeEditing.\n","authors":["Zhoubo Li","Ningyu Zhang","Yunzhi Yao","Mengru Wang","Xi Chen","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2310.02129v4.pdf","comment":"ICLR 2024"},{"id":"http://arxiv.org/abs/2307.05300v4","updated":"2024-03-26T14:32:33Z","published":"2023-07-11T14:45:19Z","title":"Unleashing the Emergent Cognitive Synergy in Large Language Models: A\n  Task-Solving Agent through Multi-Persona Self-Collaboration","summary":"  Human intelligence thrives on cognitive synergy, where collaboration among\ndifferent minds yield superior outcomes compared to isolated individuals. In\nthis work, we propose Solo Performance Prompting (SPP), which transforms a\nsingle LLM into a cognitive synergist by engaging in multi-turn\nself-collaboration with multiple personas. A cognitive synergist is an\nintelligent agent that collaboratively combines multiple minds' strengths and\nknowledge to enhance problem-solving in complex tasks. By dynamically\nidentifying and simulating different personas based on task inputs, SPP\nunleashes the potential of cognitive synergy in LLMs. Our in-depth analysis\nshows that assigning multiple fine-grained personas in LLMs improves\nproblem-solving abilities compared to using a single or fixed number of\npersonas. We evaluate SPP on three challenging tasks: Trivia Creative Writing,\nCodenames Collaborative, and Logic Grid Puzzle, encompassing both\nknowledge-intensive and reasoning-intensive types. Unlike previous works, such\nas Chain-of-Thought, that solely enhance the reasoning abilities in LLMs,\nexperimental results demonstrate that SPP effectively reduces factual\nhallucination, and maintains strong reasoning capabilities. Additionally,\ncomparative experiments show that cognitive synergy only emerges in GPT-4 and\ndoes not appear in less capable models, such as GPT-3.5-turbo and\nLlama2-13b-chat, which draws an interesting analogy to human development. Code,\ndata, and prompts can be found at:\nhttps://github.com/MikeWangWZHL/Solo-Performance-Prompting.git.\n","authors":["Zhenhailong Wang","Shaoguang Mao","Wenshan Wu","Tao Ge","Furu Wei","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2307.05300v4.pdf","comment":"Accepted as a main conference paper at NAACL 2024"},{"id":"http://arxiv.org/abs/2403.17742v1","updated":"2024-03-26T14:30:23Z","published":"2024-03-26T14:30:23Z","title":"Using Stratified Sampling to Improve LIME Image Explanations","summary":"  We investigate the use of a stratified sampling approach for LIME Image, a\npopular model-agnostic explainable AI method for computer vision tasks, in\norder to reduce the artifacts generated by typical Monte Carlo sampling. Such\nartifacts are due to the undersampling of the dependent variable in the\nsynthetic neighborhood around the image being explained, which may result in\ninadequate explanations due to the impossibility of fitting a linear regressor\non the sampled data. We then highlight a connection with the Shapley theory,\nwhere similar arguments about undersampling and sample relevance were suggested\nin the past. We derive all the formulas and adjustment factors required for an\nunbiased stratified sampling estimator. Experiments show the efficacy of the\nproposed approach.\n","authors":["Muhammad Rashid","Elvio G. Amparore","Enrico Ferrari","Damiano Verda"],"pdf_url":"https://arxiv.org/pdf/2403.17742v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17740v1","updated":"2024-03-26T14:29:34Z","published":"2024-03-26T14:29:34Z","title":"All-in-One: Heterogeneous Interaction Modeling for Cold-Start Rating\n  Prediction","summary":"  Cold-start rating prediction is a fundamental problem in recommender systems\nthat has been extensively studied. Many methods have been proposed that exploit\nexplicit relations among existing data, such as collaborative filtering, social\nrecommendations and heterogeneous information network, to alleviate the data\ninsufficiency issue for cold-start users and items. However, the explicit\nrelations constructed based on data between different roles may be unreliable\nand irrelevant, which limits the performance ceiling of the specific\nrecommendation task. Motivated by this, in this paper, we propose a flexible\nframework dubbed heterogeneous interaction rating network (HIRE). HIRE dose not\nsolely rely on the pre-defined interaction pattern or the manually constructed\nheterogeneous information network. Instead, we devise a Heterogeneous\nInteraction Module (HIM) to jointly model the heterogeneous interactions and\ndirectly infer the important interactions via the observed data. In the\nexperiments, we evaluate our model under three cold-start settings on three\nreal-world datasets. The experimental results show that HIRE outperforms other\nbaselines by a large margin. Furthermore, we visualize the inferred\ninteractions of HIRE to confirm the contribution of our model.\n","authors":["Shuheng Fang","Kangfei Zhao","Yu Rong","Zhixun Li","Jeffrey Xu Yu"],"pdf_url":"https://arxiv.org/pdf/2403.17740v1.pdf","comment":"14 pages, 9 figures"},{"id":"http://arxiv.org/abs/2311.02099v4","updated":"2024-03-26T14:25:52Z","published":"2023-10-30T21:52:37Z","title":"A Safe Preference Learning Approach for Personalization with\n  Applications to Autonomous Vehicles","summary":"  This work introduces a preference learning method that ensures adherence to\ngiven specifications, with an application to autonomous vehicles. Our approach\nincorporates the priority ordering of Signal Temporal Logic (STL) formulas\ndescribing traffic rules into a learning framework. By leveraging Parametric\nWeighted Signal Temporal Logic (PWSTL), we formulate the problem of\nsafety-guaranteed preference learning based on pairwise comparisons and propose\nan approach to solve this learning problem. Our approach finds a feasible\nvaluation for the weights of the given PWSTL formula such that, with these\nweights, preferred signals have weighted quantitative satisfaction measures\ngreater than their non-preferred counterparts. The feasible valuation of\nweights given by our approach leads to a weighted STL formula that can be used\nin correct-and-custom-by-construction controller synthesis. We demonstrate the\nperformance of our method with a pilot human subject study in two different\nsimulated driving scenarios involving a stop sign and a pedestrian crossing.\nOur approach yields competitive results compared to existing preference\nlearning methods in terms of capturing preferences and notably outperforms them\nwhen safety is considered.\n","authors":["Ruya Karagulle","Nikos Arechiga","Andrew Best","Jonathan DeCastro","Necmiye Ozay"],"pdf_url":"https://arxiv.org/pdf/2311.02099v4.pdf","comment":"9 pages, 3 figures, 2 tables. This work has been published at IEEE\n  Robotics and Automation Letters. Copyright may be transferred without notice,\n  after which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2403.17735v1","updated":"2024-03-26T14:24:01Z","published":"2024-03-26T14:24:01Z","title":"Out-of-distribution Rumor Detection via Test-Time Adaptation","summary":"  Due to the rapid spread of rumors on social media, rumor detection has become\nan extremely important challenge. Existing methods for rumor detection have\nachieved good performance, as they have collected enough corpus from the same\ndata distribution for model training. However, significant distribution shifts\nbetween the training data and real-world test data occur due to differences in\nnews topics, social media platforms, languages and the variance in propagation\nscale caused by news popularity. This leads to a substantial decline in the\nperformance of these existing methods in Out-Of-Distribution (OOD) situations.\nTo address this problem, we propose a simple and efficient method named\nTest-time Adaptation for Rumor Detection under distribution shifts (TARD). This\nmethod models the propagation of news in the form of a propagation graph, and\nbuilds propagation graph test-time adaptation framework, enhancing the model's\nadaptability and robustness when facing OOD problems. Extensive experiments\nconducted on two group datasets collected from real-world social platforms\ndemonstrate that our framework outperforms the state-of-the-art methods in\nperformance.\n","authors":["Xiang Tao","Mingqing Zhang","Qiang Liu","Shu Wu","Liang Wang"],"pdf_url":"https://arxiv.org/pdf/2403.17735v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17726v1","updated":"2024-03-26T14:14:30Z","published":"2024-03-26T14:14:30Z","title":"Tiny Models are the Computational Saver for Large Models","summary":"  This paper introduces TinySaver, an early-exit-like dynamic model compression\napproach which employs tiny models to substitute large models adaptively.\nDistinct from traditional compression techniques, dynamic methods like\nTinySaver can leverage the difficulty differences to allow certain inputs to\ncomplete their inference processes early, thereby conserving computational\nresources. Most existing early exit designs are implemented by attaching\nadditional network branches to the model's backbone. Our study, however,\nreveals that completely independent tiny models can replace a substantial\nportion of the larger models' job with minimal impact on performance. Employing\nthem as the first exit can remarkably enhance computational efficiency. By\nsearching and employing the most appropriate tiny model as the computational\nsaver for a given large model, the proposed approaches work as a novel and\ngeneric method to model compression. This finding will help the research\ncommunity in exploring new compression methods to address the escalating\ncomputational demands posed by rapidly evolving AI models. Our evaluation of\nthis approach in ImageNet-1k classification demonstrates its potential to\nreduce the number of compute operations by up to 90%, with only negligible\nlosses in performance, across various modern vision models. The code of this\nwork will be available.\n","authors":["Qingyuan Wang","Barry Cardiff","Antoine Frappé","Benoit Larras","Deepu John"],"pdf_url":"https://arxiv.org/pdf/2403.17726v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.05337v2","updated":"2024-03-26T14:09:56Z","published":"2023-12-08T19:52:48Z","title":"Artificial Neural Nets and the Representation of Human Concepts","summary":"  What do artificial neural networks (ANNs) learn? The machine learning (ML)\ncommunity shares the narrative that ANNs must develop abstract human concepts\nto perform complex tasks. Some go even further and believe that these concepts\nare stored in individual units of the network. Based on current research, I\nsystematically investigate the assumptions underlying this narrative. I\nconclude that ANNs are indeed capable of performing complex prediction tasks,\nand that they may learn human and non-human concepts to do so. However,\nevidence indicates that ANNs do not represent these concepts in individual\nunits.\n","authors":["Timo Freiesleben"],"pdf_url":"https://arxiv.org/pdf/2312.05337v2.pdf","comment":"For: Philosophy of Science for Machine Learning: Core Issues and New\n  Perspectives, edited by Juan Duran and Giorgia Pozzi"},{"id":"http://arxiv.org/abs/2403.17710v1","updated":"2024-03-26T13:58:00Z","published":"2024-03-26T13:58:00Z","title":"Optimization-based Prompt Injection Attack to LLM-as-a-Judge","summary":"  LLM-as-a-Judge is a novel solution that can assess textual information with\nlarge language models (LLMs). Based on existing research studies, LLMs\ndemonstrate remarkable performance in providing a compelling alternative to\ntraditional human assessment. However, the robustness of these systems against\nprompt injection attacks remains an open question. In this work, we introduce\nJudgeDeceiver, a novel optimization-based prompt injection attack tailored to\nLLM-as-a-Judge. Our method formulates a precise optimization objective for\nattacking the decision-making process of LLM-as-a-Judge and utilizes an\noptimization algorithm to efficiently automate the generation of adversarial\nsequences, achieving targeted and effective manipulation of model evaluations.\nCompared to handcraft prompt injection attacks, our method demonstrates\nsuperior efficacy, posing a significant challenge to the current security\nparadigms of LLM-based judgment systems. Through extensive experiments, we\nshowcase the capability of JudgeDeceiver in altering decision outcomes across\nvarious cases, highlighting the vulnerability of LLM-as-a-Judge systems to the\noptimization-based prompt injection attack.\n","authors":["Jiawen Shi","Zenghui Yuan","Yinuo Liu","Yue Huang","Pan Zhou","Lichao Sun","Neil Zhenqiang Gong"],"pdf_url":"https://arxiv.org/pdf/2403.17710v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17706v1","updated":"2024-03-26T13:50:34Z","published":"2024-03-26T13:50:34Z","title":"Enhanced Short Text Modeling: Leveraging Large Language Models for Topic\n  Refinement","summary":"  Crafting effective topic models for brief texts, like tweets and news\nheadlines, is essential for capturing the swift shifts in social dynamics.\nTraditional topic models, however, often fall short in accurately representing\nthe semantic intricacies of short texts due to their brevity and lack of\ncontextual data. In our study, we harness the advanced capabilities of Large\nLanguage Models (LLMs) to introduce a novel approach termed \"Topic Refinement\".\nThis approach does not directly involve itself in the initial modeling of\ntopics but focuses on improving topics after they have been mined. By employing\nprompt engineering, we direct LLMs to eliminate off-topic words within a given\ntopic, ensuring that only contextually relevant words are preserved or\nsubstituted with ones that fit better semantically. This method emulates\nhuman-like scrutiny and improvement of topics, thereby elevating the semantic\nquality of the topics generated by various models. Our comprehensive evaluation\nacross three unique datasets has shown that our topic refinement approach\nsignificantly enhances the semantic coherence of topics.\n","authors":["Shuyu Chang","Rui Wang","Peng Ren","Haiping Huang"],"pdf_url":"https://arxiv.org/pdf/2403.17706v1.pdf","comment":"6 pages, 4 figures"},{"id":"http://arxiv.org/abs/2403.17698v1","updated":"2024-03-26T13:38:06Z","published":"2024-03-26T13:38:06Z","title":"MEP: Multiple Kernel Learning Enhancing Relative Positional Encoding\n  Length Extrapolation","summary":"  When the predicted sequence length exceeds the length seen during training,\nthe transformer's inference accuracy diminishes. Existing relative position\nencoding methods, such as those based on the ALiBi technique, address the\nlength extrapolation challenge exclusively through the implementation of a\nsingle kernel function, which introduces a constant bias to every post-softmax\nattention scores according to their distance. These approaches do not\ninvestigate or employ multiple kernel functions to address the extrapolation\nchallenge. Drawing on the ALiBi approach, this study proposes a novel relative\npositional encoding method, called MEP, which employs a weighted average to\ncombine distinct kernel functions(such as the exponential kernel and the\nGaussian kernel) to generate a bias that is applied to post-softmax attention\nscores. Initially, the framework utilizes various kernel functions to construct\nmultiple kernel functions. Each kernel function adheres to a consistent mean\nweight coefficient, harnessing the synergistic advantages of different kernels\nto formulate an innovative bias function. Subsequently, specific slopes are\ntailored for each kernel function, applying penalties at varying rates, to\nenhance the model's extrapolation capabilities. Finally, this bias is\nseamlessly incorporated as a penalty to the post-softmax scores. We present two\ndistinct versions of our method: a parameter-free variant that requires no new\nlearnable parameters, which enhances length extrapolation capabilities without\ncompromising training efficiency, and a parameterized variant capable of\nintegrating state-of-the-art techniques. Empirical evaluations across diverse\ndatasets have demonstrated that both variants of our method achieve\nstate-of-the-art performance, outperforming traditional parameter-free and\nparameterized approaches.\n","authors":["Weiguo Gao"],"pdf_url":"https://arxiv.org/pdf/2403.17698v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17693v1","updated":"2024-03-26T13:34:21Z","published":"2024-03-26T13:34:21Z","title":"ExpressEdit: Video Editing with Natural Language and Sketching","summary":"  Informational videos serve as a crucial source for explaining conceptual and\nprocedural knowledge to novices and experts alike. When producing informational\nvideos, editors edit videos by overlaying text/images or trimming footage to\nenhance the video quality and make it more engaging. However, video editing can\nbe difficult and time-consuming, especially for novice video editors who often\nstruggle with expressing and implementing their editing ideas. To address this\nchallenge, we first explored how multimodality$-$natural language (NL) and\nsketching, which are natural modalities humans use for expression$-$can be\nutilized to support video editors in expressing video editing ideas. We\ngathered 176 multimodal expressions of editing commands from 10 video editors,\nwhich revealed the patterns of use of NL and sketching in describing edit\nintents. Based on the findings, we present ExpressEdit, a system that enables\nediting videos via NL text and sketching on the video frame. Powered by LLM and\nvision models, the system interprets (1) temporal, (2) spatial, and (3)\noperational references in an NL command and spatial references from sketching.\nThe system implements the interpreted edits, which then the user can iterate\non. An observational study (N=10) showed that ExpressEdit enhanced the ability\nof novice video editors to express and implement their edit ideas. The system\nallowed participants to perform edits more efficiently and generate more ideas\nby generating edits based on user's multimodal edit commands and supporting\niterations on the editing commands. This work offers insights into the design\nof future multimodal interfaces and AI-based pipelines for video editing.\n","authors":["Bekzat Tilekbay","Saelyne Yang","Michal Lewkowicz","Alex Suryapranata","Juho Kim"],"pdf_url":"https://arxiv.org/pdf/2403.17693v1.pdf","comment":"22 pages, 5 figures, to be published in ACM IUI 2024"},{"id":"http://arxiv.org/abs/2311.16081v2","updated":"2024-03-26T13:32:06Z","published":"2023-11-27T18:52:09Z","title":"ViT-Lens: Towards Omni-modal Representations","summary":"  Aiming to advance AI agents, large foundation models significantly improve\nreasoning and instruction execution, yet the current focus on vision and\nlanguage neglects the potential of perceiving diverse modalities in open-world\nenvironments. However, the success of data-driven vision and language models is\ncostly or even infeasible to be reproduced for rare modalities. In this paper,\nwe present ViT-Lens-2 that facilitates efficient omni-modal representation\nlearning by perceiving novel modalities with a pretrained ViT and aligning them\nto a pre-defined space. Specifically, the modality-specific lens is tuned to\nproject any-modal signals to an intermediate embedding space, which are then\nprocessed by a strong ViT with pre-trained visual knowledge. The encoded\nrepresentations are optimized toward aligning with the modal-independent space,\npre-defined by off-the-shelf foundation models. ViT-Lens-2 provides a unified\nsolution for representation learning of increasing modalities with two\nappealing advantages: (i) Unlocking the great potential of pretrained ViTs to\nnovel modalities effectively with efficient data regime; (ii) Enabling emergent\ndownstream capabilities through modality alignment and shared ViT parameters.\nWe tailor ViT-Lens-2 to learn representations for 3D point cloud, depth, audio,\ntactile and EEG, and set new state-of-the-art results across various\nunderstanding tasks, such as zero-shot classification. By seamlessly\nintegrating ViT-Lens-2 into Multimodal Foundation Models, we enable\nAny-modality to Text and Image Generation in a zero-shot manner. Code and\nmodels are available at https://github.com/TencentARC/ViT-Lens.\n","authors":["Weixian Lei","Yixiao Ge","Kun Yi","Jianfeng Zhang","Difei Gao","Dylan Sun","Yuying Ge","Ying Shan","Mike Zheng Shou"],"pdf_url":"https://arxiv.org/pdf/2311.16081v2.pdf","comment":"This work is a follow-up of arXiv:2308.10185. Accepted to CVPR2024"},{"id":"http://arxiv.org/abs/2312.02512v2","updated":"2024-03-26T13:21:28Z","published":"2023-12-05T05:36:44Z","title":"AV2AV: Direct Audio-Visual Speech to Audio-Visual Speech Translation\n  with Unified Audio-Visual Speech Representation","summary":"  This paper proposes a novel direct Audio-Visual Speech to Audio-Visual Speech\nTranslation (AV2AV) framework, where the input and output of the system are\nmultimodal (i.e., audio and visual speech). With the proposed AV2AV, two key\nadvantages can be brought: 1) We can perform real-like conversations with\nindividuals worldwide in a virtual meeting by utilizing our own primary\nlanguages. In contrast to Speech-to-Speech Translation (A2A), which solely\ntranslates between audio modalities, the proposed AV2AV directly translates\nbetween audio-visual speech. This capability enhances the dialogue experience\nby presenting synchronized lip movements along with the translated speech. 2)\nWe can improve the robustness of the spoken language translation system. By\nemploying the complementary information of audio-visual speech, the system can\neffectively translate spoken language even in the presence of acoustic noise,\nshowcasing robust performance. To mitigate the problem of the absence of a\nparallel AV2AV translation dataset, we propose to train our spoken language\ntranslation system with the audio-only dataset of A2A. This is done by learning\nunified audio-visual speech representations through self-supervised learning in\nadvance to train the translation system. Moreover, we propose an AV-Renderer\nthat can generate raw audio and video in parallel. It is designed with\nzero-shot speaker modeling, thus the speaker in source audio-visual speech can\nbe maintained at the target translated audio-visual speech. The effectiveness\nof AV2AV is evaluated with extensive experiments in a many-to-many language\ntranslation setting. Demo page is available on\nhttps://choijeongsoo.github.io/av2av.\n","authors":["Jeongsoo Choi","Se Jin Park","Minsu Kim","Yong Man Ro"],"pdf_url":"https://arxiv.org/pdf/2312.02512v2.pdf","comment":"CVPR 2024. Code & Demo: https://choijeongsoo.github.io/av2av"},{"id":"http://arxiv.org/abs/2403.17683v1","updated":"2024-03-26T13:14:18Z","published":"2024-03-26T13:14:18Z","title":"Solution for Emotion Prediction Competition of Workshop on Emotionally\n  and Culturally Intelligent AI","summary":"  This report provide a detailed description of the method that we explored and\nproposed in the WECIA Emotion Prediction Competition (EPC), which predicts a\nperson's emotion through an artistic work with a comment. The dataset of this\ncompetition is ArtELingo, designed to encourage work on diversity across\nlanguages and cultures. The dataset has two main challenges, namely modal\nimbalance problem and language-cultural differences problem. In order to\naddress this issue, we propose a simple yet effective approach called\nsingle-multi modal with Emotion-Cultural specific prompt(ECSP), which focuses\non using the single modal message to enhance the performance of multimodal\nmodels and a well-designed prompt to reduce cultural differences problem. To\nclarify, our approach contains two main blocks:\n(1)XLM-R\\cite{conneau2019unsupervised} based unimodal model and\nX$^2$-VLM\\cite{zeng2022x} based multimodal model (2) Emotion-Cultural specific\nprompt. Our approach ranked first in the final test with a score of 0.627.\n","authors":["Shengdong Xu","Zhouyang Chi","Yang Yang"],"pdf_url":"https://arxiv.org/pdf/2403.17683v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16915v2","updated":"2024-03-26T13:11:44Z","published":"2024-03-25T16:32:50Z","title":"Coarse-Tuning for Ad-hoc Document Retrieval Using Pre-trained Language\n  Models","summary":"  Fine-tuning in information retrieval systems using pre-trained language\nmodels (PLM-based IR) requires learning query representations and\nquery-document relations, in addition to downstream task-specific learning.\nThis study introduces coarse-tuning as an intermediate learning stage that\nbridges pre-training and fine-tuning. By learning query representations and\nquery-document relations in coarse-tuning, we aim to reduce the load of\nfine-tuning and improve the learning effect of downstream IR tasks. We propose\nQuery-Document Pair Prediction (QDPP) for coarse-tuning, which predicts the\nappropriateness of query-document pairs. Evaluation experiments show that the\nproposed method significantly improves MRR and/or nDCG@5 in four ad-hoc\ndocument retrieval datasets. Furthermore, the results of the query prediction\ntask suggested that coarse-tuning facilitated learning of query representation\nand query-document relations.\n","authors":["Atsushi Keyaki","Ribeka Keyaki"],"pdf_url":"https://arxiv.org/pdf/2403.16915v2.pdf","comment":"Accepted at LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2311.09994v2","updated":"2024-03-26T13:06:28Z","published":"2023-11-16T16:09:44Z","title":"Towards more Practical Threat Models in Artificial Intelligence Security","summary":"  Recent works have identified a gap between research and practice in\nartificial intelligence security: threats studied in academia do not always\nreflect the practical use and security risks of AI. For example, while models\nare often studied in isolation, they form part of larger ML pipelines in\npractice. Recent works also brought forward that adversarial manipulations\nintroduced by academic attacks are impractical. We take a first step towards\ndescribing the full extent of this disparity. To this end, we revisit the\nthreat models of the six most studied attacks in AI security research and match\nthem to AI usage in practice via a survey with 271 industrial practitioners. On\nthe one hand, we find that all existing threat models are indeed applicable. On\nthe other hand, there are significant mismatches: research is often too\ngenerous with the attacker, assuming access to information not frequently\navailable in real-world settings. Our paper is thus a call for action to study\nmore practical threat models in artificial intelligence security.\n","authors":["Kathrin Grosse","Lukas Bieringer","Tarek Richard Besold","Alexandre Alahi"],"pdf_url":"https://arxiv.org/pdf/2311.09994v2.pdf","comment":"18 pages, 4 figures, 8 tables, accepted to Usenix Security,\n  incorporated external feedback"},{"id":"http://arxiv.org/abs/2403.17677v1","updated":"2024-03-26T13:05:02Z","published":"2024-03-26T13:05:02Z","title":"Onboard deep lossless and near-lossless predictive coding of\n  hyperspectral images with line-based attention","summary":"  Deep learning methods have traditionally been difficult to apply to\ncompression of hyperspectral images onboard of spacecrafts, due to the large\ncomputational complexity needed to achieve adequate representational power, as\nwell as the lack of suitable datasets for training and testing. In this paper,\nwe depart from the traditional autoencoder approach and we design a predictive\nneural network, called LineRWKV, that works recursively line-by-line to limit\nmemory consumption. In order to achieve that, we adopt a novel hybrid\nattentive-recursive operation that combines the representational advantages of\nTransformers with the linear complexity and recursive implementation of\nrecurrent neural networks. The compression algorithm performs prediction of\neach pixel using LineRWKV, followed by entropy coding of the residual.\nExperiments on the HySpecNet-11k dataset and PRISMA images show that LineRWKV\nis the first deep-learning method to outperform CCSDS-123.0-B-2 at lossless and\nnear-lossless compression. Promising throughput results are also evaluated on a\n7W embedded system.\n","authors":["Diego Valsesia","Tiziano Bianchi","Enrico Magli"],"pdf_url":"https://arxiv.org/pdf/2403.17677v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17674v1","updated":"2024-03-26T13:02:46Z","published":"2024-03-26T13:02:46Z","title":"Depending on yourself when you should: Mentoring LLM with RL agents to\n  become the master in cybersecurity games","summary":"  Integrating LLM and reinforcement learning (RL) agent effectively to achieve\ncomplementary performance is critical in high stake tasks like cybersecurity\noperations. In this study, we introduce SecurityBot, a LLM agent mentored by\npre-trained RL agents, to support cybersecurity operations. In particularly,\nthe LLM agent is supported with a profile module to generated behavior\nguidelines, a memory module to accumulate local experiences, a reflection\nmodule to re-evaluate choices, and an action module to reduce action space.\nAdditionally, it adopts the collaboration mechanism to take suggestions from\npre-trained RL agents, including a cursor for dynamic suggestion taken, an\naggregator for multiple mentors' suggestions ranking and a caller for proactive\nsuggestion asking. Building on the CybORG experiment framework, our experiences\nshow that SecurityBot demonstrates significant performance improvement compared\nwith LLM or RL standalone, achieving the complementary performance in the\ncybersecurity games.\n","authors":["Yikuan Yan","Yaolun Zhang","Keman Huang"],"pdf_url":"https://arxiv.org/pdf/2403.17674v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2403.17661v1","updated":"2024-03-26T12:47:39Z","published":"2024-03-26T12:47:39Z","title":"Language Models for Text Classification: Is In-Context Learning Enough?","summary":"  Recent foundational language models have shown state-of-the-art performance\nin many NLP tasks in zero- and few-shot settings. An advantage of these models\nover more standard approaches based on fine-tuning is the ability to understand\ninstructions written in natural language (prompts), which helps them generalise\nbetter to different tasks and domains without the need for specific training\ndata. This makes them suitable for addressing text classification problems for\ndomains with limited amounts of annotated instances. However, existing research\nis limited in scale and lacks understanding of how text generation models\ncombined with prompting techniques compare to more established methods for text\nclassification such as fine-tuning masked language models. In this paper, we\naddress this research gap by performing a large-scale evaluation study for 16\ntext classification datasets covering binary, multiclass, and multilabel\nproblems. In particular, we compare zero- and few-shot approaches of large\nlanguage models to fine-tuning smaller language models. We also analyse the\nresults by prompt, classification type, domain, and number of labels. In\ngeneral, the results show how fine-tuning smaller and more efficient language\nmodels can still outperform few-shot approaches of larger language models,\nwhich have room for improvement when it comes to text classification.\n","authors":["Aleksandra Edwards","Jose Camacho-Collados"],"pdf_url":"https://arxiv.org/pdf/2403.17661v1.pdf","comment":"Accepted at LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2312.14149v4","updated":"2024-03-26T12:47:12Z","published":"2023-12-21T18:59:06Z","title":"TagAlign: Improving Vision-Language Alignment with Multi-Tag\n  Classification","summary":"  The crux of learning vision-language models is to extract semantically\naligned information from visual and linguistic data. Existing attempts usually\nface the problem of coarse alignment, e.g., the vision encoder struggles in\nlocalizing an attribute-specified object. In this work, we propose an\nembarrassingly simple approach to better align image and text features with no\nneed of additional data formats other than image-text pairs. Concretely, given\nan image and its paired text, we manage to parse objects (e.g., cat) and\nattributes (e.g., black) from the description, which are highly likely to exist\nin the image. It is noteworthy that the parsing pipeline is fully automatic and\nthus enjoys good scalability. With these parsed semantics as supervision\nsignals, we can complement the commonly used image-text contrastive loss with\nthe multi-tag classification loss. Extensive experimental results on a broad\nsuite of semantic segmentation datasets substantiate the average 5.2\\%\nimprovement of our framework over existing alternatives. Furthermore, the\nvisualization results indicate that attribute supervision makes vision-language\nmodels accurately localize attribute-specified objects. Project page can be\nfound at https://qinying-liu.github.io/Tag-Align.\n","authors":["Qinying Liu","Wei Wu","Kecheng Zheng","Zhan Tong","Jiawei Liu","Yu Liu","Wei Chen","Zilei Wang","Yujun Shen"],"pdf_url":"https://arxiv.org/pdf/2312.14149v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17656v1","updated":"2024-03-26T12:39:02Z","published":"2024-03-26T12:39:02Z","title":"SGHormer: An Energy-Saving Graph Transformer Driven by Spikes","summary":"  Graph Transformers (GTs) with powerful representation learning ability make a\nhuge success in wide range of graph tasks. However, the costs behind\noutstanding performances of GTs are higher energy consumption and computational\noverhead. The complex structure and quadratic complexity during attention\ncalculation in vanilla transformer seriously hinder its scalability on the\nlarge-scale graph data. Though existing methods have made strides in\nsimplifying combinations among blocks or attention-learning paradigm to improve\nGTs' efficiency, a series of energy-saving solutions originated from\nbiologically plausible structures are rarely taken into consideration when\nconstructing GT framework. To this end, we propose a new spiking-based graph\ntransformer (SGHormer). It turns full-precision embeddings into sparse and\nbinarized spikes to reduce memory and computational costs. The spiking graph\nself-attention and spiking rectify blocks in SGHormer explicitly capture global\nstructure information and recover the expressive power of spiking embeddings,\nrespectively. In experiments, SGHormer achieves comparable performances to\nother full-precision GTs with extremely low computational energy consumption.\nThe results show that SGHomer makes a remarkable progress in the field of\nlow-energy GTs.\n","authors":["Huizhe Zhang","Jintang Li","Liang Chen","Zibin Zheng"],"pdf_url":"https://arxiv.org/pdf/2403.17656v1.pdf","comment":"9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2403.17653v1","updated":"2024-03-26T12:36:11Z","published":"2024-03-26T12:36:11Z","title":"An Extension-based Approach for Computing and Verifying Preferences in\n  Abstract Argumentation","summary":"  We present an extension-based approach for computing and verifying\npreferences in an abstract argumentation system. Although numerous\nargumentation semantics have been developed previously for identifying\nacceptable sets of arguments from an argumentation framework, there is a lack\nof justification behind their acceptability based on implicit argument\npreferences. Preference-based argumentation frameworks allow one to determine\nwhat arguments are justified given a set of preferences. Our research considers\nthe inverse of the standard reasoning problem, i.e., given an abstract\nargumentation framework and a set of justified arguments, we compute what the\npossible preferences over arguments are. Furthermore, there is a need to verify\n(i.e., assess) that the computed preferences would lead to the acceptable sets\nof arguments. This paper presents a novel approach and algorithm for\nexhaustively computing and enumerating all possible sets of preferences\n(restricted to three identified cases) for a conflict-free set of arguments in\nan abstract argumentation framework. We prove the soundness, completeness and\ntermination of the algorithm. The research establishes that preferences are\ndetermined using an extension-based approach after the evaluation phase\n(acceptability of arguments) rather than stated beforehand. In this work, we\nfocus our research study on grounded, preferred and stable semantics. We show\nthat the complexity of computing sets of preferences is exponential in the\nnumber of arguments, and thus, describe an approximate approach and algorithm\nto compute the preferences. Furthermore, we present novel algorithms for\nverifying (i.e., assessing) the computed preferences. We provide details of the\nimplementation of the algorithms (source code has been made available), various\nexperiments performed to evaluate the algorithms and the analysis of the\nresults.\n","authors":["Quratul-ain Mahesar","Nir Oren","Wamberto W. Vasconcelos"],"pdf_url":"https://arxiv.org/pdf/2403.17653v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.03246v5","updated":"2024-03-26T12:35:03Z","published":"2024-02-05T18:03:53Z","title":"SGS-SLAM: Semantic Gaussian Splatting For Neural Dense SLAM","summary":"  We present SGS-SLAM, the first semantic visual SLAM system based on Gaussian\nSplatting. It incorporates appearance, geometry, and semantic features through\nmulti-channel optimization, addressing the oversmoothing limitations of neural\nimplicit SLAM systems in high-quality rendering, scene understanding, and\nobject-level geometry. We introduce a unique semantic feature loss that\neffectively compensates for the shortcomings of traditional depth and color\nlosses in object optimization. Through a semantic-guided keyframe selection\nstrategy, we prevent erroneous reconstructions caused by cumulative errors.\nExtensive experiments demonstrate that SGS-SLAM delivers state-of-the-art\nperformance in camera pose estimation, map reconstruction, precise semantic\nsegmentation, and object-level geometric accuracy, while ensuring real-time\nrendering capabilities.\n","authors":["Mingrui Li","Shuhong Liu","Heng Zhou","Guohao Zhu","Na Cheng","Tianchen Deng","Hongyu Wang"],"pdf_url":"https://arxiv.org/pdf/2402.03246v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13374v2","updated":"2024-03-26T12:33:16Z","published":"2024-03-20T08:15:08Z","title":"Byzantine-resilient Federated Learning With Adaptivity to Data\n  Heterogeneity","summary":"  This paper deals with federated learning (FL) in the presence of malicious\nByzantine attacks and data heterogeneity. A novel Robust Average Gradient\nAlgorithm (RAGA) is proposed, which leverages the geometric median for\naggregation and can freely select the round number for local updating.\nDifferent from most existing resilient approaches, which perform convergence\nanalysis based on strongly-convex loss function or homogeneously distributed\ndataset, we conduct convergence analysis for not only strongly-convex but also\nnon-convex loss function over heterogeneous dataset. According to our\ntheoretical analysis, as long as the fraction of dataset from malicious users\nis less than half, RAGA can achieve convergence at rate\n$\\mathcal{O}({1}/{T^{2/3- \\delta}})$ where $T$ is the iteration number and\n$\\delta \\in (0, 2/3)$ for non-convex loss function, and at linear rate for\nstrongly-convex loss function. Moreover, stationary point or global optimal\nsolution is proved to obtainable as data heterogeneity vanishes. Experimental\nresults corroborate the robustness of RAGA to Byzantine attacks and verifies\nthe advantage of RAGA over baselines on convergence performance under various\nintensity of Byzantine attacks, for heterogeneous dataset.\n","authors":["Shiyuan Zuo","Xingrun Yan","Rongfei Fan","Han Hu","Hangguan Shan","Tony Q. S. Quek"],"pdf_url":"https://arxiv.org/pdf/2403.13374v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13334v2","updated":"2024-03-26T12:24:46Z","published":"2024-03-20T06:37:59Z","title":"Hyacinth6B: A large language model for Traditional Chinese","summary":"  This research's primary motivation of this study is to address the high\nhardware and computational demands typically associated with LLMs.Therefore,our\ngoal is to find a balance between model lightness and performance,striving to\nmaximize performance while using a comparatively lightweight model. Hyacinth6B\nwas developed with this objective in mind,aiming to fully leverage the core\ncapabilities of LLMs without incurring substantial resource costs, effectively\npushing the boundaries of smaller model's performance. The training approach\ninvolves parameter efficient finetuning using the LoRA method.\n","authors":["Chih-Wei Song","Yin-Te Tsai"],"pdf_url":"https://arxiv.org/pdf/2403.13334v2.pdf","comment":"14pages"},{"id":"http://arxiv.org/abs/2403.17643v1","updated":"2024-03-26T12:23:34Z","published":"2024-03-26T12:23:34Z","title":"S+t-SNE - Bringing dimensionality reduction to data streams","summary":"  We present S+t-SNE, an adaptation of the t-SNE algorithm designed to handle\ninfinite data streams. The core idea behind S+t-SNE is to update the t-SNE\nembedding incrementally as new data arrives, ensuring scalability and\nadaptability to handle streaming scenarios. By selecting the most important\npoints at each step, the algorithm ensures scalability while keeping\ninformative visualisations. Employing a blind method for drift management\nadjusts the embedding space, facilitating continuous visualisation of evolving\ndata dynamics. Our experimental evaluations demonstrate the effectiveness and\nefficiency of S+t-SNE. The results highlight its ability to capture patterns in\na streaming scenario. We hope our approach offers researchers and practitioners\na real-time tool for understanding and interpreting high-dimensional data.\n","authors":["Pedro C. Vieira","João P. Montrezol","João T. Vieira","João Gama"],"pdf_url":"https://arxiv.org/pdf/2403.17643v1.pdf","comment":"This preprint has not undergone peer review or any post-submission\n  improvements or corrections. We will soon add a link to the final version of\n  this contribution that underwent peer-review and post-acceptance improvements\n  and was presented at IDA2024 (https://ida2024.org/)"},{"id":"http://arxiv.org/abs/2403.17637v1","updated":"2024-03-26T12:12:44Z","published":"2024-03-26T12:12:44Z","title":"PeersimGym: An Environment for Solving the Task Offloading Problem with\n  Reinforcement Learning","summary":"  Task offloading, crucial for balancing computational loads across devices in\nnetworks such as the Internet of Things, poses significant optimization\nchallenges, including minimizing latency and energy usage under strict\ncommunication and storage constraints. While traditional optimization falls\nshort in scalability; and heuristic approaches lack in achieving optimal\noutcomes, Reinforcement Learning (RL) offers a promising avenue by enabling the\nlearning of optimal offloading strategies through iterative interactions.\nHowever, the efficacy of RL hinges on access to rich datasets and\ncustom-tailored, realistic training environments. To address this, we introduce\nPeersimGym, an open-source, customizable simulation environment tailored for\ndeveloping and optimizing task offloading strategies within computational\nnetworks. PeersimGym supports a wide range of network topologies and\ncomputational constraints and integrates a \\textit{PettingZoo}-based interface\nfor RL agent deployment in both solo and multi-agent setups. Furthermore, we\ndemonstrate the utility of the environment through experiments with Deep\nReinforcement Learning agents, showcasing the potential of RL-based approaches\nto significantly enhance offloading strategies in distributed computing\nsettings. PeersimGym thus bridges the gap between theoretical RL models and\ntheir practical applications, paving the way for advancements in efficient task\noffloading methodologies.\n","authors":["Frederico Metelo","Stevo Racković","Pedro Ákos","Cláudia Soares"],"pdf_url":"https://arxiv.org/pdf/2403.17637v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17633v1","updated":"2024-03-26T12:08:14Z","published":"2024-03-26T12:08:14Z","title":"UADA3D: Unsupervised Adversarial Domain Adaptation for 3D Object\n  Detection with Sparse LiDAR and Large Domain Gaps","summary":"  In this study, we address a gap in existing unsupervised domain adaptation\napproaches on LiDAR-based 3D object detection, which have predominantly\nconcentrated on adapting between established, high-density autonomous driving\ndatasets. We focus on sparser point clouds, capturing scenarios from different\nperspectives: not just from vehicles on the road but also from mobile robots on\nsidewalks, which encounter significantly different environmental conditions and\nsensor configurations. We introduce Unsupervised Adversarial Domain Adaptation\nfor 3D Object Detection (UADA3D). UADA3D does not depend on pre-trained source\nmodels or teacher-student architectures. Instead, it uses an adversarial\napproach to directly learn domain-invariant features. We demonstrate its\nefficacy in various adaptation scenarios, showing significant improvements in\nboth self-driving car and mobile robot domains. Our code is open-source and\nwill be available soon.\n","authors":["Maciej K Wozniak","Mattias Hansson","Marko Thiel","Patric Jensfelt"],"pdf_url":"https://arxiv.org/pdf/2403.17633v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17632v1","updated":"2024-03-26T12:08:05Z","published":"2024-03-26T12:08:05Z","title":"Data-driven Energy Consumption Modelling for Electric Micromobility\n  using an Open Dataset","summary":"  The escalating challenges of traffic congestion and environmental degradation\nunderscore the critical importance of embracing E-Mobility solutions in urban\nspaces. In particular, micro E-Mobility tools such as E-scooters and E-bikes,\nplay a pivotal role in this transition, offering sustainable alternatives for\nurban commuters. However, the energy consumption patterns for these tools are a\ncritical aspect that impacts their effectiveness in real-world scenarios and is\nessential for trip planning and boosting user confidence in using these. To\nthis effect, recent studies have utilised physical models customised for\nspecific mobility tools and conditions, but these models struggle with\ngeneralization and effectiveness in real-world scenarios due to a notable\nabsence of open datasets for thorough model evaluation and verification. To\nfill this gap, our work presents an open dataset, collected in Dublin, Ireland,\nspecifically designed for energy modelling research related to E-Scooters and\nE-Bikes. Furthermore, we provide a comprehensive analysis of energy consumption\nmodelling based on the dataset using a set of representative machine learning\nalgorithms and compare their performance against the contemporary mathematical\nmodels as a baseline. Our results demonstrate a notable advantage for\ndata-driven models in comparison to the corresponding mathematical models for\nestimating energy consumption. Specifically, data-driven models outperform\nphysical models in accuracy by up to 83.83% for E-Bikes and 82.16% for\nE-Scooters based on an in-depth analysis of the dataset under certain\nassumptions.\n","authors":["Yue Ding","Sen Yan","Maqsood Hussain Shah","Hongyuan Fang","Ji Li","Mingming Liu"],"pdf_url":"https://arxiv.org/pdf/2403.17632v1.pdf","comment":"7 pages, 5 figures, 4 tables. This manuscript has been accepted by\n  the IEEE ITEC 2024"},{"id":"http://arxiv.org/abs/2310.12541v3","updated":"2024-03-26T12:04:44Z","published":"2023-10-19T07:46:54Z","title":"Large Language Model for Multi-objective Evolutionary Optimization","summary":"  Multiobjective evolutionary algorithms (MOEAs) are major methods for solving\nmultiobjective optimization problems (MOPs). Many MOEAs have been proposed in\nthe past decades, of which the search operators need a carefully handcrafted\ndesign with domain knowledge. Recently, some attempts have been made to replace\nthe manually designed operators in MOEAs with learning-based operators (e.g.,\nneural network models). However, much effort is still required for designing\nand training such models, and the learned operators might not generalize well\non new problems. To tackle the above challenges, this work investigates a novel\napproach that leverages the powerful large language model (LLM) to design MOEA\noperators. With proper prompt engineering, we successfully let a general LLM\nserve as a black-box search operator for decomposition-based MOEA (MOEA/D) in a\nzero-shot manner. In addition, by learning from the LLM behavior, we further\ndesign an explicit white-box operator with randomness and propose a new version\nof decomposition-based MOEA, termed MOEA/D-LO. Experimental studies on\ndifferent test benchmarks show that our proposed method can achieve competitive\nperformance with widely used MOEAs. It is also promising to see the operator\nonly learned from a few instances can have robust generalization performance on\nunseen problems with quite different patterns and settings. The results reveal\nthe potential benefits of using pre-trained LLMs in the design of MOEAs.To\nfoster reproducibility and accessibility, the source code is\nhttps://github.com/FeiLiu36/LLM4MOEA.\n","authors":["Fei Liu","Xi Lin","Zhenkun Wang","Shunyu Yao","Xialiang Tong","Mingxuan Yuan","Qingfu Zhang"],"pdf_url":"https://arxiv.org/pdf/2310.12541v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17611v1","updated":"2024-03-26T11:44:49Z","published":"2024-03-26T11:44:49Z","title":"Denoising Table-Text Retrieval for Open-Domain Question Answering","summary":"  In table-text open-domain question answering, a retriever system retrieves\nrelevant evidence from tables and text to answer questions. Previous studies in\ntable-text open-domain question answering have two common challenges: firstly,\ntheir retrievers can be affected by false-positive labels in training datasets;\nsecondly, they may struggle to provide appropriate evidence for questions that\nrequire reasoning across the table. To address these issues, we propose\nDenoised Table-Text Retriever (DoTTeR). Our approach involves utilizing a\ndenoised training dataset with fewer false positive labels by discarding\ninstances with lower question-relevance scores measured through a false\npositive detection model. Subsequently, we integrate table-level ranking\ninformation into the retriever to assist in finding evidence for questions that\ndemand reasoning across the table. To encode this ranking information, we\nfine-tune a rank-aware column encoder to identify minimum and maximum values\nwithin a column. Experimental results demonstrate that DoTTeR significantly\noutperforms strong baselines on both retrieval recall and downstream QA tasks.\nOur code is available at https://github.com/deokhk/DoTTeR.\n","authors":["Deokhyung Kang","Baikjin Jung","Yunsu Kim","Gary Geunbae Lee"],"pdf_url":"https://arxiv.org/pdf/2403.17611v1.pdf","comment":"Accepted to LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2403.17607v1","updated":"2024-03-26T11:38:39Z","published":"2024-03-26T11:38:39Z","title":"Fully-fused Multi-Layer Perceptrons on Intel Data Center GPUs","summary":"  This paper presents a SYCL implementation of Multi-Layer Perceptrons (MLPs),\nwhich targets and is optimized for the Intel Data Center GPU Max 1550. To\nincrease the performance, our implementation minimizes the slow global memory\naccesses by maximizing the data reuse within the general register file and the\nshared local memory by fusing the operations in each layer of the MLP. We show\nwith a simple roofline model that this results in a significant increase in the\narithmetic intensity, leading to improved performance, especially for\ninference. We compare our approach to a similar CUDA implementation for MLPs\nand show that our implementation on the Intel Data Center GPU outperforms the\nCUDA implementation on Nvidia's H100 GPU by a factor up to 2.84 in inference\nand 1.75 in training. The paper also showcases the efficiency of our SYCL\nimplementation in three significant areas: Image Compression, Neural Radiance\nFields, and Physics-Informed Machine Learning. In all cases, our implementation\noutperforms the off-the-shelf Intel Extension for PyTorch (IPEX) implementation\non the same Intel GPU by up to a factor of 30 and the CUDA PyTorch version on\nNvidia's H100 GPU by up to a factor 19. The code can be found at\nhttps://github.com/intel/tiny-dpcpp-nn.\n","authors":["Kai Yuan","Christoph Bauinger","Xiangyi Zhang","Pascal Baehr","Matthias Kirchhart","Darius Dabert","Adrien Tousnakhoff","Pierre Boudier","Michael Paulitsch"],"pdf_url":"https://arxiv.org/pdf/2403.17607v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16451v2","updated":"2024-03-26T11:35:08Z","published":"2024-03-25T06:30:54Z","title":"DeepMachining: Online Prediction of Machining Errors of Lathe Machines","summary":"  We describe DeepMachining, a deep learning-based AI system for online\nprediction of machining errors of lathe machine operations. We have built and\nevaluated DeepMachining based on manufacturing data from factories.\nSpecifically, we first pretrain a deep learning model for a given lathe\nmachine's operations to learn the salient features of machining states. Then,\nwe fine-tune the pretrained model to adapt to specific machining tasks. We\ndemonstrate that DeepMachining achieves high prediction accuracy for multiple\ntasks that involve different workpieces and cutting tools. To the best of our\nknowledge, this work is one of the first factory experiments using pre-trained\ndeep-learning models to predict machining errors of lathe machines.\n","authors":["Xiang-Li Lu","Hwai-Jung Hsu","Che-Wei Chou","H. T. Kung","Chen-Hsin Lee"],"pdf_url":"https://arxiv.org/pdf/2403.16451v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.14790v2","updated":"2024-03-26T11:29:21Z","published":"2023-05-24T06:43:23Z","title":"Advancing Topic Segmentation and Outline Generation in Chinese Texts:\n  The Paragraph-level Topic Representation, Corpus, and Benchmark","summary":"  Topic segmentation and outline generation strive to divide a document into\ncoherent topic sections and generate corresponding subheadings, unveiling the\ndiscourse topic structure of a document. Compared with sentence-level topic\nstructure, the paragraph-level topic structure can quickly grasp and understand\nthe overall context of the document from a higher level, benefitting many\ndownstream tasks such as summarization, discourse parsing, and information\nretrieval. However, the lack of large-scale, high-quality Chinese\nparagraph-level topic structure corpora restrained relative research and\napplications. To fill this gap, we build the Chinese paragraph-level topic\nrepresentation, corpus, and benchmark in this paper. Firstly, we propose a\nhierarchical paragraph-level topic structure representation with three layers\nto guide the corpus construction. Then, we employ a two-stage man-machine\ncollaborative annotation method to construct the largest Chinese\nParagraph-level Topic Structure corpus (CPTS), achieving high quality. We also\nbuild several strong baselines, including ChatGPT, to validate the\ncomputability of CPTS on two fundamental tasks (topic segmentation and outline\ngeneration) and preliminarily verified its usefulness for the downstream task\n(discourse parsing).\n","authors":["Feng Jiang","Weihao Liu","Xiaomin Chu","Peifeng Li","Qiaoming Zhu","Haizhou Li"],"pdf_url":"https://arxiv.org/pdf/2305.14790v2.pdf","comment":"Accepted by LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2403.04701v3","updated":"2024-03-26T11:26:17Z","published":"2024-03-07T17:48:48Z","title":"ObjectCompose: Evaluating Resilience of Vision-Based Models on\n  Object-to-Background Compositional Changes","summary":"  Given the large-scale multi-modal training of recent vision-based models and\ntheir generalization capabilities, understanding the extent of their robustness\nis critical for their real-world deployment. In this work, we evaluate the\nresilience of current vision-based models against diverse object-to-background\ncontext variations. The majority of robustness evaluation methods have\nintroduced synthetic datasets to induce changes to object characteristics\n(viewpoints, scale, color) or utilized image transformation techniques\n(adversarial changes, common corruptions) on real images to simulate shifts in\ndistributions. Recent works have explored leveraging large language models and\ndiffusion models to generate changes in the background. However, these methods\neither lack in offering control over the changes to be made or distort the\nobject semantics, making them unsuitable for the task. Our method, on the other\nhand, can induce diverse object-to-background changes while preserving the\noriginal semantics and appearance of the object. To achieve this goal, we\nharness the generative capabilities of text-to-image, image-to-text, and\nimage-to-segment models to automatically generate a broad spectrum of\nobject-to-background changes. We induce both natural and adversarial background\nchanges by either modifying the textual prompts or optimizing the latents and\ntextual embedding of text-to-image models. We produce various versions of\nstandard vision datasets (ImageNet, COCO), incorporating either diverse and\nrealistic backgrounds into the images or introducing color, texture, and\nadversarial changes in the background. We conduct extensive experiment to\nanalyze the robustness of vision-based models against object-to-background\ncontext variations across diverse tasks. Code\nhttps://github.com/Muhammad-Huzaifaa/ObjectCompose.git\n","authors":["Hashmat Shadab Malik","Muhammad Huzaifa","Muzammal Naseer","Salman Khan","Fahad Shahbaz Khan"],"pdf_url":"https://arxiv.org/pdf/2403.04701v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13518v2","updated":"2024-03-26T11:16:47Z","published":"2024-03-20T11:38:30Z","title":"Motion Generation from Fine-grained Textual Descriptions","summary":"  The task of text2motion is to generate human motion sequences from given\ntextual descriptions, where the model explores diverse mappings from natural\nlanguage instructions to human body movements. While most existing works are\nconfined to coarse-grained motion descriptions, e.g., \"A man squats.\",\nfine-grained descriptions specifying movements of relevant body parts are\nbarely explored. Models trained with coarse-grained texts may not be able to\nlearn mappings from fine-grained motion-related words to motion primitives,\nresulting in the failure to generate motions from unseen descriptions. In this\npaper, we build a large-scale language-motion dataset specializing in\nfine-grained textual descriptions, FineHumanML3D, by feeding GPT-3.5-turbo with\nstep-by-step instructions with pseudo-code compulsory checks. Accordingly, we\ndesign a new text2motion model, FineMotionDiffuse, making full use of\nfine-grained textual information. Our quantitative evaluation shows that\nFineMotionDiffuse trained on FineHumanML3D improves FID by a large margin of\n0.38, compared with competitive baselines. According to the qualitative\nevaluation and case study, our model outperforms MotionDiffuse in generating\nspatially or chronologically composite motions, by learning the implicit\nmappings from fine-grained descriptions to the corresponding basic motions. We\nrelease our data at https://github.com/KunhangL/finemotiondiffuse.\n","authors":["Kunhang Li","Yansong Feng"],"pdf_url":"https://arxiv.org/pdf/2403.13518v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.08644v3","updated":"2024-03-26T11:13:56Z","published":"2024-02-13T18:24:08Z","title":"Tandem Transformers for Inference Efficient LLMs","summary":"  The autoregressive nature of conventional large language models (LLMs)\ninherently limits inference speed, as tokens are generated sequentially. While\nspeculative and parallel decoding techniques attempt to mitigate this, they\nface limitations: either relying on less accurate smaller models for generation\nor failing to fully leverage the base LLM's representations.\n  We introduce a novel architecture, Tandem transformers, to address these\nissues. This architecture uniquely combines (1) a small autoregressive model\nand (2) a large model operating in block mode (processing multiple tokens\nsimultaneously). The small model's predictive accuracy is substantially\nenhanced by granting it attention to the large model's richer representations.\nOn the PaLM2 pretraining dataset, a tandem of PaLM2-Bison and PaLM2-Gecko\ndemonstrates a 3.3% improvement in next-token prediction accuracy over a\nstandalone PaLM2-Gecko, offering a 1.16x speedup compared to a PaLM2-Otter\nmodel with comparable downstream performance. We further incorporate the tandem\nmodel within the speculative decoding (SPEED) framework where the large model\nvalidates tokens from the small model. This ensures that the Tandem of\nPaLM2-Bison and PaLM2-Gecko achieves substantial speedup (around 1.14x faster\nthan using vanilla PaLM2-Gecko in SPEED) while maintaining identical downstream\ntask accuracy.\n","authors":["Aishwarya P S","Pranav Ajit Nair","Yashas Samaga","Toby Boyd","Sanjiv Kumar","Prateek Jain","Praneeth Netrapalli"],"pdf_url":"https://arxiv.org/pdf/2402.08644v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17601v1","updated":"2024-03-26T11:13:35Z","published":"2024-03-26T11:13:35Z","title":"LASIL: Learner-Aware Supervised Imitation Learning For Long-term\n  Microscopic Traffic Simulation","summary":"  Microscopic traffic simulation plays a crucial role in transportation\nengineering by providing insights into individual vehicle behavior and overall\ntraffic flow. However, creating a realistic simulator that accurately\nreplicates human driving behaviors in various traffic conditions presents\nsignificant challenges. Traditional simulators relying on heuristic models\noften fail to deliver accurate simulations due to the complexity of real-world\ntraffic environments. Due to the covariate shift issue, existing imitation\nlearning-based simulators often fail to generate stable long-term simulations.\nIn this paper, we propose a novel approach called learner-aware supervised\nimitation learning to address the covariate shift problem in multi-agent\nimitation learning. By leveraging a variational autoencoder simultaneously\nmodeling the expert and learner state distribution, our approach augments\nexpert states such that the augmented state is aware of learner state\ndistribution. Our method, applied to urban traffic simulation, demonstrates\nsignificant improvements over existing state-of-the-art baselines in both\nshort-term microscopic and long-term macroscopic realism when evaluated on the\nreal-world dataset pNEUMA.\n","authors":["Ke Guo","Zhenwei Miao","Wei Jing","Weiwei Liu","Weizi Li","Dayang Hao","Jia Pan"],"pdf_url":"https://arxiv.org/pdf/2403.17601v1.pdf","comment":"accepted by cvpr 2024. arXiv admin note: text overlap with\n  arXiv:2306.06401"},{"id":"http://arxiv.org/abs/2306.00038v3","updated":"2024-03-26T11:07:30Z","published":"2023-05-31T09:51:45Z","title":"FedCSD: A Federated Learning Based Approach for Code-Smell Detection","summary":"  This paper proposes a Federated Learning Code Smell Detection (FedCSD)\napproach that allows organizations to collaboratively train federated ML models\nwhile preserving their data privacy. These assertions have been supported by\nthree experiments that have significantly leveraged three manually validated\ndatasets aimed at detecting and examining different code smell scenarios. In\nexperiment 1, which was concerned with a centralized training experiment,\ndataset two achieved the lowest accuracy (92.30%) with fewer smells, while\ndatasets one and three achieved the highest accuracy with a slight difference\n(98.90% and 99.5%, respectively). This was followed by experiment 2, which was\nconcerned with cross-evaluation, where each ML model was trained using one\ndataset, which was then evaluated over the other two datasets. Results from\nthis experiment show a significant drop in the model's accuracy (lowest\naccuracy: 63.80\\%) where fewer smells exist in the training dataset, which has\na noticeable reflection (technical debt) on the model's performance. Finally,\nthe last and third experiments evaluate our approach by splitting the dataset\ninto 10 companies. The ML model was trained on the company's site, then all\nmodel-updated weights were transferred to the server. Ultimately, an accuracy\nof 98.34% was achieved by the global model that has been trained using 10\ncompanies for 100 training rounds. The results reveal a slight difference in\nthe global model's accuracy compared to the highest accuracy of the centralized\nmodel, which can be ignored in favour of the global model's comprehensive\nknowledge, lower training cost, preservation of data privacy, and avoidance of\nthe technical debt problem.\n","authors":["Sadi Alawadi","Khalid Alkharabsheh","Fahed Alkhabbas","Victor Kebande","Feras M. Awaysheh","Fabio Palomba","Mohammed Awad"],"pdf_url":"https://arxiv.org/pdf/2306.00038v3.pdf","comment":"17 pages, 7 figures, Journal paper"},{"id":"http://arxiv.org/abs/2403.17589v1","updated":"2024-03-26T10:54:07Z","published":"2024-03-26T10:54:07Z","title":"Dual Memory Networks: A Versatile Adaptation Approach for\n  Vision-Language Models","summary":"  With the emergence of pre-trained vision-language models like CLIP, how to\nadapt them to various downstream classification tasks has garnered significant\nattention in recent research. The adaptation strategies can be typically\ncategorized into three paradigms: zero-shot adaptation, few-shot adaptation,\nand the recently-proposed training-free few-shot adaptation. Most existing\napproaches are tailored for a specific setting and can only cater to one or two\nof these paradigms. In this paper, we introduce a versatile adaptation approach\nthat can effectively work under all three settings. Specifically, we propose\nthe dual memory networks that comprise dynamic and static memory components.\nThe static memory caches training data knowledge, enabling training-free\nfew-shot adaptation, while the dynamic memory preserves historical test\nfeatures online during the testing process, allowing for the exploration of\nadditional data insights beyond the training set. This novel capability\nenhances model performance in the few-shot setting and enables model usability\nin the absence of training data. The two memory networks employ the same\nflexible memory interactive strategy, which can operate in a training-free mode\nand can be further enhanced by incorporating learnable projection layers. Our\napproach is tested across 11 datasets under the three task settings.\nRemarkably, in the zero-shot scenario, it outperforms existing methods by over\n3\\% and even shows superior results against methods utilizing external training\ndata. Additionally, our method exhibits robust performance against natural\ndistribution shifts. Codes are available at \\url{https://github.com/YBZh/DMN}.\n","authors":["Yabin Zhang","Wenjie Zhu","Hui Tang","Zhiyuan Ma","Kaiyang Zhou","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.17589v1.pdf","comment":"CVPR2024; Codes are available at \\url{https://github.com/YBZh/DMN}"},{"id":"http://arxiv.org/abs/2403.17587v1","updated":"2024-03-26T10:53:25Z","published":"2024-03-26T10:53:25Z","title":"Parameterized Analysis of Bribery in Challenge the Champ Tournaments","summary":"  Challenge the champ tournaments are one of the simplest forms of competition,\nwhere a (initially selected) champ is repeatedly challenged by other players.\nIf a player beats the champ, then that player is considered the new (current)\nchamp. Each player in the competition challenges the current champ once in a\nfixed order. The champ of the last round is considered the winner of the\ntournament. We investigate a setting where players can be bribed to lower their\nwinning probability against the initial champ. The goal is to maximize the\nprobability of the initial champ winning the tournament by bribing the other\nplayers, while not exceeding a given budget for the bribes. Mattei et al.\n[Journal of Applied Logic, 2015] showed that the problem can be solved in\npseudo-polynomial time, and that it is in XP when parameterized by the number\nof players.\n  We show that the problem is weakly NP-hard and W[1]-hard when parameterized\nby the number of players. On the algorithmic side, we show that the problem is\nfixed-parameter tractable when parameterized either by the number of different\nbribe values or the number of different probability values. To this end, we\nestablish several results that are of independent interest. In particular, we\nshow that the product knapsack problem is W[1]-hard when parameterized by the\nnumber of items in the knapsack, and that constructive bribery for cup\ntournaments is W[1]-hard when parameterized by the number of players.\nFurthermore, we present a novel way of designing mixed integer linear programs,\nensuring optimal solutions where all variables are integers.\n","authors":["Juhi Chaudhary","Hendrik Molter","Meirav Zehavi"],"pdf_url":"https://arxiv.org/pdf/2403.17587v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.11537v2","updated":"2024-03-26T10:45:40Z","published":"2024-02-18T10:36:05Z","title":"Deciphering the Impact of Pretraining Data on Large Language Models\n  through Machine Unlearning","summary":"  Through pretraining on a corpus with various sources, Large Language Models\n(LLMs) have gained impressive performance. However, the impact of each\ncomponent of the pretraining corpus remains opaque. As a result, the\norganization of the pretraining corpus is still empirical and may deviate from\nthe optimal. To address this issue, we systematically analyze the impact of 48\ndatasets from 5 major categories of pretraining data of LLMs and measure their\nimpacts on LLMs using benchmarks about nine major categories of model\ncapabilities. Our analyses provide empirical results about the contribution of\nmultiple corpora on the performances of LLMs, along with their joint impact\npatterns, including complementary, orthogonal, and correlational relationships.\nWe also identify a set of ``high-impact data'' such as Books that is\nsignificantly related to a set of model capabilities. These findings provide\ninsights into the organization of data to support more efficient pretraining of\nLLMs.\n","authors":["Yang Zhao","Li Du","Xiao Ding","Kai Xiong","Zhouhao Sun","Jun Shi","Ting Liu","Bing Qin"],"pdf_url":"https://arxiv.org/pdf/2402.11537v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17582v1","updated":"2024-03-26T10:45:11Z","published":"2024-03-26T10:45:11Z","title":"Towards a Zero-Data, Controllable, Adaptive Dialog System","summary":"  Conversational Tree Search (V\\\"ath et al., 2023) is a recent approach to\ncontrollable dialog systems, where domain experts shape the behavior of a\nReinforcement Learning agent through a dialog tree. The agent learns to\nefficiently navigate this tree, while adapting to information needs, e.g.,\ndomain familiarity, of different users. However, the need for additional\ntraining data hinders deployment in new domains. To address this, we explore\napproaches to generate this data directly from dialog trees. We improve the\noriginal approach, and show that agents trained on synthetic data can achieve\ncomparable dialog success to models trained on human data, both when using a\ncommercial Large Language Model for generation, or when using a smaller\nopen-source model, running on a single GPU. We further demonstrate the\nscalability of our approach by collecting and testing on two new datasets:\nONBOARD, a new domain helping foreign residents moving to a new city, and the\nmedical domain DIAGNOSE, a subset of Wikipedia articles related to scalp and\nhead symptoms. Finally, we perform human testing, where no statistically\nsignificant differences were found in either objective or subjective measures\nbetween models trained on human and generated data.\n","authors":["Dirk Väth","Lindsey Vanderlyn","Ngoc Thang Vu"],"pdf_url":"https://arxiv.org/pdf/2403.17582v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.08274v4","updated":"2024-03-26T10:36:31Z","published":"2023-12-13T16:43:41Z","title":"High-throughput Biomedical Relation Extraction for Semi-Structured Web\n  Articles Empowered by Large Language Models","summary":"  Objective: To develop a high-throughput biomedical relation extraction system\nthat takes advantage of the large language models'(LLMs) reading comprehension\nability and biomedical world knowledge in a scalable and evidential manner.\nMethods: We formulate the relation extraction task as binary classifications\nfor large language models. Specifically, LLMs make the decision based on the\nexternal corpus and its world knowledge, giving the reason for the judgment for\nfactual verification. This method is tailored for semi-structured web articles,\nwherein we designate the main title as the tail entity and explicitly\nincorporate it into the context, and the potential head entities are matched\nbased on a biomedical thesaurus. Moreover, lengthy contents are sliced into\ntext chunks, embedded, and retrieved with additional embedding models. Results:\nUsing an open-source LLM, we extracted 248659 relation triplets of three\ndistinct relation types from three reputable biomedical websites. To assess the\nefficacy of the basic pipeline employed for biomedical relation extraction, we\ncurated a benchmark dataset annotated by a medical expert. Evaluation results\nindicate that the pipeline exhibits performance comparable to that of GPT-4.\nCase studies further illuminate challenges faced by contemporary LLMs in the\ncontext of biomedical relation extraction for semi-structured web articles.\nConclusion: The proposed method has demonstrated its effectiveness in\nleveraging the strengths of LLMs for high-throughput biomedical relation\nextraction. Its adaptability is evident, as it can be seamlessly extended to\ndiverse semi-structured biomedical websites, facilitating the extraction of\nvarious types of biomedical relations with ease.\n","authors":["Songchi Zhou","Sheng Yu"],"pdf_url":"https://arxiv.org/pdf/2312.08274v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.03611v2","updated":"2024-03-26T10:13:11Z","published":"2023-12-06T16:55:53Z","title":"DreamComposer: Controllable 3D Object Generation via Multi-View\n  Conditions","summary":"  Utilizing pre-trained 2D large-scale generative models, recent works are\ncapable of generating high-quality novel views from a single in-the-wild image.\nHowever, due to the lack of information from multiple views, these works\nencounter difficulties in generating controllable novel views. In this paper,\nwe present DreamComposer, a flexible and scalable framework that can enhance\nexisting view-aware diffusion models by injecting multi-view conditions.\nSpecifically, DreamComposer first uses a view-aware 3D lifting module to obtain\n3D representations of an object from multiple views. Then, it renders the\nlatent features of the target view from 3D representations with the multi-view\nfeature fusion module. Finally the target view features extracted from\nmulti-view inputs are injected into a pre-trained diffusion model. Experiments\nshow that DreamComposer is compatible with state-of-the-art diffusion models\nfor zero-shot novel view synthesis, further enhancing them to generate\nhigh-fidelity novel view images with multi-view conditions, ready for\ncontrollable 3D object reconstruction and various other applications.\n","authors":["Yunhan Yang","Yukun Huang","Xiaoyang Wu","Yuan-Chen Guo","Song-Hai Zhang","Hengshuang Zhao","Tong He","Xihui Liu"],"pdf_url":"https://arxiv.org/pdf/2312.03611v2.pdf","comment":"Project Page: https://yhyang-myron.github.io/DreamComposer/"},{"id":"http://arxiv.org/abs/2403.17556v1","updated":"2024-03-26T10:04:24Z","published":"2024-03-26T10:04:24Z","title":"m3P: Towards Multimodal Multilingual Translation with Multimodal Prompt","summary":"  Multilingual translation supports multiple translation directions by\nprojecting all languages in a shared space, but the translation quality is\nundermined by the difference between languages in the text-only modality,\nespecially when the number of languages is large. To bridge this gap, we\nintroduce visual context as the universal language-independent representation\nto facilitate multilingual translation. In this paper, we propose a framework\nto leverage the multimodal prompt to guide the Multimodal Multilingual neural\nMachine Translation (m3P), which aligns the representations of different\nlanguages with the same meaning and generates the conditional vision-language\nmemory for translation. We construct a multilingual multimodal instruction\ndataset (InstrMulti102) to support 102 languages. Our method aims to minimize\nthe representation distance of different languages by regarding the image as a\ncentral language. Experimental results show that m3P outperforms previous\ntext-only baselines and multilingual multimodal methods by a large margin.\nFurthermore, the probing experiments validate the effectiveness of our method\nin enhancing translation under the low-resource and massively multilingual\nscenario.\n","authors":["Jian Yang","Hongcheng Guo","Yuwei Yin","Jiaqi Bai","Bing Wang","Jiaheng Liu","Xinnian Liang","Linzheng Cahi","Liqun Yang","Zhoujun Li"],"pdf_url":"https://arxiv.org/pdf/2403.17556v1.pdf","comment":"COLING 2024"},{"id":"http://arxiv.org/abs/2403.17549v1","updated":"2024-03-26T09:55:49Z","published":"2024-03-26T09:55:49Z","title":"Practical Applications of Advanced Cloud Services and Generative AI\n  Systems in Medical Image Analysis","summary":"  The medical field is one of the important fields in the application of\nartificial intelligence technology. With the explosive growth and\ndiversification of medical data, as well as the continuous improvement of\nmedical needs and challenges, artificial intelligence technology is playing an\nincreasingly important role in the medical field. Artificial intelligence\ntechnologies represented by computer vision, natural language processing, and\nmachine learning have been widely penetrated into diverse scenarios such as\nmedical imaging, health management, medical information, and drug research and\ndevelopment, and have become an important driving force for improving the level\nand quality of medical services.The article explores the transformative\npotential of generative AI in medical imaging, emphasizing its ability to\ngenerate syntheticACM-2 data, enhance images, aid in anomaly detection, and\nfacilitate image-to-image translation. Despite challenges like model\ncomplexity, the applications of generative models in healthcare, including\nMed-PaLM 2 technology, show promising results. By addressing limitations in\ndataset size and diversity, these models contribute to more accurate diagnoses\nand improved patient outcomes. However, ethical considerations and\ncollaboration among stakeholders are essential for responsible implementation.\nThrough experiments leveraging GANs to augment brain tumor MRI datasets, the\nstudy demonstrates how generative AI can enhance image quality and diversity,\nultimately advancing medical diagnostics and patient care.\n","authors":["Jingyu Xu","Binbin Wu","Jiaxin Huang","Yulu Gong","Yifan Zhang","Bo Liu"],"pdf_url":"https://arxiv.org/pdf/2403.17549v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.07953v2","updated":"2024-03-26T09:52:36Z","published":"2021-10-15T09:12:44Z","title":"Attention-based Estimation and Prediction of Human Intent to augment\n  Haptic Glove aided Control of Robotic Hand","summary":"  The letter focuses on Haptic Glove (HG) based control of a Robotic Hand (RH)\nexecuting in-hand manipulation of certain objects of interest. The high\ndimensional motion signals in HG and RH possess intrinsic variability of\nkinematics resulting in difficulty to establish a direct mapping of the motion\nsignals from HG onto the RH. An estimation mechanism is proposed to quantify\nthe motion signal acquired from the human controller in relation to the\nintended goal pose of the object being held by the robotic hand. A control\nalgorithm is presented to transform the synthesized intent at the RH and allow\nrelocation of the object to the expected goal pose. The lag in synthesis of the\nintent in the presence of communication delay leads to a requirement of\npredicting the estimated intent. We leverage an attention-based convolutional\nneural network encoder to predict the trajectory of intent for a certain\nlookahead to compensate for the delays. The proposed methodology is evaluated\nacross objects of different shapes, mass, and materials. We present a\ncomparative performance of the estimation and prediction mechanisms on\n5G-driven real-world robotic setup against benchmark methodologies. The\ntest-MSE in prediction of human intent is reported to yield ~ 97.3 -98.7%\nimprovement of accuracy in comparison to LSTM-based benchmark\n","authors":["Muneeb Ahmed","Rajesh Kumar","Qaim Abbas","Brejesh Lall","Arzad A. Kherani","Sudipto Mukherjee"],"pdf_url":"https://arxiv.org/pdf/2110.07953v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17542v1","updated":"2024-03-26T09:44:57Z","published":"2024-03-26T09:44:57Z","title":"VDSC: Enhancing Exploration Timing with Value Discrepancy and State\n  Counts","summary":"  Despite the considerable attention given to the questions of \\textit{how\nmuch} and \\textit{how to} explore in deep reinforcement learning, the\ninvestigation into \\textit{when} to explore remains relatively less researched.\nWhile more sophisticated exploration strategies can excel in specific, often\nsparse reward environments, existing simpler approaches, such as\n$\\epsilon$-greedy, persist in outperforming them across a broader spectrum of\ndomains. The appeal of these simpler strategies lies in their ease of\nimplementation and generality across a wide range of domains. The downside is\nthat these methods are essentially a blind switching mechanism, which\ncompletely disregards the agent's internal state. In this paper, we propose to\nleverage the agent's internal state to decide \\textit{when} to explore,\naddressing the shortcomings of blind switching mechanisms. We present Value\nDiscrepancy and State Counts through homeostasis (VDSC), a novel approach for\nefficient exploration timing. Experimental results on the Atari suite\ndemonstrate the superiority of our strategy over traditional methods such as\n$\\epsilon$-greedy and Boltzmann, as well as more sophisticated techniques like\nNoisy Nets.\n","authors":["Marius Captari","Remo Sasso","Matthia Sabatelli"],"pdf_url":"https://arxiv.org/pdf/2403.17542v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17532v1","updated":"2024-03-26T09:36:59Z","published":"2024-03-26T09:36:59Z","title":"KC-GenRe: A Knowledge-constrained Generative Re-ranking Method Based on\n  Large Language Models for Knowledge Graph Completion","summary":"  The goal of knowledge graph completion (KGC) is to predict missing facts\namong entities. Previous methods for KGC re-ranking are mostly built on\nnon-generative language models to obtain the probability of each candidate.\nRecently, generative large language models (LLMs) have shown outstanding\nperformance on several tasks such as information extraction and dialog systems.\nLeveraging them for KGC re-ranking is beneficial for leveraging the extensive\npre-trained knowledge and powerful generative capabilities. However, it may\nencounter new problems when accomplishing the task, namely mismatch,\nmisordering and omission. To this end, we introduce KC-GenRe, a\nknowledge-constrained generative re-ranking method based on LLMs for KGC. To\novercome the mismatch issue, we formulate the KGC re-ranking task as a\ncandidate identifier sorting generation problem implemented by generative LLMs.\nTo tackle the misordering issue, we develop a knowledge-guided interactive\ntraining method that enhances the identification and ranking of candidates. To\naddress the omission issue, we design a knowledge-augmented constrained\ninference method that enables contextual prompting and controlled generation,\nso as to obtain valid rankings. Experimental results show that KG-GenRe\nachieves state-of-the-art performance on four datasets, with gains of up to\n6.7% and 7.7% in the MRR and Hits@1 metric compared to previous methods, and\n9.0% and 11.1% compared to that without re-ranking. Extensive analysis\ndemonstrates the effectiveness of components in KG-GenRe.\n","authors":["Yilin Wang","Minghao Hu","Zhen Huang","Dongsheng Li","Dong Yang","Xicheng Lu"],"pdf_url":"https://arxiv.org/pdf/2403.17532v1.pdf","comment":"This paper has been accepted for publication in the proceedings of\n  LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2403.17530v1","updated":"2024-03-26T09:36:20Z","published":"2024-03-26T09:36:20Z","title":"Boosting Few-Shot Learning with Disentangled Self-Supervised Learning\n  and Meta-Learning for Medical Image Classification","summary":"  Background and objective: Employing deep learning models in critical domains\nsuch as medical imaging poses challenges associated with the limited\navailability of training data. We present a strategy for improving the\nperformance and generalization capabilities of models trained in low-data\nregimes. Methods: The proposed method starts with a pre-training phase, where\nfeatures learned in a self-supervised learning setting are disentangled to\nimprove the robustness of the representations for downstream tasks. We then\nintroduce a meta-fine-tuning step, leveraging related classes between\nmeta-training and meta-testing phases but varying the granularity level. This\napproach aims to enhance the model's generalization capabilities by exposing it\nto more challenging classification tasks during meta-training and evaluating it\non easier tasks but holding greater clinical relevance during meta-testing. We\ndemonstrate the effectiveness of the proposed approach through a series of\nexperiments exploring several backbones, as well as diverse pre-training and\nfine-tuning schemes, on two distinct medical tasks, i.e., classification of\nprostate cancer aggressiveness from MRI data and classification of breast\ncancer malignity from microscopic images. Results: Our results indicate that\nthe proposed approach consistently yields superior performance w.r.t. ablation\nexperiments, maintaining competitiveness even when a distribution shift between\ntraining and evaluation data occurs. Conclusion: Extensive experiments\ndemonstrate the effectiveness and wide applicability of the proposed approach.\nWe hope that this work will add another solution to the arsenal of addressing\nlearning issues in data-scarce imaging domains.\n","authors":["Eva Pachetti","Sotirios A. Tsaftaris","Sara Colantonio"],"pdf_url":"https://arxiv.org/pdf/2403.17530v1.pdf","comment":"20 pages, 4 figures, 4 tables. Submitted to Elsevier on 25 March 2024"},{"id":"http://arxiv.org/abs/2403.08281v4","updated":"2024-03-26T09:29:51Z","published":"2024-03-13T06:18:48Z","title":"Mastering Text, Code and Math Simultaneously via Fusing Highly\n  Specialized Language Models","summary":"  Underlying data distributions of natural language, programming code, and\nmathematical symbols vary vastly, presenting a complex challenge for large\nlanguage models (LLMs) that strive to achieve high performance across all three\ndomains simultaneously. Achieving a very high level of proficiency for an LLM\nwithin a specific domain often requires extensive training with relevant\ncorpora, which is typically accompanied by a sacrifice in performance in other\ndomains. In this paper, we propose to fuse models that are already\nhighly-specialized directly. The proposed fusing framework, UltraFuser,\nconsists of three distinct specialists that are already sufficiently trained on\nlanguage, coding, and mathematics. A token-level gating mechanism is introduced\nto blend the specialists' outputs. A two-stage training strategy accompanied by\nbalanced sampling is designed to ensure stability. To effectively train the\nfused model, we further construct a high-quality supervised instruction tuning\ndataset, UltraChat 2, which includes text, code, and mathematical content. This\ndataset comprises approximately 300,000 instructions and covers a wide range of\ntopics in each domain. Experiments show that our model could simultaneously\nachieve mastery of the three crucial domains.\n","authors":["Ning Ding","Yulin Chen","Ganqu Cui","Xingtai Lv","Weilin Zhao","Ruobing Xie","Bowen Zhou","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2403.08281v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17525v1","updated":"2024-03-26T09:26:12Z","published":"2024-03-26T09:26:12Z","title":"Equipping Sketch Patches with Context-Aware Positional Encoding for\n  Graphic Sketch Representation","summary":"  The drawing order of a sketch records how it is created stroke-by-stroke by a\nhuman being. For graphic sketch representation learning, recent studies have\ninjected sketch drawing orders into graph edge construction by linking each\npatch to another in accordance to a temporal-based nearest neighboring\nstrategy. However, such constructed graph edges may be unreliable, since a\nsketch could have variants of drawings. In this paper, we propose a\nvariant-drawing-protected method by equipping sketch patches with context-aware\npositional encoding (PE) to make better use of drawing orders for learning\ngraphic sketch representation. Instead of injecting sketch drawings into graph\nedges, we embed these sequential information into graph nodes only. More\nspecifically, each patch embedding is equipped with a sinusoidal absolute PE to\nhighlight the sequential position in the drawing order. And its neighboring\npatches, ranked by the values of self-attention scores between patch\nembeddings, are equipped with learnable relative PEs to restore the contextual\npositions within a neighborhood. During message aggregation via graph\nconvolutional networks, a node receives both semantic contents from patch\nembeddings and contextual patterns from PEs by its neighbors, arriving at\ndrawing-order-enhanced sketch representations. Experimental results indicate\nthat our method significantly improves sketch healing and controllable sketch\nsynthesis.\n","authors":["Sicong Zang","Zhijun Fang"],"pdf_url":"https://arxiv.org/pdf/2403.17525v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16291v2","updated":"2024-03-26T09:23:07Z","published":"2024-03-24T20:43:29Z","title":"Guessing human intentions to avoid dangerous situations in caregiving\n  robots","summary":"  For robots to interact socially, they must interpret human intentions and\nanticipate their potential outcomes accurately. This is particularly important\nfor social robots designed for human care, which may face potentially dangerous\nsituations for people, such as unseen obstacles in their way, that should be\navoided. This paper explores the Artificial Theory of Mind (ATM) approach to\ninferring and interpreting human intentions. We propose an algorithm that\ndetects risky situations for humans, selecting a robot action that removes the\ndanger in real time. We use the simulation-based approach to ATM and adopt the\n'like-me' policy to assign intentions and actions to people. Using this\nstrategy, the robot can detect and act with a high rate of success under\ntime-constrained situations. The algorithm has been implemented as part of an\nexisting robotics cognitive architecture and tested in simulation scenarios.\nThree experiments have been conducted to test the implementation's robustness,\nprecision and real-time response, including a simulated scenario, a\nhuman-in-the-loop hybrid configuration and a real-world scenario.\n","authors":["Noé Zapata","Gerardo Pérez","Lucas Bonilla","Pedro Núñez","Pilar Bachiller","Pablo Bustos"],"pdf_url":"https://arxiv.org/pdf/2403.16291v2.pdf","comment":"8 pages, 6 figures. Submitted to IROS2024. For associated mpeg file\n  see https://youtu.be/87UEB8P97KY"},{"id":"http://arxiv.org/abs/2403.17516v1","updated":"2024-03-26T09:18:59Z","published":"2024-03-26T09:18:59Z","title":"MapGuide: A Simple yet Effective Method to Reconstruct Continuous\n  Language from Brain Activities","summary":"  Decoding continuous language from brain activity is a formidable yet\npromising field of research. It is particularly significant for aiding people\nwith speech disabilities to communicate through brain signals. This field\naddresses the complex task of mapping brain signals to text. The previous best\nattempt reverse-engineered this process in an indirect way: it began by\nlearning to encode brain activity from text and then guided text generation by\naligning with predicted brain responses. In contrast, we propose a simple yet\neffective method that guides text reconstruction by directly comparing them\nwith the predicted text embeddings mapped from brain activities. Comprehensive\nexperiments reveal that our method significantly outperforms the current\nstate-of-the-art model, showing average improvements of 77% and 54% on BLEU and\nMETEOR scores. We further validate the proposed modules through detailed\nablation studies and case analyses and highlight a critical correlation: the\nmore precisely we map brain activities to text embeddings, the better the text\nreconstruction results. Such insight can simplify the task of reconstructing\nlanguage from brain activities for future work, emphasizing the importance of\nimproving brain-to-text-embedding mapping techniques.\n","authors":["Xinpei Zhao","Jingyuan Sun","Shaonan Wang","Jing Ye","Xiaohan Zhang","Chengqing Zong"],"pdf_url":"https://arxiv.org/pdf/2403.17516v1.pdf","comment":"Accepted to NAACL 2024 main conference"},{"id":"http://arxiv.org/abs/2403.17515v1","updated":"2024-03-26T09:18:50Z","published":"2024-03-26T09:18:50Z","title":"Prediction-sharing During Training and Inference","summary":"  Two firms are engaged in a competitive prediction task. Each firm has two\nsources of data -- labeled historical data and unlabeled inference-time data --\nand uses the former to derive a prediction model, and the latter to make\npredictions on new instances. We study data-sharing contracts between the\nfirms. The novelty of our study is to introduce and highlight the differences\nbetween contracts that share prediction models only, contracts to share\ninference-time predictions only, and contracts to share both. Our analysis\nproceeds on three levels. First, we develop a general Bayesian framework that\nfacilitates our study. Second, we narrow our focus to two natural settings\nwithin this framework: (i) a setting in which the accuracy of each firm's\nprediction model is common knowledge, but the correlation between the\nrespective models is unknown; and (ii) a setting in which two hypotheses exist\nregarding the optimal predictor, and one of the firms has a structural\nadvantage in deducing it. Within these two settings we study optimal contract\nchoice. More specifically, we find the individually rational and Pareto-optimal\ncontracts for some notable cases, and describe specific settings where each of\nthe different sharing contracts emerge as optimal. Finally, in the third level\nof our analysis we demonstrate the applicability of our concepts in a synthetic\nsimulation using real loan data.\n","authors":["Yotam Gafni","Ronen Gradwohl","Moshe Tennenholtz"],"pdf_url":"https://arxiv.org/pdf/2403.17515v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16808v2","updated":"2024-03-26T08:59:17Z","published":"2024-03-25T14:32:18Z","title":"Navigating the EU AI Act: A Methodological Approach to Compliance for\n  Safety-critical Products","summary":"  In December 2023, the European Parliament provisionally agreed on the EU AI\nAct. This unprecedented regulatory framework for AI systems lays out guidelines\nto ensure the safety, legality, and trustworthiness of AI products. This paper\npresents a methodology for interpreting the EU AI Act requirements for\nhigh-risk AI systems by leveraging product quality models. We first propose an\nextended product quality model for AI systems, incorporating attributes\nrelevant to the Act not covered by current quality models. We map the Act\nrequirements to relevant quality attributes with the goal of refining them into\nmeasurable characteristics. We then propose a contract-based approach to derive\ntechnical requirements at the stakeholder level. This facilitates the\ndevelopment and assessment of AI systems that not only adhere to established\nquality standards, but also comply with the regulatory requirements outlined in\nthe Act for high-risk (including safety-critical) AI systems. We demonstrate\nthe applicability of this methodology on an exemplary automotive supply chain\nuse case, where several stakeholders interact to achieve EU AI Act compliance.\n","authors":["J. Kelly","S. Zafar","L. Heidemann","J. Zacchi","D. Espinoza","N. Mata"],"pdf_url":"https://arxiv.org/pdf/2403.16808v2.pdf","comment":"To be published in: 2024 IEEE Conference on Artificial Intelligence\n  (CAI 2024)"},{"id":"http://arxiv.org/abs/2302.10891v3","updated":"2024-03-26T08:50:19Z","published":"2023-02-06T10:08:42Z","title":"An Implicit GNN Solver for Poisson-like problems","summary":"  This paper presents $\\Psi$-GNN, a novel Graph Neural Network (GNN) approach\nfor solving the ubiquitous Poisson PDE problems with mixed boundary conditions.\nBy leveraging the Implicit Layer Theory, $\\Psi$-GNN models an \"infinitely\" deep\nnetwork, thus avoiding the empirical tuning of the number of required Message\nPassing layers to attain the solution. Its original architecture explicitly\ntakes into account the boundary conditions, a critical prerequisite for\nphysical applications, and is able to adapt to any initially provided solution.\n$\\Psi$-GNN is trained using a \"physics-informed\" loss, and the training process\nis stable by design, and insensitive to its initialization. Furthermore, the\nconsistency of the approach is theoretically proven, and its flexibility and\ngeneralization efficiency are experimentally demonstrated: the same learned\nmodel can accurately handle unstructured meshes of various sizes, as well as\ndifferent boundary conditions. To the best of our knowledge, $\\Psi$-GNN is the\nfirst physics-informed GNN-based method that can handle various unstructured\ndomains, boundary conditions and initial solutions while also providing\nconvergence guarantees.\n","authors":["Matthieu Nastorg","Michele Alessandro Bucci","Thibault Faney","Jean-Marc Gratien","Guillaume Charpiat","Marc Schoenauer"],"pdf_url":"https://arxiv.org/pdf/2302.10891v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.14974v3","updated":"2024-03-26T08:46:07Z","published":"2023-09-25T09:21:25Z","title":"Detecting Sexual Content at the Sentence Level in First Millennium Latin\n  Texts","summary":"  In this study, we propose to evaluate the use of deep learning methods for\nsemantic classification at the sentence level to accelerate the process of\ncorpus building in the field of humanities and linguistics, a traditional and\ntime-consuming task. We introduce a novel corpus comprising around 2500\nsentences spanning from 300 BCE to 900 CE including sexual semantics (medical,\nerotica, etc.). We evaluate various sentence classification approaches and\ndifferent input embedding layers, and show that all consistently outperform\nsimple token-based searches. We explore the integration of idiolectal and\nsociolectal metadata embeddings (centuries, author, type of writing), but find\nthat it leads to overfitting. Our results demonstrate the effectiveness of this\napproach, achieving high precision and true positive rates (TPR) of\nrespectively 70.60% and 86.33% using HAN. We evaluate the impact of the dataset\nsize on the model performances (420 instead of 2013), and show that, while our\nmodels perform worse, they still offer a high enough precision and TPR, even\nwithout MLM, respectively 69% and 51%. Given the result, we provide an analysis\nof the attention mechanism as a supporting added value for humanists in order\nto produce more data.\n","authors":["Thibault Clérice"],"pdf_url":"https://arxiv.org/pdf/2309.14974v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13653v2","updated":"2024-03-26T08:45:09Z","published":"2024-03-20T14:58:40Z","title":"Learning User Embeddings from Human Gaze for Personalised Saliency\n  Prediction","summary":"  Reusable embeddings of user behaviour have shown significant performance\nimprovements for the personalised saliency prediction task. However, prior\nworks require explicit user characteristics and preferences as input, which are\noften difficult to obtain. We present a novel method to extract user embeddings\nfrom pairs of natural images and corresponding saliency maps generated from a\nsmall amount of user-specific eye tracking data. At the core of our method is a\nSiamese convolutional neural encoder that learns the user embeddings by\ncontrasting the image and personal saliency map pairs of different users.\nEvaluations on two public saliency datasets show that the generated embeddings\nhave high discriminative power, are effective at refining universal saliency\nmaps to the individual users, and generalise well across users and images.\nFinally, based on our model's ability to encode individual user\ncharacteristics, our work points towards other applications that can benefit\nfrom reusable embeddings of gaze behaviour.\n","authors":["Florian Strohm","Mihai Bâce","Andreas Bulling"],"pdf_url":"https://arxiv.org/pdf/2403.13653v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17479v1","updated":"2024-03-26T08:19:29Z","published":"2024-03-26T08:19:29Z","title":"Natural Language Requirements Testability Measurement Based on\n  Requirement Smells","summary":"  Requirements form the basis for defining software systems' obligations and\ntasks. Testable requirements help prevent failures, reduce maintenance costs,\nand make it easier to perform acceptance tests. However, despite the importance\nof measuring and quantifying requirements testability, no automatic approach\nfor measuring requirements testability has been proposed based on the\nrequirements smells, which are at odds with the requirements testability. This\npaper presents a mathematical model to evaluate and rank the natural language\nrequirements testability based on an extensive set of nine requirements smells,\ndetected automatically, and acceptance test efforts determined by requirement\nlength and its application domain. Most of the smells stem from uncountable\nadjectives, context-sensitive, and ambiguous words. A comprehensive dictionary\nis required to detect such words. We offer a neural word-embedding technique to\ngenerate such a dictionary automatically. Using the dictionary, we could\nautomatically detect Polysemy smell (domain-specific ambiguity) for the first\ntime in 10 application domains. Our empirical study on nearly 1000 software\nrequirements from six well-known industrial and academic projects demonstrates\nthat the proposed smell detection approach outperforms Smella, a\nstate-of-the-art tool, in detecting requirements smells. The precision and\nrecall of smell detection are improved with an average of 0.03 and 0.33,\nrespectively, compared to the state-of-the-art. The proposed requirement\ntestability model measures the testability of 985 requirements with a mean\nabsolute error of 0.12 and a mean squared error of 0.03, demonstrating the\nmodel's potential for practical use.\n","authors":["Morteza Zakeri-Nasrabadi","Saeed Parsa"],"pdf_url":"https://arxiv.org/pdf/2403.17479v1.pdf","comment":"45 pages, 16 figures, and 13 tables; submitted as a journal paper"},{"id":"http://arxiv.org/abs/2403.17467v1","updated":"2024-03-26T07:55:45Z","published":"2024-03-26T07:55:45Z","title":"A Unified Kernel for Neural Network Learning","summary":"  Past decades have witnessed a great interest in the distinction and\nconnection between neural network learning and kernel learning. Recent\nadvancements have made theoretical progress in connecting infinite-wide neural\nnetworks and Gaussian processes. Two predominant approaches have emerged: the\nNeural Network Gaussian Process (NNGP) and the Neural Tangent Kernel (NTK). The\nformer, rooted in Bayesian inference, represents a zero-order kernel, while the\nlatter, grounded in the tangent space of gradient descents, is a first-order\nkernel. In this paper, we present the Unified Neural Kernel (UNK), which\ncharacterizes the learning dynamics of neural networks with gradient descents\nand parameter initialization. The proposed UNK kernel maintains the limiting\nproperties of both NNGP and NTK, exhibiting behaviors akin to NTK with a finite\nlearning step and converging to NNGP as the learning step approaches infinity.\nBesides, we also theoretically characterize the uniform tightness and learning\nconvergence of the UNK kernel, providing comprehensive insights into this\nunified kernel. Experimental results underscore the effectiveness of our\nproposed method.\n","authors":["Shao-Qun Zhang","Zong-Yi Chen","Yong-Ming Tian","Xun Lu"],"pdf_url":"https://arxiv.org/pdf/2403.17467v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17465v1","updated":"2024-03-26T07:55:16Z","published":"2024-03-26T07:55:16Z","title":"LaRE^2: Latent Reconstruction Error Based Method for Diffusion-Generated\n  Image Detection","summary":"  The evolution of Diffusion Models has dramatically improved image generation\nquality, making it increasingly difficult to differentiate between real and\ngenerated images. This development, while impressive, also raises significant\nprivacy and security concerns. In response to this, we propose a novel Latent\nREconstruction error guided feature REfinement method (LaRE^2) for detecting\nthe diffusion-generated images. We come up with the Latent Reconstruction Error\n(LaRE), the first reconstruction-error based feature in the latent space for\ngenerated image detection. LaRE surpasses existing methods in terms of feature\nextraction efficiency while preserving crucial cues required to differentiate\nbetween the real and the fake. To exploit LaRE, we propose an Error-Guided\nfeature REfinement module (EGRE), which can refine the image feature guided by\nLaRE to enhance the discriminativeness of the feature. Our EGRE utilizes an\nalign-then-refine mechanism, which effectively refines the image feature for\ngenerated-image detection from both spatial and channel perspectives. Extensive\nexperiments on the large-scale GenImage benchmark demonstrate the superiority\nof our LaRE^2, which surpasses the best SoTA method by up to 11.9%/12.1%\naverage ACC/AP across 8 different image generators. LaRE also surpasses\nexisting methods in terms of feature extraction cost, delivering an impressive\nspeed enhancement of 8 times.\n","authors":["Yunpeng Luo","Junlong Du","Ke Yan","Shouhong Ding"],"pdf_url":"https://arxiv.org/pdf/2403.17465v1.pdf","comment":"CVPR 2024"},{"id":"http://arxiv.org/abs/2403.17456v1","updated":"2024-03-26T07:41:54Z","published":"2024-03-26T07:41:54Z","title":"Imitating Cost-Constrained Behaviors in Reinforcement Learning","summary":"  Complex planning and scheduling problems have long been solved using various\noptimization or heuristic approaches. In recent years, imitation learning that\naims to learn from expert demonstrations has been proposed as a viable\nalternative to solving these problems. Generally speaking, imitation learning\nis designed to learn either the reward (or preference) model or directly the\nbehavioral policy by observing the behavior of an expert. Existing work in\nimitation learning and inverse reinforcement learning has focused on imitation\nprimarily in unconstrained settings (e.g., no limit on fuel consumed by the\nvehicle). However, in many real-world domains, the behavior of an expert is\ngoverned not only by reward (or preference) but also by constraints. For\ninstance, decisions on self-driving delivery vehicles are dependent not only on\nthe route preferences/rewards (depending on past demand data) but also on the\nfuel in the vehicle and the time available. In such problems, imitation\nlearning is challenging as decisions are not only dictated by the reward model\nbut are also dependent on a cost-constrained model. In this paper, we provide\nmultiple methods that match expert distributions in the presence of trajectory\ncost constraints through (a) Lagrangian-based method; (b) Meta-gradients to\nfind a good trade-off between expected return and minimizing constraint\nviolation; and (c) Cost-violation-based alternating gradient. We empirically\nshow that leading imitation learning approaches imitate cost-constrained\nbehaviors poorly and our meta-gradient-based approach achieves the best\nperformance.\n","authors":["Qian Shao","Pradeep Varakantham","Shih-Fen Cheng"],"pdf_url":"https://arxiv.org/pdf/2403.17456v1.pdf","comment":"Accepted to the 34th International Conference on Automated Planning\n  and Scheduling (ICAPS-24)"},{"id":"http://arxiv.org/abs/2403.17445v1","updated":"2024-03-26T07:23:46Z","published":"2024-03-26T07:23:46Z","title":"Incorporating Exponential Smoothing into MLP: A Simple but Effective\n  Sequence Model","summary":"  Modeling long-range dependencies in sequential data is a crucial step in\nsequence learning. A recently developed model, the Structured State Space (S4),\ndemonstrated significant effectiveness in modeling long-range sequences.\nHowever, It is unclear whether the success of S4 can be attributed to its\nintricate parameterization and HiPPO initialization or simply due to State\nSpace Models (SSMs). To further investigate the potential of the deep SSMs, we\nstart with exponential smoothing (ETS), a simple SSM, and propose a stacked\narchitecture by directly incorporating it into an element-wise MLP. We augment\nsimple ETS with additional parameters and complex field to reduce the inductive\nbias. Despite increasing less than 1\\% of parameters of element-wise MLP, our\nmodels achieve comparable results to S4 on the LRA benchmark.\n","authors":["Jiqun Chu","Zuoquan Lin"],"pdf_url":"https://arxiv.org/pdf/2403.17445v1.pdf","comment":"12 pages, 5 tables, 3 figures"},{"id":"http://arxiv.org/abs/2403.16427v2","updated":"2024-03-26T07:21:01Z","published":"2024-03-25T05:12:18Z","title":"Re2LLM: Reflective Reinforcement Large Language Model for Session-based\n  Recommendation","summary":"  Large Language Models (LLMs) are emerging as promising approaches to enhance\nsession-based recommendation (SBR), where both prompt-based and\nfine-tuning-based methods have been widely investigated to align LLMs with SBR.\nHowever, the former methods struggle with optimal prompts to elicit the correct\nreasoning of LLMs due to the lack of task-specific feedback, leading to\nunsatisfactory recommendations. Although the latter methods attempt to\nfine-tune LLMs with domain-specific knowledge, they face limitations such as\nhigh computational costs and reliance on open-source backbones. To address such\nissues, we propose a \\underline{Re}flective \\underline{Re}inforcement\n\\underline{L}arge \\underline{L}anguage \\underline{M}odel (Re2LLM) for SBR,\nguiding LLMs to focus on specialized knowledge essential for more accurate\nrecommendations effectively and efficiently. In particular, we first design the\nReflective Exploration Module to effectively extract knowledge that is readily\nunderstandable and digestible by LLMs. To be specific, we direct LLMs to\nexamine recommendation errors through self-reflection and construct a knowledge\nbase (KB) comprising hints capable of rectifying these errors. To efficiently\nelicit the correct reasoning of LLMs, we further devise the Reinforcement\nUtilization Module to train a lightweight retrieval agent. It learns to select\nhints from the constructed KB based on the task-specific feedback, where the\nhints can serve as guidance to help correct LLMs reasoning for better\nrecommendations. Extensive experiments on multiple real-world datasets\ndemonstrate that our method consistently outperforms state-of-the-art methods.\n","authors":["Ziyan Wang","Yingpeng Du","Zhu Sun","Haoyan Chua","Kaidong Feng","Wenya Wang","Jie Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.16427v2.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2403.14633v2","updated":"2024-03-26T07:12:40Z","published":"2024-02-16T23:18:19Z","title":"Born With a Silver Spoon? Investigating Socioeconomic Bias in Large\n  Language Models","summary":"  Socioeconomic bias in society exacerbates disparities, influencing access to\nopportunities and resources based on individuals' economic and social\nbackgrounds. This pervasive issue perpetuates systemic inequalities, hindering\nthe pursuit of inclusive progress as a society. In this paper, we investigate\nthe presence of socioeconomic bias, if any, in large language models. To this\nend, we introduce a novel dataset SilverSpoon, consisting of 3000 samples that\nillustrate hypothetical scenarios that involve underprivileged people\nperforming ethically ambiguous actions due to their circumstances, and ask\nwhether the action is ethically justified. Further, this dataset has a\ndual-labeling scheme and has been annotated by people belonging to both ends of\nthe socioeconomic spectrum. Using SilverSpoon, we evaluate the degree of\nsocioeconomic bias expressed in large language models and the variation of this\ndegree as a function of model size. We also perform qualitative analysis to\nanalyze the nature of this bias. Our analysis reveals that while humans\ndisagree on which situations require empathy toward the underprivileged, most\nlarge language models are unable to empathize with the socioeconomically\nunderprivileged regardless of the situation. To foster further research in this\ndomain, we make SilverSpoon and our evaluation harness publicly available.\n","authors":["Smriti Singh","Shuvam Keshari","Vinija Jain","Aman Chadha"],"pdf_url":"https://arxiv.org/pdf/2403.14633v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.01557v2","updated":"2024-03-26T06:50:43Z","published":"2023-08-03T06:36:21Z","title":"Motion Planning Diffusion: Learning and Planning of Robot Motions with\n  Diffusion Models","summary":"  Learning priors on trajectory distributions can help accelerate robot motion\nplanning optimization. Given previously successful plans, learning trajectory\ngenerative models as priors for a new planning problem is highly desirable.\nPrior works propose several ways on utilizing this prior to bootstrapping the\nmotion planning problem. Either sampling the prior for initializations or using\nthe prior distribution in a maximum-a-posterior formulation for trajectory\noptimization. In this work, we propose learning diffusion models as priors. We\nthen can sample directly from the posterior trajectory distribution conditioned\non task goals, by leveraging the inverse denoising process of diffusion models.\nFurthermore, diffusion has been recently shown to effectively encode data\nmultimodality in high-dimensional settings, which is particularly well-suited\nfor large trajectory dataset. To demonstrate our method efficacy, we compare\nour proposed method - Motion Planning Diffusion - against several baselines in\nsimulated planar robot and 7-dof robot arm manipulator environments. To assess\nthe generalization capabilities of our method, we test it in environments with\npreviously unseen obstacles. Our experiments show that diffusion models are\nstrong priors to encode high-dimensional trajectory distributions of robot\nmotions.\n","authors":["Joao Carvalho","An T. Le","Mark Baierl","Dorothea Koert","Jan Peters"],"pdf_url":"https://arxiv.org/pdf/2308.01557v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17428v1","updated":"2024-03-26T06:50:04Z","published":"2024-03-26T06:50:04Z","title":"Aligning Large Language Models for Enhancing Psychiatric Interviews\n  through Symptom Delineation and Summarization","summary":"  Recent advancements in Large Language Models (LLMs) have accelerated their\nusage in various domains. Given the fact that psychiatric interviews are\ngoal-oriented and structured dialogues between the professional interviewer and\nthe interviewee, it is one of the most underexplored areas where LLMs can\ncontribute substantial value. Here, we explore the use of LLMs for enhancing\npsychiatric interviews, by analyzing counseling data from North Korean\ndefectors with traumatic events and mental health issues. Specifically, we\ninvestigate whether LLMs can (1) delineate the part of the conversation that\nsuggests psychiatric symptoms and name the symptoms, and (2) summarize\nstressors and symptoms, based on the interview dialogue transcript. Here, the\ntranscript data was labeled by mental health experts for training and\nevaluation of LLMs. Our experimental results show that appropriately prompted\nLLMs can achieve high performance on both the symptom delineation task and the\nsummarization task. This research contributes to the nascent field of applying\nLLMs to psychiatric interview and demonstrates their potential effectiveness in\naiding mental health practitioners.\n","authors":["Jae-hee So","Joonhwan Chang","Eunji Kim","Junho Na","JiYeon Choi","Jy-yong Sohn","Byung-Hoon Kim","Sang Hui Chu"],"pdf_url":"https://arxiv.org/pdf/2403.17428v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17426v1","updated":"2024-03-26T06:47:17Z","published":"2024-03-26T06:47:17Z","title":"Knowledge-Powered Recommendation for an Improved Diet Water Footprint","summary":"  According to WWF, 1.1 billion people lack access to water, and 2.7 billion\nexperience water scarcity at least one month a year. By 2025, two-thirds of the\nworld's population may be facing water shortages. This highlights the urgency\nof managing water usage efficiently, especially in water-intensive sectors like\nfood. This paper proposes a recommendation engine, powered by knowledge graphs,\naiming to facilitate sustainable and healthy food consumption. The engine\nrecommends ingredient substitutes in user recipes that improve nutritional\nvalue and reduce environmental impact, particularly water footprint. The system\narchitecture includes source identification, information extraction, schema\nalignment, knowledge graph construction, and user interface development. The\nresearch offers a promising tool for promoting healthier eating habits and\ncontributing to water conservation efforts.\n","authors":["Saurav Joshi","Filip Ilievski","Jay Pujara"],"pdf_url":"https://arxiv.org/pdf/2403.17426v1.pdf","comment":"3 pages, 1 figure, AAAI'24"},{"id":"http://arxiv.org/abs/2403.17421v1","updated":"2024-03-26T06:34:23Z","published":"2024-03-26T06:34:23Z","title":"MA4DIV: Multi-Agent Reinforcement Learning for Search Result\n  Diversification","summary":"  The objective of search result diversification (SRD) is to ensure that\nselected documents cover as many different subtopics as possible. Existing\nmethods primarily utilize a paradigm of \"greedy selection\", i.e., selecting one\ndocument with the highest diversity score at a time. These approaches tend to\nbe inefficient and are easily trapped in a suboptimal state. In addition, some\nother methods aim to approximately optimize the diversity metric, such as\n$\\alpha$-NDCG, but the results still remain suboptimal. To address these\nchallenges, we introduce Multi-Agent reinforcement learning (MARL) for search\nresult DIVersity, which called MA4DIV. In this approach, each document is an\nagent and the search result diversification is modeled as a cooperative task\namong multiple agents. This approach allows for directly optimizing the\ndiversity metrics, such as $\\alpha$-NDCG, while achieving high training\nefficiency. We conducted preliminary experiments on public TREC datasets to\ndemonstrate the effectiveness and potential of MA4DIV. Considering the limited\nnumber of queries in public TREC datasets, we construct a large-scale dataset\nfrom industry sources and show that MA4DIV achieves substantial improvements in\nboth effectiveness and efficiency than existing baselines on a industrial scale\ndataset.\n","authors":["Yiqun Chen","Jiaxin Mao","Yi Zhang","Dehong MA","Long Xia","Jun Fan","Daiting Shi","Zhicong Cheng","Dawei Yin"],"pdf_url":"https://arxiv.org/pdf/2403.17421v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17419v1","updated":"2024-03-26T06:18:42Z","published":"2024-03-26T06:18:42Z","title":"AI Safety: Necessary, but insufficient and possibly problematic","summary":"  This article critically examines the recent hype around AI safety. We first\nstart with noting the nature of the AI safety hype as being dominated by\ngovernments and corporations, and contrast it with other avenues within AI\nresearch on advancing social good. We consider what 'AI safety' actually means,\nand outline the dominant concepts that the digital footprint of AI safety\naligns with. We posit that AI safety has a nuanced and uneasy relationship with\ntransparency and other allied notions associated with societal good, indicating\nthat it is an insufficient notion if the goal is that of societal good in a\nbroad sense. We note that the AI safety debate has already influenced some\nregulatory efforts in AI, perhaps in not so desirable directions. We also share\nour concerns on how AI safety may normalize AI that advances structural harm\nthrough providing exploitative and harmful AI with a veneer of safety.\n","authors":["Deepak P"],"pdf_url":"https://arxiv.org/pdf/2403.17419v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16649v2","updated":"2024-03-26T06:08:20Z","published":"2024-03-25T11:37:15Z","title":"CLHA: A Simple yet Effective Contrastive Learning Framework for Human\n  Alignment","summary":"  Reinforcement learning from human feedback (RLHF) is a crucial technique in\naligning large language models (LLMs) with human preferences, ensuring these\nLLMs behave in beneficial and comprehensible ways to users. However, a\nlongstanding challenge in human alignment techniques based on reinforcement\nlearning lies in their inherent complexity and difficulty in training. To\naddress this challenge, we present a simple yet effective Contrastive Learning\nFramework for Human Alignment (CLHA) to align LLMs with human preferences\ndirectly. CLHA employs a novel rescoring strategy to evaluate the noise within\nthe data by considering its inherent quality and dynamically adjusting the\ntraining process. Simultaneously, CLHA utilizes pairwise contrastive loss and\nadaptive supervised fine-tuning loss to adaptively modify the likelihood of\ngenerating responses, ensuring enhanced alignment with human preferences. Using\nadvanced methods, CLHA surpasses other algorithms, showcasing superior\nperformance in terms of reward model scores, automatic evaluations, and human\nassessments on the widely used ``Helpful and Harmless'' dataset.\n","authors":["Feiteng Fang","Liang Zhu","Min Yang","Xi Feng","Jinchang Hou","Qixuan Zhao","Chengming Li","Xiping Hu","Ruifeng Xu"],"pdf_url":"https://arxiv.org/pdf/2403.16649v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17410v1","updated":"2024-03-26T06:06:01Z","published":"2024-03-26T06:06:01Z","title":"On permutation-invariant neural networks","summary":"  Conventional machine learning algorithms have traditionally been designed\nunder the assumption that input data follows a vector-based format, with an\nemphasis on vector-centric paradigms. However, as the demand for tasks\ninvolving set-based inputs has grown, there has been a paradigm shift in the\nresearch community towards addressing these challenges. In recent years, the\nemergence of neural network architectures such as Deep Sets and Transformers\nhas presented a significant advancement in the treatment of set-based data.\nThese architectures are specifically engineered to naturally accommodate sets\nas input, enabling more effective representation and processing of set\nstructures. Consequently, there has been a surge of research endeavors\ndedicated to exploring and harnessing the capabilities of these architectures\nfor various tasks involving the approximation of set functions. This\ncomprehensive survey aims to provide an overview of the diverse problem\nsettings and ongoing research efforts pertaining to neural networks that\napproximate set functions. By delving into the intricacies of these approaches\nand elucidating the associated challenges, the survey aims to equip readers\nwith a comprehensive understanding of the field. Through this comprehensive\nperspective, we hope that researchers can gain valuable insights into the\npotential applications, inherent limitations, and future directions of\nset-based neural networks. Indeed, from this survey we gain two insights: i)\nDeep Sets and its variants can be generalized by differences in the aggregation\nfunction, and ii) the behavior of Deep Sets is sensitive to the choice of the\naggregation function. From these observations, we show that Deep Sets, one of\nthe well-known permutation-invariant neural networks, can be generalized in the\nsense of a quasi-arithmetic mean.\n","authors":["Masanari Kimura","Ryotaro Shimizu","Yuki Hirakawa","Ryosuke Goto","Yuki Saito"],"pdf_url":"https://arxiv.org/pdf/2403.17410v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.03520v2","updated":"2024-03-26T06:05:13Z","published":"2023-11-06T20:58:07Z","title":"Brain Networks and Intelligence: A Graph Neural Network Based Approach\n  to Resting State fMRI Data","summary":"  Resting-state functional magnetic resonance imaging (rsfMRI) is a powerful\ntool for investigating the relationship between brain function and cognitive\nprocesses as it allows for the functional organization of the brain to be\ncaptured without relying on a specific task or stimuli. In this paper, we\npresent a novel modeling architecture called BrainRGIN for predicting\nintelligence (fluid, crystallized, and total intelligence) using graph neural\nnetworks on rsfMRI derived static functional network connectivity matrices.\nExtending from the existing graph convolution networks, our approach\nincorporates a clustering-based embedding and graph isomorphism network in the\ngraph convolutional layer to reflect the nature of the brain sub-network\norganization and efficient network expression, in combination with TopK pooling\nand attention-based readout functions. We evaluated our proposed architecture\non a large dataset, specifically the Adolescent Brain Cognitive Development\nDataset, and demonstrated its effectiveness in predicting individual\ndifferences in intelligence. Our model achieved lower mean squared errors and\nhigher correlation scores than existing relevant graph architectures and other\ntraditional machine learning models for all of the intelligence prediction\ntasks. The middle frontal gyrus exhibited a significant contribution to both\nfluid and crystallized intelligence, suggesting their pivotal role in these\ncognitive processes. Total composite scores identified a diverse set of brain\nregions to be relevant which underscores the complex nature of total\nintelligence.\n","authors":["Bishal Thapaliya","Esra Akbas","Jiayu Chen","Raam Sapkota","Bhaskar Ray","Pranav Suresh","Vince Calhoun","Jingyu Liu"],"pdf_url":"https://arxiv.org/pdf/2311.03520v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17407v1","updated":"2024-03-26T05:55:21Z","published":"2024-03-26T05:55:21Z","title":"Transcribing Bengali Text with Regional Dialects to IPA using District\n  Guided Tokens","summary":"  Accurate transcription of Bengali text to the International Phonetic Alphabet\n(IPA) is a challenging task due to the complex phonology of the language and\ncontext-dependent sound changes. This challenge is even more for regional\nBengali dialects due to unavailability of standardized spelling conventions for\nthese dialects, presence of local and foreign words popular in those regions\nand phonological diversity across different regions. This paper presents an\napproach to this sequence-to-sequence problem by introducing the District\nGuided Tokens (DGT) technique on a new dataset spanning six districts of\nBangladesh. The key idea is to provide the model with explicit information\nabout the regional dialect or \"district\" of the input text before generating\nthe IPA transcription. This is achieved by prepending a district token to the\ninput sequence, effectively guiding the model to understand the unique phonetic\npatterns associated with each district. The DGT technique is applied to\nfine-tune several transformer-based models, on this new dataset. Experimental\nresults demonstrate the effectiveness of DGT, with the ByT5 model achieving\nsuperior performance over word-based models like mT5, BanglaT5, and umT5. This\nis attributed to ByT5's ability to handle a high percentage of\nout-of-vocabulary words in the test set. The proposed approach highlights the\nimportance of incorporating regional dialect information into ubiquitous\nnatural language processing systems for languages with diverse phonological\nvariations. The following work was a result of the \"Bhashamul\" challenge, which\nis dedicated to solving the problem of Bengali text with regional dialects to\nIPA transcription https://www.kaggle.com/competitions/regipa/. The training and\ninference notebooks are available through the competition link.\n","authors":["S M Jishanul Islam","Sadia Ahmmed","Sahid Hossain Mustakim"],"pdf_url":"https://arxiv.org/pdf/2403.17407v1.pdf","comment":"This work became the champion of the Bhashamul challenge"},{"id":"http://arxiv.org/abs/2403.14736v2","updated":"2024-03-26T05:25:04Z","published":"2024-03-21T13:27:57Z","title":"NaNa and MiGu: Semantic Data Augmentation Techniques to Enhance Protein\n  Classification in Graph Neural Networks","summary":"  Protein classification tasks are essential in drug discovery. Real-world\nprotein structures are dynamic, which will determine the properties of\nproteins. However, the existing machine learning methods, like ProNet (Wang et\nal., 2022a), only access limited conformational characteristics and protein\nside-chain features, leading to impractical protein structure and inaccuracy of\nprotein classes in their predictions. In this paper, we propose novel semantic\ndata augmentation methods, Novel Augmentation of New Node Attributes (NaNa),\nand Molecular Interactions and Geometric Upgrading (MiGu) to incorporate\nbackbone chemical and side-chain biophysical information into protein\nclassification tasks and a co-embedding residual learning framework.\nSpecifically, we leverage molecular biophysical, secondary structure, chemical\nbonds, and ionic features of proteins to facilitate protein classification\ntasks. Furthermore, our semantic augmentation methods and the co-embedding\nresidual learning framework can improve the performance of GIN (Xu et al.,\n2019) on EC and Fold datasets (Bairoch, 2000; Andreeva et al., 2007) by 16.41%\nand 11.33% respectively. Our code is available at\nhttps://github.com/r08b46009/Code_for_MIGU_NANA/tree/main.\n","authors":["Yi-Shan Lan","Pin-Yu Chen","Tsung-Yi Ho"],"pdf_url":"https://arxiv.org/pdf/2403.14736v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17395v1","updated":"2024-03-26T05:25:01Z","published":"2024-03-26T05:25:01Z","title":"An Open-source End-to-End Logic Optimization Framework for Large-scale\n  Boolean Network with Reinforcement Learning","summary":"  We propose an open-source end-to-end logic optimization framework for\nlarge-scale boolean network with reinforcement learning.\n","authors":["Zhen Li","Kaixiang Zhu","Xuegong Zhou","Lingli Wang"],"pdf_url":"https://arxiv.org/pdf/2403.17395v1.pdf","comment":"5 pages, 4 figures, 1 table"},{"id":"http://arxiv.org/abs/2305.19125v4","updated":"2024-03-26T05:18:13Z","published":"2023-05-30T15:36:37Z","title":"Graph Generation with $K^2$-trees","summary":"  Generating graphs from a target distribution is a significant challenge\nacross many domains, including drug discovery and social network analysis. In\nthis work, we introduce a novel graph generation method leveraging $K^2$-tree\nrepresentation, originally designed for lossless graph compression. The\n$K^2$-tree representation {encompasses inherent hierarchy while enabling\ncompact graph generation}. In addition, we make contributions by (1) presenting\na sequential $K^2$-treerepresentation that incorporates pruning, flattening,\nand tokenization processes and (2) introducing a Transformer-based architecture\ndesigned to generate the sequence by incorporating a specialized tree\npositional encoding scheme. Finally, we extensively evaluate our algorithm on\nfour general and two molecular graph datasets to confirm its superiority for\ngraph generation.\n","authors":["Yunhui Jang","Dongwoo Kim","Sungsoo Ahn"],"pdf_url":"https://arxiv.org/pdf/2305.19125v4.pdf","comment":"International Conference on Learning Representations (ICLR) 2024"},{"id":"http://arxiv.org/abs/2403.17385v1","updated":"2024-03-26T05:11:51Z","published":"2024-03-26T05:11:51Z","title":"ELLEN: Extremely Lightly Supervised Learning For Efficient Named Entity\n  Recognition","summary":"  In this work, we revisit the problem of semi-supervised named entity\nrecognition (NER) focusing on extremely light supervision, consisting of a\nlexicon containing only 10 examples per class. We introduce ELLEN, a simple,\nfully modular, neuro-symbolic method that blends fine-tuned language models\nwith linguistic rules. These rules include insights such as ''One Sense Per\nDiscourse'', using a Masked Language Model as an unsupervised NER, leveraging\npart-of-speech tags to identify and eliminate unlabeled entities as false\nnegatives, and other intuitions about classifier confidence scores in local and\nglobal context. ELLEN achieves very strong performance on the CoNLL-2003\ndataset when using the minimal supervision from the lexicon above. It also\noutperforms most existing (and considerably more complex) semi-supervised NER\nmethods under the same supervision settings commonly used in the literature\n(i.e., 5% of the training data). Further, we evaluate our CoNLL-2003 model in a\nzero-shot scenario on WNUT-17 where we find that it outperforms GPT-3.5 and\nachieves comparable performance to GPT-4. In a zero-shot setting, ELLEN also\nachieves over 75% of the performance of a strong, fully supervised model\ntrained on gold data. Our code is available at:\nhttps://github.com/hriaz17/ELLEN.\n","authors":["Haris Riaz","Razvan-Gabriel Dumitru","Mihai Surdeanu"],"pdf_url":"https://arxiv.org/pdf/2403.17385v1.pdf","comment":"Accepted to LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2312.02230v2","updated":"2024-03-26T05:10:53Z","published":"2023-12-04T03:43:26Z","title":"A Simple and Scalable Representation for Graph Generation","summary":"  Recently, there has been a surge of interest in employing neural networks for\ngraph generation, a fundamental statistical learning problem with critical\napplications like molecule design and community analysis. However, most\napproaches encounter significant limitations when generating large-scale\ngraphs. This is due to their requirement to output the full adjacency matrices\nwhose size grows quadratically with the number of nodes. In response to this\nchallenge, we introduce a new, simple, and scalable graph representation named\ngap encoded edge list (GEEL) that has a small representation size that aligns\nwith the number of edges. In addition, GEEL significantly reduces the\nvocabulary size by incorporating the gap encoding and bandwidth restriction\nschemes. GEEL can be autoregressively generated with the incorporation of node\npositional encoding, and we further extend GEEL to deal with attributed graphs\nby designing a new grammar. Our findings reveal that the adoption of this\ncompact representation not only enhances scalability but also bolsters\nperformance by simplifying the graph generation process. We conduct a\ncomprehensive evaluation across ten non-attributed and two molecular graph\ngeneration tasks, demonstrating the effectiveness of GEEL.\n","authors":["Yunhui Jang","Seul Lee","Sungsoo Ahn"],"pdf_url":"https://arxiv.org/pdf/2312.02230v2.pdf","comment":"International Conference on Learning Representations (ICLR) 2024"},{"id":"http://arxiv.org/abs/2403.17384v1","updated":"2024-03-26T05:10:47Z","published":"2024-03-26T05:10:47Z","title":"Explainable Graph Neural Networks for Observation Impact Analysis in\n  Atmospheric State Estimation","summary":"  This paper investigates the impact of observations on atmospheric state\nestimation in weather forecasting systems using graph neural networks (GNNs)\nand explainability methods. We integrate observation and Numerical Weather\nPrediction (NWP) points into a meteorological graph, extracting $k$-hop\nsubgraphs centered on NWP points. Self-supervised GNNs are employed to estimate\nthe atmospheric state by aggregating data within these $k$-hop radii. The study\napplies gradient-based explainability methods to quantify the significance of\ndifferent observations in the estimation process. Evaluated with data from 11\nsatellite and land-based observations, the results highlight the effectiveness\nof visualizing the importance of observation types, enhancing the understanding\nand optimization of observational data in weather forecasting.\n","authors":["Hyeon-Ju Jeon","Jeon-Ho Kang","In-Hyuk Kwon","O-Joun Lee"],"pdf_url":"https://arxiv.org/pdf/2403.17384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17381v1","updated":"2024-03-26T04:59:27Z","published":"2024-03-26T04:59:27Z","title":"Application-Driven Innovation in Machine Learning","summary":"  As applications of machine learning proliferate, innovative algorithms\ninspired by specific real-world challenges have become increasingly important.\nSuch work offers the potential for significant impact not merely in domains of\napplication but also in machine learning itself. In this paper, we describe the\nparadigm of application-driven research in machine learning, contrasting it\nwith the more standard paradigm of methods-driven research. We illustrate the\nbenefits of application-driven machine learning and how this approach can\nproductively synergize with methods-driven work. Despite these benefits, we\nfind that reviewing, hiring, and teaching practices in machine learning often\nhold back application-driven innovation. We outline how these processes may be\nimproved.\n","authors":["David Rolnick","Alan Aspuru-Guzik","Sara Beery","Bistra Dilkina","Priya L. Donti","Marzyeh Ghassemi","Hannah Kerner","Claire Monteleoni","Esther Rolf","Milind Tambe","Adam White"],"pdf_url":"https://arxiv.org/pdf/2403.17381v1.pdf","comment":"12 pages, 3 figures"},{"id":"http://arxiv.org/abs/2403.17377v1","updated":"2024-03-26T04:49:11Z","published":"2024-03-26T04:49:11Z","title":"Self-Rectifying Diffusion Sampling with Perturbed-Attention Guidance","summary":"  Recent studies have demonstrated that diffusion models are capable of\ngenerating high-quality samples, but their quality heavily depends on sampling\nguidance techniques, such as classifier guidance (CG) and classifier-free\nguidance (CFG). These techniques are often not applicable in unconditional\ngeneration or in various downstream tasks such as image restoration. In this\npaper, we propose a novel sampling guidance, called Perturbed-Attention\nGuidance (PAG), which improves diffusion sample quality across both\nunconditional and conditional settings, achieving this without requiring\nadditional training or the integration of external modules. PAG is designed to\nprogressively enhance the structure of samples throughout the denoising\nprocess. It involves generating intermediate samples with degraded structure by\nsubstituting selected self-attention maps in diffusion U-Net with an identity\nmatrix, by considering the self-attention mechanisms' ability to capture\nstructural information, and guiding the denoising process away from these\ndegraded samples. In both ADM and Stable Diffusion, PAG surprisingly improves\nsample quality in conditional and even unconditional scenarios. Moreover, PAG\nsignificantly improves the baseline performance in various downstream tasks\nwhere existing guidances such as CG or CFG cannot be fully utilized, including\nControlNet with empty prompts and image restoration such as inpainting and\ndeblurring.\n","authors":["Donghoon Ahn","Hyoungwon Cho","Jaewon Min","Wooseok Jang","Jungwoo Kim","SeonHwa Kim","Hyun Hee Park","Kyong Hwan Jin","Seungryong Kim"],"pdf_url":"https://arxiv.org/pdf/2403.17377v1.pdf","comment":"Project page is available at\n  https://ku-cvlab.github.io/Perturbed-Attention-Guidance"},{"id":"http://arxiv.org/abs/2403.17373v1","updated":"2024-03-26T04:27:56Z","published":"2024-03-26T04:27:56Z","title":"AIDE: An Automatic Data Engine for Object Detection in Autonomous\n  Driving","summary":"  Autonomous vehicle (AV) systems rely on robust perception models as a\ncornerstone of safety assurance. However, objects encountered on the road\nexhibit a long-tailed distribution, with rare or unseen categories posing\nchallenges to a deployed perception model. This necessitates an expensive\nprocess of continuously curating and annotating data with significant human\neffort. We propose to leverage recent advances in vision-language and large\nlanguage models to design an Automatic Data Engine (AIDE) that automatically\nidentifies issues, efficiently curates data, improves the model through\nauto-labeling, and verifies the model through generation of diverse scenarios.\nThis process operates iteratively, allowing for continuous self-improvement of\nthe model. We further establish a benchmark for open-world detection on AV\ndatasets to comprehensively evaluate various learning paradigms, demonstrating\nour method's superior performance at a reduced cost.\n","authors":["Mingfu Liang","Jong-Chyi Su","Samuel Schulter","Sparsh Garg","Shiyu Zhao","Ying Wu","Manmohan Chandraker"],"pdf_url":"https://arxiv.org/pdf/2403.17373v1.pdf","comment":"Accepted by CVPR-2024"},{"id":"http://arxiv.org/abs/2403.16206v2","updated":"2024-03-26T04:23:23Z","published":"2024-03-24T15:59:47Z","title":"Rumor Detection with a novel graph neural network approach","summary":"  The wide spread of rumors on social media has caused a negative impact on\npeople's daily life, leading to potential panic, fear, and mental health\nproblems for the public. How to debunk rumors as early as possible remains a\nchallenging problem. Existing studies mainly leverage information propagation\nstructure to detect rumors, while very few works focus on correlation among\nusers that they may coordinate to spread rumors in order to gain large\npopularity. In this paper, we propose a new detection model, that jointly\nlearns both the representations of user correlation and information propagation\nto detect rumors on social media. Specifically, we leverage graph neural\nnetworks to learn the representations of user correlation from a bipartite\ngraph that describes the correlations between users and source tweets, and the\nrepresentations of information propagation with a tree structure. Then we\ncombine the learned representations from these two modules to classify the\nrumors. Since malicious users intend to subvert our model after deployment, we\nfurther develop a greedy attack scheme to analyze the cost of three adversarial\nattacks: graph attack, comment attack, and joint attack. Evaluation results on\ntwo public datasets illustrate that the proposed MODEL outperforms the\nstate-of-the-art rumor detection models. We also demonstrate our method\nperforms well for early rumor detection. Moreover, the proposed detection\nmethod is more robust to adversarial attacks compared to the best existing\nmethod. Importantly, we show that it requires a high cost for attackers to\nsubvert user correlation pattern, demonstrating the importance of considering\nuser correlation for rumor detection.\n","authors":["Tianrui Liu","Qi Cai","Changxin Xu","Bo Hong","Fanghao Ni","Yuxin Qiao","Tsungwei Yang"],"pdf_url":"https://arxiv.org/pdf/2403.16206v2.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2403.16209v2","updated":"2024-03-26T04:22:02Z","published":"2024-03-24T16:08:10Z","title":"Image Captioning in news report scenario","summary":"  Image captioning strives to generate pertinent captions for specified images,\nsituating itself at the crossroads of Computer Vision (CV) and Natural Language\nProcessing (NLP). This endeavor is of paramount importance with far-reaching\napplications in recommendation systems, news outlets, social media, and beyond.\nParticularly within the realm of news reporting, captions are expected to\nencompass detailed information, such as the identities of celebrities captured\nin the images. However, much of the existing body of work primarily centers\naround understanding scenes and actions. In this paper, we explore the realm of\nimage captioning specifically tailored for celebrity photographs, illustrating\nits broad potential for enhancing news industry practices. This exploration\naims to augment automated news content generation, thereby facilitating a more\nnuanced dissemination of information. Our endeavor shows a broader horizon,\nenriching the narrative in news reporting through a more intuitive image\ncaptioning framework.\n","authors":["Tianrui Liu","Qi Cai","Changxin Xu","Bo Hong","Jize Xiong","Yuxin Qiao","Tsungwei Yang"],"pdf_url":"https://arxiv.org/pdf/2403.16209v2.pdf","comment":"10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2403.15931v2","updated":"2024-03-26T04:15:02Z","published":"2024-03-23T20:30:28Z","title":"X-Portrait: Expressive Portrait Animation with Hierarchical Motion\n  Attention","summary":"  We propose X-Portrait, an innovative conditional diffusion model tailored for\ngenerating expressive and temporally coherent portrait animation. Specifically,\ngiven a single portrait as appearance reference, we aim to animate it with\nmotion derived from a driving video, capturing both highly dynamic and subtle\nfacial expressions along with wide-range head movements. As its core, we\nleverage the generative prior of a pre-trained diffusion model as the rendering\nbackbone, while achieve fine-grained head pose and expression control with\nnovel controlling signals within the framework of ControlNet. In contrast to\nconventional coarse explicit controls such as facial landmarks, our motion\ncontrol module is learned to interpret the dynamics directly from the original\ndriving RGB inputs. The motion accuracy is further enhanced with a patch-based\nlocal control module that effectively enhance the motion attention to\nsmall-scale nuances like eyeball positions. Notably, to mitigate the identity\nleakage from the driving signals, we train our motion control modules with\nscaling-augmented cross-identity images, ensuring maximized disentanglement\nfrom the appearance reference modules. Experimental results demonstrate the\nuniversal effectiveness of X-Portrait across a diverse range of facial\nportraits and expressive driving sequences, and showcase its proficiency in\ngenerating captivating portrait animations with consistently maintained\nidentity characteristics.\n","authors":["You Xie","Hongyi Xu","Guoxian Song","Chao Wang","Yichun Shi","Linjie Luo"],"pdf_url":"https://arxiv.org/pdf/2403.15931v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.09963v2","updated":"2024-03-26T04:08:47Z","published":"2024-03-15T02:04:35Z","title":"Take Care of Your Prompt Bias! Investigating and Mitigating Prompt Bias\n  in Factual Knowledge Extraction","summary":"  Recent research shows that pre-trained language models (PLMs) suffer from\n\"prompt bias\" in factual knowledge extraction, i.e., prompts tend to introduce\nbiases toward specific labels. Prompt bias presents a significant challenge in\nassessing the factual knowledge within PLMs. Therefore, this paper aims to\nimprove the reliability of existing benchmarks by thoroughly investigating and\nmitigating prompt bias. We show that: 1) all prompts in the experiments exhibit\nnon-negligible bias, with gradient-based prompts like AutoPrompt and OptiPrompt\ndisplaying significantly higher levels of bias; 2) prompt bias can amplify\nbenchmark accuracy unreasonably by overfitting the test datasets, especially on\nimbalanced datasets like LAMA. Based on these findings, we propose a\nrepresentation-based approach to mitigate the prompt bias during inference\ntime. Specifically, we first estimate the biased representation using\nprompt-only querying, and then remove it from the model's internal\nrepresentations to generate the debiased representations, which are used to\nproduce the final debiased outputs. Experiments across various prompts, PLMs,\nand benchmarks show that our approach can not only correct the overfitted\nperformance caused by prompt bias, but also significantly improve the prompt\nretrieval capability (up to 10% absolute performance gain). These results\nindicate that our approach effectively alleviates prompt bias in knowledge\nevaluation, thereby enhancing the reliability of benchmark assessments.\nHopefully, our plug-and-play approach can be a golden standard to strengthen\nPLMs toward reliable knowledge bases. Code and data are released in\nhttps://github.com/FelliYang/PromptBias.\n","authors":["Ziyang Xu","Keqin Peng","Liang Ding","Dacheng Tao","Xiliang Lu"],"pdf_url":"https://arxiv.org/pdf/2403.09963v2.pdf","comment":"Accepted by COLING 2024"},{"id":"http://arxiv.org/abs/2403.17368v1","updated":"2024-03-26T04:07:08Z","published":"2024-03-26T04:07:08Z","title":"ChatGPT Rates Natural Language Explanation Quality Like Humans: But on\n  Which Scales?","summary":"  As AI becomes more integral in our lives, the need for transparency and\nresponsibility grows. While natural language explanations (NLEs) are vital for\nclarifying the reasoning behind AI decisions, evaluating them through human\njudgments is complex and resource-intensive due to subjectivity and the need\nfor fine-grained ratings. This study explores the alignment between ChatGPT and\nhuman assessments across multiple scales (i.e., binary, ternary, and 7-Likert\nscale). We sample 300 data instances from three NLE datasets and collect 900\nhuman annotations for both informativeness and clarity scores as the text\nquality measurement. We further conduct paired comparison experiments under\ndifferent ranges of subjectivity scores, where the baseline comes from 8,346\nhuman annotations. Our results show that ChatGPT aligns better with humans in\nmore coarse-grained scales. Also, paired comparisons and dynamic prompting\n(i.e., providing semantically similar examples in the prompt) improve the\nalignment. This research advances our understanding of large language models'\ncapabilities to assess the text explanation quality in different configurations\nfor responsible AI development.\n","authors":["Fan Huang","Haewoon Kwak","Kunwoo Park","Jisun An"],"pdf_url":"https://arxiv.org/pdf/2403.17368v1.pdf","comment":"Accpeted by LREC-COLING 2024 main conference, long paper"},{"id":"http://arxiv.org/abs/2403.17361v1","updated":"2024-03-26T03:54:25Z","published":"2024-03-26T03:54:25Z","title":"Bridging Textual and Tabular Worlds for Fact Verification: A\n  Lightweight, Attention-Based Model","summary":"  FEVEROUS is a benchmark and research initiative focused on fact extraction\nand verification tasks involving unstructured text and structured tabular data.\nIn FEVEROUS, existing works often rely on extensive preprocessing and utilize\nrule-based transformations of data, leading to potential context loss or\nmisleading encodings. This paper introduces a simple yet powerful model that\nnullifies the need for modality conversion, thereby preserving the original\nevidence's context. By leveraging pre-trained models on diverse text and\ntabular datasets and by incorporating a lightweight attention-based mechanism,\nour approach efficiently exploits latent connections between different data\ntypes, thereby yielding comprehensive and reliable verdict predictions. The\nmodel's modular structure adeptly manages multi-modal information, ensuring the\nintegrity and authenticity of the original evidence are uncompromised.\nComparative analyses reveal that our approach exhibits competitive performance,\naligning itself closely with top-tier models on the FEVEROUS benchmark.\n","authors":["Shirin Dabbaghi Varnosfaderani","Canasai Kruengkrai","Ramin Yahyapour","Junichi Yamagishi"],"pdf_url":"https://arxiv.org/pdf/2403.17361v1.pdf","comment":"Accepted for a presentation at LREC-COLING 2024 - The 2024 Joint\n  International Conference on Computational Linguistics, Language Resources and\n  Evaluation"},{"id":"http://arxiv.org/abs/2403.17358v1","updated":"2024-03-26T03:46:33Z","published":"2024-03-26T03:46:33Z","title":"Addressing Myopic Constrained POMDP Planning with Recursive Dual Ascent","summary":"  Lagrangian-guided Monte Carlo tree search with global dual ascent has been\napplied to solve large constrained partially observable Markov decision\nprocesses (CPOMDPs) online. In this work, we demonstrate that these global dual\nparameters can lead to myopic action selection during exploration, ultimately\nleading to suboptimal decision making. To address this, we introduce\nhistory-dependent dual variables that guide local action selection and are\noptimized with recursive dual ascent. We empirically compare the performance of\nour approach on a motivating toy example and two large CPOMDPs, demonstrating\nimproved exploration, and ultimately, safer outcomes.\n","authors":["Paula Stocco","Suhas Chundi","Arec Jamgochian","Mykel J. Kochenderfer"],"pdf_url":"https://arxiv.org/pdf/2403.17358v1.pdf","comment":"Accepted to the 2024 International Conference on Automated Planning\n  and Scheduling (ICAPS)"},{"id":"http://arxiv.org/abs/2403.17357v1","updated":"2024-03-26T03:44:51Z","published":"2024-03-26T03:44:51Z","title":"MESIA: Understanding and Leveraging Supplementary Nature of Method-level\n  Comments for Automatic Comment Generation","summary":"  Code comments are important for developers in program comprehension. In\nscenarios of comprehending and reusing a method, developers expect code\ncomments to provide supplementary information beyond the method signature.\nHowever, the extent of such supplementary information varies a lot in different\ncode comments. In this paper, we raise the awareness of the supplementary\nnature of method-level comments and propose a new metric named MESIA (Mean\nSupplementary Information Amount) to assess the extent of supplementary\ninformation that a code comment can provide. With the MESIA metric, we conduct\nexperiments on a popular code-comment dataset and three common types of neural\napproaches to generate method-level comments. Our experimental results\ndemonstrate the value of our proposed work with a number of findings. (1)\nSmall-MESIA comments occupy around 20% of the dataset and mostly fall into only\nthe WHAT comment category. (2) Being able to provide various kinds of essential\ninformation, large-MESIA comments in the dataset are difficult for existing\nneural approaches to generate. (3) We can improve the capability of existing\nneural approaches to generate large-MESIA comments by reducing the proportion\nof small-MESIA comments in the training set. (4) The retrained model can\ngenerate large-MESIA comments that convey essential meaningful supplementary\ninformation for methods in the small-MESIA test set, but will get a lower BLEU\nscore in evaluation. These findings indicate that with good training data,\nauto-generated comments can sometimes even surpass human-written reference\ncomments, and having no appropriate ground truth for evaluation is an issue\nthat needs to be addressed by future work on automatic comment generation.\n","authors":["Xinglu Pan","Chenxiao Liu","Yanzhen Zou","Tao Xie","Bing Xie"],"pdf_url":"https://arxiv.org/pdf/2403.17357v1.pdf","comment":"In 32nd IEEE/ACM International Conference on Program Comprehension\n  (ICPC'24)"},{"id":"http://arxiv.org/abs/2303.02490v2","updated":"2024-03-26T03:41:26Z","published":"2023-03-04T20:08:57Z","title":"Diffusion Models Generate Images Like Painters: an Analytical Theory of\n  Outline First, Details Later","summary":"  How do diffusion generative models convert pure noise into meaningful images?\nIn a variety of pretrained diffusion models (including conditional latent space\nmodels like Stable Diffusion), we observe that the reverse diffusion process\nthat underlies image generation has the following properties: (i) individual\ntrajectories tend to be low-dimensional and resemble 2D `rotations'; (ii)\nhigh-variance scene features like layout tend to emerge earlier, while\nlow-variance details tend to emerge later; and (iii) early perturbations tend\nto have a greater impact on image content than later perturbations. To\nunderstand these phenomena, we derive and study a closed-form solution to the\nprobability flow ODE for a Gaussian distribution, which shows that the reverse\ndiffusion state rotates towards a gradually-specified target on the image\nmanifold. It also shows that generation involves first committing to an\noutline, and then to finer and finer details. We find that this solution\naccurately describes the initial phase of image generation for pretrained\nmodels, and can in principle be used to make image generation more efficient by\nskipping reverse diffusion steps. Finally, we use our solution to characterize\nthe image manifold in Stable Diffusion. Our viewpoint reveals an unexpected\nsimilarity between generation by GANs and diffusion and provides a conceptual\nlink between diffusion and image retrieval.\n","authors":["Binxu Wang","John J. Vastola"],"pdf_url":"https://arxiv.org/pdf/2303.02490v2.pdf","comment":"44 pages, 28 figures. A briefer version was presented at NeurIPS23\n  Workshop on Diffusion Models [arXiv:2311.10892]"},{"id":"http://arxiv.org/abs/2309.06578v3","updated":"2024-03-26T03:33:45Z","published":"2023-09-07T04:15:17Z","title":"Can Large Language Models Discern Evidence for Scientific Hypotheses?\n  Case Studies in the Social Sciences","summary":"  Hypothesis formulation and testing are central to empirical research. A\nstrong hypothesis is a best guess based on existing evidence and informed by a\ncomprehensive view of relevant literature. However, with exponential increase\nin the number of scientific articles published annually, manual aggregation and\nsynthesis of evidence related to a given hypothesis is a challenge. Our work\nexplores the ability of current large language models (LLMs) to discern\nevidence in support or refute of specific hypotheses based on the text of\nscientific abstracts. We share a novel dataset for the task of scientific\nhypothesis evidencing using community-driven annotations of studies in the\nsocial sciences. We compare the performance of LLMs to several state-of-the-art\nbenchmarks and highlight opportunities for future research in this area. The\ndataset is available at\nhttps://github.com/Sai90000/ScientificHypothesisEvidencing.git\n","authors":["Sai Koneru","Jian Wu","Sarah Rajtmajer"],"pdf_url":"https://arxiv.org/pdf/2309.06578v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17350v1","updated":"2024-03-26T03:28:02Z","published":"2024-03-26T03:28:02Z","title":"The Solution of the Zodiac Killer's 340-Character Cipher","summary":"  The case of the Zodiac Killer is one of the most widely known unsolved serial\nkiller cases in history. The unidentified killer murdered five known victims\nand terrorized the state of California. He also communicated extensively with\nthe press and law enforcement. Besides his murders, Zodiac was known for his\nuse of ciphers. The first Zodiac cipher was solved within a week of its\npublication, while the second cipher was solved by the authors after 51 years,\nwhen it was discovered to be a transposition and homophonic substitution cipher\nwith unusual qualities. In this paper, we detail the historical significance of\nthis cipher and the numerous efforts which culminated in its solution.\n","authors":["David Oranchak","Sam Blake","Jarl Van Eycke"],"pdf_url":"https://arxiv.org/pdf/2403.17350v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17342v1","updated":"2024-03-26T03:03:50Z","published":"2024-03-26T03:03:50Z","title":"The Solution for the ICCV 2023 1st Scientific Figure Captioning\n  Challenge","summary":"  In this paper, we propose a solution for improving the quality of captions\ngenerated for figures in papers. We adopt the approach of summarizing the\ntextual content in the paper to generate image captions. Throughout our study,\nwe encounter discrepancies in the OCR information provided in the official\ndataset. To rectify this, we employ the PaddleOCR toolkit to extract OCR\ninformation from all images. Moreover, we observe that certain textual content\nin the official paper pertains to images that are not relevant for captioning,\nthereby introducing noise during caption generation. To mitigate this issue, we\nleverage LLaMA to extract image-specific information by querying the textual\ncontent based on image mentions, effectively filtering out extraneous\ninformation. Additionally, we recognize a discrepancy between the primary use\nof maximum likelihood estimation during text generation and the evaluation\nmetrics such as ROUGE employed to assess the quality of generated captions. To\nbridge this gap, we integrate the BRIO model framework, enabling a more\ncoherent alignment between the generation and evaluation processes. Our\napproach ranked first in the final test with a score of 4.49.\n","authors":["Dian Chao","Xin Song","Shupeng Zhong","Boyuan Wang","Xiangyu Wu","Chen Zhu","Yang Yang"],"pdf_url":"https://arxiv.org/pdf/2403.17342v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17338v1","updated":"2024-03-26T02:49:08Z","published":"2024-03-26T02:49:08Z","title":"Reinforcement Learning-based Receding Horizon Control using Adaptive\n  Control Barrier Functions for Safety-Critical Systems","summary":"  Optimal control methods provide solutions to safety-critical problems but\neasily become intractable. Control Barrier Functions (CBFs) have emerged as a\npopular technique that facilitates their solution by provably guaranteeing\nsafety, through their forward invariance property, at the expense of some\nperformance loss. This approach involves defining a performance objective\nalongside CBF-based safety constraints that must always be enforced.\nUnfortunately, both performance and solution feasibility can be significantly\nimpacted by two key factors: (i) the selection of the cost function and\nassociated parameters, and (ii) the calibration of parameters within the\nCBF-based constraints, which capture the trade-off between performance and\nconservativeness. %as well as infeasibility. To address these challenges, we\npropose a Reinforcement Learning (RL)-based Receding Horizon Control (RHC)\napproach leveraging Model Predictive Control (MPC) with CBFs (MPC-CBF). In\nparticular, we parameterize our controller and use bilevel optimization, where\nRL is used to learn the optimal parameters while MPC computes the optimal\ncontrol input. We validate our method by applying it to the challenging\nautomated merging control problem for Connected and Automated Vehicles (CAVs)\nat conflicting roadways. Results demonstrate improved performance and a\nsignificant reduction in the number of infeasible cases compared to traditional\nheuristic approaches used for tuning CBF-based controllers, showcasing the\neffectiveness of the proposed method.\n","authors":["Ehsan Sabouni","H. M. Sabbir Ahmad","Vittorio Giammarino","Christos G. Cassandras","Ioannis Ch. Paschalidis","Wenchao Li"],"pdf_url":"https://arxiv.org/pdf/2403.17338v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15729v2","updated":"2024-03-26T02:42:08Z","published":"2024-03-23T05:32:46Z","title":"Towards a RAG-based Summarization Agent for the Electron-Ion Collider","summary":"  The complexity and sheer volume of information encompassing documents,\npapers, data, and other resources from large-scale experiments demand\nsignificant time and effort to navigate, making the task of accessing and\nutilizing these varied forms of information daunting, particularly for new\ncollaborators and early-career scientists. To tackle this issue, a Retrieval\nAugmented Generation (RAG)--based Summarization AI for EIC (RAGS4EIC) is under\ndevelopment. This AI-Agent not only condenses information but also effectively\nreferences relevant responses, offering substantial advantages for\ncollaborators. Our project involves a two-step approach: first, querying a\ncomprehensive vector database containing all pertinent experiment information;\nsecond, utilizing a Large Language Model (LLM) to generate concise summaries\nenriched with citations based on user queries and retrieved data. We describe\nthe evaluation methods that use RAG assessments (RAGAs) scoring mechanisms to\nassess the effectiveness of responses. Furthermore, we describe the concept of\nprompt template-based instruction-tuning which provides flexibility and\naccuracy in summarization. Importantly, the implementation relies on LangChain,\nwhich serves as the foundation of our entire workflow. This integration ensures\nefficiency and scalability, facilitating smooth deployment and accessibility\nfor various user groups within the Electron Ion Collider (EIC) community. This\ninnovative AI-driven framework not only simplifies the understanding of vast\ndatasets but also encourages collaborative participation, thereby empowering\nresearchers. As a demonstration, a web application has been developed to\nexplain each stage of the RAG Agent development in detail.\n","authors":["Karthik Suresh","Neeltje Kackar","Luke Schleck","Cristiano Fanelli"],"pdf_url":"https://arxiv.org/pdf/2403.15729v2.pdf","comment":"updated title to have no latex formatting"},{"id":"http://arxiv.org/abs/2403.16971v2","updated":"2024-03-26T02:35:07Z","published":"2024-03-25T17:32:23Z","title":"AIOS: LLM Agent Operating System","summary":"  The integration and deployment of large language model (LLM)-based\nintelligent agents have been fraught with challenges that compromise their\nefficiency and efficacy. Among these issues are sub-optimal scheduling and\nresource allocation of agent requests over the LLM, the difficulties in\nmaintaining context during interactions between agent and LLM, and the\ncomplexities inherent in integrating heterogeneous agents with different\ncapabilities and specializations. The rapid increase of agent quantity and\ncomplexity further exacerbates these issues, often leading to bottlenecks and\nsub-optimal utilization of resources. Inspired by these challenges, this paper\npresents AIOS, an LLM agent operating system, which embeds large language model\ninto operating systems (OS) as the brain of the OS, enabling an operating\nsystem \"with soul\" -- an important step towards AGI. Specifically, AIOS is\ndesigned to optimize resource allocation, facilitate context switch across\nagents, enable concurrent execution of agents, provide tool service for agents,\nand maintain access control for agents. We present the architecture of such an\noperating system, outline the core challenges it aims to resolve, and provide\nthe basic design and implementation of the AIOS. Our experiments on concurrent\nexecution of multiple agents demonstrate the reliability and efficiency of our\nAIOS modules. Through this, we aim to not only improve the performance and\nefficiency of LLM agents but also to pioneer for better development and\ndeployment of the AIOS ecosystem in the future. The project is open-source at\nhttps://github.com/agiresearch/AIOS.\n","authors":["Kai Mei","Zelong Li","Shuyuan Xu","Ruosong Ye","Yingqiang Ge","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.16971v2.pdf","comment":"14 pages, 5 figures, 5 tables; comments and suggestions are\n  appreciated"},{"id":"http://arxiv.org/abs/2403.17333v1","updated":"2024-03-26T02:33:36Z","published":"2024-03-26T02:33:36Z","title":"The Pursuit of Fairness in Artificial Intelligence Models: A Survey","summary":"  Artificial Intelligence (AI) models are now being utilized in all facets of\nour lives such as healthcare, education and employment. Since they are used in\nnumerous sensitive environments and make decisions that can be life altering,\npotential biased outcomes are a pressing matter. Developers should ensure that\nsuch models don't manifest any unexpected discriminatory practices like\npartiality for certain genders, ethnicities or disabled people. With the\nubiquitous dissemination of AI systems, researchers and practitioners are\nbecoming more aware of unfair models and are bound to mitigate bias in them.\nSignificant research has been conducted in addressing such issues to ensure\nmodels don't intentionally or unintentionally perpetuate bias. This survey\noffers a synopsis of the different ways researchers have promoted fairness in\nAI systems. We explore the different definitions of fairness existing in the\ncurrent literature. We create a comprehensive taxonomy by categorizing\ndifferent types of bias and investigate cases of biased AI in different\napplication domains. A thorough study is conducted of the approaches and\ntechniques employed by researchers to mitigate bias in AI models. Moreover, we\nalso delve into the impact of biased models on user experience and the ethical\nconsiderations to contemplate when developing and deploying such models. We\nhope this survey helps researchers and practitioners understand the intricate\ndetails of fairness and bias in AI systems. By sharing this thorough survey, we\naim to promote additional discourse in the domain of equitable and responsible\nAI.\n","authors":["Tahsin Alamgir Kheya","Mohamed Reda Bouadjenek","Sunil Aryal"],"pdf_url":"https://arxiv.org/pdf/2403.17333v1.pdf","comment":"37 pages, 6 figures"},{"id":"http://arxiv.org/abs/2403.16950v2","updated":"2024-03-26T02:28:42Z","published":"2024-03-25T17:11:28Z","title":"Aligning with Human Judgement: The Role of Pairwise Preference in Large\n  Language Model Evaluators","summary":"  Large Language Models (LLMs) have demonstrated promising capabilities as\nautomatic evaluators in assessing the quality of generated natural language.\nHowever, LLMs still exhibit biases in evaluation and often struggle to generate\ncoherent evaluations that align with human assessments. In this work, we first\nconduct a systematic study of the misalignment between LLM evaluators and human\njudgement, revealing that existing calibration methods aimed at mitigating\nbiases are insufficient for effectively aligning LLM evaluators. Inspired by\nthe use of preference data in RLHF, we formulate the evaluation as a ranking\nproblem and introduce Pairwise-preference Search (PairS), an uncertainty-guided\nsearch method that employs LLMs to conduct pairwise comparisons and efficiently\nranks candidate texts. PairS achieves state-of-the-art performance on\nrepresentative evaluation tasks and demonstrates significant improvements over\ndirect scoring. Furthermore, we provide insights into the role of pairwise\npreference in quantifying the transitivity of LLMs and demonstrate how PairS\nbenefits from calibration.\n","authors":["Yinhong Liu","Han Zhou","Zhijiang Guo","Ehsan Shareghi","Ivan Vulić","Anna Korhonen","Nigel Collier"],"pdf_url":"https://arxiv.org/pdf/2403.16950v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16303v2","updated":"2024-03-26T02:24:36Z","published":"2024-03-24T21:29:39Z","title":"Large Language Models in Biomedical and Health Informatics: A\n  Bibliometric Review","summary":"  Large Language Models (LLMs) have rapidly become important tools in\nBiomedical and Health Informatics (BHI), enabling new ways to analyze data,\ntreat patients, and conduct research. This bibliometric review aims to provide\na panoramic view of how LLMs have been used in BHI by examining research\narticles and collaboration networks from 2022 to 2023. It further explores how\nLLMs can improve Natural Language Processing (NLP) applications in various BHI\nareas like medical diagnosis, patient engagement, electronic health record\nmanagement, and personalized medicine. To do this, our bibliometric review\nidentifies key trends, maps out research networks, and highlights major\ndevelopments in this fast-moving field. Lastly, it discusses the ethical\nconcerns and practical challenges of using LLMs in BHI, such as data privacy\nand reliable medical recommendations. Looking ahead, we consider how LLMs could\nfurther transform biomedical research as well as healthcare delivery and\npatient outcomes. This bibliometric review serves as a resource for\nstakeholders in healthcare, including researchers, clinicians, and\npolicymakers, to understand the current state and future potential of LLMs in\nBHI.\n","authors":["Huizi Yu","Lizhou Fan","Lingyao Li","Jiayan Zhou","Zihui Ma","Lu Xian","Wenyue Hua","Sijia He","Mingyu Jin","Yongfeng Zhang","Ashvin Gandhi","Xin Ma"],"pdf_url":"https://arxiv.org/pdf/2403.16303v2.pdf","comment":"50 pages, 7 figures, 4 tables"},{"id":"http://arxiv.org/abs/2403.17329v1","updated":"2024-03-26T02:24:32Z","published":"2024-03-26T02:24:32Z","title":"Deep Support Vectors","summary":"  While the success of deep learning is commonly attributed to its theoretical\nequivalence with Support Vector Machines (SVM), the practical implications of\nthis relationship have not been thoroughly explored. This paper pioneers an\nexploration in this domain, specifically focusing on the identification of Deep\nSupport Vectors (DSVs) within deep learning models. We introduce the concept of\nDeepKKT conditions, an adaptation of the traditional Karush-Kuhn-Tucker (KKT)\nconditions tailored for deep learning. Through empirical investigations, we\nillustrate that DSVs exhibit similarities to support vectors in SVM, offering a\ntangible method to interpret the decision-making criteria of models.\nAdditionally, our findings demonstrate that models can be effectively\nreconstructed using DSVs, resembling the process in SVM. The code will be\navailable.\n","authors":["Junhoo Lee","Hyunho Lee","Kyomin Hwang","Nojun Kwak"],"pdf_url":"https://arxiv.org/pdf/2403.17329v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17328v1","updated":"2024-03-26T02:22:08Z","published":"2024-03-26T02:22:08Z","title":"Learning Traffic Signal Control via Genetic Programming","summary":"  The control of traffic signals is crucial for improving transportation\nefficiency. Recently, learning-based methods, especially Deep Reinforcement\nLearning (DRL), garnered substantial success in the quest for more efficient\ntraffic signal control strategies. However, the design of rewards in DRL highly\ndemands domain knowledge to converge to an effective policy, and the final\npolicy also presents difficulties in terms of explainability. In this work, a\nnew learning-based method for signal control in complex intersections is\nproposed. In our approach, we design a concept of phase urgency for each signal\nphase. During signal transitions, the traffic light control strategy selects\nthe next phase to be activated based on the phase urgency. We then proposed to\nrepresent the urgency function as an explainable tree structure. The urgency\nfunction can calculate the phase urgency for a specific phase based on the\ncurrent road conditions. Genetic programming is adopted to perform\ngradient-free optimization of the urgency function. We test our algorithm on\nmultiple public traffic signal control datasets. The experimental results\nindicate that the tree-shaped urgency function evolved by genetic programming\noutperforms the baselines, including a state-of-the-art method in the\ntransportation field and a well-known DRL-based method.\n","authors":["Xiao-Cheng Liao","Yi Mei","Mengjie Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.17328v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17319v1","updated":"2024-03-26T02:01:18Z","published":"2024-03-26T02:01:18Z","title":"JMultiWOZ: A Large-Scale Japanese Multi-Domain Task-Oriented Dialogue\n  Dataset","summary":"  Dialogue datasets are crucial for deep learning-based task-oriented dialogue\nsystem research. While numerous English language multi-domain task-oriented\ndialogue datasets have been developed and contributed to significant\nadvancements in task-oriented dialogue systems, such a dataset does not exist\nin Japanese, and research in this area is limited compared to that in English.\nIn this study, towards the advancement of research and development of\ntask-oriented dialogue systems in Japanese, we constructed JMultiWOZ, the first\nJapanese language large-scale multi-domain task-oriented dialogue dataset.\nUsing JMultiWOZ, we evaluated the dialogue state tracking and response\ngeneration capabilities of the state-of-the-art methods on the existing major\nEnglish benchmark dataset MultiWOZ2.2 and the latest large language model\n(LLM)-based methods. Our evaluation results demonstrated that JMultiWOZ\nprovides a benchmark that is on par with MultiWOZ2.2. In addition, through\nevaluation experiments of interactive dialogues with the models and human\nparticipants, we identified limitations in the task completion capabilities of\nLLMs in Japanese.\n","authors":["Atsumoto Ohashi","Ryu Hirai","Shinya Iizuka","Ryuichiro Higashinaka"],"pdf_url":"https://arxiv.org/pdf/2403.17319v1.pdf","comment":"Accepted by LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2309.13339v4","updated":"2024-03-26T01:53:30Z","published":"2023-09-23T11:21:12Z","title":"Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models\n  through Logic","summary":"  Recent advancements in large language models have showcased their remarkable\ngeneralizability across various domains. However, their reasoning abilities\nstill have significant room for improvement, especially when confronted with\nscenarios requiring multi-step reasoning. Although large language models\npossess extensive knowledge, their reasoning often fails to effectively utilize\nthis knowledge to establish a coherent thinking paradigm. These models\nsometimes show hallucinations as their reasoning procedures are unconstrained\nby logical principles. Aiming at improving the zero-shot chain-of-thought\nreasoning ability of large language models, we propose LoT (Logical Thoughts),\na self-improvement prompting framework that leverages principles rooted in\nsymbolic logic, particularly Reductio ad Absurdum, to systematically verify and\nrectify the reasoning processes step by step. Experimental evaluations\nconducted on language tasks in diverse domains, including arithmetic,\ncommonsense, symbolic, causal inference, and social problems, demonstrate the\nefficacy of enhanced reasoning by logic. The implementation code for LoT can be\naccessed at: https://github.com/xf-zhao/LoT.\n","authors":["Xufeng Zhao","Mengdi Li","Wenhao Lu","Cornelius Weber","Jae Hee Lee","Kun Chu","Stefan Wermter"],"pdf_url":"https://arxiv.org/pdf/2309.13339v4.pdf","comment":"Accepted in COLING 2024. Code see https://github.com/xf-zhao/LoT"},{"id":"http://arxiv.org/abs/2403.05000v2","updated":"2024-03-26T01:51:37Z","published":"2024-03-08T02:42:34Z","title":"Medical Speech Symptoms Classification via Disentangled Representation","summary":"  Intent is defined for understanding spoken language in existing works. Both\ntextual features and acoustic features involved in medical speech contain\nintent, which is important for symptomatic diagnosis. In this paper, we propose\na medical speech classification model named DRSC that automatically learns to\ndisentangle intent and content representations from textual-acoustic data for\nclassification. The intent representations of the text domain and the\nMel-spectrogram domain are extracted via intent encoders, and then the\nreconstructed text feature and the Mel-spectrogram feature are obtained through\ntwo exchanges. After combining the intent from two domains into a joint\nrepresentation, the integrated intent representation is fed into a decision\nlayer for classification. Experimental results show that our model obtains an\naverage accuracy rate of 95% in detecting 25 different medical symptoms.\n","authors":["Jianzong Wang","Pengcheng Li","Xulong Zhang","Ning Cheng","Jing Xiao"],"pdf_url":"https://arxiv.org/pdf/2403.05000v2.pdf","comment":"Accepted by the 27th International Conference on Computer Supported\n  Cooperative Work in Design (CSCWD 2024)"},{"id":"http://arxiv.org/abs/2312.12467v3","updated":"2024-03-26T01:50:54Z","published":"2023-12-19T05:30:08Z","title":"Learning Flexible Body Collision Dynamics with Hierarchical Contact Mesh\n  Transformer","summary":"  Recently, many mesh-based graph neural network (GNN) models have been\nproposed for modeling complex high-dimensional physical systems. Remarkable\nachievements have been made in significantly reducing the solving time compared\nto traditional numerical solvers. These methods are typically designed to i)\nreduce the computational cost in solving physical dynamics and/or ii) propose\ntechniques to enhance the solution accuracy in fluid and rigid body dynamics.\nHowever, it remains under-explored whether they are effective in addressing the\nchallenges of flexible body dynamics, where instantaneous collisions occur\nwithin a very short timeframe. In this paper, we present Hierarchical Contact\nMesh Transformer (HCMT), which uses hierarchical mesh structures and can learn\nlong-range dependencies (occurred by collisions) among spatially distant\npositions of a body -- two close positions in a higher-level mesh correspond to\ntwo distant positions in a lower-level mesh. HCMT enables long-range\ninteractions, and the hierarchical mesh structure quickly propagates collision\neffects to faraway positions. To this end, it consists of a contact mesh\nTransformer and a hierarchical mesh Transformer (CMT and HMT, respectively).\nLastly, we propose a flexible body dynamics dataset, consisting of trajectories\nthat reflect experimental settings frequently used in the display industry for\nproduct designs. We also compare the performance of several baselines using\nwell-known benchmark datasets. Our results show that HCMT provides significant\nperformance improvements over existing methods. Our code is available at\nhttps://github.com/yuyudeep/hcmt.\n","authors":["Youn-Yeol Yu","Jeongwhan Choi","Woojin Cho","Kookjin Lee","Nayong Kim","Kiseok Chang","Chang-Seung Woo","Ilho Kim","Seok-Woo Lee","Joon-Young Yang","Sooyoung Yoon","Noseong Park"],"pdf_url":"https://arxiv.org/pdf/2312.12467v3.pdf","comment":"Accepted at ICLR 2024"},{"id":"http://arxiv.org/abs/2403.09887v2","updated":"2024-03-26T23:52:35Z","published":"2024-03-14T21:44:48Z","title":"Sabiá-2: A New Generation of Portuguese Large Language Models","summary":"  We introduce Sabi\\'a-2, a family of large language models trained on\nPortuguese texts. The models are evaluated on a diverse range of exams,\nincluding entry-level tests for Brazilian universities, professional\ncertification exams, and graduate-level exams for various disciplines such as\naccounting, economics, engineering, law and medicine. Our results reveal that\nour best model so far, Sabi\\'a-2 Medium, matches or surpasses GPT-4's\nperformance in 23 out of 64 exams and outperforms GPT-3.5 in 58 out of 64\nexams. Notably, specialization has a significant impact on a model's\nperformance without the need to increase its size, allowing us to offer\nSabi\\'a-2 Medium at a price per token that is 10 times cheaper than GPT-4.\nFinally, we identified that math and coding are key abilities that need\nimprovement.\n","authors":["Thales Sales Almeida","Hugo Abonizio","Rodrigo Nogueira","Ramon Pires"],"pdf_url":"https://arxiv.org/pdf/2403.09887v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18159v1","updated":"2024-03-26T23:51:44Z","published":"2024-03-26T23:51:44Z","title":"Oh! We Freeze: Improving Quantized Knowledge Distillation via Signal\n  Propagation Analysis for Large Language Models","summary":"  Large generative models, such as large language models (LLMs) and diffusion\nmodels have as revolutionized the fields of NLP and computer vision\nrespectively. However, their slow inference, high computation and memory\nrequirement makes it challenging to deploy them on edge devices. In this study,\nwe propose a light-weight quantization aware fine tuning technique using\nknowledge distillation (KD-QAT) to improve the performance of 4-bit weight\nquantized LLMs using commonly available datasets to realize a popular language\nuse case, on device chat applications. To improve this paradigm of finetuning,\nas main contributions, we provide insights into stability of KD-QAT by\nempirically studying the gradient propagation during training to better\nunderstand the vulnerabilities of KD-QAT based approaches to low-bit\nquantization errors. Based on our insights, we propose ov-freeze, a simple\ntechnique to stabilize the KD-QAT process. Finally, we experiment with the\npopular 7B LLaMAv2-Chat model at 4-bit quantization level and demonstrate that\nov-freeze results in near float-point precision performance, i.e., less than\n0.7% loss of accuracy on Commonsense Reasoning benchmarks.\n","authors":["Kartikeya Bhardwaj","Nilesh Prasad Pandey","Sweta Priyadarshi","Kyunggeun Lee","Jun Ma","Harris Teague"],"pdf_url":"https://arxiv.org/pdf/2403.18159v1.pdf","comment":"Accepted at Practical ML for Low Resource Settings Workshop at ICLR\n  2024"},{"id":"http://arxiv.org/abs/2403.18148v1","updated":"2024-03-26T23:14:34Z","published":"2024-03-26T23:14:34Z","title":"Large Language Models Produce Responses Perceived to be Empathic","summary":"  Large Language Models (LLMs) have demonstrated surprising performance on many\ntasks, including writing supportive messages that display empathy. Here, we had\nthese models generate empathic messages in response to posts describing common\nlife experiences, such as workplace situations, parenting, relationships, and\nother anxiety- and anger-eliciting situations. Across two studies (N=192, 202),\nwe showed human raters a variety of responses written by several models (GPT4\nTurbo, Llama2, and Mistral), and had people rate these responses on how\nempathic they seemed to be. We found that LLM-generated responses were\nconsistently rated as more empathic than human-written responses. Linguistic\nanalyses also show that these models write in distinct, predictable ``styles\",\nin terms of their use of punctuation, emojis, and certain words. These results\nhighlight the potential of using LLMs to enhance human peer support in contexts\nwhere empathy is important.\n","authors":["Yoon Kyung Lee","Jina Suh","Hongli Zhan","Junyi Jessy Li","Desmond C. Ong"],"pdf_url":"https://arxiv.org/pdf/2403.18148v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18145v1","updated":"2024-03-26T23:10:41Z","published":"2024-03-26T23:10:41Z","title":"A Real-Time Rescheduling Algorithm for Multi-robot Plan Execution","summary":"  One area of research in multi-agent path finding is to determine how\nreplanning can be efficiently achieved in the case of agents being delayed\nduring execution. One option is to reschedule the passing order of agents,\ni.e., the sequence in which agents visit the same location. In response, we\npropose Switchable-Edge Search (SES), an A*-style algorithm designed to find\noptimal passing orders. We prove the optimality of SES and evaluate its\nefficiency via simulations. The best variant of SES takes less than 1 second\nfor small- and medium-sized problems and runs up to 4 times faster than\nbaselines for large-sized problems.\n","authors":["Ying Feng","Adittyo Paul","Zhe Chen","Jiaoyang Li"],"pdf_url":"https://arxiv.org/pdf/2403.18145v1.pdf","comment":"ICAPS 2024"},{"id":"http://arxiv.org/abs/2303.09618v2","updated":"2024-03-26T22:59:52Z","published":"2023-03-16T19:47:41Z","title":"HIVE: Harnessing Human Feedback for Instructional Visual Editing","summary":"  Incorporating human feedback has been shown to be crucial to align text\ngenerated by large language models to human preferences. We hypothesize that\nstate-of-the-art instructional image editing models, where outputs are\ngenerated based on an input image and an editing instruction, could similarly\nbenefit from human feedback, as their outputs may not adhere to the correct\ninstructions and preferences of users. In this paper, we present a novel\nframework to harness human feedback for instructional visual editing (HIVE).\nSpecifically, we collect human feedback on the edited images and learn a reward\nfunction to capture the underlying user preferences. We then introduce scalable\ndiffusion model fine-tuning methods that can incorporate human preferences\nbased on the estimated reward. Besides, to mitigate the bias brought by the\nlimitation of data, we contribute a new 1M training dataset, a 3.6K reward\ndataset for rewards learning, and a 1K evaluation dataset to boost the\nperformance of instructional image editing. We conduct extensive empirical\nexperiments quantitatively and qualitatively, showing that HIVE is favored over\nprevious state-of-the-art instructional image editing approaches by a large\nmargin.\n","authors":["Shu Zhang","Xinyi Yang","Yihao Feng","Can Qin","Chia-Chih Chen","Ning Yu","Zeyuan Chen","Huan Wang","Silvio Savarese","Stefano Ermon","Caiming Xiong","Ran Xu"],"pdf_url":"https://arxiv.org/pdf/2303.09618v2.pdf","comment":"In CVPR, 2024"},{"id":"http://arxiv.org/abs/2403.18140v1","updated":"2024-03-26T22:54:12Z","published":"2024-03-26T22:54:12Z","title":"Juru: Legal Brazilian Large Language Model from Reputable Sources","summary":"  The high computational cost associated with pretraining large language models\nlimits their research. Two strategies have emerged to address this issue:\ndomain specialization and pretraining with high-quality data. To explore these\nstrategies, we specialized the Sabi\\'a-2 Small model with 1.9 billion unique\ntokens from reputable Brazilian legal sources and conducted few-shot\nevaluations on legal and general knowledge exams. Our model, Juru, demonstrates\nthe benefits of domain specialization with a reduced amount of pretraining\ndata. However, this specialization comes at the expense of degrading\nperformance in other knowledge areas within the same language. This study\ncontributes to the growing body of scientific evidence showing that pretraining\ndata selection may enhance the performance of large language models, enabling\nthe exploration of these models at a lower cost.\n","authors":["Roseval Malaquias Junior","Ramon Pires","Roseli Romero","Rodrigo Nogueira"],"pdf_url":"https://arxiv.org/pdf/2403.18140v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.05677v2","updated":"2024-03-26T22:53:56Z","published":"2023-12-09T20:51:48Z","title":"Batched Low-Rank Adaptation of Foundation Models","summary":"  Low-Rank Adaptation (LoRA) has recently gained attention for fine-tuning\nfoundation models by incorporating trainable low-rank matrices, thereby\nreducing the number of trainable parameters. While LoRA offers numerous\nadvantages, its applicability for real-time serving to a diverse and global\nuser base is constrained by its incapability to handle multiple task-specific\nadapters efficiently. This imposes a performance bottleneck in scenarios\nrequiring personalized, task-specific adaptations for each incoming request. To\nmitigate this constraint, we introduce Fast LoRA (FLoRA), a framework in which\neach input example in a minibatch can be associated with its unique low-rank\nadaptation weights, allowing for efficient batching of heterogeneous requests.\nWe empirically demonstrate that FLoRA retains the performance merits of LoRA,\nshowcasing competitive results on the MultiPL-E code generation benchmark\nspanning over 8 languages and a multilingual speech recognition task across 6\nlanguages.\n","authors":["Yeming Wen","Swarat Chaudhuri"],"pdf_url":"https://arxiv.org/pdf/2312.05677v2.pdf","comment":"16 pages, 3 figures"},{"id":"http://arxiv.org/abs/2403.18136v1","updated":"2024-03-26T22:41:41Z","published":"2024-03-26T22:41:41Z","title":"Securing GNNs: Explanation-Based Identification of Backdoored Training\n  Graphs","summary":"  Graph Neural Networks (GNNs) have gained popularity in numerous domains, yet\nthey are vulnerable to backdoor attacks that can compromise their performance\nand ethical application. The detection of these attacks is crucial for\nmaintaining the reliability and security of GNN classification tasks, but\neffective detection techniques are lacking. Following an initial investigation,\nwe observed that while graph-level explanations can offer limited insights,\ntheir effectiveness in detecting backdoor triggers is inconsistent and\nincomplete. To bridge this gap, we extract and transform secondary outputs of\nGNN explanation mechanisms, designing seven novel metrics that more effectively\ndetect backdoor attacks. Additionally, we develop an adaptive attack to\nrigorously evaluate our approach. We test our method on multiple benchmark\ndatasets and examine its efficacy against various attack models. Our results\nshow that our method can achieve high detection performance, marking a\nsignificant advancement in safeguarding GNNs against backdoor attacks.\n","authors":["Jane Downer","Ren Wang","Binghui Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18136v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18133v1","updated":"2024-03-26T22:28:43Z","published":"2024-03-26T22:28:43Z","title":"AE SemRL: Learning Semantic Association Rules with Autoencoders","summary":"  Association Rule Mining (ARM) is the task of learning associations among data\nfeatures in the form of logical rules. Mining association rules from\nhigh-dimensional numerical data, for example, time series data from a large\nnumber of sensors in a smart environment, is a computationally intensive task.\nIn this study, we propose an Autoencoder-based approach to learn and extract\nassociation rules from time series data (AE SemRL). Moreover, we argue that in\nthe presence of semantic information related to time series data sources,\nsemantics can facilitate learning generalizable and explainable association\nrules. Despite enriching time series data with additional semantic features, AE\nSemRL makes learning association rules from high-dimensional data feasible. Our\nexperiments show that semantic association rules can be extracted from a latent\nrepresentation created by an Autoencoder and this method has in the order of\nhundreds of times faster execution time than state-of-the-art ARM approaches in\nmany scenarios. We believe that this study advances a new way of extracting\nassociations from representations and has the potential to inspire more\nresearch in this field.\n","authors":["Erkan Karabulut","Victoria Degeler","Paul Groth"],"pdf_url":"https://arxiv.org/pdf/2403.18133v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18132v1","updated":"2024-03-26T22:26:39Z","published":"2024-03-26T22:26:39Z","title":"Recommendation of data-free class-incremental learning algorithms by\n  simulating future data","summary":"  Class-incremental learning deals with sequential data streams composed of\nbatches of classes. Various algorithms have been proposed to address the\nchallenging case where samples from past classes cannot be stored. However,\nselecting an appropriate algorithm for a user-defined setting is an open\nproblem, as the relative performance of these algorithms depends on the\nincremental settings. To solve this problem, we introduce an algorithm\nrecommendation method that simulates the future data stream. Given an initial\nset of classes, it leverages generative models to simulate future classes from\nthe same visual domain. We evaluate recent algorithms on the simulated stream\nand recommend the one which performs best in the user-defined incremental\nsetting. We illustrate the effectiveness of our method on three large datasets\nusing six algorithms and six incremental settings. Our method outperforms\ncompetitive baselines, and performance is close to that of an oracle choosing\nthe best algorithm in each setting. This work contributes to facilitate the\npractical deployment of incremental learning.\n","authors":["Eva Feillet","Adrian Popescu","Céline Hudelot"],"pdf_url":"https://arxiv.org/pdf/2403.18132v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18120v1","updated":"2024-03-26T22:01:13Z","published":"2024-03-26T22:01:13Z","title":"Don't Trust: Verify -- Grounding LLM Quantitative Reasoning with\n  Autoformalization","summary":"  Large language models (LLM), such as Google's Minerva and OpenAI's GPT\nfamilies, are becoming increasingly capable of solving mathematical\nquantitative reasoning problems. However, they still make unjustified logical\nand computational errors in their reasoning steps and answers. In this paper,\nwe leverage the fact that if the training corpus of LLMs contained sufficiently\nmany examples of formal mathematics (e.g. in Isabelle, a formal theorem proving\nenvironment), they can be prompted to translate i.e. autoformalize informal\nmathematical statements into formal Isabelle code -- which can be verified\nautomatically for internal consistency. This provides a mechanism to\nautomatically reject solutions whose formalized versions are inconsistent\nwithin themselves or with the formalized problem statement. We evaluate our\nmethod on GSM8K, MATH and MultiArith datasets and demonstrate that our approach\nprovides a consistently better heuristic than vanilla majority voting -- the\npreviously best method to identify correct answers, by more than 12% on GSM8K.\nIn our experiments it improves results consistently across all datasets and LLM\nmodel sizes. The code can be found at https://github.com/jinpz/dtv.\n","authors":["Jin Peng Zhou","Charles Staats","Wenda Li","Christian Szegedy","Kilian Q. Weinberger","Yuhuai Wu"],"pdf_url":"https://arxiv.org/pdf/2403.18120v1.pdf","comment":"ICLR 2024"}],"Optimization and Control":[{"id":"http://arxiv.org/abs/2403.17923v1","updated":"2024-03-26T17:56:33Z","published":"2024-03-26T17:56:33Z","title":"Optimizing Vaccine Site Locations While Considering Travel Inconvenience\n  and Public Health Outcomes","summary":"  During the COVID-19 pandemic, there were over three million infections in Los\nAngeles County (LAC). To facilitate distribution when vaccines first became\navailable, LAC set up six mega-sites for dispensing a large number of vaccines\nto the public. To understand if another choice of mega-site location would have\nimproved accessibility and health outcomes, and to provide insight into future\nvaccine allocation problems, we propose a multi-objective mixed integer linear\nprogramming model that balances travel convenience, infection reduction, and\nequitable distribution. We provide a tractable objective formulation that\neffectively proxies real-world public health goals of reducing infections while\nconsidering travel inconvenience and equitable distribution of resources.\nCompared with the solution empirically used in LAC in 2020, we recommend more\ndispersed mega-site locations that result in a 28% reduction in travel\ninconvenience and avert an additional 1,000 infections.\n","authors":["Suyanpeng Zhang","Sze-chuan Suen","Han Yu","Maged Dessouky","Fernando Ordonez"],"pdf_url":"https://arxiv.org/pdf/2403.17923v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14259v2","updated":"2024-03-26T17:55:55Z","published":"2024-03-21T09:37:11Z","title":"Minimal covariance realization and system identification algorithm for a\n  class of stochastic linear switched systems with i.i.d. switching","summary":"  In this paper, we consider stochastic realization theory of Linear Switched\nSystems (LSS) with i.i.d. switching. We characterize minimality of stochastic\nLSSs and show existence and uniqueness (up to isomorphism) of minimal LSSs in\ninnovation form. We present a realization algorithm to compute a minimal LSS in\ninnovation form from output and input covariances. Finally, based on this\nrealization algorithm, by replacing true covariances with empirical ones, we\npropose a statistically consistent system identification algorithm.\n","authors":["Elie Rouphael","Manas Mejari","Mihaly Petreczky","Lotfi Belkoura"],"pdf_url":"https://arxiv.org/pdf/2403.14259v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17919v1","updated":"2024-03-26T17:55:02Z","published":"2024-03-26T17:55:02Z","title":"LISA: Layerwise Importance Sampling for Memory-Efficient Large Language\n  Model Fine-Tuning","summary":"  The machine learning community has witnessed impressive advancements since\nthe first appearance of large language models (LLMs), yet their huge memory\nconsumption has become a major roadblock to large-scale training. Parameter\nEfficient Fine-Tuning techniques such as Low-Rank Adaptation (LoRA) have been\nproposed to alleviate this problem, but their performance still fails to match\nfull parameter training in most large-scale fine-tuning settings. Attempting to\ncomplement this deficiency, we investigate layerwise properties of LoRA on\nfine-tuning tasks and observe an uncommon skewness of weight norms across\ndifferent layers. Utilizing this key observation, a surprisingly simple\ntraining strategy is discovered, which outperforms both LoRA and full parameter\ntraining in a wide range of settings with memory costs as low as LoRA. We name\nit Layerwise Importance Sampled AdamW (LISA), a promising alternative for LoRA,\nwhich applies the idea of importance sampling to different layers in LLMs and\nrandomly freeze most middle layers during optimization. Experimental results\nshow that with similar or less GPU memory consumption, LISA surpasses LoRA or\neven full parameter tuning in downstream fine-tuning tasks, where LISA\nconsistently outperforms LoRA by over $11\\%$-$37\\%$ in terms of MT-Bench\nscores. On large models, specifically LLaMA-2-70B, LISA achieves on-par or\nbetter performance than LoRA on MT-Bench, GSM8K, and PubMedQA, demonstrating\nits effectiveness across different domains.\n","authors":["Rui Pan","Xiang Liu","Shizhe Diao","Renjie Pi","Jipeng Zhang","Chi Han","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.17919v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.01364v3","updated":"2024-03-26T17:45:01Z","published":"2022-11-02T17:59:09Z","title":"An optimal control perspective on diffusion-based generative modeling","summary":"  We establish a connection between stochastic optimal control and generative\nmodels based on stochastic differential equations (SDEs), such as recently\ndeveloped diffusion probabilistic models. In particular, we derive a\nHamilton-Jacobi-Bellman equation that governs the evolution of the\nlog-densities of the underlying SDE marginals. This perspective allows to\ntransfer methods from optimal control theory to generative modeling. First, we\nshow that the evidence lower bound is a direct consequence of the well-known\nverification theorem from control theory. Further, we can formulate\ndiffusion-based generative modeling as a minimization of the Kullback-Leibler\ndivergence between suitable measures in path space. Finally, we develop a novel\ndiffusion-based method for sampling from unnormalized densities -- a problem\nfrequently occurring in statistics and computational sciences. We demonstrate\nthat our time-reversed diffusion sampler (DIS) can outperform other\ndiffusion-based sampling approaches on multiple numerical examples.\n","authors":["Julius Berner","Lorenz Richter","Karen Ullrich"],"pdf_url":"https://arxiv.org/pdf/2211.01364v3.pdf","comment":"Accepted for oral presentation at NeurIPS 2022 Workshop on\n  Score-Based Methods"},{"id":"http://arxiv.org/abs/2310.18841v2","updated":"2024-03-26T17:39:30Z","published":"2023-10-28T22:57:56Z","title":"A randomized algorithm for nonconvex minimization with inexact\n  evaluations and complexity guarantees","summary":"  We consider minimization of a smooth nonconvex function with inexact oracle\naccess to gradient and Hessian (without assuming access to the function value)\nto achieve approximate second-order optimality. A novel feature of our method\nis that if an approximate direction of negative curvature is chosen as the\nstep, we choose its sense to be positive or negative with equal probability. We\nallow gradients to be inexact in a relative sense and relax the coupling\nbetween inexactness thresholds for the first- and second-order optimality\nconditions. Our convergence analysis includes both an expectation bound based\non martingale analysis and a high-probability bound based on concentration\ninequalities. We apply our algorithm to empirical risk minimization problems\nand obtain improved gradient sample complexity over existing works.\n","authors":["Shuyao Li","Stephen J. Wright"],"pdf_url":"https://arxiv.org/pdf/2310.18841v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.07858v2","updated":"2024-03-26T17:31:49Z","published":"2024-01-15T17:46:26Z","title":"Optimal Analysis of Method with Batching for Monotone Stochastic\n  Finite-Sum Variational Inequalities","summary":"  Variational inequalities are a universal optimization paradigm that is\ninteresting in itself, but also incorporates classical minimization and saddle\npoint problems. Modern realities encourage to consider stochastic formulations\nof optimization problems. In this paper, we present an analysis of a method\nthat gives optimal convergence estimates for monotone stochastic finite-sum\nvariational inequalities. In contrast to the previous works, our method\nsupports batching and does not lose the oracle complexity optimality. The\neffectiveness of the algorithm, especially in the case of small but not single\nbatches is confirmed experimentally.\n","authors":["Alexander Pichugin","Maksim Pechin","Aleksandr Beznosikov","Alexander Gasnikov"],"pdf_url":"https://arxiv.org/pdf/2401.07858v2.pdf","comment":"22 pages, 1 algorithm, 2 figures, 1 table"},{"id":"http://arxiv.org/abs/2401.07809v2","updated":"2024-03-26T17:29:07Z","published":"2024-01-15T16:30:12Z","title":"Optimal Data Splitting in Distributed Optimization for Machine Learning","summary":"  The distributed optimization problem has become increasingly relevant\nrecently. It has a lot of advantages such as processing a large amount of data\nin less time compared to non-distributed methods. However, most distributed\napproaches suffer from a significant bottleneck - the cost of communications.\nTherefore, a large amount of research has recently been directed at solving\nthis problem. One such approach uses local data similarity. In particular,\nthere exists an algorithm provably optimally exploiting the similarity\nproperty. But this result, as well as results from other works solve the\ncommunication bottleneck by focusing only on the fact that communication is\nsignificantly more expensive than local computing and does not take into\naccount the various capacities of network devices and the different\nrelationship between communication time and local computing expenses. We\nconsider this setup and the objective of this study is to achieve an optimal\nratio of distributed data between the server and local machines for any costs\nof communications and local computations. The running times of the network are\ncompared between uniform and optimal distributions. The superior theoretical\nperformance of our solutions is experimentally validated.\n","authors":["Daniil Medyakov","Gleb Molodtsov","Aleksandr Beznosikov","Alexander Gasnikov"],"pdf_url":"https://arxiv.org/pdf/2401.07809v2.pdf","comment":"17 pages, 2 figures"},{"id":"http://arxiv.org/abs/2307.09616v3","updated":"2024-03-26T17:15:08Z","published":"2023-07-13T19:09:22Z","title":"Continuous Non-monotone DR-submodular Maximization with Down-closed\n  Convex Constraint","summary":"  We investigate the continuous non-monotone DR-submodular maximization problem\nsubject to a down-closed convex solvable constraint. Our first contribution is\nto construct an example to demonstrate that (first-order) stationary points can\nhave arbitrarily bad approximation ratios, and they are usually on the boundary\nof the feasible domain. These findings are in contrast with the monotone case\nwhere any stationary point yields a $1/2$-approximation (Hassani et al.\n(2017)). Moreover, this example offers insights on how to design improved\nalgorithms by avoiding bad stationary points, such as the restricted continuous\nlocal search algorithm (Chekuri et al. (2014)) and the aided measured\ncontinuous greedy (Buchbinder and Feldman (2019)). However, the analyses in the\nlast two algorithms only work for the discrete domain because both need to\ninvoke the inequality that the multilinear extension of any submodular set\nfunction is bounded from below by its Lovasz extension. Our second\ncontribution, therefore, is to remove this restriction and show that both\nalgorithms can be extended to the continuous domain while retaining the same\napproximation ratios, and hence offering improved approximation ratios over\nthose in Bian et al. (2017a). for the same problem. At last, we also include\nnumerical experiments to demonstrate our algorithms on problems arising from\nmachine learning and artificial intelligence.\n","authors":["Shengminjie Chen","Donglei Du","Wenguo Yang","Dachuan Xu","Suixiang Gao"],"pdf_url":"https://arxiv.org/pdf/2307.09616v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17875v1","updated":"2024-03-26T17:03:55Z","published":"2024-03-26T17:03:55Z","title":"The Solution to an Impulse Control Problem Motivated by Optimal\n  Harvesting","summary":"  We consider a stochastic impulse control problem that is motivated by\napplications such as the optimal exploitation of a natural resource. In\nparticular, we consider a stochastic system whose uncontrolled state dynamics\nare modelled by a non-explosive positive linear diffusion. The control that can\nbe applied to this system takes the form of one-sided impulsive action. The\nobjective of the control problem is to maximise a discounted performance\ncriterion that rewards the effect of control action but involves a fixed cost\nat each time of a control intervention. We derive the complete solution to this\nproblem under general assumptions. It turns out that the solution can take four\nqualitatively different forms, several of which have not been observed in the\nliterature. In two of the four cases, there exist only $\\varepsilon$-optimal\ncontrol strategies. We also show that the boundary classification of 0 may play\na critical role in the solution of the problem. Furthermore, we develop a way\nfor establishing the strong solution to a stochastic impulse control problem's\noptimally controlled SDE.\n","authors":["Zhesheng Liu","Mihail Zervos"],"pdf_url":"https://arxiv.org/pdf/2403.17875v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17874v1","updated":"2024-03-26T17:03:17Z","published":"2024-03-26T17:03:17Z","title":"Scaling Mixed-Integer Programming for Certification of Neural Network\n  Controllers Using Bounds Tightening","summary":"  Neural networks offer a computationally efficient approximation of model\npredictive control, but they lack guarantees on the resulting controlled\nsystem's properties. Formal certification of neural networks is crucial for\nensuring safety, particularly in safety-critical domains such as autonomous\nvehicles. One approach to formally certify properties of neural networks is to\nsolve a mixed-integer program based on the network. This approach suffers from\nscalability issues due to the complexity of solving the resulting mixed-integer\nprograms. Nevertheless, these issues can be (partially) mitigated via\nbound-tightening techniques prior to forming the mixed-integer program, which\nresults in tighter formulations and faster optimisation. This paper presents\nbound-tightening techniques in the context of neural network explicit control\npolicies. Bound tightening is particularly important when considering problems\nspanning multiple time steps of a controlled system, as the bounds must be\npropagated through the problem depth. Several strategies for bound tightening\nare evaluated in terms of both computational complexity and tightness of the\nbounds.\n","authors":["Philip Sosnin","Calvin Tsay"],"pdf_url":"https://arxiv.org/pdf/2403.17874v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.07788v2","updated":"2024-03-26T16:49:44Z","published":"2024-01-15T15:54:54Z","title":"Activations and Gradients Compression for Model-Parallel Training","summary":"  Large neural networks require enormous computational clusters of machines.\nModel-parallel training, when the model architecture is partitioned\nsequentially between workers, is a popular approach for training modern models.\nInformation compression can be applied to decrease workers communication time,\nas it is often a bottleneck in such systems. This work explores how\nsimultaneous compression of activations and gradients in model-parallel\ndistributed training setup affects convergence. We analyze compression methods\nsuch as quantization and TopK compression, and also experiment with error\ncompensation techniques. Moreover, we employ TopK with AQ-SGD per-batch error\nfeedback approach. We conduct experiments on image classification and language\nmodel fine-tuning tasks. Our findings demonstrate that gradients require milder\ncompression rates than activations. We observe that $K=10\\%$ is the lowest TopK\ncompression level, which does not harm model convergence severely. Experiments\nalso show that models trained with TopK perform well only when compression is\nalso applied during inference. We find that error feedback techniques do not\nimprove model-parallel training compared to plain compression, but allow model\ninference without compression with almost no quality drop. Finally, when\napplied with the AQ-SGD approach, TopK stronger than with $ K=30\\%$ worsens\nmodel performance significantly.\n","authors":["Mikhail Rudakov","Aleksandr Beznosikov","Yaroslav Kholodov","Alexander Gasnikov"],"pdf_url":"https://arxiv.org/pdf/2401.07788v2.pdf","comment":"17 pages, 6 figures, 5 tables"},{"id":"http://arxiv.org/abs/2403.17858v1","updated":"2024-03-26T16:46:05Z","published":"2024-03-26T16:46:05Z","title":"Parallelizable Parametric Nonlinear System Identification via tuning of\n  a Moving Horizon State Estimator","summary":"  This paper introduces a novel optimization-based approach for parametric\nnonlinear system identification. Building upon the prediction error method\nframework, traditionally used for linear system identification, we extend its\ncapabilities to nonlinear systems. The predictions are computed using a moving\nhorizon state estimator with a constant arrival cost. Eventually, both the\nsystem parameters and the arrival cost are estimated by minimizing the sum of\nthe squared prediction errors. Since the predictions are induced by the state\nestimator, the method can be viewed as the tuning of a state estimator, based\non its predictive capacities. The present extension of the prediction error\nmethod not only enhances performance for nonlinear systems but also enables\nlearning from multiple trajectories with unknown initial states, broadening its\napplicability in practical scenarios. Additionally, the novel formulation\nleaves room for the design of efficient and parallelizable optimization\nalgorithms, since each output prediction only depends on a fixed window of past\nactions and measurements. In the special case of linear time-invariant systems,\nwe show an important property of the proposed method which suggests asymptotic\nconsistency under reasonable assumptions. Numerical examples illustrate the\neffectiveness and practicality of the approach, and one of the examples also\nhighlights the necessity for the arrival cost.\n","authors":["Léo Simpson","Jonas Asprion","Simon Muntwiler","Johannes Köhler","Moritz Diehl"],"pdf_url":"https://arxiv.org/pdf/2403.17858v1.pdf","comment":"Submitted to IEEE Control and Decision Conference in March 2024.\n  Contains 7 pages including 5 figures"},{"id":"http://arxiv.org/abs/2403.17850v1","updated":"2024-03-26T16:38:13Z","published":"2024-03-26T16:38:13Z","title":"An Integer Linear Program to create the shifts in a supermarket","summary":"  The shift design and the personnel scheduling problem is known to be a\ndifficult problem. It is a real-world problem which has lots of applications in\nthe organization of companies. Solutions are usually found by dividing the\nproblem in two steps: first the shifts are created, then the employees are\nassigned to them by respecting a bunch of constraints. The assignment of\ndifferent tasks increases the complexity, since we have to consider the skills\nof the single employee necessary to perform any activity. In this paper we\npresent aa integer linear programming formulation which models together the\nshift creation and the construction of rosters for employees, with the\nobjective of minimizing the amount of uncovered demand. Finally we provide the\nresults for three real-world instances, confirming that this approach is\npromising.\n","authors":["Nicolo Gusmeroli","Andrea Bettinelli"],"pdf_url":"https://arxiv.org/pdf/2403.17850v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17849v1","updated":"2024-03-26T16:38:12Z","published":"2024-03-26T16:38:12Z","title":"Multi Agent Pathfinding for Noise Restricted Hybrid Fuel Unmanned Aerial\n  Vehicles","summary":"  Multi Agent Path Finding (MAPF) seeks the optimal set of paths for multiple\nagents from respective start to goal locations such that no paths conflict. We\naddress the MAPF problem for a fleet of hybrid-fuel unmanned aerial vehicles\nwhich are subject to location-dependent noise restrictions. We solve this\nproblem by searching a constraint tree for which the subproblem at each node is\na set of shortest path problems subject to the noise and fuel constraints and\nconflict zone avoidance. A labeling algorithm is presented to solve this\nsubproblem, including the conflict zones which are treated as dynamic\nobstacles. We present the experimental results of the algorithms for various\ngraph sizes and number of agents.\n","authors":["Drew Scott","Satyanarayana G. Manyam","David W. Casbeer","Manish Kumar","Isaac E. Weintraub"],"pdf_url":"https://arxiv.org/pdf/2403.17849v1.pdf","comment":"6 pages, 7 figures"},{"id":"http://arxiv.org/abs/2402.10672v2","updated":"2024-03-26T16:07:06Z","published":"2024-02-16T13:24:33Z","title":"A note on weak compactness of occupation measures for an absorbing\n  Markov decision process","summary":"  We consider an absorbing Markov decision process with a discrete time\nparameter with Borel state and action spaces. We study the issue of the set of\noccupation measures being compact for the weak topology and its relation to the\ncontrol model being uniformly absorbing.\n","authors":["François Dufour","Tomás Prieto-Rumeau"],"pdf_url":"https://arxiv.org/pdf/2402.10672v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16173v2","updated":"2024-03-26T16:06:48Z","published":"2024-03-24T14:30:13Z","title":"A robust optimization approach model for a multi-vaccine multi-echelon\n  supply chain","summary":"  This research investigates a multi-product, multi-echelon, and multi-period\nvaccine supply chain network model under uncertainty and quality inspection\nerrors. The objective function seeks optimizing the total cost of the supply\nchain. Moreover, the proposed model is formulated as a mixed integer linear\nprogramming problem under multiple sources of uncertain parameters including\ndemand, inspection errors, vaccine waste generated in healthcare centers, and\ndefective treatment rate of vaccine waste. To provide meaningful solutions that\nare robust against future fluctuation of parameters, the robust optimization\napproach is utilized to incorporate the decision maker risk attitude under\ndifferent type of uncertainty sets. Namely, box, polyhedral and combination of\ninterval polyhedral. The performance of the proposed model is demonstrated\nthrough an illustrative example. The results show the effect of different types\nof uncertainties on the overall objective function. Managerial insights and\nresearch implications in terms of vaccine supply chain is advised and future\nresearch directions are proposed.\n","authors":["Abderrahmen Bochenine","Ismail Almaraj"],"pdf_url":"https://arxiv.org/pdf/2403.16173v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.12243v4","updated":"2024-03-26T15:12:19Z","published":"2023-08-23T16:42:27Z","title":"Multi-Objective Optimization for Sparse Deep Multi-Task Learning","summary":"  Different conflicting optimization criteria arise naturally in various Deep\nLearning scenarios. These can address different main tasks (i.e., in the\nsetting of Multi-Task Learning), but also main and secondary tasks such as loss\nminimization versus sparsity. The usual approach is a simple weighting of the\ncriteria, which formally only works in the convex setting. In this paper, we\npresent a Multi-Objective Optimization algorithm using a modified Weighted\nChebyshev scalarization for training Deep Neural Networks (DNNs) with respect\nto several tasks. By employing this scalarization technique, the algorithm can\nidentify all optimal solutions of the original problem while reducing its\ncomplexity to a sequence of single-objective problems. The simplified problems\nare then solved using an Augmented Lagrangian method, enabling the use of\npopular optimization techniques such as Adam and Stochastic Gradient Descent,\nwhile efficaciously handling constraints. Our work aims to address the\n(economical and also ecological) sustainability issue of DNN models, with a\nparticular focus on Deep Multi-Task models, which are typically designed with a\nvery large number of weights to perform equally well on multiple tasks. Through\nexperiments conducted on two Machine Learning datasets, we demonstrate the\npossibility of adaptively sparsifying the model during training without\nsignificantly impacting its performance, if we are willing to apply\ntask-specific adaptations to the network weights. Code is available at\nhttps://github.com/salomonhotegni/MDMTN\n","authors":["S. S. Hotegni","M. Berkemeier","S. Peitz"],"pdf_url":"https://arxiv.org/pdf/2308.12243v4.pdf","comment":"12 pages, 7 figures"},{"id":"http://arxiv.org/abs/2306.02987v2","updated":"2024-03-26T14:38:44Z","published":"2023-06-05T16:00:22Z","title":"Frequency Regulation with Storage: On Losses and Profits","summary":"  Low-carbon societies will need to store vast amounts of electricity to\nbalance intermittent generation from wind and solar energy, for example,\nthrough frequency regulation. Here, we derive an analytical solution to the\ndecision-making problem of storage operators who sell frequency regulation\npower to grid operators and trade electricity on day-ahead markets.\nMathematically, we treat future frequency deviation trajectories as functional\nuncertainties in a receding horizon robust optimization problem. We constrain\nthe expected terminal state-of-charge to be equal to some target to allow\nstorage operators to make good decisions not only for the present but also the\nfuture. Thanks to this constraint, the amount of electricity traded on\nday-ahead markets is an implicit function of the regulation power sold to grid\noperators. The implicit function quantifies the amount of power that needs to\nbe purchased to cover the expected energy loss that results from providing\nfrequency regulation. We show how the marginal cost associated with the\nexpected energy loss decreases with roundtrip efficiency and increases with\nfrequency deviation dispersion. We find that the profits from frequency\nregulation over the lifetime of energy-constrained storage devices are roughly\ninversely proportional to the length of time for which regulation power must be\ncommitted.\n","authors":["Dirk Lauinger","François Vuille","Daniel Kuhn"],"pdf_url":"https://arxiv.org/pdf/2306.02987v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17730v1","updated":"2024-03-26T14:19:22Z","published":"2024-03-26T14:19:22Z","title":"On Structural Non-commutativity in Affine Feedback of SISO Nonlinear\n  Systems","summary":"  The affine feedback connection of SISO nonlinear systems modeled by\nChen--Fliess series is shown to be a group action on the plant which is\nisomorphic to the semi-direct product of shuffle and additive group of\nnon-commutative formal power series. The additive and multiplicative feedback\nloops in an affine feedback connection are thus proven to be structurally\nnon-commutative. A flip in the order of these loops results in a net additive\nfeedback loop.\n","authors":["Venkatesh G. S."],"pdf_url":"https://arxiv.org/pdf/2403.17730v1.pdf","comment":"submitted to $26^{th}$ International Symposium on Mathematical Theory\n  of Networks and Systems, 2024"},{"id":"http://arxiv.org/abs/2310.02969v2","updated":"2024-03-26T14:00:59Z","published":"2023-10-04T17:06:30Z","title":"Dual Conic Proxies for AC Optimal Power Flow","summary":"  In recent years, there has been significant interest in the development of\nmachine learning-based optimization proxies for AC Optimal Power Flow (AC-OPF).\nAlthough significant progress has been achieved in predicting high-quality\nprimal solutions, no existing learning-based approach can provide valid dual\nbounds for AC-OPF. This paper addresses this gap by training optimization\nproxies for a convex relaxation of AC-OPF. Namely, the paper considers a\nsecond-order cone (SOC) relaxation of AC-OPF, and proposes \\revision{a novel\narchitecture} that embeds a fast, differentiable (dual) feasibility recovery,\nthus providing valid dual bounds. The paper combines this new architecture with\na self-supervised learning scheme, which alleviates the need for costly\ntraining data generation. Extensive numerical experiments on medium- and\nlarge-scale power grids demonstrate the efficiency and scalability of the\nproposed methodology.\n","authors":["Guancheng Qiu","Mathieu Tanneau","Pascal Van Hentenryck"],"pdf_url":"https://arxiv.org/pdf/2310.02969v2.pdf","comment":"accepted to PSCC 2024"},{"id":"http://arxiv.org/abs/2403.17711v1","updated":"2024-03-26T13:58:21Z","published":"2024-03-26T13:58:21Z","title":"Using quantum computers in control: interval matrix properties","summary":"  Quantum computing provides a powerful framework for tackling computational\nproblems that are classically intractable. The goal of this paper is to explore\nthe use of quantum computers for solving relevant problems in systems and\ncontrol theory. In the recent literature, different quantum algorithms have\nbeen developed to tackle binary optimization, which plays an important role in\nvarious control-theoretic problems. As a prototypical example, we consider the\nverification of interval matrix properties such as non-singularity and\nstability on a quantum computer. We present a quantum algorithm solving these\nproblems and we study its performance in simulation. Our results demonstrate\nthat quantum computers provide a promising tool for control whose applicability\nto further computationally complex problems remains to be explored.\n","authors":["Jan Schneider","Julian Berberich"],"pdf_url":"https://arxiv.org/pdf/2403.17711v1.pdf","comment":"Final version, accepted for publication in Proc. European Control\n  Conference (ECC), 2024"},{"id":"http://arxiv.org/abs/2311.04070v2","updated":"2024-03-26T13:55:33Z","published":"2023-11-07T15:35:45Z","title":"On the Post-Lie Structure in SISO Affine Feedback Control Systems","summary":"  The main objective of this work is to show that the single-input,\nsingle-output (SISO) affine feedback group, a transformation group in the\ncontext of the affine feedback interconnection of Chen-Fliess series, is a\npost-group in the sense of Bai, Guo, Sheng and Tang.\n","authors":["Kurusch Ebrahimi-Fard","W. Steven Gray","Venkatesh G. S."],"pdf_url":"https://arxiv.org/pdf/2311.04070v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.09557v2","updated":"2024-03-26T13:54:44Z","published":"2022-11-17T14:27:52Z","title":"Optimal Design of Volt/VAR Control Rules of Inverters using Deep\n  Learning","summary":"  Distribution grids are challenged by rapid voltage fluctuations induced by\nvariable power injections from distributed energy resources (DERs). To regulate\nvoltage, the IEEE Standard 1547 recommends each DER inject reactive power\naccording to piecewise-affine Volt/VAR control rules. Although the standard\nsuggests a default shape, the rule can be customized per bus. This task of\noptimal rule design (ORD) is challenging as Volt/VAR rules introduce nonlinear\ndynamics, and lurk trade-offs between stability and steady-state voltage\nprofiles. ORD is formulated as a mixed-integer nonlinear program (MINLP), but\nscales unfavorably with the problem size. Towards a more efficient solution, we\nreformulate ORD as a deep learning problem. The idea is to design a DNN that\nemulates Volt/VAR dynamics. The DNN takes grid scenarios as inputs, rule\nparameters as weights, and outputs equilibrium voltages. Optimal rule\nparameters can be found by training the DNN so its output approaches unity for\nvarious scenarios. The DNN is only used to optimize rules and is never employed\nin the field. While dealing with ORD, we also review and expand on stability\nconditions and convergence rates for Volt/VAR dynamics on single- and\nmulti-phase feeders. Tests showcase the merit of DNN-based ORD by benchmarking\nit against its MINLP counterpart.\n","authors":["Sarthak Gupta","Vassilis Kekatos","Spyros Chatzivasileiadis"],"pdf_url":"https://arxiv.org/pdf/2211.09557v2.pdf","comment":"Accepted in the IEEE Trans. on Smart Grid"},{"id":"http://arxiv.org/abs/2310.02869v2","updated":"2024-03-26T13:43:55Z","published":"2023-10-04T15:03:56Z","title":"Harmonic Control Lyapunov Barrier Functions for Constrained Optimal\n  Control with Reach-Avoid Specifications","summary":"  This paper introduces harmonic control Lyapunov barrier functions (harmonic\nCLBF) that aid in constrained control problems such as reach-avoid problems.\nHarmonic CLBFs exploit the maximum principle that harmonic functions satisfy to\nencode the properties of control Lyapunov barrier functions (CLBFs). As a\nresult, they can be initiated at the start of an experiment rather than trained\nbased on sample trajectories. The control inputs are selected to maximize the\ninner product of the system dynamics with the steepest descent direction of the\nharmonic CLBF. Numerical results are presented with four different systems\nunder different reach-avoid environments. Harmonic CLBFs show a significantly\nlow risk of entering unsafe regions and a high probability of entering the goal\nregion.\n","authors":["Amartya Mukherjee","Ruikun Zhou","Haocheng Chang","Jun Liu"],"pdf_url":"https://arxiv.org/pdf/2310.02869v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17692v1","updated":"2024-03-26T13:33:16Z","published":"2024-03-26T13:33:16Z","title":"Manifold-Guided Lyapunov Control with Diffusion Models","summary":"  This paper presents a novel approach to generating stabilizing controllers\nfor a large class of dynamical systems using diffusion models. The core\nobjective is to develop stabilizing control functions by identifying the\nclosest asymptotically stable vector field relative to a predetermined manifold\nand adjusting the control function based on this finding. To achieve this, we\nemploy a diffusion model trained on pairs consisting of asymptotically stable\nvector fields and their corresponding Lyapunov functions. Our numerical results\ndemonstrate that this pre-trained model can achieve stabilization over\npreviously unseen systems efficiently and rapidly, showcasing the potential of\nour approach in fast zero-shot control and generalizability.\n","authors":["Amartya Mukherjee","Thanin Quartz","Jun Liu"],"pdf_url":"https://arxiv.org/pdf/2403.17692v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2311.00521v2","updated":"2024-03-26T13:31:16Z","published":"2023-11-01T13:49:21Z","title":"Gaussian smoothing gradient descent for minimizing functions (GSmoothGD)","summary":"  This work analyzes the convergence of a class of smoothing-based gradient\ndescent methods when applied to optimization problems. In particular, Gaussian\nsmoothing is employed to define a nonlocal gradient that reduces high-frequency\nnoise, small variations, and rapid fluctuations in the computation of the\ndescent directions while preserving the structure and features of the loss\nlandscape. The resulting Gaussian smoothing gradient descent (GSmoothGD)\napproach can facilitate gradient descent in navigating away from and avoiding\nlocal minima with increased ease, thereby substantially enhancing its overall\nperformance even when applied to non-convex optimization problems. This work\nalso provides rigorous theoretical error estimates on the rate of convergence\nof GSmoothGD iterates. These estimates exemplify the impact of underlying\nfunction convexity, smoothness, input dimension, and the Gaussian smoothing\nradius. To combat the curse of dimensionality, we numerically approximate the\nGSmoothGD nonlocal gradient using Monte Carlo (MC) sampling and provide a\ntheory in which the iterates converge regardless of the function smoothness and\ndimension. Finally, we present several strategies to update the smoothing\nparameter aimed at diminishing the impact of local minima, thereby rendering\nthe attainment of global minima more achievable. Computational evidence\ncomplements the present theory and shows the effectiveness of the MC-GSmoothGD\nmethod compared to other smoothing-based algorithms, momentum-based approaches,\nand classical gradient-based algorithms from numerical optimization.\n","authors":["Andrew Starnes","Anton Dereventsov","Clayton Webster"],"pdf_url":"https://arxiv.org/pdf/2311.00521v2.pdf","comment":"29 pages, 2 figures, 2 tables"},{"id":"http://arxiv.org/abs/2403.17675v1","updated":"2024-03-26T13:02:48Z","published":"2024-03-26T13:02:48Z","title":"Chattering Phenomena in Time-Optimal Control for High-Order\n  Chain-of-Integrators Systems with Full State Constraints","summary":"  Time-optimal control for high-order chain-of-integrators systems with full\nstate constraints and arbitrary given terminal states remains an open and\nchallenging problem in optimal control theory domain. However, optimal\ncontrol's behaviors in high-order problems lack of precision characterization,\neven where the existence of chattering phenomena remain unknown and overlooked.\nThis paper establishes a theoretical framework of chattering phenomena in the\nproblem, focusing on the uniqueness of state constraints inducing chattering,\nthe upper bound of switching times in an unconstrained arc during chattering,\nand the convergence of states and costates to the chattering limit point. For\nthe first time, this paper proves the existence of chattering phenomena in the\nproblems. The chattering optimal control for 4th order problems with velocity\nconstraints is precisely solved, providing an approach to plan strictly\ntime-optimal snap-limited trajectories, while other cases of order $n\\leq4$ are\nproved to not allow chattering. The conclusions correct the longstanding\nmisconception in the industry regarding the time-optimality of S-shaped\ntrajectories with minimal switching times.\n","authors":["Yunan Wang","Chuxiong Hu","Zeyang Li","Yujie Lin","Shize Lin","Suqin He","Yu Zhu"],"pdf_url":"https://arxiv.org/pdf/2403.17675v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.07939v2","updated":"2024-03-26T11:54:27Z","published":"2023-11-14T06:33:41Z","title":"Discretized Distributed Optimization over Dynamic Digraphs","summary":"  We consider a discrete-time model of continuous-time distributed optimization\nover dynamic directed-graphs (digraphs) with applications to distributed\nlearning. Our optimization algorithm works over general strongly connected\ndynamic networks under switching topologies, e.g., in mobile multi-agent\nsystems and volatile networks due to link failures. Compared to many existing\nlines of work, there is no need for bi-stochastic weight designs on the links.\nThe existing literature mostly needs the link weights to be stochastic using\nspecific weight-design algorithms needed both at the initialization and at all\ntimes when the topology of the network changes. This paper eliminates the need\nfor such algorithms and paves the way for distributed optimization over\ntime-varying digraphs. We derive the bound on the gradient-tracking step-size\nand discrete time-step for convergence and prove dynamic stability using\narguments from consensus algorithms, matrix perturbation theory, and Lyapunov\ntheory. This work, particularly, is an improvement over existing\nstochastic-weight undirected networks in case of link removal or packet drops.\nThis is because the existing literature may need to rerun time-consuming and\ncomputationally complex algorithms for stochastic design, while the proposed\nstrategy works as long as the underlying network is weight-symmetric and\nbalanced. The proposed optimization framework finds applications to distributed\nclassification and learning.\n","authors":["Mohammadreza Doostmohammadian","Wei Jiang","Muwahida Liaquat","Alireza Aghasi","Houman Zarrabi"],"pdf_url":"https://arxiv.org/pdf/2311.07939v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17613v1","updated":"2024-03-26T11:48:19Z","published":"2024-03-26T11:48:19Z","title":"A Globally Convergent Gradient Method with Momentum","summary":"  In this work, we consider smooth unconstrained optimization problems and we\ndeal with the class of gradient methods with momentum, i.e., descent algorithms\nwhere the search direction is defined as a linear combination of the current\ngradient and the preceding search direction. This family of algorithms includes\nnonlinear conjugate gradient methods and Polyak's heavy-ball approach, and is\nthus of high practical and theoretical interest in large-scale nonlinear\noptimization. We propose a general framework where the scalars of the linear\ncombination defining the search direction are computed simultaneously by\nminimizing the approximate quadratic model in the 2 dimensional subspace. This\nstrategy allows us to define a class of gradient methods with momentum enjoying\nglobal convergence guarantees and an optimal worst-case complexity bound in the\nnonconvex setting. Differently than all related works in the literature, the\nconvergence conditions are stated in terms of the Hessian matrix of the\nbi-dimensional quadratic model. To the best of our knowledge, these results are\nnovel to the literature. Moreover, extensive computational experiments show\nthat the gradient methods with momentum here presented outperform classical\nconjugate gradient methods and are (at least) competitive with the state-of-art\nmethod for unconstrained optimization, i.e, L-BFGS method.\n","authors":["Matteo Lapucci","Giampaolo Liuzzi","Stefano Lucidi","Marco Sciandrone"],"pdf_url":"https://arxiv.org/pdf/2403.17613v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17597v1","updated":"2024-03-26T11:08:48Z","published":"2024-03-26T11:08:48Z","title":"An Exact Solution for Allocating Car Parking Spaces on Campus","summary":"  All over the world, especially in the university environment, planning\nmanagers and traffic engineers are constantly faced with the problem of\ninadequate allocation of car parking spaces to demanded users. Users could\neither prefer reserved parking spaces to unreserved parking spaces or vice\nversa. This makes the campus parking manager to be faced with two basic problem\nwhich are: the problem of allocating the actual number of available reserved\nspaces to users without any conflict over the same parking space, and the\nproblem of determining the number of parking permit to be issued for parking\nlot with unreserved spaces. Hence, an optimal or available solution to the\nproblem is required. This paper investigates a model for allocating car parking\nspaces, adds a constraint to address the reserved parking policy in a\nuniversity environment and solves the parking allocation problem using an exact\nsolution method. The result obtained gives the value of the objective function\nand the optimal allocation of users to each parking lot.\n","authors":["Luke Oluwaseye Joel","Sawyerr A. Babatunde","Adewumi O. Aderemi"],"pdf_url":"https://arxiv.org/pdf/2403.17597v1.pdf","comment":"An International Multidiscinary Conference on Research, Development\n  and Practices in Science, Technology, Education, Arts, Management & the\n  Social Science (iSTEAMS). Conference Centre, University of Ibandan, Nigeria.\n  30 May - 01 June 2013"},{"id":"http://arxiv.org/abs/2403.17572v1","updated":"2024-03-26T10:25:21Z","published":"2024-03-26T10:25:21Z","title":"Enhancing Privacy in Federated Learning through Local Training","summary":"  In this paper we propose the federated private local training algorithm\n(Fed-PLT) for federated learning, to overcome the challenges of (i) expensive\ncommunications and (ii) privacy preservation. We address (i) by allowing for\nboth partial participation and local training, which significantly reduce the\nnumber of communication rounds between the central coordinator and computing\nagents. The algorithm matches the state of the art in the sense that the use of\nlocal training demonstrably does not impact accuracy. Additionally, agents have\nthe flexibility to choose from various local training solvers, such as\n(stochastic) gradient descent and accelerated gradient descent. Further, we\ninvestigate how employing local training can enhance privacy, addressing point\n(ii). In particular, we derive differential privacy bounds and highlight their\ndependence on the number of local training epochs. We assess the effectiveness\nof the proposed algorithm by comparing it to alternative techniques,\nconsidering both theoretical analysis and numerical results from a\nclassification task.\n","authors":["Nicola Bastianello","Changxin Liu","Karl H. Johansson"],"pdf_url":"https://arxiv.org/pdf/2403.17572v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17554v1","updated":"2024-03-26T10:01:13Z","published":"2024-03-26T10:01:13Z","title":"Robust Stability for Multiagent Systems with Spatio-Temporally\n  Correlated Packet Loss","summary":"  A problem with considering correlations in the analysis of multiagent system\nwith stochastic packet loss is that they induce dependencies between agents\nthat are otherwise decoupled, preventing the application of decomposition\nmethods required for efficient evaluation. To circumvent that issue, this paper\nis proposing an approach based on analysing sets of networks with independent\ncommunication links, only considering the correlations in an implicit fashion.\nCombining ideas from the robust stabilization of Markov jump linear systems\nwith recently proposed techniques for analysing packet loss in multiagent\nsystems, we obtain a linear matrix inequality based stability condition which\nis independent of the number of agents. The main result is that the set of\nstabilized probability distributions has non-empty interior such that small\ncorrelations cannot lead to instability, even though only distributions of\nindependent links were analysed. Moreover, two examples are provided to\ndemonstrate the applicability of the results to practically relevant scenarios.\n","authors":["Christian Hespe","Adwait Datar","Herbert Werner"],"pdf_url":"https://arxiv.org/pdf/2403.17554v1.pdf","comment":"7 pages, 2 figures, 1 table"},{"id":"http://arxiv.org/abs/2403.17535v1","updated":"2024-03-26T09:40:39Z","published":"2024-03-26T09:40:39Z","title":"Nonsmooth convex-concave saddle point problems with cardinality\n  penalties","summary":"  In this paper, we focus on a class of convexly constrained nonsmooth\nconvex-concave saddle point problems with cardinality penalties. Although such\nnonsmooth nonconvex-nonconcave and discontinuous min-max problems may not have\na saddle point, we show that they have a local saddle point and a global\nminimax point, and some local saddle points have the lower bound properties. We\ndefine a class of strong local saddle points based on the lower bound\nproperties for stability of variable selection. Moreover, we give a framework\nto construct continuous relaxations of the discontinuous min-max problems based\non the convolution, such that they have the same saddle points with the\noriginal problem. We also establish the relations between the continuous\nrelaxation problems and the original problems regarding local saddle points,\nglobal minimax points, local minimax points and stationary points. Finally, we\nillustrate our results with distributionally robust sparse convex regression,\nsparse robust bond portfolio construction and sparse convex-concave logistic\nregression saddle point problems.\n","authors":["Wei Bian","Xiaojun Chen"],"pdf_url":"https://arxiv.org/pdf/2403.17535v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17527v1","updated":"2024-03-26T09:30:16Z","published":"2024-03-26T09:30:16Z","title":"Minimum-Delay Opportunity Charging Scheduling for Electric Buses","summary":"  Transit agencies that operate battery-electric buses must carefully manage\nfast-charging infrastructure to extend daily bus range without degrading\non-time performance. To support this need, we propose a mixed-integer linear\nprogramming model to schedule opportunity charging that minimizes the amount of\ndeparture delay in all trips served by electric buses. Our novel approach\ndirectly tracks queuing at chargers in order to set and propagate departure\ndelays. Allowing but minimizing delays makes it possible to optimize\nperformance when delays due to traffic conditions and charging needs are\ninevitable, in contrast with existing methods that require charging to occur\nduring scheduled layover time. To solve the model, we develop two algorithms\nbased on decomposition. The first is an exact solution method based on\nCombinatorial Benders (CB) decomposition, which avoids directly enumerating the\nmodel's logic-based \"big M\" constraints and their inevitable computational\nchallenges. The second, inspired by the CB approach but more efficient, is a\npolynomial-time heuristic based on linear programming that we call 3S.\nComputational experiments on both a simple notional transit network and the\nreal bus system of King County, Washington, USA demonstrate the performance of\nboth methods. The 3S method appears particularly promising for creating good\ncharging schedules quickly at real-world scale.\n","authors":["Dan McCabe"," Xuegang"," Ban","Balazs Kulcsar"],"pdf_url":"https://arxiv.org/pdf/2403.17527v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17495v1","updated":"2024-03-26T08:52:54Z","published":"2024-03-26T08:52:54Z","title":"Quantum Optimization for the Future Energy Grid: Summary and Quantum\n  Utility Prospects","summary":"  In this project summary paper, we summarize the key results and use-cases\nexplored in the German Federal Ministry of Education and Research (BMBF) funded\nproject \"Q-GRID\" which aims to assess potential quantum utility optimization\napplications in the electrical grid. The project focuses on two layers of\noptimization problems relevant to decentralized energy generation and\ntransmission as well as novel energy transportation/exchange methods such as\nPeer-2-Peer energy trading and microgrid formation. For select energy grid\noptimization problems, we demonstrate exponential classical optimizer runtime\nscaling even for small problem instances, and present initial findings that\nvariational quantum algorithms such as QAOA and hybrid quantum annealing\nsolvers may provide more favourable runtime scaling to obtain similar solution\nquality. These initial results suggest that quantum computing may be a key\nenabling technology in the future energy transition insofar that they may be\nable to solve business problems which are already challenging at small problem\ninstance sizes.\n","authors":["Jonas Blenninger","David Bucher","Giorgio Cortiana","Kumar Ghosh","Naeimeh Mohseni","Jonas Nüßlein","Corey O'Meara","Daniel Porawski","Benedikt Wimmer"],"pdf_url":"https://arxiv.org/pdf/2403.17495v1.pdf","comment":"12 pages. arXiv admin note: text overlap with arXiv:2309.05502"},{"id":"http://arxiv.org/abs/2204.00406v3","updated":"2024-03-26T08:48:53Z","published":"2022-04-01T13:08:49Z","title":"A Semismooth Newton Stochastic Proximal Point Algorithm with Variance\n  Reduction","summary":"  We develop an implementable stochastic proximal point (SPP) method for a\nclass of weakly convex, composite optimization problems. The proposed\nstochastic proximal point algorithm incorporates a variance reduction mechanism\nand the resulting SPP updates are solved using an inexact semismooth Newton\nframework. We establish detailed convergence results that take the inexactness\nof the SPP steps into account and that are in accordance with existing\nconvergence guarantees of (proximal) stochastic variance-reduced gradient\nmethods. Numerical experiments show that the proposed algorithm competes\nfavorably with other state-of-the-art methods and achieves higher robustness\nwith respect to the step size selection.\n","authors":["Andre Milzarek","Fabian Schaipp","Michael Ulbrich"],"pdf_url":"https://arxiv.org/pdf/2204.00406v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17470v1","updated":"2024-03-26T07:57:56Z","published":"2024-03-26T07:57:56Z","title":"Investigations on Physics-Informed Neural Networks for Aerodynamics","summary":"  Physics-Informed Neural Networks (PINNs) have recently emerged as a novel\napproach to simulate complex physical systems on the basis of both data\nobservations and physical models. In this work, we investigate the use of PINNs\nfor various applications in aerodynamics and we explain how to leverage their\nspecific formulation to perform some tasks effectively. In particular, we\ndemonstrate the ability of PINNs to construct parametric surrogate models, to\nachieve multiphysic couplings and to infer turbulence characteristics via data\nassimilation. The robustness and accuracy of the PINNs approach are analysed,\nthen current issues and challenges are discussed.\n","authors":["Guillaume Coulaud","Maxime Le","Régis Duvigneau"],"pdf_url":"https://arxiv.org/pdf/2403.17470v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17450v1","updated":"2024-03-26T07:31:15Z","published":"2024-03-26T07:31:15Z","title":"An inexact proximal MM method for a class of nonconvex composite image\n  reconstruction models","summary":"  This paper concerns a class of composite image reconstruction models for\nimpluse noise removal, which is rather general and covers existing convex and\nnonconvex models proposed for reconstructing images with impluse noise. For\nthis nonconvex and nonsmooth optimization problem, we propose a proximal\nmajorization-minimization (MM) algorithm with an implementable inexactness\ncriterion by seeking in each step an inexact minimizer of a strongly convex\nmajorization of the objective function, and establish the convergence of the\niterate sequence under the KL assumption on the constructed potential function.\nThis inexact proximal MM method is applied to handle gray image deblurring and\ncolor image inpainting problems, for which the associated potential function\nsatisfy the required KL assumption. Numerical comparisons with two state-of-art\nsolvers for image deblurring and inpainting tasks validate the efficiency of\nthe proposed algorithm and models.\n","authors":["Bujin Li","Shaohua Pan","Tieyong Zeng"],"pdf_url":"https://arxiv.org/pdf/2403.17450v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.10810v2","updated":"2024-03-26T05:48:18Z","published":"2023-05-18T08:48:10Z","title":"On the Geometric Convergence of Byzantine-Resilient Distributed\n  Optimization Algorithms","summary":"  The problem of designing distributed optimization algorithms that are\nresilient to Byzantine adversaries has received significant attention. For the\nByzantine-resilient distributed optimization problem, the goal is to\n(approximately) minimize the average of the local cost functions held by the\nregular (non adversarial) agents in the network. In this paper, we provide a\ngeneral algorithmic framework for Byzantine-resilient distributed optimization\nwhich includes some state-of-the-art algorithms as special cases. We analyze\nthe convergence of algorithms within the framework, and derive a geometric rate\nof convergence of all regular agents to a ball around the optimal solution\n(whose size we characterize). Furthermore, we show that approximate consensus\ncan be achieved geometrically fast under some minimal conditions. Our analysis\nprovides insights into the relationship among the convergence region, distance\nbetween regular agents' values, step-size, and properties of the agents'\nfunctions for Byzantine-resilient distributed optimization.\n","authors":["Kananart Kuwaranancharoen","Shreyas Sundaram"],"pdf_url":"https://arxiv.org/pdf/2305.10810v2.pdf","comment":"29 pages, 5 figures"},{"id":"http://arxiv.org/abs/2403.17364v1","updated":"2024-03-26T04:02:09Z","published":"2024-03-26T04:02:09Z","title":"A Moreau Envelope Approach for LQR Meta-Policy Estimation","summary":"  We study the problem of policy estimation for the Linear Quadratic Regulator\n(LQR) in discrete-time linear time-invariant uncertain dynamical systems. We\npropose a Moreau Envelope-based surrogate LQR cost, built from a finite set of\nrealizations of the uncertain system, to define a meta-policy efficiently\nadjustable to new realizations. Moreover, we design an algorithm to find an\napproximate first-order stationary point of the meta-LQR cost function.\nNumerical results show that the proposed approach outperforms naive averaging\nof controllers on new realizations of the linear system. We also provide\nempirical evidence that our method has better sample complexity than\nModel-Agnostic Meta-Learning (MAML) approaches.\n","authors":["Ashwin Aravind","Mohammad Taha Toghani","César A. Uribe"],"pdf_url":"https://arxiv.org/pdf/2403.17364v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2306.07905v2","updated":"2024-03-26T00:21:41Z","published":"2023-06-13T16:56:13Z","title":"Omega: Optimistic EMA Gradients","summary":"  Stochastic min-max optimization has gained interest in the machine learning\ncommunity with the advancements in GANs and adversarial training. Although game\noptimization is fairly well understood in the deterministic setting, some\nissues persist in the stochastic regime. Recent work has shown that stochastic\ngradient descent-ascent methods such as the optimistic gradient are highly\nsensitive to noise or can fail to converge. Although alternative strategies\nexist, they can be prohibitively expensive. We introduce Omega, a method with\noptimistic-like updates that mitigates the impact of noise by incorporating an\nEMA of historic gradients in its update rule. We also explore a variation of\nthis algorithm that incorporates momentum. Although we do not provide\nconvergence guarantees, our experiments on stochastic games show that Omega\noutperforms the optimistic gradient method when applied to linear players.\n","authors":["Juan Ramirez","Rohan Sukumaran","Quentin Bertrand","Gauthier Gidel"],"pdf_url":"https://arxiv.org/pdf/2306.07905v2.pdf","comment":"Oral at the LatinX in AI workshop @ ICML 2023"},{"id":"http://arxiv.org/abs/2403.18155v1","updated":"2024-03-26T23:40:13Z","published":"2024-03-26T23:40:13Z","title":"An inexact infeasible arc-search interior-point method for linear\n  programming problems","summary":"  Inexact interior-point methods (IPMs) are a type of interior-point methods\nthat inexactly solve the linear equation system for obtaining the search\ndirection. On the other hand,arc-search IPMs approximate the central path with\nan ellipsoidal arc obtained by solving two linear equation systems in each\niteration, while conventional line-search IPMs solve one linear system,\ntherefore, the improvement due to the inexact solutions of the linear equation\nsystems can be more beneficial in arc-search IPMs than conventional IPMs. In\nthis paper, we propose an inexact infeasible arc-search interior-point\nmethod.We establish that the proposed method is a polynomial-time algorithm\nthrough its convergence analysis. The numerical experiments with the conjugate\ngradient method show that the proposed method can reduce the number of\niterations compared to an existing method for benchmark problems; the numbers\nof iterations are reduced to two-thirds for more than 70% of the problems.\n","authors":["Einosuke Iida","Makoto Yamashita"],"pdf_url":"https://arxiv.org/pdf/2403.18155v1.pdf","comment":"25 pages, 3 figures"},{"id":"http://arxiv.org/abs/2403.18149v1","updated":"2024-03-26T23:17:05Z","published":"2024-03-26T23:17:05Z","title":"Code Generation for Conic Model-Predictive Control on Microcontrollers\n  with TinyMPC","summary":"  Conic constraints appear in many important control applications like legged\nlocomotion, robotic manipulation, and autonomous rocket landing. However,\ncurrent solvers for conic optimization problems have relatively heavy\ncomputational demands in terms of both floating-point operations and memory\nfootprint, making them impractical for use on small embedded devices. We extend\nTinyMPC, an open-source, high-speed solver targeting low-power embedded control\napplications, to handle second-order cone constraints. We also present\ncode-generation software to enable deployment of TinyMPC on a variety of\nmicrocontrollers. We benchmark our generated code against state-of-the-art\nembedded QP and SOCP solvers, demonstrating a two-order-of-magnitude speed\nincrease over ECOS while consuming less memory. Finally, we demonstrate\nTinyMPC's efficacy on the Crazyflie, a lightweight, resource-constrained\nquadrotor with fast dynamics. TinyMPC and its code-generation tools are\npublicly available at https://tinympc.org.\n","authors":["Sam Schoedel","Khai Nguyen","Elakhya Nedumaran","Brian Plancher","Zachary Manchester"],"pdf_url":"https://arxiv.org/pdf/2403.18149v1.pdf","comment":"Submitted to CDC, 2024. First two authors contributed equally"},{"id":"http://arxiv.org/abs/2403.00465v2","updated":"2024-03-26T23:02:48Z","published":"2024-03-01T11:39:46Z","title":"Polyamorous Scheduling","summary":"  Finding schedules for pairwise meetings between the members of a complex\nsocial group without creating interpersonal conflict is challenging, especially\nwhen different relationships have different needs. We formally define and study\nthe underlying optimisation problem: Polyamorous Scheduling.\n  In Polyamorous Scheduling, we are given an edge-weighted graph and try to\nfind a periodic schedule of matchings in this graph such that the maximal\nweighted waiting time between consecutive occurrences of the same edge is\nminimised. We show that the problem is NP-hard and that there is no efficient\napproximation algorithm with a better ratio than 4/3 unless P = NP. On the\npositive side, we obtain an $O(\\log n)$-approximation algorithm; indeed, a\n$O(\\log \\Delta)$-approximation for $\\Delta$ the maximum degree, i.e., the\nlargest number of relationships of any individual. We also define a\ngeneralisation of density from the Pinwheel Scheduling Problem, \"poly density\",\nand ask whether there exists a poly-density threshold similar to the\n5/6-density threshold for Pinwheel Scheduling [Kawamura, STOC 2024].\nPolyamorous Scheduling is a natural generalisation of Pinwheel Scheduling with\nrespect to its optimisation variant, Bamboo Garden Trimming.\n  Our work contributes the first nontrivial hardness-of-approximation reduction\nfor any periodic scheduling problem, and opens up numerous avenues for further\nstudy of Polyamorous Scheduling.\n","authors":["Leszek Gąsieniec","Benjamin Smith","Sebastian Wild"],"pdf_url":"https://arxiv.org/pdf/2403.00465v2.pdf","comment":"v2: stronger and simplified hardness-of-approximation results,\n  corrected constant in layering approximation algorithm"},{"id":"http://arxiv.org/abs/2403.18131v1","updated":"2024-03-26T22:24:11Z","published":"2024-03-26T22:24:11Z","title":"Convergence of Iterative Quadratic Programming for Robust Fixed-Endpoint\n  Transfer of Bilinear Systems","summary":"  We present a computational method for open-loop minimum-norm control\nsynthesis for fixed-endpoint transfer of bilinear ensemble systems that are\nindexed by two continuously varying parameters. We suppose that one ensemble\nparameter scales the homogeneous, linear part of the dynamics, and the second\nparameter scales the effect of the applied control inputs on the inhomogeneous,\nbilinear dynamics. This class of dynamical systems is motivated by robust\nquantum control pulse synthesis, where the ensemble parameters correspond to\nuncertainty in the free Hamiltonian and inhomogeneity in the control\nHamiltonian, respectively. Our computational method is based on polynomial\napproximation of the ensemble state in parameter space and discretization of\nthe evolution equations in the time domain using a product of matrix\nexponentials corresponding to zero-order hold controls over the time intervals.\nThe dynamics are successively linearized about control and trajectory iterates\nto formulate a sequence of quadratic programs for computing perturbations to\nthe control that successively improve the objective until the iteration\nconverges. We use a two-stage computation to first ensure transfer to the\ndesired terminal state, and then minimize the norm of the control function. The\nmethod is demonstrated for the canonical uniform transfer problem for the Bloch\nsystem that appears in nuclear magnetic resonance, as well as the matter-wave\nsplitting problem for the Raman-Nath system that appears in ultra-cold atom\ninterferometry.\n","authors":["Luke S. Baker","Andre Luiz P. de Lima","Anatoly Zlotnik","Jr-Shin Li"],"pdf_url":"https://arxiv.org/pdf/2403.18131v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18130v1","updated":"2024-03-26T22:19:39Z","published":"2024-03-26T22:19:39Z","title":"Generalized Maximum Entropy Differential Dynamic Programming","summary":"  We present a sampling-based trajectory optimization method derived from the\nmaximum entropy formulation of Differential Dynamic Programming with Tsallis\nentropy. This method can be seen as a generalization of the legacy work with\nShannon entropy, which leads to a Gaussian optimal control policy for\nexploration during optimization. With the Tsallis entropy, the optimal control\npolicy takes the form of $q$-Gaussian, which further encourages exploration\nwith its heavy-tailed shape. Moreover, in our formulation, the exploration\nvariance, which was scaled by a fixed constant inverse temperature in the\noriginal formulation with Shannon entropy, is automatically scaled based on the\nvalue function of the trajectory. Due to this property, our algorithms can\npromote exploration when necessary, that is, the cost of the trajectory is\nhigh, rather than using the same scaling factor. The simulation results\ndemonstrate the properties of the proposed algorithm described above.\n","authors":["Yuichiro Aoyama","Evangelos A. Theodorou"],"pdf_url":"https://arxiv.org/pdf/2403.18130v1.pdf","comment":"7 pages, 5 figures, This paper is for CDC 2024"},{"id":"http://arxiv.org/abs/2403.18124v1","updated":"2024-03-26T22:07:29Z","published":"2024-03-26T22:07:29Z","title":"Stochastic Finite Volume Method for Uncertainty Management in Gas\n  Pipeline Network Flows","summary":"  Natural gas consumption by users of pipeline networks is subject to\nincreasing uncertainty that originates from the intermittent nature of electric\npower loads serviced by gas-fired generators. To enable computationally\nefficient optimization of gas network flows subject to uncertainty, we develop\na finite volume representation of stochastic solutions of hyperbolic partial\ndifferential equation (PDE) systems on graph-connected domains with nodal\ncoupling and boundary conditions. The representation is used to express the\nphysical constraints in stochastic optimization problems for gas flow\nallocation subject to uncertain parameters. The method is based on the\nstochastic finite volume approach that was recently developed for uncertainty\nquantification in transient flows represented by hyperbolic PDEs on graphs. In\nthis study, we develop optimization formulations for steady-state gas flow over\nactuated transport networks subject to probabilistic constraints. In addition\nto the distributions for the physical solutions, we examine the dual variables\nthat are produced by way of the optimization, and interpret them as price\ndistributions that quantify the financial volatility that arises through demand\nuncertainty modeled in an optimization-driven gas market mechanism. We\ndemonstrate the computation and distributional analysis using a single-pipe\nexample and a small test network.\n","authors":["Saif R. Kazi","Sidhant Misra","Svetlana Tokareva","Kaarthik Sundar","Anatoly Zlotnik"],"pdf_url":"https://arxiv.org/pdf/2403.18124v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.03244v2","updated":"2024-03-26T20:35:45Z","published":"2024-01-06T15:55:14Z","title":"Artificial Intelligence for Operations Research: Revolutionizing the\n  Operations Research Process","summary":"  The rapid advancement of artificial intelligence (AI) techniques has opened\nup new opportunities to revolutionize various fields, including operations\nresearch (OR). This survey paper explores the integration of AI within the OR\nprocess (AI4OR) to enhance its effectiveness and efficiency across multiple\nstages, such as parameter generation, model formulation, and model\noptimization. By providing a comprehensive overview of the state-of-the-art and\nexamining the potential of AI to transform OR, this paper aims to inspire\nfurther research and innovation in the development of AI-enhanced OR methods\nand tools. The synergy between AI and OR is poised to drive significant\nadvancements and novel solutions in a multitude of domains, ultimately leading\nto more effective and efficient decision-making.\n","authors":["Zhenan Fan","Bissan Ghaddar","Xinglu Wang","Linzi Xing","Yong Zhang","Zirui Zhou"],"pdf_url":"https://arxiv.org/pdf/2401.03244v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18091v1","updated":"2024-03-26T20:22:16Z","published":"2024-03-26T20:22:16Z","title":"The Flying Sidekick Traveling Salesman Problem with Multiple Drops: A\n  Simple and Effective Heuristic Approach","summary":"  We study the Flying Sidekick Traveling Salesman Problem with Multiple Drops\n(FSTSP-MD), a multi-modal last-mile delivery model where a single truck and a\nsingle drone cooperatively deliver customer packages. In the FSTSP-MD, the\ndrone can be launched from the truck to deliver multiple packages before it\nreturns to the truck for a new delivery operation. The FSTSP-MD aims to find\nthe synchronized truck and drone delivery routes that minimize the completion\ntime of the delivery process. We develop a simple and effective heuristic\napproach based on an order-first, split-second scheme. This heuristic combines\nstandard local search and diversification techniques with a novel shortest-path\nproblem that finds FSTSP-MD solutions in polynomial time. We show that our\nheuristic consistently outperforms state-of-the-art heuristics developed for\nthe FSTSP-MD and the FSTSP (i.e., the single-drop case) through extensive\nnumerical experiments. We also show that the FSTSP-MD substantially reduces\ncompletion times compared to a traditional truck-only delivery system. Several\nmanagerial insights are described regarding the effects of drone capacity,\ndrone speed, drone flight endurance, and customer distribution.\n","authors":["Sarah K. Schaumann","Abhishake Kundu","Juan C. Pina-Pardo","Matthias Winkenbach","Ricardo A. Gatica","Stephan M. Wagner","Timothy I. Matis"],"pdf_url":"https://arxiv.org/pdf/2403.18091v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.06822v2","updated":"2024-03-26T19:39:23Z","published":"2023-08-13T17:40:56Z","title":"Approximate and Weighted Data Reconstruction Attack in Federated\n  Learning","summary":"  Federated Learning (FL) is a distributed learning paradigm that enables\nmultiple clients to collaborate on building a machine learning model without\nsharing their private data. Although FL is considered privacy-preserved by\ndesign, recent data reconstruction attacks demonstrate that an attacker can\nrecover clients' training data based on the parameters shared in FL. However,\nmost existing methods fail to attack the most widely used horizontal Federated\nAveraging (FedAvg) scenario, where clients share model parameters after\nmultiple local training steps. To tackle this issue, we propose an\ninterpolation-based approximation method, which makes attacking FedAvg\nscenarios feasible by generating the intermediate model updates of the clients'\nlocal training processes. Then, we design a layer-wise weighted loss function\nto improve the data quality of reconstruction. We assign different weights to\nmodel updates in different layers concerning the neural network structure, with\nthe weights tuned by Bayesian optimization. Finally, experimental results\nvalidate the superiority of our proposed approximate and weighted attack (AWA)\nmethod over the other state-of-the-art methods, as demonstrated by the\nsubstantial improvement in different evaluation metrics for image data\nreconstructions.\n","authors":["Yongcun Song","Ziqi Wang","Enrique Zuazua"],"pdf_url":"https://arxiv.org/pdf/2308.06822v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18044v1","updated":"2024-03-26T18:57:56Z","published":"2024-03-26T18:57:56Z","title":"Deep polytopic autoencoders for low-dimensional linear parameter-varying\n  approximations and nonlinear feedback design","summary":"  Polytopic autoencoders provide low-dimensional parametrizations of states in\na polytope. For nonlinear PDEs, this is readily applied to low-dimensional\nlinear parameter-varying (LPV) approximations as they have been exploited for\nefficient nonlinear controller design via series expansions of the solution to\nthe state-dependent Riccati equation. In this work, we develop a polytopic\nautoencoder for control applications and show how it outperforms standard\nlinear approaches in view of LPV approximations of nonlinear systems and how\nthe particular architecture enables higher order series expansions at little\nextra computational effort. We illustrate the properties and potentials of this\napproach to computational nonlinear controller design for large-scale systems\nwith a thorough numerical study.\n","authors":["Jan Heiland","Yongho Kim","Steffen W. R. Werner"],"pdf_url":"https://arxiv.org/pdf/2403.18044v1.pdf","comment":"9 pages, 6 figures, 2 tables"}],"Systems and Control":[{"id":"http://arxiv.org/abs/2403.17917v1","updated":"2024-03-26T17:54:05Z","published":"2024-03-26T17:54:05Z","title":"Multi-Agent Clarity-Aware Dynamic Coverage with Gaussian Processes","summary":"  This paper presents two algorithms for multi-agent dynamic coverage in\nspatiotemporal environments, where the coverage algorithms are informed by the\nmethod of data assimilation. In particular, we show that by considering the\ninformation assimilation algorithm, here a Numerical Gaussian Process Kalman\nFilter, the influence of measurements taken at one position on the uncertainty\nof the estimate at another location can be computed. We use this relationship\nto propose new coverage algorithms. Furthermore, we show that the controllers\nnaturally extend to the multi-agent context, allowing for a distributed-control\ncentral-information paradigm for multi-agent coverage. Finally, we demonstrate\nthe algorithms through a realistic simulation of a team of UAVs collecting wind\ndata over a region in Austria.\n","authors":["Devansh R. Agrawal","Dimitra Panagou"],"pdf_url":"https://arxiv.org/pdf/2403.17917v1.pdf","comment":"8 pages, 2 figures, submitted to CDC 2024"},{"id":"http://arxiv.org/abs/2403.17907v1","updated":"2024-03-26T17:45:48Z","published":"2024-03-26T17:45:48Z","title":"Multi-Agent Resilient Consensus under Intermittent Faulty and Malicious\n  Transmissions (Extended Version)","summary":"  In this work, we consider the consensus problem in which legitimate agents\nshare their values over an undirected communication network in the presence of\nmalicious or faulty agents. Different from the previous works, we characterize\nthe conditions that generalize to several scenarios such as intermittent faulty\nor malicious transmissions, based on trust observations. As the standard trust\naggregation approach based on a constant threshold fails to distinguish\nintermittent malicious/faulty activity, we propose a new detection algorithm\nutilizing time-varying thresholds and the random trust values available to\nlegitimate agents. Under these conditions, legitimate agents almost surely\ndetermine their trusted neighborhood correctly with geometrically decaying\nmisclassification probabilities. We further prove that the consensus process\nconverges almost surely even in the presence of malicious agents. We also\nderive the probabilistic bounds on the deviation from the nominal consensus\nvalue that would have been achieved with no malicious agents in the system.\nNumerical results verify the convergence among agents and exemplify the\ndeviation under different scenarios.\n","authors":["Sarper Aydın","Orhan Eren Akgün","Stephanie Gil","Angelia Nedić"],"pdf_url":"https://arxiv.org/pdf/2403.17907v1.pdf","comment":"Extended Version of CDC '24 submission"},{"id":"http://arxiv.org/abs/2310.00473v2","updated":"2024-03-26T17:43:01Z","published":"2023-09-30T19:32:56Z","title":"Optimal Control of Grid-Interfacing Inverters With Current Magnitude\n  Limits","summary":"  Grid-interfacing inverters act as the interface between renewable resources\nand the electric grid, and have the potential to offer fast and programmable\ncontrols compared to synchronous generators. With this flexibility there has\nbeen significant research efforts into determining the best way to control\nthese inverters. Inverters are limited in their maximum current output in order\nto protect semiconductor devices, presenting a nonlinear constraint that needs\nto be accounted for in their control algorithms. Existing approaches either\nsimply saturate a controller that is designed for unconstrained systems, or\nassume small perturbations and linearize a saturated system. These approaches\ncan lead to stability issues or limiting the control actions to be too\nconservative.\n  In this paper, we directly focus on a nonlinear system that explicitly\naccounts for the saturation of the current magnitude. We use a Lyapunov\nstability approach to determine a stability condition for the system,\nguaranteeing that a class of controllers would be stabilizing if they satisfy a\nsimple SDP condition. With this condition we fit a linear-feedback controller\nby sampling the output (offline) model predictive control problems. This\nlearned controller has improved performances with existing designs.\n","authors":["Trager Joswig-Jones","Baosen Zhang"],"pdf_url":"https://arxiv.org/pdf/2310.00473v2.pdf","comment":"6 pages, 6 figures, 1 table. Submitted to CDC'2024"},{"id":"http://arxiv.org/abs/2403.17861v1","updated":"2024-03-26T16:49:31Z","published":"2024-03-26T16:49:31Z","title":"Stealthy Deactivation of Safety Filters","summary":"  Safety filters ensure that only safe control actions are executed. We propose\na simple and stealthy false-data injection attack for deactivating such safety\nfilters; in particular, we focus on deactivating safety filters that are based\non control-barrier functions. The attack injects false sensor measurements to\nbias state estimates to the interior of a safety region, which makes the safety\nfilter accept unsafe control actions. To detect such attacks, we also propose a\ndetector that detects biases manufactured by the proposed attack policy, which\ncomplements conventional detectors when safety filters are used. The proposed\nattack policy and detector are illustrated on a double integrator example.\n","authors":["Daniel Arnström","André M. H. Teixeira"],"pdf_url":"https://arxiv.org/pdf/2403.17861v1.pdf","comment":"ECC24"},{"id":"http://arxiv.org/abs/2403.17831v1","updated":"2024-03-26T16:13:55Z","published":"2024-03-26T16:13:55Z","title":"Learning the Optimal Power Flow: Environment Design Matters","summary":"  To solve the optimal power flow (OPF) problem, reinforcement learning (RL)\nemerges as a promising new approach. However, the RL-OPF literature is strongly\ndivided regarding the exact formulation of the OPF problem as an RL\nenvironment. In this work, we collect and implement diverse environment design\ndecisions from the literature regarding training data, observation space,\nepisode definition, and reward function choice. In an experimental analysis, we\nshow the significant impact of these environment design options on RL-OPF\ntraining performance. Further, we derive some first recommendations regarding\nthe choice of these design decisions. The created environment framework is\nfully open-source and can serve as a benchmark for future research in the\nRL-OPF field.\n","authors":["Thomas Wolgast","Astrid Nieße"],"pdf_url":"https://arxiv.org/pdf/2403.17831v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.03300v4","updated":"2024-03-26T16:09:26Z","published":"2023-11-06T17:47:40Z","title":"Faster Run-to-Run Feedforward Control of Electromechanical Switching\n  Devices: a Sensitivity-Based Approach","summary":"  Electromechanical switching devices, such as solenoid valves, contactors, and\nrelays, suffer from undesirable phenomena like clicking, mechanical wear, and\ncontact bounce. Despite that, they are still widely used in industry due to\ntheir various economic and technical advantages. This has encouraged the\ndevelopment of controllers aimed at reducing the collisions that occur at the\nend of the switching operations. One of the most successful approaches has been\nthe use of iterative techniques. However, these algorithms typically require a\nlarge number of operations to converge, which is definitely a clear drawback.\nThis paper presents a strategy to improve the convergence rate of such\ncontrollers. Our proposal, which is based on the sensitivity of the control law\nwith respect to the parameters, assumes that the performance of the system is\nmore heavily affected by some parameters than others. Thus, by avoiding\nmovements in the directions that have less impact, the search algorithm is\nexpected to drive the system to near-optimal behaviors using fewer operations.\nResults obtained by simulation show significant improvement in the convergence\nrate of a state-of-the-art run-to-run feedforward controller, which\ndemonstrates the high potential of the proposal.\n","authors":["Edgar Ramirez-Laboreo","Eduardo Moya-Lasheras","Eloy Serrano-Seco"],"pdf_url":"https://arxiv.org/pdf/2311.03300v4.pdf","comment":"6 pages, 4 figures. Final version, after peer review and acceptance,\n  submitted to the 22nd European Control Conference (ECC)"},{"id":"http://arxiv.org/abs/2309.02937v2","updated":"2024-03-26T15:51:49Z","published":"2023-09-06T12:04:24Z","title":"Resilient source seeking with robot swarms","summary":"  We present a solution for locating the source, or maximum, of an unknown\nscalar field using a swarm of mobile robots. Unlike relying on the traditional\ngradient information, the swarm determines an ascending direction to approach\nthe source with arbitrary precision. The ascending direction is calculated from\nmeasurements of the field strength at the robot locations and their relative\npositions concerning the centroid. Rather than focusing on individual robots,\nwe focus the analysis on the density of robots per unit area to guarantee a\nmore resilient swarm, i.e., the functionality remains even if individuals go\nmissing or are misplaced during the mission. We reinforce the robustness of the\nalgorithm by providing sufficient conditions for the swarm shape so that the\nascending direction is almost parallel to the gradient. The swarm can respond\nto an unexpected environment by morphing its shape and exploiting the existence\nof multiple ascending directions. Finally, we validate our approach numerically\nwith hundreds of robots. The fact that a large number of robots always\ncalculate an ascending direction compensates for the loss of individuals and\nmitigates issues arising from the actuator and sensor noises.\n","authors":["Antonio Acuaviva","Jesus Bautista","Weijia Yao","Juan Jimenez","Hector Garcia de Marina"],"pdf_url":"https://arxiv.org/pdf/2309.02937v2.pdf","comment":"7 pages, submitted to CDC 2024"},{"id":"http://arxiv.org/abs/2403.17800v1","updated":"2024-03-26T15:39:59Z","published":"2024-03-26T15:39:59Z","title":"Steering Feedback in Dynamic Driving Simulators: The Influence of\n  Steering Wheel Vibration and Vehicle Motion Frequency","summary":"  The validity of the subjective evaluation of steering feedback in driving\nsimulators is crucial for modern vehicle development. Although there are\nestablished objective steering characteristics for the assessment of both\nstationary and dynamic feedback behaviour, factors such as steering wheel\nvibrations and vehicle body motion, particularly in high-frequency ranges,\npresent challenges in simulator fidelity. This work investigates the influence\nof steering wheel vibration and vehicle body motion frequency content on the\nsubjective evaluation of steering feedback during closed-loop driving in a\ndynamic driving simulator. A controlled subject study with 30 participants\nconsisting of a back-to-back comparison of a reference vehicle with an\nelectrical power steering system and three variants of its virtual\nrepresentation on a dynamic driving simulator was performed. Subjective\nevaluation focused on the representation of road feedback in comparison to the\nreference vehicle. The statistical analysis of subjective results show that\nthere is a significant influence of the frequency content of both steering\nwheel torque and vehicle motion on the subjective evaluation of steering\nfeedback in a dynamic driving simulator. The results suggest an influence of\nfrequency content on the subjective evaluation quality of steering feedback\ncharacteristics that are not associated with the dynamic feedback behaviour in\nthe context of established performance indicators.\n","authors":["Maximilian Böhle","Bernhard Schick","Steffen Müller"],"pdf_url":"https://arxiv.org/pdf/2403.17800v1.pdf","comment":"12 pages, 7 figures, 9 tables, submitted to the IEEE Transactions on\n  Intelligent Vehicles"},{"id":"http://arxiv.org/abs/2403.17793v1","updated":"2024-03-26T15:27:24Z","published":"2024-03-26T15:27:24Z","title":"Neural Exponential Stabilization of Control-affine Nonlinear Systems","summary":"  This paper proposes a novel learning-based approach for achieving exponential\nstabilization of nonlinear control-affine systems. We leverage the Control\nContraction Metrics (CCMs) framework to co-synthesize Neural Contraction\nMetrics (NCMs) and Neural Network (NN) controllers. First, we transform the\ninfinite-dimensional semi-definite program (SDP) for CCM computation into a\ntractable inequality feasibility problem using element-wise bounds of\nmatrix-valued functions. The terms in the inequality can be efficiently\ncomputed by our novel algorithms. Second, we propose a free parametrization of\nNCMs guaranteeing positive definiteness and the satisfaction of a partial\ndifferential equation, regardless of trainable parameters. Third, this\nparametrization and the inequality condition enable the design of\ncontractivity-enforcing regularizers, which can be incorporated while designing\nthe NN controller for exponential stabilization of the underlying nonlinear\nsystems. Furthermore, when the training loss goes to zero, we provide formal\nguarantees on verification of the NCM and the exponentional stabilization under\nthe NN controller. Finally, we validate our method through benchmark\nexperiments on set-point stabilization and increasing the region of attraction\nof a locally pre-stabilized closed-loop system.\n","authors":["Muhammad Zakwan","Liang Xu","Giancarlo Ferrari-Trecate"],"pdf_url":"https://arxiv.org/pdf/2403.17793v1.pdf","comment":"This paper is submitted in CDC2024 for a possible publication"},{"id":"http://arxiv.org/abs/2403.17790v1","updated":"2024-03-26T15:21:18Z","published":"2024-03-26T15:21:18Z","title":"A PAC-Bayesian Framework for Optimal Control with Stability Guarantees","summary":"  Stochastic Nonlinear Optimal Control (SNOC) involves minimizing a cost\nfunction that averages out the random uncertainties affecting the dynamics of\nnonlinear systems. For tractability reasons, this problem is typically\naddressed by minimizing an empirical cost, which represents the average cost\nacross a finite dataset of sampled disturbances. However, this approach raises\nthe challenge of quantifying the control performance against out-of-sample\nuncertainties. Particularly, in scenarios where the training dataset is small,\nSNOC policies are prone to overfitting, resulting in significant discrepancies\nbetween the empirical cost and the true cost, i.e., the average SNOC cost\nincurred during control deployment. Therefore, establishing generalization\nbounds on the true cost is crucial for ensuring reliability in real-world\napplications. In this paper, we introduce a novel approach that leverages\nPAC-Bayes theory to provide rigorous generalization bounds for SNOC. Based on\nthese bounds, we propose a new method for designing optimal controllers,\noffering a principled way to incorporate prior knowledge into the synthesis\nprocess, which aids in improving the control policy and mitigating overfitting.\nFurthermore, by leveraging recent parametrizations of stabilizing controllers\nfor nonlinear systems, our framework inherently ensures closed-loop stability.\nThe effectiveness of our proposed method in incorporating prior knowledge and\ncombating overfitting is shown by designing neural network controllers for\ntasks in cooperative robotics.\n","authors":["Mahrokh Ghoddousi Boroujeni","Clara Lucía Galimberti","Andreas Krause","Giancarlo Ferrari-Trecate"],"pdf_url":"https://arxiv.org/pdf/2403.17790v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17785v1","updated":"2024-03-26T15:17:55Z","published":"2024-03-26T15:17:55Z","title":"Neural Distributed Controllers with Port-Hamiltonian Structures","summary":"  Controlling large-scale cyber-physical systems necessitates optimal\ndistributed policies, relying solely on local real-time data and limited\ncommunication with neighboring agents. However, finding optimal controllers\nremains challenging, even in seemingly simple scenarios. Parameterizing these\npolicies using Neural Networks (NNs) can deliver good performance, but their\nsensitivity to small input changes can destabilize the closed-loop system. This\npaper addresses this issue for a network of nonlinear dissipative systems.\nSpecifically, we leverage well-established port-Hamiltonian structures to\ncharacterize deep distributed control policies with closed-loop stability\nguarantees and a finite $\\mathcal{L}_2$ gain, regardless of specific NN\nparameters. This eliminates the need to constrain the parameters during\noptimization and enables training with standard methods like stochastic\ngradient descent. A numerical study on the consensus control of Kuramoto\noscillators demonstrates the effectiveness of the proposed controllers.\n","authors":["Muhammad Zakwan","Giancarlo Ferrari-Trecate"],"pdf_url":"https://arxiv.org/pdf/2403.17785v1.pdf","comment":"This paper is submitted in CDC2024 for a possible publication"},{"id":"http://arxiv.org/abs/2403.17779v1","updated":"2024-03-26T15:12:46Z","published":"2024-03-26T15:12:46Z","title":"Optical Flow Based Detection and Tracking of Moving Objects for\n  Autonomous Vehicles","summary":"  Accurate velocity estimation of surrounding moving objects and their\ntrajectories are critical elements of perception systems in\nAutomated/Autonomous Vehicles (AVs) with a direct impact on their safety. These\nare non-trivial problems due to the diverse types and sizes of such objects and\ntheir dynamic and random behaviour. Recent point cloud based solutions often\nuse Iterative Closest Point (ICP) techniques, which are known to have certain\nlimitations. For example, their computational costs are high due to their\niterative nature, and their estimation error often deteriorates as the relative\nvelocities of the target objects increase (>2 m/sec). Motivated by such\nshortcomings, this paper first proposes a novel Detection and Tracking of\nMoving Objects (DATMO) for AVs based on an optical flow technique, which is\nproven to be computationally efficient and highly accurate for such problems.\n\\textcolor{black}{This is achieved by representing the driving scenario as a\nvector field and applying vector calculus theories to ensure spatiotemporal\ncontinuity.} We also report the results of a comprehensive performance\nevaluation of the proposed DATMO technique, carried out in this study using\nsynthetic and real-world data. The results of this study demonstrate the\nsuperiority of the proposed technique, compared to the DATMO techniques in the\nliterature, in terms of estimation accuracy and processing time in a wide range\nof relative velocities of moving objects. Finally, we evaluate and discuss the\nsensitivity of the estimation error of the proposed DATMO technique to various\nsystem and environmental parameters, as well as the relative velocities of the\nmoving objects.\n","authors":["MReza Alipour Sormoli","Mehrdad Dianati","Sajjad Mozaffari","Roger woodman"],"pdf_url":"https://arxiv.org/pdf/2403.17779v1.pdf","comment":"This manuscript has been accepted as a regular paper in Transactions\n  on Intelligent Transportation Systems (DOI: 10.1109/TITS.2024.3382495)"},{"id":"http://arxiv.org/abs/2306.02987v2","updated":"2024-03-26T14:38:44Z","published":"2023-06-05T16:00:22Z","title":"Frequency Regulation with Storage: On Losses and Profits","summary":"  Low-carbon societies will need to store vast amounts of electricity to\nbalance intermittent generation from wind and solar energy, for example,\nthrough frequency regulation. Here, we derive an analytical solution to the\ndecision-making problem of storage operators who sell frequency regulation\npower to grid operators and trade electricity on day-ahead markets.\nMathematically, we treat future frequency deviation trajectories as functional\nuncertainties in a receding horizon robust optimization problem. We constrain\nthe expected terminal state-of-charge to be equal to some target to allow\nstorage operators to make good decisions not only for the present but also the\nfuture. Thanks to this constraint, the amount of electricity traded on\nday-ahead markets is an implicit function of the regulation power sold to grid\noperators. The implicit function quantifies the amount of power that needs to\nbe purchased to cover the expected energy loss that results from providing\nfrequency regulation. We show how the marginal cost associated with the\nexpected energy loss decreases with roundtrip efficiency and increases with\nfrequency deviation dispersion. We find that the profits from frequency\nregulation over the lifetime of energy-constrained storage devices are roughly\ninversely proportional to the length of time for which regulation power must be\ncommitted.\n","authors":["Dirk Lauinger","François Vuille","Daniel Kuhn"],"pdf_url":"https://arxiv.org/pdf/2306.02987v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.02099v4","updated":"2024-03-26T14:25:52Z","published":"2023-10-30T21:52:37Z","title":"A Safe Preference Learning Approach for Personalization with\n  Applications to Autonomous Vehicles","summary":"  This work introduces a preference learning method that ensures adherence to\ngiven specifications, with an application to autonomous vehicles. Our approach\nincorporates the priority ordering of Signal Temporal Logic (STL) formulas\ndescribing traffic rules into a learning framework. By leveraging Parametric\nWeighted Signal Temporal Logic (PWSTL), we formulate the problem of\nsafety-guaranteed preference learning based on pairwise comparisons and propose\nan approach to solve this learning problem. Our approach finds a feasible\nvaluation for the weights of the given PWSTL formula such that, with these\nweights, preferred signals have weighted quantitative satisfaction measures\ngreater than their non-preferred counterparts. The feasible valuation of\nweights given by our approach leads to a weighted STL formula that can be used\nin correct-and-custom-by-construction controller synthesis. We demonstrate the\nperformance of our method with a pilot human subject study in two different\nsimulated driving scenarios involving a stop sign and a pedestrian crossing.\nOur approach yields competitive results compared to existing preference\nlearning methods in terms of capturing preferences and notably outperforms them\nwhen safety is considered.\n","authors":["Ruya Karagulle","Nikos Arechiga","Andrew Best","Jonathan DeCastro","Necmiye Ozay"],"pdf_url":"https://arxiv.org/pdf/2311.02099v4.pdf","comment":"9 pages, 3 figures, 2 tables. This work has been published at IEEE\n  Robotics and Automation Letters. Copyright may be transferred without notice,\n  after which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2403.17730v1","updated":"2024-03-26T14:19:22Z","published":"2024-03-26T14:19:22Z","title":"On Structural Non-commutativity in Affine Feedback of SISO Nonlinear\n  Systems","summary":"  The affine feedback connection of SISO nonlinear systems modeled by\nChen--Fliess series is shown to be a group action on the plant which is\nisomorphic to the semi-direct product of shuffle and additive group of\nnon-commutative formal power series. The additive and multiplicative feedback\nloops in an affine feedback connection are thus proven to be structurally\nnon-commutative. A flip in the order of these loops results in a net additive\nfeedback loop.\n","authors":["Venkatesh G. S."],"pdf_url":"https://arxiv.org/pdf/2403.17730v1.pdf","comment":"submitted to $26^{th}$ International Symposium on Mathematical Theory\n  of Networks and Systems, 2024"},{"id":"http://arxiv.org/abs/2403.17711v1","updated":"2024-03-26T13:58:21Z","published":"2024-03-26T13:58:21Z","title":"Using quantum computers in control: interval matrix properties","summary":"  Quantum computing provides a powerful framework for tackling computational\nproblems that are classically intractable. The goal of this paper is to explore\nthe use of quantum computers for solving relevant problems in systems and\ncontrol theory. In the recent literature, different quantum algorithms have\nbeen developed to tackle binary optimization, which plays an important role in\nvarious control-theoretic problems. As a prototypical example, we consider the\nverification of interval matrix properties such as non-singularity and\nstability on a quantum computer. We present a quantum algorithm solving these\nproblems and we study its performance in simulation. Our results demonstrate\nthat quantum computers provide a promising tool for control whose applicability\nto further computationally complex problems remains to be explored.\n","authors":["Jan Schneider","Julian Berberich"],"pdf_url":"https://arxiv.org/pdf/2403.17711v1.pdf","comment":"Final version, accepted for publication in Proc. European Control\n  Conference (ECC), 2024"},{"id":"http://arxiv.org/abs/2403.16488v2","updated":"2024-03-26T13:58:07Z","published":"2024-03-25T07:16:08Z","title":"Ensuring Disturbance Rejection Performance by Synthesizing\n  Grid-Following and Grid-Forming Inverters in Power Systems","summary":"  To satisfy dynamic requirements of power systems, it is imperative for\ngrid-tied inverters to ensure good disturbance rejection performance (DRP)\nunder variable grid conditions. This letter discovers and theoretically proves\nthat for general networks, synthesizing grid-following (GFL) inverters and\ngrid-forming (GFM) inverters can always more effectively ensure the DRP of\nmultiple inverters, as compared to homogeneous inverter-based systems that\nsolely utilize either GFL or GFM inverters. The synthesis of GFL inverters and\nGFM inverters can concurrently increase the smallest eigenvalue and decrease\nthe largest eigenvalue of the network grounded Laplacian matrix. This can be\nequivalent to rematching the proper short-circuit ratio (SCR) for GFL and GFM\ninverters, thereby ensuring the DRP of inverters both in weak and strong grids.\nThe results reveal the necessity of synthesizing diverse inverter control\nschemes from the network-based perspective. Sensitivity function-based tests\nand real-time simulations validate our results.\n","authors":["Fuyilong Ma","Huanhai Xin","Zhiyi Li","Linbin Huang"],"pdf_url":"https://arxiv.org/pdf/2403.16488v2.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2311.02068v2","updated":"2024-03-26T13:53:28Z","published":"2023-11-03T17:52:37Z","title":"Closing the Gap to Quadratic Invariance: a Regret Minimization Approach\n  to Optimal Distributed Control","summary":"  In this work, we focus on the design of optimal controllers that must comply\nwith an information structure. State-of-the-art approaches do so based on the\nH2 or Hinfty norm to minimize the expected or worst-case cost in the presence\nof stochastic or adversarial disturbances. Large-scale systems often experience\na combination of stochastic and deterministic disruptions (e.g., sensor\nfailures, environmental fluctuations) that spread across the system and are\ndifficult to model precisely, leading to sub-optimal closed-loop behaviors.\nHence, we propose improving performance for these scenarios by minimizing the\nregret with respect to an ideal policy that complies with less stringent\nsensor-information constraints. This endows our controller with the ability to\napproach the improved behavior of a more informed policy, which would detect\nand counteract heterogeneous and localized disturbances more promptly.\nSpecifically, we derive convex relaxations of the resulting regret minimization\nproblem that are compatible with any desired controller sparsity, while we\nreveal a renewed role of the Quadratic Invariance (QI) condition in designing\ninformative benchmarks to measure regret. Last, we validate our proposed method\nthrough numerical simulations on controlling a multi-agent distributed system,\ncomparing its performance with traditional H2 and Hinfty policies.\n","authors":["Daniele Martinelli","Andrea Martin","Giancarlo Ferrari-Trecate","Luca Furieri"],"pdf_url":"https://arxiv.org/pdf/2311.02068v2.pdf","comment":"Accepted for presentation and publication in the proceedings of the\n  2024 European Control Conference (ECC)"},{"id":"http://arxiv.org/abs/2403.17704v1","updated":"2024-03-26T13:49:48Z","published":"2024-03-26T13:49:48Z","title":"Prioritize Team Actions: Multi-Agent Temporal Logic Task Planning with\n  Ordering Constraints","summary":"  In this paper, we investigate the problem of linear temporal logic (LTL) path\nplanning for multi-agent systems, introducing the new concept of \\emph{ordering\nconstraints}. Specifically, we consider a generic objective function that is\ndefined for the path of each individual agent. The primary objective is to find\na global plan for the team of agents, ensuring they collectively meet the\nspecified LTL requirements. Simultaneously, we aim to maintain a pre-determined\norder in the values of the objective function for each agent, which we refer to\nas the ordering constraints. This new requirement stems from scenarios like\nsecurity-aware planning, where relative orders outweigh absolute values in\nimportance. We present an efficient algorithm to solve this problem, supported\nby proofs of correctness that demonstrate the optimality of our solution.\nAdditionally, we provide a case study in security-aware path planning to\nillustrate the practicality and effectiveness of our proposed approach.\n","authors":["Bowen Ye","Jianing Zhao","Shaoyuan Li","Xiang Yin"],"pdf_url":"https://arxiv.org/pdf/2403.17704v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.07039v3","updated":"2024-03-26T13:34:43Z","published":"2023-11-13T02:42:43Z","title":"Time-Optimal Control for High-Order Chain-of-Integrators Systems with\n  Full State Constraints and Arbitrary Terminal States (Extended Version)","summary":"  Time-optimal control for high-order chain-of-integrators systems with full\nstate constraints and arbitrary given terminal states remains a challenging\nproblem in the optimal control theory domain, yet to be resolved. To enhance\nfurther comprehension of the problem, this paper establishes a novel notation\nsystem and theoretical framework, providing the switching manifold for\nhigh-order problems in the form of switching laws. Through deriving properties\nof switching laws on signs and dimension, this paper proposes a definite\ncondition for time-optimal control. Guided by the developed theory, a\ntrajectory planning method named the manifold-intercept method (MIM) is\ndeveloped. The proposed MIM can plan time-optimal jerk-limited trajectories\nwith full state constraints, and can also plan near-optimal non-chattering\nhigher-order trajectories with negligible extra motion time compared to optimal\nprofiles. Numerical results indicate that the proposed MIM outperforms all\nbaselines in computational time, computational accuracy, and trajectory quality\nby a large gap.\n","authors":["Yunan Wang","Chuxiong Hu","Zeyang Li","Shize Lin","Suqin He","Ze Wang","Yu Zhu"],"pdf_url":"https://arxiv.org/pdf/2311.07039v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17675v1","updated":"2024-03-26T13:02:48Z","published":"2024-03-26T13:02:48Z","title":"Chattering Phenomena in Time-Optimal Control for High-Order\n  Chain-of-Integrators Systems with Full State Constraints","summary":"  Time-optimal control for high-order chain-of-integrators systems with full\nstate constraints and arbitrary given terminal states remains an open and\nchallenging problem in optimal control theory domain. However, optimal\ncontrol's behaviors in high-order problems lack of precision characterization,\neven where the existence of chattering phenomena remain unknown and overlooked.\nThis paper establishes a theoretical framework of chattering phenomena in the\nproblem, focusing on the uniqueness of state constraints inducing chattering,\nthe upper bound of switching times in an unconstrained arc during chattering,\nand the convergence of states and costates to the chattering limit point. For\nthe first time, this paper proves the existence of chattering phenomena in the\nproblems. The chattering optimal control for 4th order problems with velocity\nconstraints is precisely solved, providing an approach to plan strictly\ntime-optimal snap-limited trajectories, while other cases of order $n\\leq4$ are\nproved to not allow chattering. The conclusions correct the longstanding\nmisconception in the industry regarding the time-optimality of S-shaped\ntrajectories with minimal switching times.\n","authors":["Yunan Wang","Chuxiong Hu","Zeyang Li","Yujie Lin","Shize Lin","Suqin He","Yu Zhu"],"pdf_url":"https://arxiv.org/pdf/2403.17675v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.07939v2","updated":"2024-03-26T11:54:27Z","published":"2023-11-14T06:33:41Z","title":"Discretized Distributed Optimization over Dynamic Digraphs","summary":"  We consider a discrete-time model of continuous-time distributed optimization\nover dynamic directed-graphs (digraphs) with applications to distributed\nlearning. Our optimization algorithm works over general strongly connected\ndynamic networks under switching topologies, e.g., in mobile multi-agent\nsystems and volatile networks due to link failures. Compared to many existing\nlines of work, there is no need for bi-stochastic weight designs on the links.\nThe existing literature mostly needs the link weights to be stochastic using\nspecific weight-design algorithms needed both at the initialization and at all\ntimes when the topology of the network changes. This paper eliminates the need\nfor such algorithms and paves the way for distributed optimization over\ntime-varying digraphs. We derive the bound on the gradient-tracking step-size\nand discrete time-step for convergence and prove dynamic stability using\narguments from consensus algorithms, matrix perturbation theory, and Lyapunov\ntheory. This work, particularly, is an improvement over existing\nstochastic-weight undirected networks in case of link removal or packet drops.\nThis is because the existing literature may need to rerun time-consuming and\ncomputationally complex algorithms for stochastic design, while the proposed\nstrategy works as long as the underlying network is weight-symmetric and\nbalanced. The proposed optimization framework finds applications to distributed\nclassification and learning.\n","authors":["Mohammadreza Doostmohammadian","Wei Jiang","Muwahida Liaquat","Alireza Aghasi","Houman Zarrabi"],"pdf_url":"https://arxiv.org/pdf/2311.07939v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.02021v5","updated":"2024-03-26T11:41:36Z","published":"2022-09-05T15:41:13Z","title":"When Robotics Meets Wireless Communications: An Introductory Tutorial","summary":"  The importance of ground Mobile Robots (MRs) and Unmanned Aerial Vehicles\n(UAVs) within the research community, industry, and society is growing fast.\nMany of these agents are nowadays equipped with communication systems that are,\nin some cases, essential to successfully achieve certain tasks. In this\ncontext, we have begun to witness the development of a new interdisciplinary\nresearch field at the intersection of robotics and communications. This\nresearch field has been boosted by the intention of integrating UAVs within the\n5G and 6G communication networks. This research will undoubtedly lead to many\nimportant applications in the near future. Nevertheless, one of the main\nobstacles to the development of this research area is that most researchers\naddress these problems by oversimplifying either the robotics or the\ncommunications aspect. This impedes the ability of reaching the full potential\nof this new interdisciplinary research area. In this tutorial, we present some\nof the modelling tools necessary to address problems involving both robotics\nand communication from an interdisciplinary perspective. As an illustrative\nexample of such problems, we focus in this tutorial on the issue of\ncommunication-aware trajectory planning.\n","authors":["Daniel Bonilla Licea","Mounir Ghogho","Martin Saska"],"pdf_url":"https://arxiv.org/pdf/2209.02021v5.pdf","comment":"35 pages, 192 references"},{"id":"http://arxiv.org/abs/2311.03197v4","updated":"2024-03-26T11:37:38Z","published":"2023-11-06T15:39:05Z","title":"Stable Linear Subspace Identification: A Machine Learning Approach","summary":"  Machine Learning (ML) and linear System Identification (SI) have been\nhistorically developed independently. In this paper, we leverage\nwell-established ML tools - especially the automatic differentiation framework\n- to introduce SIMBa, a family of discrete linear multi-step-ahead state-space\nSI methods using backpropagation. SIMBa relies on a novel\nLinear-Matrix-Inequality-based free parametrization of Schur matrices to ensure\nthe stability of the identified model.\n  We show how SIMBa generally outperforms traditional linear state-space SI\nmethods, and sometimes significantly, although at the price of a higher\ncomputational burden. This performance gap is particularly remarkable compared\nto other SI methods with stability guarantees, where the gain is frequently\nabove 25% in our investigations, hinting at SIMBa's ability to simultaneously\nachieve state-of-the-art fitting performance and enforce stability.\nInterestingly, these observations hold for a wide variety of input-output\nsystems and on both simulated and real-world data, showcasing the flexibility\nof the proposed approach. We postulate that this new SI paradigm presents a\ngreat extension potential to identify structured nonlinear models from data,\nand we hence open-source SIMBa on https://github.com/Cemempamoi/simba.\n","authors":["Loris Di Natale","Muhammad Zakwan","Bratislav Svetozarevic","Philipp Heer","Giancarlo Ferrari-Trecate","Colin N. Jones"],"pdf_url":"https://arxiv.org/pdf/2311.03197v4.pdf","comment":"Accepted at ECC 2024"},{"id":"http://arxiv.org/abs/2403.17598v1","updated":"2024-03-26T11:09:27Z","published":"2024-03-26T11:09:27Z","title":"Ultrafast Adaptive Primary Frequency Tuning and Secondary Frequency\n  Identification for S/S WPT system","summary":"  Magnetic resonance wireless power transfer (WPT) technology is increasingly\nbeing adopted across diverse applications. However, its effectiveness can be\nsignificantly compromised by parameter shifts within the resonance network,\nowing to its high system quality factor. Such shifts are inherent and\nchallenging to mitigate during the manufacturing process. In response, this\narticle introduces a rapid frequency tuning approach. Leveraging\nswitch-controlled capacitors (SCC) to adjust the resonance network and the\nprimary side's operating frequency, alongside a current zero-crossing detection\n(ZCD) circuit for voltage-current phase determination, this method circumvents\nthe need for intricate knowledge of WPT system parameters. Moreover, it\nobviates the necessity for inter-side communication for real-time\nidentification of the secondary side resonance frequency. The swift response of\nSCC and two-step perturb-and-observe algorithm mitigate output disturbances,\nthereby expediting the frequency tuning process. Experimental validation on a\n200W Series-Series compensated WPT (SS-WPT) system demonstrates that the\nproposed method achieves frequency recognition accuracy within 0.7kHz in less\nthan 1ms, increasing system efficiency up to 9%.\n","authors":["Chang Liu","Wei Han","Guangyu Yan","Bowang Zhang","Chunlin Li"],"pdf_url":"https://arxiv.org/pdf/2403.17598v1.pdf","comment":"11 pages,16 figures,to be published in IEEE Transactions on\n  Industrial Electronics"},{"id":"http://arxiv.org/abs/2309.09012v2","updated":"2024-03-26T10:51:08Z","published":"2023-09-16T14:50:31Z","title":"Modelling Irrational Behaviour of Residential End Users using\n  Non-Stationary Gaussian Processes","summary":"  Demand response (DR) plays a critical role in ensuring efficient electricity\nconsumption and optimal use of network assets. Yet, existing DR models often\noverlook a crucial element, the irrational behaviour of electricity end users.\nIn this work, we propose a price-responsive model that incorporates key aspects\nof end-user irrationality, specifically loss aversion, time inconsistency, and\nbounded rationality. To this end, we first develop a framework that uses\nMultiple Seasonal-Trend decomposition using Loess (MSTL) and non-stationary\nGaussian processes to model the randomness in the electricity consumption by\nresidential consumers. The impact of this model is then evaluated through a\ncommunity battery storage (CBS) business model. Additionally, we apply a\nchance-constrained optimisation model for CBS operation that deals with the\nunpredictability of the end-user irrationality. Our simulations using\nreal-world data show that the proposed DR model provides a more realistic\nestimate of end-user price-responsive behaviour when considering irrationality.\nCompared to a deterministic model that cannot fully take into account the\nirrational behaviour of end users, the chance-constrained CBS operation model\nyields an additional 19% revenue. Lastly, the business model reduces the\nelectricity costs of solar end users by 11%.\n","authors":["Nam Trong Dinh","Sahand Karimi-Arpanahi","Rui Yuan","S. Ali Pourmousavi","Mingyu Guo","Jon A. R. Liisberg","Julian Lemos-Vinasco"],"pdf_url":"https://arxiv.org/pdf/2309.09012v2.pdf","comment":"This manuscript has been accepted for publication in IEEE\n  Transactions on Smart Grid"},{"id":"http://arxiv.org/abs/2403.17565v1","updated":"2024-03-26T10:19:04Z","published":"2024-03-26T10:19:04Z","title":"Aerial Robots Carrying Flexible Cables: Dynamic Shape Optimal Control\n  via Spectral Method Model","summary":"  In this work, we present a model-based optimal boundary control design for an\naerial robotic system composed of a quadrotor carrying a flexible cable. The\nwhole system is modeled by partial differential equations (PDEs) combined with\nboundary conditions described by ordinary differential equations (ODEs). The\nproper orthogonal decomposition (POD) method is adopted to project the original\ninfinite-dimensional system on a subspace spanned by orthogonal basis\nfunctions. Based on the reduced order model, nonlinear model predictive control\n(NMPC) is implemented online to realize shape trajectory tracking of the\nflexible cable in an optimal predictive fashion. The proposed reduced modeling\nand optimal control paradigms are numerically verified against an accurate\nhigh-dimensional FDM-based model in different scenarios and the controller's\nsuperior performance is shown compared to an optimally tuned PID controller.\n","authors":["Yaolei Shen","Chiara Gabellieri","Antonio Franchi"],"pdf_url":"https://arxiv.org/pdf/2403.17565v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17554v1","updated":"2024-03-26T10:01:13Z","published":"2024-03-26T10:01:13Z","title":"Robust Stability for Multiagent Systems with Spatio-Temporally\n  Correlated Packet Loss","summary":"  A problem with considering correlations in the analysis of multiagent system\nwith stochastic packet loss is that they induce dependencies between agents\nthat are otherwise decoupled, preventing the application of decomposition\nmethods required for efficient evaluation. To circumvent that issue, this paper\nis proposing an approach based on analysing sets of networks with independent\ncommunication links, only considering the correlations in an implicit fashion.\nCombining ideas from the robust stabilization of Markov jump linear systems\nwith recently proposed techniques for analysing packet loss in multiagent\nsystems, we obtain a linear matrix inequality based stability condition which\nis independent of the number of agents. The main result is that the set of\nstabilized probability distributions has non-empty interior such that small\ncorrelations cannot lead to instability, even though only distributions of\nindependent links were analysed. Moreover, two examples are provided to\ndemonstrate the applicability of the results to practically relevant scenarios.\n","authors":["Christian Hespe","Adwait Datar","Herbert Werner"],"pdf_url":"https://arxiv.org/pdf/2403.17554v1.pdf","comment":"7 pages, 2 figures, 1 table"},{"id":"http://arxiv.org/abs/2011.07529v3","updated":"2024-03-26T08:54:31Z","published":"2020-11-15T13:40:21Z","title":"Full Attitude Intelligent Controller Design of a Heliquad under Complete\n  Failure of an Actuator","summary":"  In this paper, we design a reliable Heliquad and develop an intelligent\ncontroller to handle one actuators complete failure. Heliquad is a multi-copter\nsimilar to Quadcopter, with four actuators diagonally symmetric from the\ncenter. Each actuator has two control inputs; the first input changes the\npropeller blades collective pitch (also called variable pitch), and the other\ninput changes the rotation speed. For reliable operation and high torque\ncharacteristic requirement for yaw control, a cambered airfoil is used to\ndesign propeller blades. A neural network-based control allocation is designed\nto provide complete control authority even under a complete loss of one\nactuator. Nonlinear quaternion based outer loop position control, with\nproportional-derivative inner loop for attitude control and neural\nnetwork-based control allocation is used in controller design. The proposed\ncontroller and Heliquad designs performance is evaluated using a\nsoftware-in-loop simulation to track the position reference command under\nfailure. The results clearly indicate that the Heliquad with an intelligent\ncontroller provides necessary tracking performance even under a complete loss\nof one actuator.\n","authors":["Eeshan Kulkarni","Suresh Sundaram"],"pdf_url":"https://arxiv.org/pdf/2011.07529v3.pdf","comment":"7 pages, For video go to\n  https://indianinstituteofscience-my.sharepoint.com/:v:/g/personal/eeshank_iisc_ac_in/EcMg2uTtE91AsHDejNkb6YMBNckaXGjeh_YMzDV6sAHZAQ?e=DrRqmN"},{"id":"http://arxiv.org/abs/2304.02444v2","updated":"2024-03-26T08:13:01Z","published":"2023-04-05T14:02:53Z","title":"Autonomous Hook-Based Grasping and Transportation with Quadcopters","summary":"  Payload grasping and transportation with quadcopters is an active research\narea that has rapidly developed over the last decade. To grasp a payload\nwithout human interaction, most state-of-the-art approaches apply robotic arms\nthat are attached to the quadcopter body. However, due to the large weight and\npower consumption of these aerial manipulators, their agility and flight time\nare limited. This paper proposes a motion control and planning method for\ntransportation with a lightweight, passive manipulator structure that consists\nof a hook attached to a quadrotor using a 1 DoF revolute joint. To perform\npayload grasping, transportation, and release, first, time-optimal reference\ntrajectories are designed through specific waypoints to ensure the fast and\nreliable execution of the tasks. Then, a two-stage motion control approach is\ndeveloped based on a robust geometric controller for precise and reliable\nreference tracking and a linear--quadratic payload regulator for rapid setpoint\nstabilization of the payload swing. Furthermore, stability of the closed-loop\nsystem is mathematically proven to give safety guarantee for its operation. The\nproposed control architecture and design are evaluated in a high-fidelity\nphysical simulator, and also in real flight experiments, using a custom-made\nquadrotor--hook manipulator platform.\n","authors":["Péter Antal","Tamás Péni","Roland Tóth"],"pdf_url":"https://arxiv.org/pdf/2304.02444v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.07658v3","updated":"2024-03-26T08:01:29Z","published":"2024-01-15T13:00:35Z","title":"Robustness Evaluation of Localization Techniques for Autonomous Racing","summary":"  This work introduces SynPF, an MCL-based algorithm tailored for high-speed\nracing environments. Benchmarked against Cartographer, a state-of-the-art\npose-graph SLAM algorithm, SynPF leverages synergies from previous\nparticle-filtering methods and synthesizes them for the high-performance racing\ndomain. Our extensive in-field evaluations reveal that while Cartographer\nexcels under nominal conditions, it struggles when subjected to wheel-slip, a\ncommon phenomenon in a racing scenario due to varying grip levels and\naggressive driving behaviour. Conversely, SynPF demonstrates robustness in\nthese challenging conditions and a low-latency computation time of 1.25 ms on\non-board computers without a GPU. Using the F1TENTH platform, a 1:10 scaled\nautonomous racing vehicle, this work not only highlights the vulnerabilities of\nexisting algorithms in high-speed scenarios, tested up until 7.6 m/s, but also\nemphasizes the potential of SynPF as a viable alternative, especially in\ndeteriorating odometry conditions.\n","authors":["Tian Yi Lim","Edoardo Ghignone","Nicolas Baumann","Michele Magno"],"pdf_url":"https://arxiv.org/pdf/2401.07658v3.pdf","comment":"Accepted at the Design, Automation and Test in Europe Conference 2024\n  as an extended abstract"},{"id":"http://arxiv.org/abs/2403.17417v1","updated":"2024-03-26T06:14:58Z","published":"2024-03-26T06:14:58Z","title":"Cyclic pursuit formation control for arbitrary desired shapes","summary":"  A multi-agent system comprises numerous agents that autonomously make\ndecisions to collectively accomplish tasks, drawing significant attention for\ntheir wide-ranging applications. Within this context, formation control emerges\nas a prominent task, wherein agents collaboratively shape and maneuver while\npreserving formation integrity. Our focus centers on cyclic pursuit, a method\nfacilitating the formation of circles, ellipses, and figure-eights under the\nassumption that agents can only perceive the relative positions of those\npreceding them. However, this method's scope has been restricted to these\nspecific shapes, leaving the feasibility of forming other shapes uncertain. In\nresponse, our study proposes a novel method based on cyclic pursuit capable of\nforming a broader array of shapes, enabling agents to individually shape while\npursuing preceding agents, thereby extending the repertoire of achievable\nformations. We present two scenarios concerning the information available to\nagents and devise formation control methods tailored to each scenario. Through\nextensive simulations, we demonstrate the efficacy of our proposed method in\nforming multiple shapes, including those represented as Fourier series, thereby\nunderscoring the versatility and effectiveness of our approach.\n","authors":["Anna Fujioka","Masaki Ogura","Naoki Wakamiya"],"pdf_url":"https://arxiv.org/pdf/2403.17417v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17392v1","updated":"2024-03-26T05:23:12Z","published":"2024-03-26T05:23:12Z","title":"Natural-artificial hybrid swarm: Cyborg-insect group navigation in\n  unknown obstructed soft terrain","summary":"  Navigating multi-robot systems in complex terrains has always been a\nchallenging task. This is due to the inherent limitations of traditional robots\nin collision avoidance, adaptation to unknown environments, and sustained\nenergy efficiency. In order to overcome these limitations, this research\nproposes a solution by integrating living insects with miniature electronic\ncontrollers to enable robotic-like programmable control, and proposing a novel\ncontrol algorithm for swarming. Although these creatures, called cyborg\ninsects, have the ability to instinctively avoid collisions with neighbors and\nobstacles while adapting to complex terrains, there is a lack of literature on\nthe control of multi-cyborg systems. This research gap is due to the difficulty\nin coordinating the movements of a cyborg system under the presence of insects'\ninherent individual variability in their reactions to control input. In\nresponse to this issue, we propose a novel swarm navigation algorithm\naddressing these challenges. The effectiveness of the algorithm is demonstrated\nthrough an experimental validation in which a cyborg swarm was successfully\nnavigated through an unknown sandy field with obstacles and hills. This\nresearch contributes to the domain of swarm robotics and showcases the\npotential of integrating biological organisms with robotics and control theory\nto create more intelligent autonomous systems with real-world applications.\n","authors":["Yang Bai","Phuoc Thanh Tran Ngoc","Huu Duoc Nguyen","Duc Long Le","Quang Huy Ha","Kazuki Kai","Yu Xiang See To","Yaosheng Deng","Jie Song","Naoki Wakamiya","Hirotaka Sato","Masaki Ogura"],"pdf_url":"https://arxiv.org/pdf/2403.17392v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17391v1","updated":"2024-03-26T05:21:17Z","published":"2024-03-26T05:21:17Z","title":"Reverse Kron reduction of Multi-phase Radial Network","summary":"  We consider the problem of identifying the admittance matrix of a three-phase\nradial network from voltage and current measurements at a subset of nodes.\nThese measurements are used to estimate a virtual network represented by the\nKron reduction (Schur complement) of the full admittance matrix. We focus on\nrecovering exactly the full admittance matrix from its Kron reduction, i.e.,\ncomputing the inverse of Schur complement. The key idea is to decompose Kron\nreduction into a sequence of iterations that maintains an invariance structure,\nand exploit this structure to reverse each step of the iterative Kron\nreduction.\n","authors":["Steven H. Low"],"pdf_url":"https://arxiv.org/pdf/2403.17391v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13923v3","updated":"2024-03-26T04:36:59Z","published":"2024-03-20T18:53:22Z","title":"Credit vs. Discount-Based Congestion Pricing: A Comparison Study","summary":"  Tolling, or congestion pricing, offers a promising traffic management policy\nfor regulating congestion, but has also attracted criticism for placing\noutsized financial burdens on low-income users. Credit-based congestion pricing\n(CBCP) and discount-based congestion pricing (DBCP) policies, which\nrespectively provide travel credits and toll discounts to low-income users on\ntolled roads, have emerged as promising mechanisms for reducing traffic\ncongestion without worsening societal inequities. However, the optimal design\nof CBCP and DBCP policies, as well as their relative advantages and\ndisadvantages, remain poorly understood. To address this, we study the effects\nof implementing CBCP and DBCP policies to route users on a network of\nmulti-lane highways with tolled express lanes. We formulate a non-atomic\nrouting game framework in which a subset of eligible users is granted toll\nrelief in the form of a fixed budget or toll discount, while the remaining\nineligible users must pay out-of-pocket. We prove the existence of Nash\nequilibrium traffic flow patterns corresponding to any given CBCP or DBCP\npolicy. Under the additional assumption that eligible users have time-invariant\nVoTs, we provide a convex program to efficiently compute these equilibria. For\nnetworks consisting of a single edge, we identify conditions under which CBCP\npolicies outperform DBCP policies (and vice versa), in the sense of improving\neligible users' access to the express lane. Finally, we present empirical\nresults from a CBCP pilot study of the San Mateo 101 Express Lane Project in\nCalifornia. Our empirical results corroborate our theoretical analysis of the\nimpact of deploying credit-based and discount-based policies, and lend insights\ninto the sensitivity of their impact with respect to the travel demand and\nusers' VoTs.\n","authors":["Chih-Yuan Chiu","Devansh Jalota","Marco Pavone"],"pdf_url":"https://arxiv.org/pdf/2403.13923v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17364v1","updated":"2024-03-26T04:02:09Z","published":"2024-03-26T04:02:09Z","title":"A Moreau Envelope Approach for LQR Meta-Policy Estimation","summary":"  We study the problem of policy estimation for the Linear Quadratic Regulator\n(LQR) in discrete-time linear time-invariant uncertain dynamical systems. We\npropose a Moreau Envelope-based surrogate LQR cost, built from a finite set of\nrealizations of the uncertain system, to define a meta-policy efficiently\nadjustable to new realizations. Moreover, we design an algorithm to find an\napproximate first-order stationary point of the meta-LQR cost function.\nNumerical results show that the proposed approach outperforms naive averaging\nof controllers on new realizations of the linear system. We also provide\nempirical evidence that our method has better sample complexity than\nModel-Agnostic Meta-Learning (MAML) approaches.\n","authors":["Ashwin Aravind","Mohammad Taha Toghani","César A. Uribe"],"pdf_url":"https://arxiv.org/pdf/2403.17364v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2306.02107v2","updated":"2024-03-26T03:45:05Z","published":"2023-06-03T13:14:36Z","title":"Achievable Sum Rate Optimization on NOMA-aided Cell-Free Massive MIMO\n  with Finite Blocklength Coding","summary":"  Non-orthogonal multiple access (NOMA)-aided cell-free massive multiple-input\nmultiple-output (CFmMIMO) has been considered as a promising technology to\nfulfill strict quality of service requirements for ultra-reliable low-latency\ncommunications (URLLC). However, finite blocklength coding (FBC) in URLLC makes\nit challenging to achieve the optimal performance in the NOMA-aided CFmMIMO\nsystem. In this paper, we investigate the performance of the NOMA-aided CFmMIMO\nsystem with FBC in terms of achievable sum rate (ASR). Firstly, we derive a\nlower bound (LB) on the ergodic data rate. Then, we formulate an ASR\nmaximization problem by jointly considering power allocation and user equipment\n(UE) clustering. To tackle such an intractable problem, we decompose it into\ntwo sub-problems, i.e., the power allocation problem and the UE clustering\nproblem. A successive convex approximation (SCA) algorithm is proposed to solve\nthe power allocation problem by transforming it into a series of geometric\nprogramming problems. Meanwhile, two algorithms based on graph theory are\nproposed to solve the UE clustering problem by identifying negative loops.\nFinally, alternative optimization is performed to find the maximum ASR of the\nNOMA-aided CFmMIMO system with FBC. The simulation results demonstrate that the\nproposed algorithms significantly outperform the benchmark algorithms in terms\nof ASR under various scenarios.\n","authors":["Baolin Chong","Hancheng Lu","Yuang Chen","Langtian Qin","Fengqian Guo"],"pdf_url":"https://arxiv.org/pdf/2306.02107v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17338v1","updated":"2024-03-26T02:49:08Z","published":"2024-03-26T02:49:08Z","title":"Reinforcement Learning-based Receding Horizon Control using Adaptive\n  Control Barrier Functions for Safety-Critical Systems","summary":"  Optimal control methods provide solutions to safety-critical problems but\neasily become intractable. Control Barrier Functions (CBFs) have emerged as a\npopular technique that facilitates their solution by provably guaranteeing\nsafety, through their forward invariance property, at the expense of some\nperformance loss. This approach involves defining a performance objective\nalongside CBF-based safety constraints that must always be enforced.\nUnfortunately, both performance and solution feasibility can be significantly\nimpacted by two key factors: (i) the selection of the cost function and\nassociated parameters, and (ii) the calibration of parameters within the\nCBF-based constraints, which capture the trade-off between performance and\nconservativeness. %as well as infeasibility. To address these challenges, we\npropose a Reinforcement Learning (RL)-based Receding Horizon Control (RHC)\napproach leveraging Model Predictive Control (MPC) with CBFs (MPC-CBF). In\nparticular, we parameterize our controller and use bilevel optimization, where\nRL is used to learn the optimal parameters while MPC computes the optimal\ncontrol input. We validate our method by applying it to the challenging\nautomated merging control problem for Connected and Automated Vehicles (CAVs)\nat conflicting roadways. Results demonstrate improved performance and a\nsignificant reduction in the number of infeasible cases compared to traditional\nheuristic approaches used for tuning CBF-based controllers, showcasing the\neffectiveness of the proposed method.\n","authors":["Ehsan Sabouni","H. M. Sabbir Ahmad","Vittorio Giammarino","Christos G. Cassandras","Ioannis Ch. Paschalidis","Wenchao Li"],"pdf_url":"https://arxiv.org/pdf/2403.17338v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17337v1","updated":"2024-03-26T02:48:52Z","published":"2024-03-26T02:48:52Z","title":"Destination-Constrained Linear Dynamical System Modeling in Set-Valued\n  Frameworks","summary":"  Directional motion towards a specified destination is a common occurrence in\nphysical processes and human societal activities. Utilizing this prior\ninformation can significantly improve the control and predictive performance of\nsystem models. This paper primarily focuses on reconstructing linear dynamic\nsystem models based on destination constraints in the set-valued framework. We\ntreat destination constraints as inherent information in the state evolution\nprocess and employ convex optimization techniques to construct a coherent and\nrobust state model. This refined model effectively captures the impact of\ndestination constraints on the state evolution at each time step. Furthermore,\nwe design an optimal weight matrix for the reconstructed model to ensure\nsmoother and more natural trajectories of state evolution. We also analyze the\ntheoretical guarantee of optimality for this weight matrix and the properties\nof the reconstructed model. Finally, simulation experiments verify that the\nreconstructed model has significant advantages over the unconstrained and\nunoptimized weighted models and constrains the evolution of state trajectories\nwith different starting and ending points.\n","authors":["Xiaowei Yang","Haiqi Liu","Fanqin Meng","Xiaojing Shen"],"pdf_url":"https://arxiv.org/pdf/2403.17337v1.pdf","comment":"15 pages, 11 figures"},{"id":"http://arxiv.org/abs/2403.18149v1","updated":"2024-03-26T23:17:05Z","published":"2024-03-26T23:17:05Z","title":"Code Generation for Conic Model-Predictive Control on Microcontrollers\n  with TinyMPC","summary":"  Conic constraints appear in many important control applications like legged\nlocomotion, robotic manipulation, and autonomous rocket landing. However,\ncurrent solvers for conic optimization problems have relatively heavy\ncomputational demands in terms of both floating-point operations and memory\nfootprint, making them impractical for use on small embedded devices. We extend\nTinyMPC, an open-source, high-speed solver targeting low-power embedded control\napplications, to handle second-order cone constraints. We also present\ncode-generation software to enable deployment of TinyMPC on a variety of\nmicrocontrollers. We benchmark our generated code against state-of-the-art\nembedded QP and SOCP solvers, demonstrating a two-order-of-magnitude speed\nincrease over ECOS while consuming less memory. Finally, we demonstrate\nTinyMPC's efficacy on the Crazyflie, a lightweight, resource-constrained\nquadrotor with fast dynamics. TinyMPC and its code-generation tools are\npublicly available at https://tinympc.org.\n","authors":["Sam Schoedel","Khai Nguyen","Elakhya Nedumaran","Brian Plancher","Zachary Manchester"],"pdf_url":"https://arxiv.org/pdf/2403.18149v1.pdf","comment":"Submitted to CDC, 2024. First two authors contributed equally"},{"id":"http://arxiv.org/abs/2403.18119v1","updated":"2024-03-26T21:50:09Z","published":"2024-03-26T21:50:09Z","title":"Multiple Model Reference Adaptive Control with Blending for Non-Square\n  Multivariable Systems","summary":"  In this paper we develop a multiple model reference adaptive controller\n(MMRAC) with blending. The systems under consideration are non-square, i.e.,\nthe number of inputs is not equal to the number of states; multi-input, linear,\ntime-invariant with uncertain parameters that lie inside of a known, compact,\nand convex set. Moreover, the full state of the plant is available for\nfeedback. A multiple model online identification scheme for the plant's state\nand input matrices is developed that guarantees the estimated parameters\nconverge to the underlying plant model under the assumption of persistence of\nexcitation. Using an exact matching condition, the parameter estimates are used\nin a control law such that the plant's states asymptotically track the\nreference signal generated by a state-space model reference. The control\narchitecture is proven to provide boundedness of all closed-loop signals and to\nasymptotically drive the state tracking error to zero. Numerical simulations\nillustrate the stability and efficacy of the proposed MMRAC scheme.\n","authors":["Alex Lovi","Baris Fidan","Christopher Nielsen"],"pdf_url":"https://arxiv.org/pdf/2403.18119v1.pdf","comment":"10 pages, 7 figures, IEEE Journal Submission"},{"id":"http://arxiv.org/abs/2403.18085v1","updated":"2024-03-26T20:15:30Z","published":"2024-03-26T20:15:30Z","title":"ANOCA: AC Network-aware Optimal Curtailment Approach for Dynamic Hosting\n  Capacity","summary":"  With exponential growth in distributed energy resources (DERs) coupled with\nat-capacity distribution grid infrastructure, prosumers cannot always export\nall extra power to the grid without violating technical limits. Consequently, a\nslew of dynamic hosting capacity (DHC) algorithms have emerged for optimal\nutilization of grid infrastructure while maximizing export from DERs. Most of\nthese DHC algorithms utilize the concept of operating envelopes (OE)}, where\nthe utility gives prosumers technical power export limits, and they are free to\nexport power within these limits. Recent studies have shown that OE-based\nframeworks have drawbacks, as most develop power export limits based on convex\nor linear grid models. As OEs must capture extreme operating conditions, both\nconvex and linear models can violate technical limits in practice because they\napproximate grid physics. However, AC models are unsuitable because they may\nnot be feasible within the whole region of OE. We propose a new two-stage\noptimization framework for DHC built on three-phase AC models to address the\ncurrent gaps. In this approach, the prosumers first run a receding horizon\nmulti-period optimization to identify optimal export power setpoints to\ncommunicate with the utility. The utility then performs an infeasibility-based\noptimization to either accept the prosumer's request or dispatch an optimal\ncurtail signal such that overall system technical constraints are not violated.\nTo explore various curtailment strategies, we develop an L1, L2, and Linf\nnorm-based dispatch algorithm with an exact three-phase AC model. We test our\nframework on a 1420 three-phase node meshed distribution network and show that\nthe proposed algorithm optimally curtails DERs while guaranteeing the AC\nfeasibility of the network.\n","authors":["Emmanuel O. Badmus","Amritanshu Pandey"],"pdf_url":"https://arxiv.org/pdf/2403.18085v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18071v1","updated":"2024-03-26T19:49:40Z","published":"2024-03-26T19:49:40Z","title":"From Sontag s to Cardano-Lyapunov Formula for Systems Not Affine in the\n  Control: Convection-Enabled PDE Stabilization","summary":"  We propose the first generalization of Sontag s universal controller to\nsystems not affine in the control, particularly, to PDEs with boundary\nactuation. We assume that the system admits a control Lyapunov function (CLF)\nwhose derivative, rather than being affine in the control, has either a\ndepressed cubic, quadratic, or depressed quartic dependence on the control. For\neach case, a continuous universal controller that vanishes at the origin and\nachieves global exponential stability is derived. We prove our result in the\ncontext of convectionreaction-diffusion PDEs with Dirichlet actuation. We show\nthat if the convection has a certain structure, then the L2 norm of the state\nis a CLF. In addition to generalizing Sontag s formula to some non-affine\nsystems, we present the first general Lyapunov approach for boundary control of\nnonlinear PDEs. We illustrate our results via a numerical example.\n","authors":["Mohamed Camil Belhadjoudja","Miroslav Krstic","Mohamed Maghenem","Emmanuel Witrant"],"pdf_url":"https://arxiv.org/pdf/2403.18071v1.pdf","comment":"To be presented at the 2024 American Control Conference"},{"id":"http://arxiv.org/abs/2312.10842v2","updated":"2024-03-26T19:45:15Z","published":"2023-12-17T23:20:51Z","title":"Compositional Inductive Invariant Based Verification of Neural Network\n  Controlled Systems","summary":"  The integration of neural networks into safety-critical systems has shown\ngreat potential in recent years. However, the challenge of effectively\nverifying the safety of Neural Network Controlled Systems (NNCS) persists. This\npaper introduces a novel approach to NNCS safety verification, leveraging the\ninductive invariant method. Verifying the inductiveness of a candidate\ninductive invariant in the context of NNCS is hard because of the scale and\nnonlinearity of neural networks. Our compositional method makes this\nverification process manageable by decomposing the inductiveness proof\nobligation into smaller, more tractable subproblems. Alongside the high-level\nmethod, we present an algorithm capable of automatically verifying the\ninductiveness of given candidates by automatically inferring the necessary\ndecomposition predicates. The algorithm significantly outperforms the baseline\nmethod and shows remarkable reductions in execution time in our case studies,\nshortening the verification time from hours (or timeout) to seconds.\n","authors":["Yuhao Zhou","Stavros Tripakis"],"pdf_url":"https://arxiv.org/pdf/2312.10842v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18066v1","updated":"2024-03-26T19:35:22Z","published":"2024-03-26T19:35:22Z","title":"Path Integral Control with Rollout Clustering and Dynamic Obstacles","summary":"  Model Predictive Path Integral (MPPI) control has proven to be a powerful\ntool for the control of uncertain systems (such as systems subject to\ndisturbances and systems with unmodeled dynamics). One important limitation of\nthe baseline MPPI algorithm is that it does not utilize simulated trajectories\nto their fullest extent. For one, it assumes that the average of all\ntrajectories weighted by their performance index will be a safe trajectory. In\nthis paper, multiple examples are shown where the previous assumption does not\nhold, and a trajectory clustering technique is presented that reduces the\nchances of the weighted average crossing in an unsafe region. Secondly, MPPI\ndoes not account for dynamic obstacles, so the authors put forward a novel cost\nfunction that accounts for dynamic obstacles without adding significant\ncomputation time to the overall algorithm. The novel contributions proposed in\nthis paper were evaluated with extensive simulations to demonstrate\nimprovements upon the state-of-the-art MPPI techniques.\n","authors":["Steven Patrick","Efstathios Bakolas"],"pdf_url":"https://arxiv.org/pdf/2403.18066v1.pdf","comment":"8 pages, 5 figures, extended version of ACC 2024 submission"},{"id":"http://arxiv.org/abs/2403.18055v1","updated":"2024-03-26T19:17:03Z","published":"2024-03-26T19:17:03Z","title":"Adaptive Boundary Control of the Kuramoto-Sivashinsky Equation Under\n  Intermittent Sensing","summary":"  We study in this paper boundary stabilization, in the L2 sense, of the\none-dimensional Kuramoto-Sivashinsky equation subject to intermittent sensing.\nWe assume that we measure the state of this spatio-temporal equation on a given\nspatial subdomain during certain intervals of time, while we measure the state\non the remaining spatial subdomain during the remaining intervals of time. As a\nresult, we assign a feedback law at the boundary of the spatial domain and\nforce to zero the value of the state at the junction of the two subdomains.\nThroughout the study, the destabilizing coefficient is assumed to be\nspace-dependent and bounded but unknown. Adaptive boundary controllers are\ndesigned under different assumptions on the forcing term. In particular, when\nthe forcing term is null, we guarantee global exponential stability of the\norigin. Furthermore, when the forcing term is bounded and admits a known upper\nbound, we guarantee input-to-state stability, and only global uniform ultimate\nboundedness is guaranteed when the upper bound is unknown. Numerical\nsimulations are performed to illustrate our results\n","authors":["Mohamed Camil Belhadjoudja","Mohamed Maghenem","Emmanuel Witrant","Christophe Prieur"],"pdf_url":"https://arxiv.org/pdf/2403.18055v1.pdf","comment":"Submitted to Automatica"},{"id":"http://arxiv.org/abs/2403.18041v1","updated":"2024-03-26T18:52:50Z","published":"2024-03-26T18:52:50Z","title":"Learning Piecewise Residuals of Control Barrier Functions for Safety of\n  Switching Systems using Multi-Output Gaussian Processes","summary":"  Control barrier functions (CBFs) have recently been introduced as a\nsystematic tool to ensure safety by establishing set invariance. When combined\nwith a control Lyapunov function (CLF), they form a safety-critical control\nmechanism. However, the effectiveness of CBFs and CLFs is closely tied to the\nsystem model. In practice, model uncertainty can jeopardize safety and\nstability guarantees and may lead to undesirable performance. In this paper, we\ndevelop a safe learning-based control strategy for switching systems in the\nface of uncertainty. We focus on the case that a nominal model is available for\na true underlying switching system. This uncertainty results in piecewise\nresiduals for each switching surface, impacting the CLF and CBF constraints. We\nintroduce a batch multi-output Gaussian process (MOGP) framework to approximate\nthese piecewise residuals, thereby mitigating the adverse effects of\nuncertainty. A particular structure of the covariance function enables us to\nconvert the MOGP-based chance constraints CLF and CBF into second-order cone\nconstraints, which leads to a convex optimization. We analyze the feasibility\nof the resulting optimization and provide the necessary and sufficient\nconditions for feasibility. The effectiveness of the proposed strategy is\nvalidated through a simulation of a switching adaptive cruise control system.\n","authors":["Mohammad Aali","Jun Liu"],"pdf_url":"https://arxiv.org/pdf/2403.18041v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2403.09573"},{"id":"http://arxiv.org/abs/2403.18015v1","updated":"2024-03-26T18:04:10Z","published":"2024-03-26T18:04:10Z","title":"A Constructive Method for Designing Safe Multirate Controllers for\n  Differentially-Flat Systems","summary":"  We present a multi-rate control architecture that leverages fundamental\nproperties of differential flatness to synthesize controllers for\nsafety-critical nonlinear dynamical systems. We propose a two-layer\narchitecture, where the high-level generates reference trajectories using a\nlinear Model Predictive Controller, and the low-level tracks this reference\nusing a feedback controller. The novelty lies in how we couple these layers, to\nachieve formal guarantees on recursive feasibility of the MPC problem, and\nsafety of the nonlinear system. Furthermore, using differential flatness, we\nprovide a constructive means to synthesize the multi-rate controller, thereby\nremoving the need to search for suitable Lyapunov or barrier functions, or to\napproximately linearize/discretize nonlinear dynamics. We show the synthesized\ncontroller is a convex optimization problem, making it amenable to real-time\nimplementations. The method is demonstrated experimentally on a ground rover\nand a quadruped robotic system.\n","authors":["Devansh R. Agrawal","Hardik Parwana","Ryan K. Cosner","Ugo Rosolia","Aaron D. Ames","Dimitra Panagou"],"pdf_url":"https://arxiv.org/pdf/2403.18015v1.pdf","comment":"6 pages, 3 figures, accepted at IEEE Control Systems Letters 2021"}]},"2024-03-27T00:00:00Z":{"Robotics":[{"id":"http://arxiv.org/abs/2403.18778v1","updated":"2024-03-27T17:26:42Z","published":"2024-03-27T17:26:42Z","title":"3P-LLM: Probabilistic Path Planning using Large Language Model for\n  Autonomous Robot Navigation","summary":"  Much worldly semantic knowledge can be encoded in large language models\n(LLMs). Such information could be of great use to robots that want to carry out\nhigh-level, temporally extended commands stated in natural language. However,\nthe lack of real-world experience that language models have is a key limitation\nthat makes it challenging to use them for decision-making inside a particular\nembodiment. This research assesses the feasibility of using LLM (GPT-3.5-turbo\nchatbot by OpenAI) for robotic path planning. The shortcomings of conventional\napproaches to managing complex environments and developing trustworthy plans\nfor shifting environmental conditions serve as the driving force behind the\nresearch. Due to the sophisticated natural language processing abilities of\nLLM, the capacity to provide effective and adaptive path-planning algorithms in\nreal-time, great accuracy, and few-shot learning capabilities, GPT-3.5-turbo is\nwell suited for path planning in robotics. In numerous simulated scenarios, the\nresearch compares the performance of GPT-3.5-turbo with that of\nstate-of-the-art path planners like Rapidly Exploring Random Tree (RRT) and A*.\nWe observed that GPT-3.5-turbo is able to provide real-time path planning\nfeedback to the robot and outperforms its counterparts. This paper establishes\nthe foundation for LLM-powered path planning for robotic systems.\n","authors":["Ehsan Latif"],"pdf_url":"https://arxiv.org/pdf/2403.18778v1.pdf","comment":"Exploratory Study"},{"id":"http://arxiv.org/abs/2403.18765v1","updated":"2024-03-27T17:03:31Z","published":"2024-03-27T17:03:31Z","title":"CaT: Constraints as Terminations for Legged Locomotion Reinforcement\n  Learning","summary":"  Deep Reinforcement Learning (RL) has demonstrated impressive results in\nsolving complex robotic tasks such as quadruped locomotion. Yet, current\nsolvers fail to produce efficient policies respecting hard constraints. In this\nwork, we advocate for integrating constraints into robot learning and present\nConstraints as Terminations (CaT), a novel constrained RL algorithm. Departing\nfrom classical constrained RL formulations, we reformulate constraints through\nstochastic terminations during policy learning: any violation of a constraint\ntriggers a probability of terminating potential future rewards the RL agent\ncould attain. We propose an algorithmic approach to this formulation, by\nminimally modifying widely used off-the-shelf RL algorithms in robot learning\n(such as Proximal Policy Optimization). Our approach leads to excellent\nconstraint adherence without introducing undue complexity and computational\noverhead, thus mitigating barriers to broader adoption. Through empirical\nevaluation on the real quadruped robot Solo crossing challenging obstacles, we\ndemonstrate that CaT provides a compelling solution for incorporating\nconstraints into RL frameworks. Videos and code are available at\nhttps://constraints-as-terminations.github.io.\n","authors":["Elliot Chane-Sane","Pierre-Alexandre Leziart","Thomas Flayols","Olivier Stasse","Philippe Souères","Nicolas Mansard"],"pdf_url":"https://arxiv.org/pdf/2403.18765v1.pdf","comment":"Project webpage: https://constraints-as-terminations.github.io"},{"id":"http://arxiv.org/abs/2403.18764v1","updated":"2024-03-27T17:02:21Z","published":"2024-03-27T17:02:21Z","title":"Temporal Logic Formalisation of ISO 34502 Critical Scenarios: Modular\n  Construction with the RSS Safety Distance","summary":"  As the development of autonomous vehicles progresses, efficient safety\nassurance methods become increasingly necessary. Safety assurance methods such\nas monitoring and scenario-based testing call for formalisation of driving\nscenarios. In this paper, we develop a temporal-logic formalisation of an\nimportant class of critical scenarios in the ISO standard 34502. We use signal\ntemporal logic (STL) as a logical formalism. Our formalisation has two main\nfeatures: 1) modular composition of logical formulas for systematic and\ncomprehensive formalisation (following the compositional methodology of ISO\n34502); 2) use of the RSS distance for defining danger. We find our\nformalisation comes with few parameters to tune thanks to the RSS distance. We\nexperimentally evaluated our formalisation; using its results, we discuss the\nvalidity of our formalisation and its stability with respect to the choice of\nsome parameter values.\n","authors":["Jesse Reimann","Nico Mansion","James Haydon","Benjamin Bray","Agnishom Chattopadhyay","Sota Sato","Masaki Waga","Étienne André","Ichiro Hasuo","Naoki Ueda","Yosuke Yokoyama"],"pdf_url":"https://arxiv.org/pdf/2403.18764v1.pdf","comment":"12 pages, 4 figures, 5 tables. Accepted to SAC 2024"},{"id":"http://arxiv.org/abs/2403.18762v1","updated":"2024-03-27T17:01:10Z","published":"2024-03-27T17:01:10Z","title":"ModaLink: Unifying Modalities for Efficient Image-to-PointCloud Place\n  Recognition","summary":"  Place recognition is an important task for robots and autonomous cars to\nlocalize themselves and close loops in pre-built maps. While single-modal\nsensor-based methods have shown satisfactory performance, cross-modal place\nrecognition that retrieving images from a point-cloud database remains a\nchallenging problem. Current cross-modal methods transform images into 3D\npoints using depth estimation for modality conversion, which are usually\ncomputationally intensive and need expensive labeled data for depth\nsupervision. In this work, we introduce a fast and lightweight framework to\nencode images and point clouds into place-distinctive descriptors. We propose\nan effective Field of View (FoV) transformation module to convert point clouds\ninto an analogous modality as images. This module eliminates the necessity for\ndepth estimation and helps subsequent modules achieve real-time performance. We\nfurther design a non-negative factorization-based encoder to extract mutually\nconsistent semantic features between point clouds and images. This encoder\nyields more distinctive global descriptors for retrieval. Experimental results\non the KITTI dataset show that our proposed methods achieve state-of-the-art\nperformance while running in real time. Additional evaluation on the HAOMO\ndataset covering a 17 km trajectory further shows the practical generalization\ncapabilities. We have released the implementation of our methods as open source\nat: https://github.com/haomo-ai/ModaLink.git.\n","authors":["Weidong Xie","Lun Luo","Nanfei Ye","Yi Ren","Shaoyi Du","Minhang Wang","Jintao Xu","Rui Ai","Weihao Gu","Xieyuanli Chen"],"pdf_url":"https://arxiv.org/pdf/2403.18762v1.pdf","comment":"8 pages, 11 figures, conference"},{"id":"http://arxiv.org/abs/2403.18760v1","updated":"2024-03-27T16:58:20Z","published":"2024-03-27T16:58:20Z","title":"MLDT: Multi-Level Decomposition for Complex Long-Horizon Robotic Task\n  Planning with Open-Source Large Language Model","summary":"  In the realm of data-driven AI technology, the application of open-source\nlarge language models (LLMs) in robotic task planning represents a significant\nmilestone. Recent robotic task planning methods based on open-source LLMs\ntypically leverage vast task planning datasets to enhance models' planning\nabilities. While these methods show promise, they struggle with complex\nlong-horizon tasks, which require comprehending more context and generating\nlonger action sequences. This paper addresses this limitation by proposing\nMLDT, theMulti-Level Decomposition Task planning method. This method\ninnovatively decomposes tasks at the goal-level, task-level, and action-level\nto mitigate the challenge of complex long-horizon tasks. In order to enhance\nopen-source LLMs' planning abilities, we introduce a goal-sensitive corpus\ngeneration method to create high-quality training data and conduct instruction\ntuning on the generated corpus. Since the complexity of the existing datasets\nis not high enough, we construct a more challenging dataset, LongTasks, to\nspecifically evaluate planning ability on complex long-horizon tasks. We\nevaluate our method using various LLMs on four datasets in VirtualHome. Our\nresults demonstrate a significant performance enhancement in robotic task\nplanning, showcasing MLDT's effectiveness in overcoming the limitations of\nexisting methods based on open-source LLMs as well as its practicality in\ncomplex, real-world scenarios.\n","authors":["Yike Wu","Jiatao Zhang","Nan Hu","LanLing Tang","Guilin Qi","Jun Shao","Jie Ren","Wei Song"],"pdf_url":"https://arxiv.org/pdf/2403.18760v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18721v1","updated":"2024-03-27T16:11:49Z","published":"2024-03-27T16:11:49Z","title":"PhysicsAssistant: An LLM-Powered Interactive Learning Robot for Physics\n  Lab Investigations","summary":"  Robot systems in education can leverage Large language models' (LLMs) natural\nlanguage understanding capabilities to provide assistance and facilitate\nlearning. This paper proposes a multimodal interactive robot (PhysicsAssistant)\nbuilt on YOLOv8 object detection, cameras, speech recognition, and chatbot\nusing LLM to provide assistance to students' physics labs. We conduct a user\nstudy on ten 8th-grade students to empirically evaluate the performance of\nPhysicsAssistant with a human expert. The Expert rates the assistants'\nresponses to student queries on a 0-4 scale based on Bloom's taxonomy to\nprovide educational support. We have compared the performance of\nPhysicsAssistant (YOLOv8+GPT-3.5-turbo) with GPT-4 and found that the human\nexpert rating of both systems for factual understanding is the same. However,\nthe rating of GPT-4 for conceptual and procedural knowledge (3 and 3.2 vs 2.2\nand 2.6, respectively) is significantly higher than PhysicsAssistant (p <\n0.05). However, the response time of GPT-4 is significantly higher than\nPhysicsAssistant (3.54 vs 1.64 sec, p < 0.05). Hence, despite the relatively\nlower response quality of PhysicsAssistant than GPT-4, it has shown potential\nfor being used as a real-time lab assistant to provide timely responses and can\noffload teachers' labor to assist with repetitive tasks. To the best of our\nknowledge, this is the first attempt to build such an interactive multimodal\nrobotic assistant for K-12 science (physics) education.\n","authors":["Ehsan Latif","Ramviyas Parasuraman","Xiaoming Zhai"],"pdf_url":"https://arxiv.org/pdf/2403.18721v1.pdf","comment":"Submitted to IEEE RO-MAN"},{"id":"http://arxiv.org/abs/2403.18695v1","updated":"2024-03-27T15:44:25Z","published":"2024-03-27T15:44:25Z","title":"An Efficient Risk-aware Branch MPC for Automated Driving that is Robust\n  to Uncertain Vehicle Behaviors","summary":"  One of the critical challenges in automated driving is ensuring safety of\nautomated vehicles despite the unknown behavior of the other vehicles. Although\nmotion prediction modules are able to generate a probability distribution\nassociated with various behavior modes, their probabilistic estimates are often\ninaccurate, thus leading to a possibly unsafe trajectory. To overcome this\nchallenge, we propose a risk-aware motion planning framework that appropriately\naccounts for the ambiguity in the estimated probability distribution. We\nformulate the risk-aware motion planning problem as a min-max optimization\nproblem and develop an efficient iterative method by incorporating a\nregularization term in the probability update step. Via extensive numerical\nstudies, we validate the convergence of our method and demonstrate its\nadvantages compared to the state-of-the-art approaches.\n","authors":["Luyao Zhang","George Pantazis","Shaohang Han","Sergio Grammatico"],"pdf_url":"https://arxiv.org/pdf/2403.18695v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18692v1","updated":"2024-03-27T15:42:01Z","published":"2024-03-27T15:42:01Z","title":"Teaching Introductory HRI: UChicago Course \"Human-Robot Interaction:\n  Research and Practice\"","summary":"  In 2020, I designed the course CMSC 20630/30630 Human-Robot Interaction:\nResearch and Practice as a hands-on introduction to human-robot interaction\n(HRI) research for both undergraduate and graduate students at the University\nof Chicago. Since 2020, I have taught and refined this course each academic\nyear. Human-Robot Interaction: Research and Practice focuses on the core\nconcepts and cutting-edge research in the field of human-robot interaction\n(HRI), covering topics that include: nonverbal robot behavior, verbal robot\nbehavior, social dynamics, norms & ethics, collaboration & learning, group\ninteractions, applications, and future challenges of HRI. Course meetings\ninvolve students in the class leading discussions about cutting-edge\npeer-reviewed research HRI publications. Students also participate in a\nquarter-long collaborative research project, where they pursue an HRI research\nquestion that often involves conducing their own human-subjects research study\nwhere they recruit human subjects to interact with a robot. In this paper, I\ndetail the structure of the course and its learning goals as well as my\nreflections and student feedback on the course.\n","authors":["Sarah Sebo"],"pdf_url":"https://arxiv.org/pdf/2403.18692v1.pdf","comment":"4 pages, 2 tables, Presented at the Designing an Intro to HRI Course\n  Workshop at HRI 2024 (arXiv:2403.05588)"},{"id":"http://arxiv.org/abs/2311.15803v3","updated":"2024-03-27T15:05:19Z","published":"2023-11-27T13:25:47Z","title":"SOAC: Spatio-Temporal Overlap-Aware Multi-Sensor Calibration using\n  Neural Radiance Fields","summary":"  In rapidly-evolving domains such as autonomous driving, the use of multiple\nsensors with different modalities is crucial to ensure high operational\nprecision and stability. To correctly exploit the provided information by each\nsensor in a single common frame, it is essential for these sensors to be\naccurately calibrated. In this paper, we leverage the ability of Neural\nRadiance Fields (NeRF) to represent different sensors modalities in a common\nvolumetric representation to achieve robust and accurate spatio-temporal sensor\ncalibration. By designing a partitioning approach based on the visible part of\nthe scene for each sensor, we formulate the calibration problem using only the\noverlapping areas. This strategy results in a more robust and accurate\ncalibration that is less prone to failure. We demonstrate that our approach\nworks on outdoor urban scenes by validating it on multiple established driving\ndatasets. Results show that our method is able to get better accuracy and\nrobustness compared to existing methods.\n","authors":["Quentin Herau","Nathan Piasco","Moussab Bennehar","Luis Roldão","Dzmitry Tsishkou","Cyrille Migniot","Pascal Vasseur","Cédric Demonceaux"],"pdf_url":"https://arxiv.org/pdf/2311.15803v3.pdf","comment":"Accepted at CVPR 2024. Project page: https://qherau.github.io/SOAC/"},{"id":"http://arxiv.org/abs/2403.07091v2","updated":"2024-03-27T15:04:18Z","published":"2024-03-11T18:35:32Z","title":"Sim-to-Real gap in RL: Use Case with TIAGo and Isaac Sim/Gym","summary":"  This paper explores policy-learning approaches in the context of sim-to-real\ntransfer for robotic manipulation using a TIAGo mobile manipulator, focusing on\ntwo state-of-art simulators, Isaac Gym and Isaac Sim, both developed by Nvidia.\nControl architectures are discussed, with a particular emphasis on achieving\ncollision-less movement in both simulation and the real environment. Presented\nresults demonstrate successful sim-to-real transfer, showcasing similar\nmovements executed by an RL-trained model in both simulated and real setups.\n","authors":["Jaume Albardaner","Alberto San Miguel","Néstor García","Magí Dalmau-Moreno"],"pdf_url":"https://arxiv.org/pdf/2403.07091v2.pdf","comment":"Accepted in ERF24 workshop \"Towards Efficient and Portable Robot\n  Learning for Real-World Settings\". To be published in Springer Proceedings in\n  Advanced Robotics"},{"id":"http://arxiv.org/abs/2403.18643v1","updated":"2024-03-27T14:46:54Z","published":"2024-03-27T14:46:54Z","title":"Sampling-Based Motion Planning with Online Racing Line Generation for\n  Autonomous Driving on Three-Dimensional Race Tracks","summary":"  Existing approaches to trajectory planning for autonomous racing employ\nsampling-based methods, generating numerous jerk-optimal trajectories and\nselecting the most favorable feasible trajectory based on a cost function\npenalizing deviations from an offline-calculated racing line. While successful\non oval tracks, these methods face limitations on complex circuits due to the\nsimplistic geometry of jerk-optimal edges failing to capture the complexity of\nthe racing line. Additionally, they only consider two-dimensional tracks,\npotentially neglecting or surpassing the actual dynamic potential. In this\npaper, we present a sampling-based local trajectory planning approach for\nautonomous racing that can maintain the lap time of the racing line even on\ncomplex race tracks and consider the race track's three-dimensional effects. In\nsimulative experiments, we demonstrate that our approach achieves lower lap\ntimes and improved utilization of dynamic limits compared to existing\napproaches. We also investigate the impact of online racing line generation, in\nwhich the time-optimal solution is planned from the current vehicle state for a\nlimited spatial horizon, in contrast to a closed racing line calculated\noffline. We show that combining the sampling-based planner with the online\nracing line generation can significantly reduce lap times in multi-vehicle\nscenarios.\n","authors":["Levent Ögretmen","Matthias Rowold","Boris Lohmann"],"pdf_url":"https://arxiv.org/pdf/2403.18643v1.pdf","comment":"8 pages, submitted to be published at the 35th IEEE Intelligent\n  Vehicles Symposium, June 2 - 5, 2024, Jeju Shinhwa World, Jeju Island, Korea"},{"id":"http://arxiv.org/abs/2403.18616v1","updated":"2024-03-27T14:30:56Z","published":"2024-03-27T14:30:56Z","title":"Will You Participate? Exploring the Potential of Robotics Competitions\n  on Human-centric Topics","summary":"  This paper presents findings from an exploratory needfinding study\ninvestigating the research current status and potential participation of the\ncompetitions on the robotics community towards four human-centric topics:\nsafety, privacy, explainability, and federated learning. We conducted a survey\nwith 34 participants across three distinguished European robotics consortia,\nnearly 60% of whom possessed over five years of research experience in\nrobotics. Our qualitative and quantitative analysis revealed that current\nmainstream robotic researchers prioritize safety and explainability, expressing\na greater willingness to invest in further research in these areas. Conversely,\nour results indicate that privacy and federated learning garner less attention\nand are perceived to have lower potential. Additionally, the study suggests a\nlack of enthusiasm within the robotics community for participating in\ncompetitions related to these topics. Based on these findings, we recommend\ntargeting other communities, such as the machine learning community, for future\ncompetitions related to these four human-centric topics.\n","authors":["Yuchong Zhang","Miguel Vasco","Mårten Björkman","Danica Kragic"],"pdf_url":"https://arxiv.org/pdf/2403.18616v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18600v1","updated":"2024-03-27T14:22:40Z","published":"2024-03-27T14:22:40Z","title":"RAP: Retrieval-Augmented Planner for Adaptive Procedure Planning in\n  Instructional Videos","summary":"  Procedure Planning in instructional videos entails generating a sequence of\naction steps based on visual observations of the initial and target states.\nDespite the rapid progress in this task, there remain several critical\nchallenges to be solved: (1) Adaptive procedures: Prior works hold an\nunrealistic assumption that the number of action steps is known and fixed,\nleading to non-generalizable models in real-world scenarios where the sequence\nlength varies. (2) Temporal relation: Understanding the step temporal relation\nknowledge is essential in producing reasonable and executable plans. (3)\nAnnotation cost: Annotating instructional videos with step-level labels (i.e.,\ntimestamp) or sequence-level labels (i.e., action category) is demanding and\nlabor-intensive, limiting its generalizability to large-scale datasets.In this\nwork, we propose a new and practical setting, called adaptive procedure\nplanning in instructional videos, where the procedure length is not fixed or\npre-determined. To address these challenges we introduce Retrieval-Augmented\nPlanner (RAP) model. Specifically, for adaptive procedures, RAP adaptively\ndetermines the conclusion of actions using an auto-regressive model\narchitecture. For temporal relation, RAP establishes an external memory module\nto explicitly retrieve the most relevant state-action pairs from the training\nvideos and revises the generated procedures. To tackle high annotation cost,\nRAP utilizes a weakly-supervised learning manner to expand the training dataset\nto other task-relevant, unannotated videos by generating pseudo labels for\naction steps. Experiments on CrossTask and COIN benchmarks show the superiority\nof RAP over traditional fixed-length models, establishing it as a strong\nbaseline solution for adaptive procedure planning.\n","authors":["Ali Zare","Yulei Niu","Hammad Ayyubi","Shih-fu Chang"],"pdf_url":"https://arxiv.org/pdf/2403.18600v1.pdf","comment":"23 pages, 6 figures, 12 tables"},{"id":"http://arxiv.org/abs/2311.05362v2","updated":"2024-03-27T14:22:34Z","published":"2023-11-09T13:43:36Z","title":"Modeling and Control of Intrinsically Elasticity Coupled Soft-Rigid\n  Robots","summary":"  While much work has been done recently in the realm of model-based control of\nsoft robots and soft-rigid hybrids, most works examine robots that have an\ninherently serial structure. While these systems have been prevalent in the\nliterature, there is an increasing trend toward designing soft-rigid hybrids\nwith intrinsically coupled elasticity between various degrees of freedom. In\nthis work, we seek to address the issues of modeling and controlling such\nstructures, particularly when underactuated. We introduce several simple models\nfor elastic coupling, typical of those seen in these systems. We then propose a\ncontroller that compensates for the elasticity, and we prove its stability with\nLyapunov methods without relying on the elastic dominance assumption. This\ncontroller is applicable to the general class of underactuated soft robots.\nAfter evaluating the controller in simulated cases, we then develop a simple\nhardware platform to evaluate both the models and the controller. Finally,\nusing the hardware, we demonstrate a novel use case for underactuated,\nelastically coupled systems in \"sensorless\" force control.\n","authors":["Zach J. Patterson","Cosimo Della Santina","Daniela Rus"],"pdf_url":"https://arxiv.org/pdf/2311.05362v2.pdf","comment":"7 pages, 8 figures"},{"id":"http://arxiv.org/abs/2311.03189v2","updated":"2024-03-27T14:21:13Z","published":"2023-11-06T15:28:24Z","title":"Safe Control for Soft-Rigid Robots with Self-Contact using Control\n  Barrier Functions","summary":"  Incorporating both flexible and rigid components in robot designs offers a\nunique solution to the limitations of traditional rigid robotics by enabling\nboth compliance and strength. This paper explores the challenges and solutions\nfor controlling soft-rigid hybrid robots, particularly addressing the issue of\nself-contact. Conventional control methods prioritize precise state tracking,\ninadvertently increasing the system's overall stiffness, which is not always\ndesirable in interactions with the environment or within the robot itself. To\naddress this, we investigate the application of Control Barrier Functions\n(CBFs) and High Order CBFs to manage self-contact scenarios in serially\nconnected soft-rigid hybrid robots. Through an analysis based on Piecewise\nConstant Curvature (PCC) kinematics, we establish CBFs within a classical\ncontrol framework for self-contact dynamics. Our methodology is rigorously\nevaluated in both simulation environments and physical hardware systems. The\nfindings demonstrate that our proposed control strategy effectively regulates\nself-contact in soft-rigid hybrid robotic systems, marking a significant\nadvancement in the field of robotics.\n","authors":["Zach J. Patterson","Wei Xiao","Emily Sologuren","Daniela Rus"],"pdf_url":"https://arxiv.org/pdf/2311.03189v2.pdf","comment":"6 pages, 6 figures, submitted to IEEE Robosoft 2024 Conference"},{"id":"http://arxiv.org/abs/2309.10718v2","updated":"2024-03-27T13:54:19Z","published":"2023-09-19T16:02:23Z","title":"DRIVE: Data-driven Robot Input Vector Exploration","summary":"  An accurate motion model is a fundamental component of most autonomous\nnavigation systems. While much work has been done on improving model\nformulation, no standard protocol exists for gathering empirical data required\nto train models. In this work, we address this issue by proposing Data-driven\nRobot Input Vector Exploration (DRIVE), a protocol that enables characterizing\nuncrewed ground vehicles (UGVs) input limits and gathering empirical model\ntraining data. We also propose a novel learned slip approach outperforming\nsimilar acceleration learning approaches. Our contributions are validated\nthrough an extensive experimental evaluation, cumulating over 7 km and 1.8 h of\ndriving data over three distinct UGVs and four terrain types. We show that our\nprotocol offers increased predictive performance over common human-driven\ndata-gathering protocols. Furthermore, our protocol converges with 46 s of\ntraining data, almost four times less than the shortest human dataset gathering\nprotocol. We show that the operational limit for our model is reached in\nextreme slip conditions encountered on surfaced ice. DRIVE is an efficient way\nof characterizing UGV motion in its operational conditions. Our code and\ndataset are both available online at this link:\nhttps://github.com/norlab-ulaval/DRIVE.\n","authors":["Dominic Baril","Simon-Pierre Deschênes","Luc Coupal","Cyril Goffin","Julien Lépine","Philippe Giguère","François Pomerleau"],"pdf_url":"https://arxiv.org/pdf/2309.10718v2.pdf","comment":"8 pages, 7 figures, 1 table, accepted for publication at the 2024\n  IEEE International Conference on Robotics and Automation (ICRA2024),\n  Yokohama, Japan"},{"id":"http://arxiv.org/abs/2403.18546v1","updated":"2024-03-27T13:24:58Z","published":"2024-03-27T13:24:58Z","title":"Efficient Heatmap-Guided 6-Dof Grasp Detection in Cluttered Scenes","summary":"  Fast and robust object grasping in clutter is a crucial component of\nrobotics. Most current works resort to the whole observed point cloud for 6-Dof\ngrasp generation, ignoring the guidance information excavated from global\nsemantics, thus limiting high-quality grasp generation and real-time\nperformance. In this work, we show that the widely used heatmaps are\nunderestimated in the efficiency of 6-Dof grasp generation. Therefore, we\npropose an effective local grasp generator combined with grasp heatmaps as\nguidance, which infers in a global-to-local semantic-to-point way.\nSpecifically, Gaussian encoding and the grid-based strategy are applied to\npredict grasp heatmaps as guidance to aggregate local points into graspable\nregions and provide global semantic information. Further, a novel non-uniform\nanchor sampling mechanism is designed to improve grasp accuracy and diversity.\nBenefiting from the high-efficiency encoding in the image space and focusing on\npoints in local graspable regions, our framework can perform high-quality grasp\ndetection in real-time and achieve state-of-the-art results. In addition, real\nrobot experiments demonstrate the effectiveness of our method with a success\nrate of 94% and a clutter completion rate of 100%. Our code is available at\nhttps://github.com/THU-VCLab/HGGD.\n","authors":["Siang Chen","Wei Tang","Pengwei Xie","Wenming Yang","Guijin Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18546v1.pdf","comment":"Extensive results on GraspNet-1B dataset"},{"id":"http://arxiv.org/abs/2403.18524v1","updated":"2024-03-27T12:55:16Z","published":"2024-03-27T12:55:16Z","title":"Bridging the Gap: Regularized Reinforcement Learning for Improved\n  Classical Motion Planning with Safety Modules","summary":"  Classical navigation planners can provide safe navigation, albeit often\nsuboptimally and with hindered human norm compliance. ML-based, contemporary\nautonomous navigation algorithms can imitate more natural and humancompliant\nnavigation, but usually require large and realistic datasets and do not always\nprovide safety guarantees. We present an approach that leverages a classical\nalgorithm to guide reinforcement learning. This greatly improves the results\nand convergence rate of the underlying RL algorithm and requires no\nhuman-expert demonstrations to jump-start the process. Additionally, we\nincorporate a practical fallback system that can switch back to a classical\nplanner to ensure safety. The outcome is a sample efficient ML approach for\nmobile navigation that builds on classical algorithms, improves them to ensure\nhuman compliance, and guarantees safety.\n","authors":["Elias Goldsztejn","Ronen I. Brafman"],"pdf_url":"https://arxiv.org/pdf/2403.18524v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2403.11617v2","updated":"2024-03-27T12:49:06Z","published":"2024-03-18T09:50:05Z","title":"Frontier-Based Exploration for Multi-Robot Rendezvous in\n  Communication-Restricted Unknown Environments","summary":"  Multi-robot rendezvous and exploration are fundamental challenges in the\ndomain of mobile robotic systems. This paper addresses multi-robot rendezvous\nwithin an initially unknown environment where communication is only possible\nafter the rendezvous. Traditionally, exploration has been focused on rapidly\nmapping the environment, often leading to suboptimal rendezvous performance in\nlater stages. We adapt a standard frontier-based exploration technique to\nintegrate exploration and rendezvous into a unified strategy, with a mechanism\nthat allows robots to re-visit previously explored regions thus enhancing\nrendezvous opportunities. We validate our approach in 3D realistic simulations\nusing ROS, showcasing its effectiveness in achieving faster rendezvous times\ncompared to exploration strategies.\n","authors":["Mauro Tellaroli","Matteo Luperto","Michele Antonazzi","Nicola Basilico"],"pdf_url":"https://arxiv.org/pdf/2403.11617v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17392v2","updated":"2024-03-27T12:10:00Z","published":"2024-03-26T05:23:12Z","title":"Natural-artificial hybrid swarm: Cyborg-insect group navigation in\n  unknown obstructed soft terrain","summary":"  Navigating multi-robot systems in complex terrains has always been a\nchallenging task. This is due to the inherent limitations of traditional robots\nin collision avoidance, adaptation to unknown environments, and sustained\nenergy efficiency. In order to overcome these limitations, this research\nproposes a solution by integrating living insects with miniature electronic\ncontrollers to enable robotic-like programmable control, and proposing a novel\ncontrol algorithm for swarming. Although these creatures, called cyborg\ninsects, have the ability to instinctively avoid collisions with neighbors and\nobstacles while adapting to complex terrains, there is a lack of literature on\nthe control of multi-cyborg systems. This research gap is due to the difficulty\nin coordinating the movements of a cyborg system under the presence of insects'\ninherent individual variability in their reactions to control input. In\nresponse to this issue, we propose a novel swarm navigation algorithm\naddressing these challenges. The effectiveness of the algorithm is demonstrated\nthrough an experimental validation in which a cyborg swarm was successfully\nnavigated through an unknown sandy field with obstacles and hills. This\nresearch contributes to the domain of swarm robotics and showcases the\npotential of integrating biological organisms with robotics and control theory\nto create more intelligent autonomous systems with real-world applications.\n","authors":["Yang Bai","Phuoc Thanh Tran Ngoc","Huu Duoc Nguyen","Duc Long Le","Quang Huy Ha","Kazuki Kai","Yu Xiang See To","Yaosheng Deng","Jie Song","Naoki Wakamiya","Hirotaka Sato","Masaki Ogura"],"pdf_url":"https://arxiv.org/pdf/2403.17392v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18459v1","updated":"2024-03-27T11:18:01Z","published":"2024-03-27T11:18:01Z","title":"CoBOS: Constraint-Based Online Scheduler for Human-Robot Collaboration","summary":"  Assembly processes involving humans and robots are challenging scenarios\nbecause the individual activities and access to shared workspace have to be\ncoordinated. Fixed robot programs leave no room to diverge from a fixed\nprotocol. Working on such a process can be stressful for the user and lead to\nineffective behavior or failure. We propose a novel approach of online\nconstraint-based scheduling in a reactive execution control framework\nfacilitating behavior trees called CoBOS. This allows the robot to adapt to\nuncertain events such as delayed activity completions and activity selection\n(by the human). The user will experience less stress as the robotic coworkers\nadapt their behavior to best complement the human-selected activities to\ncomplete the common task. In addition to the improved working conditions, our\nalgorithm leads to increased efficiency, even in highly uncertain scenarios. We\nevaluate our algorithm using a probabilistic simulation study with 56000\nexperiments. We outperform all baselines by a margin of 4-10%. Initial real\nrobot experiments using a Franka Emika Panda robot and human tracking based on\nHTC Vive VR gloves look promising.\n","authors":["Marina Ionova","Jan Kristof Behrens"],"pdf_url":"https://arxiv.org/pdf/2403.18459v1.pdf","comment":"7 pages, 8 figures"},{"id":"http://arxiv.org/abs/2403.18456v1","updated":"2024-03-27T11:16:04Z","published":"2024-03-27T11:16:04Z","title":"Inverse kinematics learning of a continuum manipulator using limited\n  real time data","summary":"  Data driven control of a continuum manipulator requires a lot of data for\ntraining but generating sufficient amount of real time data is not cost\nefficient. Random actuation of the manipulator can also be unsafe sometimes.\nMeta learning has been used successfully to adapt to a new environment. Hence,\nthis paper tries to solve the above mentioned problem using meta learning. We\nconsider two cases for that. First, this paper proposes a method to use\nsimulation data for training the model using MAML(Model-Agnostic\nMeta-Learning). Then, it adapts to the real world using gradient steps.\nSecondly,if the simulation model is not available or difficult to formulate,\nthen we propose a CGAN(Conditional Generative adversial network)-MAML based\nmethod for it. The model is trained using a small amount of real time data and\naugmented data for different loading conditions. Then, adaptation is done in\nthe real environment. It has been found out from the experiments that the\nrelative positioning error for both the cases are below 3%. The proposed models\nare experimentally verified on a real continuum manipulator.\n","authors":["Alok Ranjan Sahoo","Pavan Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2403.18456v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18452v1","updated":"2024-03-27T11:11:08Z","published":"2024-03-27T11:11:08Z","title":"SingularTrajectory: Universal Trajectory Predictor Using Diffusion Model","summary":"  There are five types of trajectory prediction tasks: deterministic,\nstochastic, domain adaptation, momentary observation, and few-shot. These\nassociated tasks are defined by various factors, such as the length of input\npaths, data split and pre-processing methods. Interestingly, even though they\ncommonly take sequential coordinates of observations as input and infer future\npaths in the same coordinates as output, designing specialized architectures\nfor each task is still necessary. For the other task, generality issues can\nlead to sub-optimal performances. In this paper, we propose SingularTrajectory,\na diffusion-based universal trajectory prediction framework to reduce the\nperformance gap across the five tasks. The core of SingularTrajectory is to\nunify a variety of human dynamics representations on the associated tasks. To\ndo this, we first build a Singular space to project all types of motion\npatterns from each task into one embedding space. We next propose an adaptive\nanchor working in the Singular space. Unlike traditional fixed anchor methods\nthat sometimes yield unacceptable paths, our adaptive anchor enables correct\nanchors, which are put into a wrong location, based on a traversability map.\nFinally, we adopt a diffusion-based predictor to further enhance the prototype\npaths using a cascaded denoising process. Our unified framework ensures the\ngenerality across various benchmark settings such as input modality, and\ntrajectory lengths. Extensive experiments on five public benchmarks demonstrate\nthat SingularTrajectory substantially outperforms existing models, highlighting\nits effectiveness in estimating general dynamics of human movements. Code is\npublicly available at https://github.com/inhwanbae/SingularTrajectory .\n","authors":["Inhwan Bae","Young-Jae Park","Hae-Gon Jeon"],"pdf_url":"https://arxiv.org/pdf/2403.18452v1.pdf","comment":"Accepted at CVPR 2024"},{"id":"http://arxiv.org/abs/2311.08787v2","updated":"2024-03-27T11:06:49Z","published":"2023-11-15T08:59:05Z","title":"Polygonal Cone Control Barrier Functions (PolyC2BF) for safe navigation\n  in cluttered environments","summary":"  In fields such as mining, search and rescue, and archaeological exploration,\nensuring real-time, collision-free navigation of robots in confined, cluttered\nenvironments is imperative. Despite the value of established path planning\nalgorithms, they often face challenges in convergence rates and handling\ndynamic infeasibilities. Alternative techniques like collision cones struggle\nto accurately represent complex obstacle geometries. This paper introduces a\nnovel category of control barrier functions, known as Polygonal Cone Control\nBarrier Function (PolyC2BF), which addresses overestimation and computational\ncomplexity issues. The proposed PolyC2BF, formulated as a Quadratic Programming\n(QP) problem, proves effective in facilitating collision-free movement of\nmultiple robots in complex environments. The efficacy of this approach is\nfurther demonstrated through PyBullet simulations on quadruped (unicycle\nmodel), and crazyflie 2.1 (quadrotor model) in cluttered environments.\n","authors":["Manan Tayal","Shishir Kolathaya"],"pdf_url":"https://arxiv.org/pdf/2311.08787v2.pdf","comment":"6 Pages, 6 Figures. Accepted at European Control Conference (ECC)\n  2024. arXiv admin note: text overlap with arXiv:2303.15871"},{"id":"http://arxiv.org/abs/2403.18447v1","updated":"2024-03-27T11:06:44Z","published":"2024-03-27T11:06:44Z","title":"Can Language Beat Numerical Regression? Language-Based Multimodal\n  Trajectory Prediction","summary":"  Language models have demonstrated impressive ability in context understanding\nand generative performance. Inspired by the recent success of language\nfoundation models, in this paper, we propose LMTraj (Language-based Multimodal\nTrajectory predictor), which recasts the trajectory prediction task into a sort\nof question-answering problem. Departing from traditional numerical regression\nmodels, which treat the trajectory coordinate sequence as continuous signals,\nwe consider them as discrete signals like text prompts. Specially, we first\ntransform an input space for the trajectory coordinate into the natural\nlanguage space. Here, the entire time-series trajectories of pedestrians are\nconverted into a text prompt, and scene images are described as text\ninformation through image captioning. The transformed numerical and image data\nare then wrapped into the question-answering template for use in a language\nmodel. Next, to guide the language model in understanding and reasoning\nhigh-level knowledge, such as scene context and social relationships between\npedestrians, we introduce an auxiliary multi-task question and answering. We\nthen train a numerical tokenizer with the prompt data. We encourage the\ntokenizer to separate the integer and decimal parts well, and leverage it to\ncapture correlations between the consecutive numbers in the language model.\nLastly, we train the language model using the numerical tokenizer and all of\nthe question-answer prompts. Here, we propose a beam-search-based most-likely\nprediction and a temperature-based multimodal prediction to implement both\ndeterministic and stochastic inferences. Applying our LMTraj, we show that the\nlanguage-based model can be a powerful pedestrian trajectory predictor, and\noutperforms existing numerical-based predictor methods. Code is publicly\navailable at https://github.com/inhwanbae/LMTrajectory .\n","authors":["Inhwan Bae","Junoh Lee","Hae-Gon Jeon"],"pdf_url":"https://arxiv.org/pdf/2403.18447v1.pdf","comment":"Accepted at CVPR 2024"},{"id":"http://arxiv.org/abs/2403.18413v1","updated":"2024-03-27T10:01:14Z","published":"2024-03-27T10:01:14Z","title":"HyRRT-Connect: A Bidirectional Rapidly-Exploring Random Trees Motion\n  Planning Algorithm for Hybrid Systems","summary":"  This paper proposes a bidirectional rapidly-exploring random trees (RRT)\nalgorithm to solve the motion planning problem for hybrid systems. The proposed\nalgorithm, called HyRRT-Connect, propagates in both forward and backward\ndirections in hybrid time until an overlap between the forward and backward\npropagation results is detected. Then, HyRRT-Connect constructs a motion plan\nthrough the reversal and concatenation of functions defined on hybrid time\ndomains, ensuring the motion plan thoroughly satisfies the given hybrid\ndynamics. To address the potential discontinuity along the flow caused by\ntolerating some distance between the forward and backward partial motion plans,\nwe reconstruct the backward partial motion plan by a forward-in-hybrid-time\nsimulation from the final state of the forward partial motion plan. By applying\nthe reversed input of the backward partial motion plan, the reconstruction\nprocess effectively eliminates the discontinuity and ensures that as the\ntolerance distance decreases to zero, the distance between the endpoint of the\nreconstructed motion plan and the final state set approaches zero. The proposed\nalgorithm is applied to an actuated bouncing ball example and a walking robot\nexample so as to highlight its generality and computational improvement.\n","authors":["Nan Wang","Ricardo G. Sanfelice"],"pdf_url":"https://arxiv.org/pdf/2403.18413v1.pdf","comment":"Accepted by the 8th IFAC International Conference on Analysis and\n  Design of Hybrid Systems (ADHS 2024)"},{"id":"http://arxiv.org/abs/2309.12857v2","updated":"2024-03-27T09:26:56Z","published":"2023-09-22T13:31:29Z","title":"Risk-aware Control for Robots with Non-Gaussian Belief Spaces","summary":"  This paper addresses the problem of safety-critical control of autonomous\nrobots, considering the ubiquitous uncertainties arising from unmodeled\ndynamics and noisy sensors. To take into account these uncertainties,\nprobabilistic state estimators are often deployed to obtain a belief over\npossible states. Namely, Particle Filters (PFs) can handle arbitrary\nnon-Gaussian distributions in the robot's state. In this work, we define the\nbelief state and belief dynamics for continuous-discrete PFs and construct safe\nsets in the underlying belief space. We design a controller that provably keeps\nthe robot's belief state within this safe set. As a result, we ensure that the\nrisk of the unknown robot's state violating a safety specification, such as\navoiding a dangerous area, is bounded. We provide an open-source implementation\nas a ROS2 package and evaluate the solution in simulations and hardware\nexperiments involving high-dimensional belief spaces.\n","authors":["Matti Vahs","Jana Tumova"],"pdf_url":"https://arxiv.org/pdf/2309.12857v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14864v2","updated":"2024-03-27T09:24:55Z","published":"2024-03-21T22:18:59Z","title":"Learning Quadruped Locomotion Using Differentiable Simulation","summary":"  While most recent advancements in legged robot control have been driven by\nmodel-free reinforcement learning, we explore the potential of differentiable\nsimulation. Differentiable simulation promises faster convergence and more\nstable training by computing low-variant first-order gradients using the robot\nmodel, but so far, its use for legged robot control has remained limited to\nsimulation. The main challenge with differentiable simulation lies in the\ncomplex optimization landscape of robotic tasks due to discontinuities in\ncontact-rich environments, e.g., quadruped locomotion. This work proposes a\nnew, differentiable simulation framework to overcome these challenges. The key\nidea involves decoupling the complex whole-body simulation, which may exhibit\ndiscontinuities due to contact, into two separate continuous domains.\nSubsequently, we align the robot state resulting from the simplified model with\na more precise, non-differentiable simulator to maintain sufficient simulation\naccuracy. Our framework enables learning quadruped walking in minutes using a\nsingle simulated robot without any parallelization. When augmented with GPU\nparallelization, our approach allows the quadruped robot to master diverse\nlocomotion skills, including trot, pace, bound, and gallop, on challenging\nterrains in minutes. Additionally, our policy achieves robust locomotion\nperformance in the real world zero-shot. To the best of our knowledge, this\nwork represents the first demonstration of using differentiable simulation for\ncontrolling a real quadruped robot. This work provides several important\ninsights into using differentiable simulations for legged locomotion in the\nreal world.\n","authors":["Yunlong Song","Sangbae Kim","Davide Scaramuzza"],"pdf_url":"https://arxiv.org/pdf/2403.14864v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.06494v2","updated":"2024-03-27T09:21:50Z","published":"2023-09-12T18:07:27Z","title":"Non-smooth Control Barrier Functions for Stochastic Dynamical Systems","summary":"  Uncertainties arising in various control systems, such as robots that are\nsubject to unknown disturbances or environmental variations, pose significant\nchallenges for ensuring system safety, such as collision avoidance. At the same\ntime, safety specifications are getting more and more complex, e.g., by\ncomposing multiple safety objectives through Boolean operators resulting in\nnon-smooth descriptions of safe sets. Control Barrier Functions (CBFs) have\nemerged as a control technique to provably guarantee system safety. In most\nsettings, they rely on an assumption of having deterministic dynamics and\nsmooth safe sets. This paper relaxes these two assumptions by extending CBFs to\nencompass control systems with stochastic dynamics and safe sets defined by\nnon-smooth functions. By explicitly considering the stochastic nature of system\ndynamics and accommodating complex safety specifications, our method enables\nthe design of safe control strategies in uncertain and complex systems. We\nprovide formal guarantees on the safety of the system by leveraging the\ntheoretical foundations of stochastic CBFs and non-smooth safe sets. Numerical\nsimulations demonstrate the effectiveness of the approach in various scenarios.\n","authors":["Matti Vahs","Jana Tumova"],"pdf_url":"https://arxiv.org/pdf/2309.06494v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18376v1","updated":"2024-03-27T09:15:45Z","published":"2024-03-27T09:15:45Z","title":"Extensible Hook System for Rendesvouz and Docking of a Cubesat Swarm","summary":"  The use of cubesat swarms is being proposed for different missions where\ncooperation between satellites is required. Commonly, the cube swarm requires\nformation flight and even rendezvous and docking, which are very challenging\ntasks since they required more energy and the use of advanced guidance,\nnavigation and control techniques. In this paper, we propose the use of an\nextensible hook system to mitigate these drawbacks,i.e. it allows to save fuel\nand reduce the system complexity by including techniques that have been\npreviously demonstrated on Earth. This system is based on a scissor boom\nstructure, which could reach up to five meters for a 4U dimension, including\nthree degrees of freedom to place the end effector at any pose within the\nsystem workspace. We simulated the dynamic behaviour of a cubesat with the\nproposed system, demonstrating the required power for a 16U cubesat equipped\nwith one extensible hook system is considered acceptable according to the\ncurrent state of the art actuators.\n","authors":["Carlos J. Pérez-del-Pulgar","Antonio López-Palomeque","Jesús Juli","Matteo Madi"],"pdf_url":"https://arxiv.org/pdf/2403.18376v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18358v1","updated":"2024-03-27T08:49:30Z","published":"2024-03-27T08:49:30Z","title":"Imaging radar and LiDAR image translation for 3-DOF extrinsic\n  calibration","summary":"  The integration of sensor data is crucial in the field of robotics to take\nfull advantage of the various sensors employed. One critical aspect of this\nintegration is determining the extrinsic calibration parameters, such as the\nrelative transformation, between each sensor. The use of data fusion between\ncomplementary sensors, such as radar and LiDAR, can provide significant\nbenefits, particularly in harsh environments where accurate depth data is\nrequired. However, noise included in radar sensor data can make the estimation\nof extrinsic calibration challenging. To address this issue, we present a novel\nframework for the extrinsic calibration of radar and LiDAR sensors, utilizing\nCycleGAN as amethod of image-to-image translation. Our proposed method employs\ntranslating radar bird-eye-view images into LiDAR-style images to estimate the\n3-DOF extrinsic parameters. The use of image registration techniques, as well\nas deskewing based on sensor odometry and B-spline interpolation, is employed\nto address the rolling shutter effect commonly present in spinning sensors. Our\nmethod demonstrates a notable improvement in extrinsic calibration compared to\nfilter-based methods using the MulRan dataset.\n","authors":["Sangwoo Jung","Hyesu Jang","Minwoo Jung","Ayoung Kim","Myung-Hwan Jeon"],"pdf_url":"https://arxiv.org/pdf/2403.18358v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.17072v3","updated":"2024-03-27T07:04:58Z","published":"2023-10-26T00:28:37Z","title":"MMP++: Motion Manifold Primitives with Parametric Curve Models","summary":"  Motion Manifold Primitives (MMP), a manifold-based approach for encoding\nbasic motion skills, can produce diverse trajectories, enabling the system to\nadapt to unseen constraints. Nonetheless, we argue that current MMP models lack\ncrucial functionalities of movement primitives, such as temporal and via-points\nmodulation, found in traditional approaches. This shortfall primarily stems\nfrom MMP's reliance on discrete-time trajectories. To overcome these\nlimitations, we introduce Motion Manifold Primitives++ (MMP++), a new model\nthat integrates the strengths of both MMP and traditional methods by\nincorporating parametric curve representations into the MMP framework.\nFurthermore, we identify a significant challenge with MMP++: performance\ndegradation due to geometric distortions in the latent space, meaning that\nsimilar motions are not closely positioned. To address this, Isometric Motion\nManifold Primitives++ (IMMP++) is proposed to ensure the latent space\naccurately preserves the manifold's geometry. Our experimental results across\nvarious applications, including 2-DoF planar motions, 7-DoF robot arm motions,\nand SE(3) trajectory planning, show that MMP++ and IMMP++ outperform existing\nmethods in trajectory generation tasks, achieving substantial improvements in\nsome cases. Moreover, they enable the modulation of latent coordinates and\nvia-points, thereby allowing efficient online adaptation to dynamic\nenvironments.\n","authors":["Yonghyeon Lee"],"pdf_url":"https://arxiv.org/pdf/2310.17072v3.pdf","comment":"12 pages. This work has been submitted to the IEEE for possible\n  publication"},{"id":"http://arxiv.org/abs/2403.17367v2","updated":"2024-03-27T06:16:06Z","published":"2024-03-26T04:05:01Z","title":"RoboDuet: A Framework Affording Mobile-Manipulation and Cross-Embodiment","summary":"  Combining the mobility of legged robots with the manipulation skills of arms\nhas the potential to significantly expand the operational range and enhance the\ncapabilities of robotic systems in performing various mobile manipulation\ntasks. Existing approaches are confined to imprecise six degrees of freedom\n(DoF) manipulation and possess a limited arm workspace. In this paper, we\npropose a novel framework, RoboDuet, which employs two collaborative policies\nto realize locomotion and manipulation simultaneously, achieving whole-body\ncontrol through interactions between each other. Surprisingly, going beyond the\nlarge-range pose tracking, we find that the two-policy framework may enable\ncross-embodiment deployment such as using different quadrupedal robots or other\narms. Our experiments demonstrate that the policies trained through RoboDuet\ncan accomplish stable gaits, agile 6D end-effector pose tracking, and zero-shot\nexchange of legged robots, and can be deployed in the real world to perform\nvarious mobile manipulation tasks. Our project page with demo videos is at\nhttps://locomanip-duet.github.io .\n","authors":["Guoping Pan","Qingwei Ben","Zhecheng Yuan","Guangqi Jiang","Yandong Ji","Jiangmiao Pang","Houde Liu","Huazhe Xu"],"pdf_url":"https://arxiv.org/pdf/2403.17367v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18259v1","updated":"2024-03-27T05:15:48Z","published":"2024-03-27T05:15:48Z","title":"RoboKeyGen: Robot Pose and Joint Angles Estimation via Diffusion-based\n  3D Keypoint Generation","summary":"  Estimating robot pose and joint angles is significant in advanced robotics,\nenabling applications like robot collaboration and online hand-eye\ncalibration.However, the introduction of unknown joint angles makes prediction\nmore complex than simple robot pose estimation, due to its higher\ndimensionality.Previous methods either regress 3D keypoints directly or utilise\na render&compare strategy. These approaches often falter in terms of\nperformance or efficiency and grapple with the cross-camera gap problem.This\npaper presents a novel framework that bifurcates the high-dimensional\nprediction task into two manageable subtasks: 2D keypoints detection and\nlifting 2D keypoints to 3D. This separation promises enhanced performance\nwithout sacrificing the efficiency innate to keypoint-based techniques.A vital\ncomponent of our method is the lifting of 2D keypoints to 3D keypoints. Common\ndeterministic regression methods may falter when faced with uncertainties from\n2D detection errors or self-occlusions.Leveraging the robust modeling potential\nof diffusion models, we reframe this issue as a conditional 3D keypoints\ngeneration task. To bolster cross-camera adaptability, we introduce\ntheNormalised Camera Coordinate Space (NCCS), ensuring alignment of estimated\n2D keypoints across varying camera intrinsics.Experimental results demonstrate\nthat the proposed method outperforms the state-of-the-art render\\&compare\nmethod and achieves higher inference speed.Furthermore, the tests accentuate\nour method's robust cross-camera generalisation capabilities.We intend to\nrelease both the dataset and code in https://nimolty.github.io/Robokeygen/\n","authors":["Yang Tian","Jiyao Zhang","Guowei Huang","Bin Wang","Ping Wang","Jiangmiao Pang","Hao Dong"],"pdf_url":"https://arxiv.org/pdf/2403.18259v1.pdf","comment":"Accepted by ICRA 2024"},{"id":"http://arxiv.org/abs/2403.18256v1","updated":"2024-03-27T04:56:48Z","published":"2024-03-27T04:56:48Z","title":"Manipulating Neural Path Planners via Slight Perturbations","summary":"  Data-driven neural path planners are attracting increasing interest in the\nrobotics community. However, their neural network components typically come as\nblack boxes, obscuring their underlying decision-making processes. Their\nblack-box nature exposes them to the risk of being compromised via the\ninsertion of hidden malicious behaviors. For example, an attacker may hide\nbehaviors that, when triggered, hijack a delivery robot by guiding it to a\nspecific (albeit wrong) destination, trapping it in a predefined region, or\ninducing unnecessary energy expenditure by causing the robot to repeatedly\ncircle a region. In this paper, we propose a novel approach to specify and\ninject a range of hidden malicious behaviors, known as backdoors, into neural\npath planners. Our approach provides a concise but flexible way to define these\nbehaviors, and we show that hidden behaviors can be triggered by slight\nperturbations (e.g., inserting a tiny unnoticeable object), that can\nnonetheless significantly compromise their integrity. We also discuss potential\ntechniques to identify these backdoors aimed at alleviating such risks. We\ndemonstrate our approach on both sampling-based and search-based neural path\nplanners.\n","authors":["Zikang Xiong","Suresh Jagannathan"],"pdf_url":"https://arxiv.org/pdf/2403.18256v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.11542v2","updated":"2024-03-27T04:39:26Z","published":"2024-01-21T16:51:07Z","title":"Nigel -- Mechatronic Design and Robust Sim2Real Control of an\n  Over-Actuated Autonomous Vehicle","summary":"  Simulation to reality (sim2real) transfer from a dynamics and controls\nperspective usually involves re-tuning or adapting the designed algorithms to\nsuit real-world operating conditions, which often violates the performance\nguarantees established originally. This work presents a generalizable framework\nfor achieving reliable sim2real transfer of autonomy-oriented control systems\nusing multi-model multi-objective robust optimal control synthesis, which lends\nwell to uncertainty handling and disturbance rejection with theoretical\nguarantees. Particularly, this work is centered around a novel\nactuation-redundant scaled autonomous vehicle called Nigel, with independent\nall-wheel drive and independent all-wheel steering architecture, whose enhanced\nconfiguration space bodes well for robust control applications. To this end, we\npresent the mechatronic design, dynamics modeling, parameter identification,\nand robust stabilizing as well as tracking control of Nigel using the proposed\nframework, with exhaustive experimentation and benchmarking in simulation as\nwell as real-world settings.\n","authors":["Chinmay Vilas Samak","Tanmay Vilas Samak","Javad Mohammadpour Velni","Venkat Narayan Krovi"],"pdf_url":"https://arxiv.org/pdf/2401.11542v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.08100v3","updated":"2024-03-27T04:00:07Z","published":"2023-11-14T11:53:24Z","title":"PPAD: Iterative Interactions of Prediction and Planning for End-to-end\n  Autonomous Driving","summary":"  We present a new interaction mechanism of prediction and planning for\nend-to-end autonomous driving, called PPAD (Iterative Interaction of Prediction\nand Planning Autonomous Driving), which considers the timestep-wise interaction\nto better integrate prediction and planning. An ego vehicle performs motion\nplanning at each timestep based on the trajectory prediction of surrounding\nagents (e.g., vehicles and pedestrians) and its local road conditions. Unlike\nexisting end-to-end autonomous driving frameworks, PPAD models the interactions\namong ego, agents, and the dynamic environment in an autoregressive manner by\ninterleaving the Prediction and Planning processes at every timestep, instead\nof a single sequential process of prediction followed by planning.\nSpecifically, we design ego-to-agent, ego-to-map, and ego-to-BEV interaction\nmechanisms with hierarchical dynamic key objects attention to better model the\ninteractions. The experiments on the nuScenes benchmark show that our approach\noutperforms state-of-the-art methods.\n","authors":["Zhili Chen","Maosheng Ye","Shuangjie Xu","Tongyi Cao","Qifeng Chen"],"pdf_url":"https://arxiv.org/pdf/2311.08100v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.01616v2","updated":"2024-03-27T03:56:35Z","published":"2023-12-04T04:14:09Z","title":"SchurVINS: Schur Complement-Based Lightweight Visual Inertial Navigation\n  System","summary":"  Accuracy and computational efficiency are the most important metrics to\nVisual Inertial Navigation System (VINS). The existing VINS algorithms with\neither high accuracy or low computational complexity, are difficult to provide\nthe high precision localization in resource-constrained devices. To this end,\nwe propose a novel filter-based VINS framework named SchurVINS, which could\nguarantee both high accuracy by building a complete residual model and low\ncomputational complexity with Schur complement. Technically, we first formulate\nthe full residual model where Gradient, Hessian and observation covariance are\nexplicitly modeled. Then Schur complement is employed to decompose the full\nmodel into ego-motion residual model and landmark residual model. Finally,\nExtended Kalman Filter (EKF) update is implemented in these two models with\nhigh efficiency. Experiments on EuRoC and TUM-VI datasets show that our method\nnotably outperforms state-of-the-art (SOTA) methods in both accuracy and\ncomputational complexity. The experimental code of SchurVINS is available at\nhttps://github.com/bytedance/SchurVINS.\n","authors":["Yunfei Fan","Tianyu Zhao","Guidong Wang"],"pdf_url":"https://arxiv.org/pdf/2312.01616v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18236v1","updated":"2024-03-27T03:53:30Z","published":"2024-03-27T03:53:30Z","title":"Multi-AGV Path Planning Method via Reinforcement Learning and Particle\n  Filters","summary":"  The Reinforcement Learning (RL) algorithm, renowned for its robust learning\ncapability and search stability, has garnered significant attention and found\nextensive application in Automated Guided Vehicle (AGV) path planning. However,\nRL planning algorithms encounter challenges stemming from the substantial\nvariance of neural networks caused by environmental instability and significant\nfluctuations in system structure. These challenges manifest in slow convergence\nspeed and low learning efficiency. To tackle this issue, this paper presents\nthe Particle Filter-Double Deep Q-Network (PF-DDQN) approach, which\nincorporates the Particle Filter (PF) into multi-AGV reinforcement learning\npath planning. The PF-DDQN method leverages the imprecise weight values of the\nnetwork as state values to formulate the state space equation. Through the\niterative fusion process of neural networks and particle filters, the DDQN\nmodel is optimized to acquire the optimal true weight values, thus enhancing\nthe algorithm's efficiency. The proposed method's effectiveness and superiority\nare validated through numerical simulations. Overall, the simulation results\ndemonstrate that the proposed algorithm surpasses the traditional DDQN\nalgorithm in terms of path planning superiority and training time indicators by\n92.62% and 76.88%, respectively. In conclusion, the PF-DDQN method addresses\nthe challenges encountered by RL planning algorithms in AGV path planning. By\nintegrating the Particle Filter and optimizing the DDQN model, the proposed\nmethod achieves enhanced efficiency and outperforms the traditional DDQN\nalgorithm in terms of path planning superiority and training time indicators.\n","authors":["Shao Shuo"],"pdf_url":"https://arxiv.org/pdf/2403.18236v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18222v1","updated":"2024-03-27T03:19:36Z","published":"2024-03-27T03:19:36Z","title":"Uncertainty-Aware Deployment of Pre-trained Language-Conditioned\n  Imitation Learning Policies","summary":"  Large-scale robotic policies trained on data from diverse tasks and robotic\nplatforms hold great promise for enabling general-purpose robots; however,\nreliable generalization to new environment conditions remains a major\nchallenge. Toward addressing this challenge, we propose a novel approach for\nuncertainty-aware deployment of pre-trained language-conditioned imitation\nlearning agents. Specifically, we use temperature scaling to calibrate these\nmodels and exploit the calibrated model to make uncertainty-aware decisions by\naggregating the local information of candidate actions. We implement our\napproach in simulation using three such pre-trained models, and showcase its\npotential to significantly enhance task completion rates. The accompanying code\nis accessible at the link:\nhttps://github.com/BobWu1998/uncertainty_quant_all.git\n","authors":["Bo Wu","Bruce D. Lee","Kostas Daniilidis","Bernadette Bucher","Nikolai Matni"],"pdf_url":"https://arxiv.org/pdf/2403.18222v1.pdf","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2310.04181v2","updated":"2024-03-27T02:51:24Z","published":"2023-10-06T11:53:04Z","title":"DiffPrompter: Differentiable Implicit Visual Prompts for\n  Semantic-Segmentation in Adverse Conditions","summary":"  Semantic segmentation in adverse weather scenarios is a critical task for\nautonomous driving systems. While foundation models have shown promise, the\nneed for specialized adaptors becomes evident for handling more challenging\nscenarios. We introduce DiffPrompter, a novel differentiable visual and latent\nprompting mechanism aimed at expanding the learning capabilities of existing\nadaptors in foundation models. Our proposed $\\nabla$HFC image processing block\nexcels particularly in adverse weather conditions, where conventional methods\noften fall short. Furthermore, we investigate the advantages of jointly\ntraining visual and latent prompts, demonstrating that this combined approach\nsignificantly enhances performance in out-of-distribution scenarios. Our\ndifferentiable visual prompts leverage parallel and series architectures to\ngenerate prompts, effectively improving object segmentation tasks in adverse\nconditions. Through a comprehensive series of experiments and evaluations, we\nprovide empirical evidence to support the efficacy of our approach. Project\npage at https://diffprompter.github.io.\n","authors":["Sanket Kalwar","Mihir Ungarala","Shruti Jain","Aaron Monis","Krishna Reddy Konda","Sourav Garg","K Madhava Krishna"],"pdf_url":"https://arxiv.org/pdf/2310.04181v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18212v1","updated":"2024-03-27T02:46:09Z","published":"2024-03-27T02:46:09Z","title":"Preference-Based Planning in Stochastic Environments: From\n  Partially-Ordered Temporal Goals to Most Preferred Policies","summary":"  Human preferences are not always represented via complete linear orders: It\nis natural to employ partially-ordered preferences for expressing incomparable\noutcomes. In this work, we consider decision-making and probabilistic planning\nin stochastic systems modeled as Markov decision processes (MDPs), given a\npartially ordered preference over a set of temporally extended goals.\nSpecifically, each temporally extended goal is expressed using a formula in\nLinear Temporal Logic on Finite Traces (LTL$_f$). To plan with the partially\nordered preference, we introduce order theory to map a preference over temporal\ngoals to a preference over policies for the MDP. Accordingly, a most preferred\npolicy under a stochastic ordering induces a stochastic nondominated\nprobability distribution over the finite paths in the MDP. To synthesize a most\npreferred policy, our technical approach includes two key steps. In the first\nstep, we develop a procedure to transform a partially ordered preference over\ntemporal goals into a computational model, called preference automaton, which\nis a semi-automaton with a partial order over acceptance conditions. In the\nsecond step, we prove that finding a most preferred policy is equivalent to\ncomputing a Pareto-optimal policy in a multi-objective MDP that is constructed\nfrom the original MDP, the preference automaton, and the chosen stochastic\nordering relation. Throughout the paper, we employ running examples to\nillustrate the proposed preference specification and solution approaches. We\ndemonstrate the efficacy of our algorithm using these examples, providing\ndetailed analysis, and then discuss several potential future directions.\n","authors":["Hazhar Rahmani","Abhishek N. Kulkarni","Jie Fu"],"pdf_url":"https://arxiv.org/pdf/2403.18212v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2209.12267"},{"id":"http://arxiv.org/abs/2403.18209v1","updated":"2024-03-27T02:41:52Z","published":"2024-03-27T02:41:52Z","title":"Long and Short-Term Constraints Driven Safe Reinforcement Learning for\n  Autonomous Driving","summary":"  Reinforcement learning (RL) has been widely used in decision-making tasks,\nbut it cannot guarantee the agent's safety in the training process due to the\nrequirements of interaction with the environment, which seriously limits its\nindustrial applications such as autonomous driving. Safe RL methods are\ndeveloped to handle this issue by constraining the expected safety violation\ncosts as a training objective, but they still permit unsafe state occurrence,\nwhich is unacceptable in autonomous driving tasks. Moreover, these methods are\ndifficult to achieve a balance between the cost and return expectations, which\nleads to learning performance degradation for the algorithms. In this paper, we\npropose a novel algorithm based on the long and short-term constraints (LSTC)\nfor safe RL. The short-term constraint aims to guarantee the short-term state\nsafety that the vehicle explores, while the long-term constraint ensures the\noverall safety of the vehicle throughout the decision-making process. In\naddition, we develop a safe RL method with dual-constraint optimization based\non the Lagrange multiplier to optimize the training process for end-to-end\nautonomous driving. Comprehensive experiments were conducted on the MetaDrive\nsimulator. Experimental results demonstrate that the proposed method achieves\nhigher safety in continuous state and action tasks, and exhibits higher\nexploration performance in long-distance decision-making tasks compared with\nstate-of-the-art methods.\n","authors":["Xuemin Hu","Pan Chen","Yijun Wen","Bo Tang","Long Chen"],"pdf_url":"https://arxiv.org/pdf/2403.18209v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17320v2","updated":"2024-03-27T02:39:30Z","published":"2024-03-26T02:02:35Z","title":"Leveraging Symmetry in RL-based Legged Locomotion Control","summary":"  Model-free reinforcement learning is a promising approach for autonomously\nsolving challenging robotics control problems, but faces exploration difficulty\nwithout information of the robot's kinematics and dynamics morphology. The\nunder-exploration of multiple modalities with symmetric states leads to\nbehaviors that are often unnatural and sub-optimal. This issue becomes\nparticularly pronounced in the context of robotic systems with morphological\nsymmetries, such as legged robots for which the resulting asymmetric and\naperiodic behaviors compromise performance, robustness, and transferability to\nreal hardware. To mitigate this challenge, we can leverage symmetry to guide\nand improve the exploration in policy learning via equivariance/invariance\nconstraints. In this paper, we investigate the efficacy of two approaches to\nincorporate symmetry: modifying the network architectures to be strictly\nequivariant/invariant, and leveraging data augmentation to approximate\nequivariant/invariant actor-critics. We implement the methods on challenging\nloco-manipulation and bipedal locomotion tasks and compare with an\nunconstrained baseline. We find that the strictly equivariant policy\nconsistently outperforms other methods in sample efficiency and task\nperformance in simulation. In addition, symmetry-incorporated approaches\nexhibit better gait quality, higher robustness and can be deployed zero-shot in\nreal-world experiments.\n","authors":["Zhi Su","Xiaoyu Huang","Daniel Ordoñez-Apraez","Yunfei Li","Zhongyu Li","Qiayuan Liao","Giulio Turrisi","Massimiliano Pontil","Claudio Semini","Yi Wu","Koushil Sreenath"],"pdf_url":"https://arxiv.org/pdf/2403.17320v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18207v1","updated":"2024-03-27T02:35:36Z","published":"2024-03-27T02:35:36Z","title":"Road Obstacle Detection based on Unknown Objectness Scores","summary":"  The detection of unknown traffic obstacles is vital to ensure safe autonomous\ndriving. The standard object-detection methods cannot identify unknown objects\nthat are not included under predefined categories. This is because\nobject-detection methods are trained to assign a background label to pixels\ncorresponding to the presence of unknown objects. To address this problem, the\npixel-wise anomaly-detection approach has attracted increased research\nattention. Anomaly-detection techniques, such as uncertainty estimation and\nperceptual difference from reconstructed images, make it possible to identify\npixels of unknown objects as out-of-distribution (OoD) samples. However, when\napplied to images with many unknowns and complex components, such as driving\nscenes, these methods often exhibit unstable performance. The purpose of this\nstudy is to achieve stable performance for detecting unknown objects by\nincorporating the object-detection fashions into the pixel-wise anomaly\ndetection methods. To achieve this goal, we adopt a semantic-segmentation\nnetwork with a sigmoid head that simultaneously provides pixel-wise anomaly\nscores and objectness scores. Our experimental results show that the objectness\nscores play an important role in improving the detection performance. Based on\nthese results, we propose a novel anomaly score by integrating these two\nscores, which we term as unknown objectness score. Quantitative evaluations\nshow that the proposed method outperforms state-of-the-art methods when applied\nto the publicly available datasets.\n","authors":["Chihiro Noguchi","Toshiaki Ohgushi","Masao Yamanaka"],"pdf_url":"https://arxiv.org/pdf/2403.18207v1.pdf","comment":"ICRA 2024"},{"id":"http://arxiv.org/abs/2403.18206v1","updated":"2024-03-27T02:33:15Z","published":"2024-03-27T02:33:15Z","title":"Sailing Through Point Clouds: Safe Navigation Using Point Cloud Based\n  Control Barrier Functions","summary":"  The capability to navigate safely in an unstructured environment is crucial\nwhen deploying robotic systems in real-world scenarios. Recently, control\nbarrier function (CBF) based approaches have been highly effective in\nsynthesizing safety-critical controllers. In this work, we propose a novel\nCBF-based local planner comprised of two components: Vessel and Mariner. The\nVessel is a novel scaling factor based CBF formulation that synthesizes CBFs\nusing only point cloud data. The Mariner is a CBF-based preview control\nframework that is used to mitigate getting stuck in spurious equilibria during\nnavigation. To demonstrate the efficacy of our proposed approach, we first\ncompare the proposed point cloud based CBF formulation with other point cloud\nbased CBF formulations. Then, we demonstrate the performance of our proposed\napproach and its integration with global planners using experimental studies on\nthe Unitree B1 and Unitree Go2 quadruped robots in various environments.\n","authors":["Bolun Dai","Rooholla Khorrambakht","Prashanth Krishnamurthy","Farshad Khorrami"],"pdf_url":"https://arxiv.org/pdf/2403.18206v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.00911v2","updated":"2024-03-27T02:31:36Z","published":"2023-08-02T02:37:24Z","title":"Optimal Sensor Deception to Deviate from an Allowed Itinerary","summary":"  In this work, we study a class of deception planning problems in which an\nagent aims to alter a security monitoring system's sensor readings so as to\ndisguise its adversarial itinerary as an allowed itinerary in the environment.\nThe adversarial itinerary set and allowed itinerary set are captured by regular\nlanguages. To deviate without being detected, we investigate whether there\nexists a strategy for the agent to alter the sensor readings, with a minimal\ncost, such that for any of those paths it takes, the system thinks the agent\ntook a path within the allowed itinerary. Our formulation assumes an offline\nsensor alteration where the agent determines the sensor alteration strategy and\nimplement it, and then carry out any path in its deviation itinerary. We prove\nthat the problem of solving the optimal sensor alteration is NP-hard, by a\nreduction from the directed multi-cut problem. Further, we present an exact\nalgorithm based on integer linear programming and demonstrate the correctness\nand the efficacy of the algorithm in case studies.\n","authors":["Hazhar Rahmani","Arash Ahadi","Jie Fu"],"pdf_url":"https://arxiv.org/pdf/2308.00911v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18197v1","updated":"2024-03-27T02:13:24Z","published":"2024-03-27T02:13:24Z","title":"LocoMan: Advancing Versatile Quadrupedal Dexterity with Lightweight\n  Loco-Manipulators","summary":"  Quadrupedal robots have emerged as versatile agents capable of locomoting and\nmanipulating in complex environments. Traditional designs typically rely on the\nrobot's inherent body parts or incorporate top-mounted arms for manipulation\ntasks. However, these configurations may limit the robot's operational\ndexterity, efficiency and adaptability, particularly in cluttered or\nconstrained spaces. In this work, we present LocoMan, a dexterous quadrupedal\nrobot with a novel morphology to perform versatile manipulation in diverse\nconstrained environments. By equipping a Unitree Go1 robot with two low-cost\nand lightweight modular 3-DoF loco-manipulators on its front calves, LocoMan\nleverages the combined mobility and functionality of the legs and grippers for\ncomplex manipulation tasks that require precise 6D positioning of the end\neffector in a wide workspace. To harness the loco-manipulation capabilities of\nLocoMan, we introduce a unified control framework that extends the whole-body\ncontroller (WBC) to integrate the dynamics of loco-manipulators. Through\nexperiments, we validate that the proposed whole-body controller can accurately\nand stably follow desired 6D trajectories of the end effector and torso, which,\nwhen combined with the large workspace from our design, facilitates a diverse\nset of challenging dexterous loco-manipulation tasks in confined spaces, such\nas opening doors, plugging into sockets, picking objects in narrow and\nlow-lying spaces, and bimanual manipulation.\n","authors":["Changyi Lin","Xingyu Liu","Yuxiang Yang","Yaru Niu","Wenhao Yu","Tingnan Zhang","Jie Tan","Byron Boots","Ding Zhao"],"pdf_url":"https://arxiv.org/pdf/2403.18197v1.pdf","comment":"Project page: https://linchangyi1.github.io/LocoMan"},{"id":"http://arxiv.org/abs/2403.18195v1","updated":"2024-03-27T02:08:12Z","published":"2024-03-27T02:08:12Z","title":"SCANet: Correcting LEGO Assembly Errors with Self-Correct Assembly\n  Network","summary":"  Autonomous assembly in robotics and 3D vision presents significant\nchallenges, particularly in ensuring assembly correctness. Presently,\npredominant methods such as MEPNet focus on assembling components based on\nmanually provided images. However, these approaches often fall short in\nachieving satisfactory results for tasks requiring long-term planning.\nConcurrently, we observe that integrating a self-correction module can\npartially alleviate such issues. Motivated by this concern, we introduce the\nsingle-step assembly error correction task, which involves identifying and\nrectifying misassembled components. To support research in this area, we\npresent the LEGO Error Correction Assembly Dataset (LEGO-ECA), comprising\nmanual images for assembly steps and instances of assembly failures.\nAdditionally, we propose the Self-Correct Assembly Network (SCANet), a novel\nmethod to address this task. SCANet treats assembled components as queries,\ndetermining their correctness in manual images and providing corrections when\nnecessary. Finally, we utilize SCANet to correct the assembly results of\nMEPNet. Experimental results demonstrate that SCANet can identify and correct\nMEPNet's misassembled results, significantly improving the correctness of\nassembly. Our code and dataset are available at\nhttps://github.com/Yaser-wyx/SCANet.\n","authors":["Yuxuan Wan","Kaichen Zhou","jinhong Chen","Hao Dong"],"pdf_url":"https://arxiv.org/pdf/2403.18195v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18178v1","updated":"2024-03-27T01:12:31Z","published":"2024-03-27T01:12:31Z","title":"Online Embedding Multi-Scale CLIP Features into 3D Maps","summary":"  This study introduces a novel approach to online embedding of multi-scale\nCLIP (Contrastive Language-Image Pre-Training) features into 3D maps. By\nharnessing CLIP, this methodology surpasses the constraints of conventional\nvocabulary-limited methods and enables the incorporation of semantic\ninformation into the resultant maps. While recent approaches have explored the\nembedding of multi-modal features in maps, they often impose significant\ncomputational costs, lacking practicality for exploring unfamiliar environments\nin real time. Our approach tackles these challenges by efficiently computing\nand embedding multi-scale CLIP features, thereby facilitating the exploration\nof unfamiliar environments through real-time map generation. Moreover, the\nembedding CLIP features into the resultant maps makes offline retrieval via\nlinguistic queries feasible. In essence, our approach simultaneously achieves\nreal-time object search and mapping of unfamiliar environments. Additionally,\nwe propose a zero-shot object-goal navigation system based on our mapping\napproach, and we validate its efficacy through object-goal navigation, offline\nobject retrieval, and multi-object-goal navigation in both simulated\nenvironments and real robot experiments. The findings demonstrate that our\nmethod not only exhibits swifter performance than state-of-the-art mapping\nmethods but also surpasses them in terms of the success rate of object-goal\nnavigation tasks.\n","authors":["Shun Taguchi","Hideki Deguchi"],"pdf_url":"https://arxiv.org/pdf/2403.18178v1.pdf","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2403.18172v1","updated":"2024-03-27T00:58:31Z","published":"2024-03-27T00:58:31Z","title":"Vision-Based Force Estimation for Minimally Invasive Telesurgery Through\n  Contact Detection and Local Stiffness Models","summary":"  In minimally invasive telesurgery, obtaining accurate force information is\ndifficult due to the complexities of in-vivo end effector force sensing. This\nconstrains development and implementation of haptic feedback and force-based\nautomated performance metrics, respectively. Vision-based force sensing\napproaches using deep learning are a promising alternative to intrinsic end\neffector force sensing. However, they have limited ability to generalize to\nnovel scenarios, and require learning on high-quality force sensor training\ndata that can be difficult to obtain. To address these challenges, this paper\npresents a novel vision-based contact-conditional approach for force estimation\nin telesurgical environments. Our method leverages supervised learning with\nhuman labels and end effector position data to train deep neural networks.\nPredictions from these trained models are optionally combined with robot joint\ntorque information to estimate forces indirectly from visual data. We benchmark\nour method against ground truth force sensor data and demonstrate generality by\nfine-tuning to novel surgical scenarios in a data-efficient manner. Our methods\ndemonstrated greater than 90% accuracy on contact detection and less than 10%\nforce prediction error. These results suggest potential usefulness of\ncontact-conditional force estimation for sensory substitution haptic feedback\nand tissue handling skill evaluation in clinical settings.\n","authors":["Shuyuan Yang","My H. Le","Kyle R. Golobish","Juan C. Beaver","Zonghe Chua"],"pdf_url":"https://arxiv.org/pdf/2403.18172v1.pdf","comment":"Preprint of an article accepted in Journal of Medical Robotics\n  Research \\copyright 2024 copyright World Scientific Publishing Company"}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2403.18814v1","updated":"2024-03-27T17:59:04Z","published":"2024-03-27T17:59:04Z","title":"Mini-Gemini: Mining the Potential of Multi-modality Vision Language\n  Models","summary":"  In this work, we introduce Mini-Gemini, a simple and effective framework\nenhancing multi-modality Vision Language Models (VLMs). Despite the\nadvancements in VLMs facilitating basic visual dialog and reasoning, a\nperformance gap persists compared to advanced models like GPT-4 and Gemini. We\ntry to narrow the gap by mining the potential of VLMs for better performance\nand any-to-any workflow from three aspects, i.e., high-resolution visual\ntokens, high-quality data, and VLM-guided generation. To enhance visual tokens,\nwe propose to utilize an additional visual encoder for high-resolution\nrefinement without increasing the visual token count. We further construct a\nhigh-quality dataset that promotes precise image comprehension and\nreasoning-based generation, expanding the operational scope of current VLMs. In\ngeneral, Mini-Gemini further mines the potential of VLMs and empowers current\nframeworks with image understanding, reasoning, and generation simultaneously.\nMini-Gemini supports a series of dense and MoE Large Language Models (LLMs)\nfrom 2B to 34B. It is demonstrated to achieve leading performance in several\nzero-shot benchmarks and even surpasses the developed private models. Code and\nmodels are available at https://github.com/dvlab-research/MiniGemini.\n","authors":["Yanwei Li","Yuechen Zhang","Chengyao Wang","Zhisheng Zhong","Yixin Chen","Ruihang Chu","Shaoteng Liu","Jiaya Jia"],"pdf_url":"https://arxiv.org/pdf/2403.18814v1.pdf","comment":"Code and models are available at\n  https://github.com/dvlab-research/MiniGemini"},{"id":"http://arxiv.org/abs/2403.18807v1","updated":"2024-03-27T17:53:30Z","published":"2024-03-27T17:53:30Z","title":"ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth\n  Estimation","summary":"  In the absence of parallax cues, a learning-based single image depth\nestimation (SIDE) model relies heavily on shading and contextual cues in the\nimage. While this simplicity is attractive, it is necessary to train such\nmodels on large and varied datasets, which are difficult to capture. It has\nbeen shown that using embeddings from pre-trained foundational models, such as\nCLIP, improves zero shot transfer in several applications. Taking inspiration\nfrom this, in our paper we explore the use of global image priors generated\nfrom a pre-trained ViT model to provide more detailed contextual information.\nWe argue that the embedding vector from a ViT model, pre-trained on a large\ndataset, captures greater relevant information for SIDE than the usual route of\ngenerating pseudo image captions, followed by CLIP based text embeddings. Based\non this idea, we propose a new SIDE model using a diffusion backbone which is\nconditioned on ViT embeddings. Our proposed design establishes a new\nstate-of-the-art (SOTA) for SIDE on NYUv2 dataset, achieving Abs Rel error of\n0.059(14% improvement) compared to 0.069 by the current SOTA (VPD). And on\nKITTI dataset, achieving Sq Rel error of 0.139 (2% improvement) compared to\n0.142 by the current SOTA (GEDepth). For zero-shot transfer with a model\ntrained on NYUv2, we report mean relative improvement of (20%, 23%, 81%, 25%)\nover NeWCRFs on (Sun-RGBD, iBims1, DIODE, HyperSim) datasets, compared to (16%,\n18%, 45%, 9%) by ZoeDepth. The code is available at\nhttps://github.com/Aradhye2002/EcoDepth.\n","authors":["Suraj Patni","Aradhye Agarwal","Chetan Arora"],"pdf_url":"https://arxiv.org/pdf/2403.18807v1.pdf","comment":"Accepted at IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition (CVPR) 2024"},{"id":"http://arxiv.org/abs/2403.18802v1","updated":"2024-03-27T17:48:55Z","published":"2024-03-27T17:48:55Z","title":"Long-form factuality in large language models","summary":"  Large language models (LLMs) often generate content that contains factual\nerrors when responding to fact-seeking prompts on open-ended topics. To\nbenchmark a model's long-form factuality in open domains, we first use GPT-4 to\ngenerate LongFact, a prompt set comprising thousands of questions spanning 38\ntopics. We then propose that LLM agents can be used as automated evaluators for\nlong-form factuality through a method which we call Search-Augmented Factuality\nEvaluator (SAFE). SAFE utilizes an LLM to break down a long-form response into\na set of individual facts and to evaluate the accuracy of each fact using a\nmulti-step reasoning process comprising sending search queries to Google Search\nand determining whether a fact is supported by the search results. Furthermore,\nwe propose extending F1 score as an aggregated metric for long-form factuality.\nTo do so, we balance the percentage of supported facts in a response\n(precision) with the percentage of provided facts relative to a hyperparameter\nrepresenting a user's preferred response length (recall).\n  Empirically, we demonstrate that LLM agents can achieve superhuman rating\nperformance - on a set of ~16k individual facts, SAFE agrees with crowdsourced\nhuman annotators 72% of the time, and on a random subset of 100 disagreement\ncases, SAFE wins 76% of the time. At the same time, SAFE is more than 20 times\ncheaper than human annotators. We also benchmark thirteen language models on\nLongFact across four model families (Gemini, GPT, Claude, and PaLM-2), finding\nthat larger language models generally achieve better long-form factuality.\nLongFact, SAFE, and all experimental code are available at\nhttps://github.com/google-deepmind/long-form-factuality.\n","authors":["Jerry Wei","Chengrun Yang","Xinying Song","Yifeng Lu","Nathan Hu","Dustin Tran","Daiyi Peng","Ruibo Liu","Da Huang","Cosmo Du","Quoc V. Le"],"pdf_url":"https://arxiv.org/pdf/2403.18802v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.13525v2","updated":"2024-03-27T17:47:56Z","published":"2023-05-22T22:41:49Z","title":"A 4D Hybrid Algorithm to Scale Parallel Training to Thousands of GPUs","summary":"  Large communication costs are a critical bottleneck in training\nstate-of-the-art neural networks on distributed systems. This paper introduces\nAxoNN, a novel four-dimensional (4D) parallelization approach, inspired by\nAgarwal's algorithm for matrix multiplication, for parallelizing tensor\ncomputations in deep learning, AxoNN employs two key strategies to minimize\ncommunication overhead. First, we optimize communication by overlapping\nexpensive collective operations (reduce-scatter, all-gather, all-reduce) with\ncomputations. Our experiments with a 20-billion parameter transformer model\ndemonstrate that these optimizations deliver nearly 53\\% improvement. Second,\nwe present an analytical model to assist users in identifying\ncommunication-minimizing configurations within the vast search space defined by\nour 4D algorithm. This model empowers practitioners by simplifying the tuning\nprocess for their specific training workloads. When training an 80-billion\nparameter model on 1024 GPUs of Perlmutter, AxoNN surpasses Megatron-LM, a\nstate-of-the-art framework, by a significant 26%. Additionally, it achieves 57%\nof the theoretical peak FLOP/s.\n","authors":["Siddharth Singh","Prajwal Singhania","Aditya K. Ranjan","Zack Sating","Abhinav Bhatele"],"pdf_url":"https://arxiv.org/pdf/2305.13525v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10319v4","updated":"2024-03-27T17:41:50Z","published":"2023-11-17T04:04:29Z","title":"Shifting to Machine Supervision: Annotation-Efficient Semi and\n  Self-Supervised Learning for Automatic Medical Image Segmentation and\n  Classification","summary":"  Advancements in clinical treatment are increasingly constrained by the\nlimitations of supervised learning techniques, which depend heavily on large\nvolumes of annotated data. The annotation process is not only costly but also\ndemands substantial time from clinical specialists. Addressing this issue, we\nintroduce the S4MI (Self-Supervision and Semi-Supervision for Medical Imaging)\npipeline, a novel approach that leverages advancements in self-supervised and\nsemi-supervised learning. These techniques engage in auxiliary tasks that do\nnot require labeling, thus simplifying the scaling of machine supervision\ncompared to fully-supervised methods. Our study benchmarks these techniques on\nthree distinct medical imaging datasets to evaluate their effectiveness in\nclassification and segmentation tasks. Notably, we observed that self\nsupervised learning significantly surpassed the performance of supervised\nmethods in the classification of all evaluated datasets. Remarkably, the\nsemi-supervised approach demonstrated superior outcomes in segmentation,\noutperforming fully-supervised methods while using 50% fewer labels across all\ndatasets. In line with our commitment to contributing to the scientific\ncommunity, we have made the S4MI code openly accessible, allowing for broader\napplication and further development of these methods.\n","authors":["Pranav Singh","Raviteja Chukkapalli","Shravan Chaudhari","Luoyao Chen","Mei Chen","Jinqian Pan","Craig Smuda","Jacopo Cirrone"],"pdf_url":"https://arxiv.org/pdf/2311.10319v4.pdf","comment":"Seventeen pages (incl. references), five figures, and one table.\n  (Under Review)"},{"id":"http://arxiv.org/abs/2403.18795v1","updated":"2024-03-27T17:40:14Z","published":"2024-03-27T17:40:14Z","title":"Gamba: Marry Gaussian Splatting with Mamba for single view 3D\n  reconstruction","summary":"  We tackle the challenge of efficiently reconstructing a 3D asset from a\nsingle image with growing demands for automated 3D content creation pipelines.\nPrevious methods primarily rely on Score Distillation Sampling (SDS) and Neural\nRadiance Fields (NeRF). Despite their significant success, these approaches\nencounter practical limitations due to lengthy optimization and considerable\nmemory usage. In this report, we introduce Gamba, an end-to-end amortized 3D\nreconstruction model from single-view images, emphasizing two main insights:\n(1) 3D representation: leveraging a large number of 3D Gaussians for an\nefficient 3D Gaussian splatting process; (2) Backbone design: introducing a\nMamba-based sequential network that facilitates context-dependent reasoning and\nlinear scalability with the sequence (token) length, accommodating a\nsubstantial number of Gaussians. Gamba incorporates significant advancements in\ndata preprocessing, regularization design, and training methodologies. We\nassessed Gamba against existing optimization-based and feed-forward 3D\ngeneration approaches using the real-world scanned OmniObject3D dataset. Here,\nGamba demonstrates competitive generation capabilities, both qualitatively and\nquantitatively, while achieving remarkable speed, approximately 0.6 second on a\nsingle NVIDIA A100 GPU.\n","authors":["Qiuhong Shen","Xuanyu Yi","Zike Wu","Pan Zhou","Hanwang Zhang","Shuicheng Yan","Xinchao Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18795v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.17574v2","updated":"2024-03-27T17:34:57Z","published":"2024-02-27T15:09:20Z","title":"Agent-Pro: Learning to Evolve via Policy-Level Reflection and\n  Optimization","summary":"  Large Language Models exhibit robust problem-solving capabilities for diverse\ntasks. However, most LLM-based agents are designed as specific task solvers\nwith sophisticated prompt engineering, rather than agents capable of learning\nand evolving through interactions. These task solvers necessitate manually\ncrafted prompts to inform task rules and regulate LLM behaviors, inherently\nincapacitating to address complex dynamic scenarios e.g., large interactive\ngames. In light of this, we propose Agent-Pro: an LLM-based Agent with\nPolicy-level Reflection and Optimization that can learn a wealth of expertise\nfrom interactive experiences and progressively elevate its behavioral policy.\nSpecifically, it involves a dynamic belief generation and reflection process\nfor policy evolution. Rather than action-level reflection, Agent-Pro\niteratively reflects on past trajectories and beliefs, fine-tuning its\nirrational beliefs for a better policy. Moreover, a depth-first search is\nemployed for policy optimization, ensuring continual enhancement in policy\npayoffs. Agent-Pro is evaluated across two games: Blackjack and Texas Hold'em,\noutperforming vanilla LLM and specialized models. Our results show Agent-Pro\ncan learn and evolve in complex and dynamic scenes, which also benefits\nnumerous LLM-based applications.\n","authors":["Wenqi Zhang","Ke Tang","Hai Wu","Mengna Wang","Yongliang Shen","Guiyang Hou","Zeqi Tan","Peng Li","Yueting Zhuang","Weiming Lu"],"pdf_url":"https://arxiv.org/pdf/2402.17574v2.pdf","comment":"LLM-based Agent"},{"id":"http://arxiv.org/abs/2401.02009v2","updated":"2024-03-27T17:24:47Z","published":"2024-01-04T00:32:33Z","title":"Self-Contrast: Better Reflection Through Inconsistent Solving\n  Perspectives","summary":"  The reflection capacity of Large Language Model (LLM) has garnered extensive\nattention. A post-hoc prompting strategy, e.g., reflexion and self-refine,\nrefines LLM's response based on self-evaluated or external feedback. However,\nrecent research indicates without external feedback, LLM's intrinsic reflection\nis unstable. Our investigation unveils that the key bottleneck is the quality\nof the self-evaluated feedback. We find LLMs often exhibit overconfidence or\nhigh randomness when self-evaluate, offering stubborn or inconsistent feedback,\nwhich causes poor reflection. To remedy this, we advocate Self-Contrast: It\nadaptively explores diverse solving perspectives tailored to the request,\ncontrasts the differences, and summarizes these discrepancies into a checklist\nwhich could be used to re-examine and eliminate discrepancies. Our method\nendows LLM with diverse perspectives to alleviate stubborn biases. Moreover,\ntheir discrepancies indicate potential errors or inherent uncertainties that\nLLM often overlooks. Reflecting upon these can catalyze more accurate and\nstable reflection. Experiments conducted on a series of reasoning and\ntranslation tasks with different LLMs serve to underscore the effectiveness and\ngenerality of our strategy.\n","authors":["Wenqi Zhang","Yongliang Shen","Linjuan Wu","Qiuying Peng","Jun Wang","Yueting Zhuang","Weiming Lu"],"pdf_url":"https://arxiv.org/pdf/2401.02009v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18775v1","updated":"2024-03-27T17:23:39Z","published":"2024-03-27T17:23:39Z","title":"ImageNet-D: Benchmarking Neural Network Robustness on Diffusion\n  Synthetic Object","summary":"  We establish rigorous benchmarks for visual perception robustness. Synthetic\nimages such as ImageNet-C, ImageNet-9, and Stylized ImageNet provide specific\ntype of evaluation over synthetic corruptions, backgrounds, and textures, yet\nthose robustness benchmarks are restricted in specified variations and have low\nsynthetic quality. In this work, we introduce generative model as a data source\nfor synthesizing hard images that benchmark deep models' robustness. Leveraging\ndiffusion models, we are able to generate images with more diversified\nbackgrounds, textures, and materials than any prior work, where we term this\nbenchmark as ImageNet-D. Experimental results show that ImageNet-D results in a\nsignificant accuracy drop to a range of vision models, from the standard ResNet\nvisual classifier to the latest foundation models like CLIP and MiniGPT-4,\nsignificantly reducing their accuracy by up to 60\\%. Our work suggests that\ndiffusion models can be an effective source to test vision models. The code and\ndataset are available at https://github.com/chenshuang-zhang/imagenet_d.\n","authors":["Chenshuang Zhang","Fei Pan","Junmo Kim","In So Kweon","Chengzhi Mao"],"pdf_url":"https://arxiv.org/pdf/2403.18775v1.pdf","comment":"Accepted at CVPR 2024"},{"id":"http://arxiv.org/abs/2309.04381v2","updated":"2024-03-27T17:07:47Z","published":"2023-09-08T15:23:40Z","title":"Generalization Bounds: Perspectives from Information Theory and\n  PAC-Bayes","summary":"  A fundamental question in theoretical machine learning is generalization.\nOver the past decades, the PAC-Bayesian approach has been established as a\nflexible framework to address the generalization capabilities of machine\nlearning algorithms, and design new ones. Recently, it has garnered increased\ninterest due to its potential applicability for a variety of learning\nalgorithms, including deep neural networks. In parallel, an\ninformation-theoretic view of generalization has developed, wherein the\nrelation between generalization and various information measures has been\nestablished. This framework is intimately connected to the PAC-Bayesian\napproach, and a number of results have been independently discovered in both\nstrands. In this monograph, we highlight this strong connection and present a\nunified treatment of PAC-Bayesian and information-theoretic generalization\nbounds. We present techniques and results that the two perspectives have in\ncommon, and discuss the approaches and interpretations that differ. In\nparticular, we demonstrate how many proofs in the area share a modular\nstructure, through which the underlying ideas can be intuited. We pay special\nattention to the conditional mutual information (CMI) framework; analytical\nstudies of the information complexity of learning algorithms; and the\napplication of the proposed methods to deep learning. This monograph is\nintended to provide a comprehensive introduction to information-theoretic\ngeneralization bounds and their connection to PAC-Bayes, serving as a\nfoundation from which the most recent developments are accessible. It is aimed\nbroadly towards researchers with an interest in generalization and theoretical\nmachine learning.\n","authors":["Fredrik Hellström","Giuseppe Durisi","Benjamin Guedj","Maxim Raginsky"],"pdf_url":"https://arxiv.org/pdf/2309.04381v2.pdf","comment":"228 pages"},{"id":"http://arxiv.org/abs/2403.06054v4","updated":"2024-03-27T17:06:10Z","published":"2024-03-10T00:47:05Z","title":"Decoupled Data Consistency with Diffusion Purification for Image\n  Restoration","summary":"  Diffusion models have recently gained traction as a powerful class of deep\ngenerative priors, excelling in a wide range of image restoration tasks due to\ntheir exceptional ability to model data distributions. To solve image\nrestoration problems, many existing techniques achieve data consistency by\nincorporating additional likelihood gradient steps into the reverse sampling\nprocess of diffusion models. However, the additional gradient steps pose a\nchallenge for real-world practical applications as they incur a large\ncomputational overhead, thereby increasing inference time. They also present\nadditional difficulties when using accelerated diffusion model samplers, as the\nnumber of data consistency steps is limited by the number of reverse sampling\nsteps. In this work, we propose a novel diffusion-based image restoration\nsolver that addresses these issues by decoupling the reverse process from the\ndata consistency steps. Our method involves alternating between a\nreconstruction phase to maintain data consistency and a refinement phase that\nenforces the prior via diffusion purification. Our approach demonstrates\nversatility, making it highly adaptable for efficient problem-solving in latent\nspace. Additionally, it reduces the necessity for numerous sampling steps\nthrough the integration of consistency models. The efficacy of our approach is\nvalidated through comprehensive experiments across various image restoration\ntasks, including image denoising, deblurring, inpainting, and super-resolution.\n","authors":["Xiang Li","Soo Min Kwon","Ismail R. Alkhouri","Saiprasad Ravishankar","Qing Qu"],"pdf_url":"https://arxiv.org/pdf/2403.06054v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18766v1","updated":"2024-03-27T17:05:03Z","published":"2024-03-27T17:05:03Z","title":"Superior Parallel Big Data Clustering through Competitive Stochastic\n  Sample Size Optimization in Big-means","summary":"  This paper introduces a novel K-means clustering algorithm, an advancement on\nthe conventional Big-means methodology. The proposed method efficiently\nintegrates parallel processing, stochastic sampling, and competitive\noptimization to create a scalable variant designed for big data applications.\nIt addresses scalability and computation time challenges typically faced with\ntraditional techniques. The algorithm adjusts sample sizes dynamically for each\nworker during execution, optimizing performance. Data from these sample sizes\nare continually analyzed, facilitating the identification of the most efficient\nconfiguration. By incorporating a competitive element among workers using\ndifferent sample sizes, efficiency within the Big-means algorithm is further\nstimulated. In essence, the algorithm balances computational time and\nclustering quality by employing a stochastic, competitive sampling strategy in\na parallel computing setting.\n","authors":["Rustam Mussabayev","Ravil Mussabayev"],"pdf_url":"https://arxiv.org/pdf/2403.18766v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18762v1","updated":"2024-03-27T17:01:10Z","published":"2024-03-27T17:01:10Z","title":"ModaLink: Unifying Modalities for Efficient Image-to-PointCloud Place\n  Recognition","summary":"  Place recognition is an important task for robots and autonomous cars to\nlocalize themselves and close loops in pre-built maps. While single-modal\nsensor-based methods have shown satisfactory performance, cross-modal place\nrecognition that retrieving images from a point-cloud database remains a\nchallenging problem. Current cross-modal methods transform images into 3D\npoints using depth estimation for modality conversion, which are usually\ncomputationally intensive and need expensive labeled data for depth\nsupervision. In this work, we introduce a fast and lightweight framework to\nencode images and point clouds into place-distinctive descriptors. We propose\nan effective Field of View (FoV) transformation module to convert point clouds\ninto an analogous modality as images. This module eliminates the necessity for\ndepth estimation and helps subsequent modules achieve real-time performance. We\nfurther design a non-negative factorization-based encoder to extract mutually\nconsistent semantic features between point clouds and images. This encoder\nyields more distinctive global descriptors for retrieval. Experimental results\non the KITTI dataset show that our proposed methods achieve state-of-the-art\nperformance while running in real time. Additional evaluation on the HAOMO\ndataset covering a 17 km trajectory further shows the practical generalization\ncapabilities. We have released the implementation of our methods as open source\nat: https://github.com/haomo-ai/ModaLink.git.\n","authors":["Weidong Xie","Lun Luo","Nanfei Ye","Yi Ren","Shaoyi Du","Minhang Wang","Jintao Xu","Rui Ai","Weihao Gu","Xieyuanli Chen"],"pdf_url":"https://arxiv.org/pdf/2403.18762v1.pdf","comment":"8 pages, 11 figures, conference"},{"id":"http://arxiv.org/abs/2311.01483v3","updated":"2024-03-27T16:56:23Z","published":"2023-11-02T14:47:06Z","title":"FedSN: A Novel Federated Learning Framework over LEO Satellite Networks","summary":"  Recently, a large number of Low Earth Orbit (LEO) satellites have been\nlaunched and deployed successfully in space by commercial companies, such as\nSpaceX. Due to multimodal sensors equipped by the LEO satellites, they serve\nnot only for communication but also for various machine learning applications,\nsuch as space modulation recognition, remote sensing image classification, etc.\nHowever, the ground station (GS) may be incapable of downloading such a large\nvolume of raw sensing data for centralized model training due to the limited\ncontact time with LEO satellites (e.g. 5 minutes). Therefore, federated\nlearning (FL) has emerged as the promising solution to address this problem via\non-device training. Unfortunately, to enable FL on LEO satellites, we still\nface three critical challenges that are i) heterogeneous computing and memory\ncapabilities, ii) limited uplink rate, and iii) model staleness. To this end,\nwe propose FedSN as a general FL framework to tackle the above challenges, and\nfully explore data diversity on LEO satellites. Specifically, we first present\na novel sub-structure scheme to enable heterogeneous local model training\nconsidering different computing, memory, and communication constraints on LEO\nsatellites. Additionally, we propose a pseudo-synchronous model aggregation\nstrategy to dynamically schedule model aggregation for compensating model\nstaleness. To further demonstrate the effectiveness of the FedSN, we evaluate\nit using space modulation recognition and remote sensing image classification\ntasks by leveraging the data from real-world satellite networks. Extensive\nexperimental results demonstrate that FedSN framework achieves higher accuracy,\nlower computing, and communication overhead than the state-of-the-art\nbenchmarks and the effectiveness of each components in FedSN.\n","authors":["Zheng Lin","Zhe Chen","Zihan Fang","Xianhao Chen","Xiong Wang","Yue Gao"],"pdf_url":"https://arxiv.org/pdf/2311.01483v3.pdf","comment":"14 pages, 17 figures"},{"id":"http://arxiv.org/abs/2403.18756v1","updated":"2024-03-27T16:56:14Z","published":"2024-03-27T16:56:14Z","title":"Detection of subclinical atherosclerosis by image-based deep learning on\n  chest x-ray","summary":"  Aims. To develop a deep-learning based system for recognition of subclinical\natherosclerosis on a plain frontal chest x-ray. Methods and Results. A\ndeep-learning algorithm to predict coronary artery calcium (CAC) score (the\nAI-CAC model) was developed on 460 chest x-ray (80% training cohort, 20%\ninternal validation cohort) of primary prevention patients (58.4% male, median\nage 63 [51-74] years) with available paired chest x-ray and chest computed\ntomography (CT) indicated for any clinical reason and performed within 3\nmonths. The CAC score calculated on chest CT was used as ground truth. The\nmodel was validated on an temporally-independent cohort of 90 patients from the\nsame institution (external validation). The diagnostic accuracy of the AI-CAC\nmodel assessed by the area under the curve (AUC) was the primary outcome.\nOverall, median AI-CAC score was 35 (0-388) and 28.9% patients had no AI-CAC.\nAUC of the AI-CAC model to identify a CAC>0 was 0.90 in the internal validation\ncohort and 0.77 in the external validation cohort. Sensitivity was consistently\nabove 92% in both cohorts. In the overall cohort (n=540), among patients with\nAI-CAC=0, a single ASCVD event occurred, after 4.3 years. Patients with\nAI-CAC>0 had significantly higher Kaplan Meier estimates for ASCVD events\n(13.5% vs. 3.4%, log-rank=0.013). Conclusion. The AI-CAC model seems to\naccurately detect subclinical atherosclerosis on chest x-ray with elevated\nsensitivity, and to predict ASCVD events with elevated negative predictive\nvalue. Adoption of the AI-CAC model to refine CV risk stratification or as an\nopportunistic screening tool requires prospective evaluation.\n","authors":["Guglielmo Gallone","Francesco Iodice","Alberto Presta","Davide Tore","Ovidio de Filippo","Michele Visciano","Carlo Alberto Barbano","Alessandro Serafini","Paola Gorrini","Alessandro Bruno","Walter Grosso Marra","James Hughes","Mario Iannaccone","Paolo Fonio","Attilio Fiandrotti","Alessandro Depaoli","Marco Grangetto","Gaetano Maria de Ferrari","Fabrizio D'Ascenzo"],"pdf_url":"https://arxiv.org/pdf/2403.18756v1.pdf","comment":"Submitted to European Heart Journal - Cardiovascular Imaging Added\n  also the additional material 44 pages (30 main paper, 14 additional\n  material), 14 figures (5 main manuscript, 9 additional material)"},{"id":"http://arxiv.org/abs/2403.18755v1","updated":"2024-03-27T16:54:45Z","published":"2024-03-27T16:54:45Z","title":"Many-Objective Evolutionary Influence Maximization: Balancing Spread,\n  Budget, Fairness, and Time","summary":"  The Influence Maximization (IM) problem seeks to discover the set of nodes in\na graph that can spread the information propagation at most. This problem is\nknown to be NP-hard, and it is usually studied by maximizing the influence\n(spread) and, optionally, optimizing a second objective, such as minimizing the\nseed set size or maximizing the influence fairness. However, in many practical\nscenarios multiple aspects of the IM problem must be optimized at the same\ntime. In this work, we propose a first case study where several IM-specific\nobjective functions, namely budget, fairness, communities, and time, are\noptimized on top of the maximization of influence and minimization of the seed\nset size. To this aim, we introduce MOEIM (Many-Objective Evolutionary\nAlgorithm for Influence Maximization) a Multi-Objective Evolutionary Algorithm\n(MOEA) based on NSGA-II incorporating graph-aware operators and a smart\ninitialization. We compare MOEIM in two experimental settings, including a\ntotal of nine graph datasets, two heuristic methods, a related MOEA, and a\nstate-of-the-art Deep Learning approach. The experiments show that MOEIM\noverall outperforms the competitors in most of the tested many-objective\nsettings. To conclude, we also investigate the correlation between the\nobjectives, leading to novel insights into the topic. The codebase is available\nat https://github.com/eliacunegatti/MOEIM.\n","authors":["Elia Cunegatti","Leonardo Lucio Custode","Giovanni Iacca"],"pdf_url":"https://arxiv.org/pdf/2403.18755v1.pdf","comment":"To appear in Genetic and Evolutionary Computation Conference (GECCO\n  24 Companion), July 14 18, 2024, Melbourne, VIC, Australia. ACM, New York,\n  NY, USA"},{"id":"http://arxiv.org/abs/2201.06180v2","updated":"2024-03-27T16:45:26Z","published":"2022-01-17T02:30:25Z","title":"Nonlinear Control Allocation: A Learning Based Approach","summary":"  Modern aircraft are designed with redundant control effectors to cater for\nfault tolerance and maneuverability requirements. This leads to aircraft being\nover-actuated and requires control allocation schemes to distribute the control\ncommands among control effectors. Traditionally, optimization-based control\nallocation schemes are used; however, for nonlinear allocation problems, these\nmethods require large computational resources. In this work, an artificial\nneural network (ANN) based nonlinear control allocation scheme is proposed. The\nproposed scheme is composed of learning the inverse of the control\neffectiveness map through ANN, and then implementing it as an allocator instead\nof solving an online optimization problem. Stability conditions are presented\nfor closed-loop systems incorporating the allocator, and computational\nchallenges are explored with piece-wise linear effectiveness functions and\nANN-based allocators. To demonstrate the efficacy of the proposed scheme, it is\ncompared with a standard quadratic programming-based method for control\nallocation.\n","authors":["Hafiz Zeeshan Iqbal Khan","Surrayya Mobeen","Jahanzeb Rajput","Jamshed Riaz"],"pdf_url":"https://arxiv.org/pdf/2201.06180v2.pdf","comment":"submitted to IEEE Conference on Decision and Control (CDC), 2024"},{"id":"http://arxiv.org/abs/2403.18742v1","updated":"2024-03-27T16:39:28Z","published":"2024-03-27T16:39:28Z","title":"Understanding the Learning Dynamics of Alignment with Human Feedback","summary":"  Aligning large language models (LLMs) with human intentions has become a\ncritical task for safely deploying models in real-world systems. While existing\nalignment approaches have seen empirical success, theoretically understanding\nhow these methods affect model behavior remains an open question. Our work\nprovides an initial attempt to theoretically analyze the learning dynamics of\nhuman preference alignment. We formally show how the distribution of preference\ndatasets influences the rate of model updates and provide rigorous guarantees\non the training accuracy. Our theory also reveals an intricate phenomenon where\nthe optimization is prone to prioritizing certain behaviors with higher\npreference distinguishability. We empirically validate our findings on\ncontemporary LLMs and alignment tasks, reinforcing our theoretical insights and\nshedding light on considerations for future alignment approaches. Disclaimer:\nThis paper contains potentially offensive text; reader discretion is advised.\n","authors":["Shawn Im","Yixuan Li"],"pdf_url":"https://arxiv.org/pdf/2403.18742v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18731v1","updated":"2024-03-27T16:21:24Z","published":"2024-03-27T16:21:24Z","title":"Enhancing Manufacturing Quality Prediction Models through the\n  Integration of Explainability Methods","summary":"  This research presents a method that utilizes explainability techniques to\namplify the performance of machine learning (ML) models in forecasting the\nquality of milling processes, as demonstrated in this paper through a\nmanufacturing use case. The methodology entails the initial training of ML\nmodels, followed by a fine-tuning phase where irrelevant features identified\nthrough explainability methods are eliminated. This procedural refinement\nresults in performance enhancements, paving the way for potential reductions in\nmanufacturing costs and a better understanding of the trained ML models. This\nstudy highlights the usefulness of explainability techniques in both explaining\nand optimizing predictive models in the manufacturing realm.\n","authors":["Dennis Gross","Helge Spieker","Arnaud Gotlieb","Ricardo Knoblauch"],"pdf_url":"https://arxiv.org/pdf/2403.18731v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18725v1","updated":"2024-03-27T16:15:21Z","published":"2024-03-27T16:15:21Z","title":"Probabilistic Model Checking of Stochastic Reinforcement Learning\n  Policies","summary":"  We introduce a method to verify stochastic reinforcement learning (RL)\npolicies. This approach is compatible with any RL algorithm as long as the\nalgorithm and its corresponding environment collectively adhere to the Markov\nproperty. In this setting, the future state of the environment should depend\nsolely on its current state and the action executed, independent of any\nprevious states or actions. Our method integrates a verification technique,\nreferred to as model checking, with RL, leveraging a Markov decision process, a\ntrained RL policy, and a probabilistic computation tree logic (PCTL) formula to\nbuild a formal model that can be subsequently verified via the model checker\nStorm. We demonstrate our method's applicability across multiple benchmarks,\ncomparing it to baseline methods called deterministic safety estimates and\nnaive monolithic model checking. Our results show that our method is suited to\nverify stochastic RL policies.\n","authors":["Dennis Gross","Helge Spieker"],"pdf_url":"https://arxiv.org/pdf/2403.18725v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.03100v2","updated":"2024-03-27T16:14:34Z","published":"2024-03-05T16:35:25Z","title":"NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and\n  Diffusion Models","summary":"  While recent large-scale text-to-speech (TTS) models have achieved\nsignificant progress, they still fall short in speech quality, similarity, and\nprosody. Considering speech intricately encompasses various attributes (e.g.,\ncontent, prosody, timbre, and acoustic details) that pose significant\nchallenges for generation, a natural idea is to factorize speech into\nindividual subspaces representing different attributes and generate them\nindividually. Motivated by it, we propose NaturalSpeech 3, a TTS system with\nnovel factorized diffusion models to generate natural speech in a zero-shot\nway. Specifically, 1) we design a neural codec with factorized vector\nquantization (FVQ) to disentangle speech waveform into subspaces of content,\nprosody, timbre, and acoustic details; 2) we propose a factorized diffusion\nmodel to generate attributes in each subspace following its corresponding\nprompt. With this factorization design, NaturalSpeech 3 can effectively and\nefficiently model intricate speech with disentangled subspaces in a\ndivide-and-conquer way. Experiments show that NaturalSpeech 3 outperforms the\nstate-of-the-art TTS systems on quality, similarity, prosody, and\nintelligibility, and achieves on-par quality with human recordings.\nFurthermore, we achieve better performance by scaling to 1B parameters and 200K\nhours of training data.\n","authors":["Zeqian Ju","Yuancheng Wang","Kai Shen","Xu Tan","Detai Xin","Dongchao Yang","Yanqing Liu","Yichong Leng","Kaitao Song","Siliang Tang","Zhizheng Wu","Tao Qin","Xiang-Yang Li","Wei Ye","Shikun Zhang","Jiang Bian","Lei He","Jinyu Li","Sheng Zhao"],"pdf_url":"https://arxiv.org/pdf/2403.03100v2.pdf","comment":"Achieving human-level quality and naturalness on multi-speaker\n  datasets (e.g., LibriSpeech) in a zero-shot way"},{"id":"http://arxiv.org/abs/2403.18717v1","updated":"2024-03-27T16:06:37Z","published":"2024-03-27T16:06:37Z","title":"Semi-Supervised Learning for Deep Causal Generative Models","summary":"  Developing models that can answer questions of the form \"How would $x$ change\nif $y$ had been $z$?\" is fundamental for advancing medical image analysis.\nTraining causal generative models that address such counterfactual questions,\nthough, currently requires that all relevant variables have been observed and\nthat corresponding labels are available in training data. However, clinical\ndata may not have complete records for all patients and state of the art causal\ngenerative models are unable to take full advantage of this. We thus develop,\nfor the first time, a semi-supervised deep causal generative model that\nexploits the causal relationships between variables to maximise the use of all\navailable data. We explore this in the setting where each sample is either\nfully labelled or fully unlabelled, as well as the more clinically realistic\ncase of having different labels missing for each sample. We leverage techniques\nfrom causal inference to infer missing values and subsequently generate\nrealistic counterfactuals, even for samples with incomplete labels.\n","authors":["Yasin Ibrahim","Hermione Warr","Konstantinos Kamnitsas"],"pdf_url":"https://arxiv.org/pdf/2403.18717v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18715v1","updated":"2024-03-27T16:04:47Z","published":"2024-03-27T16:04:47Z","title":"Mitigating Hallucinations in Large Vision-Language Models with\n  Instruction Contrastive Decoding","summary":"  Large Vision-Language Models (LVLMs) are increasingly adept at generating\ncontextually detailed and coherent responses from visual inputs. However, their\napplication in multimodal decision-making and open-ended generation is hindered\nby a notable rate of hallucinations, where generated text inaccurately\nrepresents the visual contents. To address this issue, this paper introduces\nthe Instruction Contrastive Decoding (ICD) method, a novel approach designed to\nreduce hallucinations during LVLM inference. Our method is inspired by our\nobservation that what we call disturbance instructions significantly exacerbate\nhallucinations in multimodal fusion modules. ICD contrasts distributions from\nstandard and instruction disturbance, thereby increasing alignment uncertainty\nand effectively subtracting hallucinated concepts from the original\ndistribution. Through comprehensive experiments on discriminative benchmarks\n(POPE and MME) and a generative benchmark (LLaVa-Bench), we demonstrate that\nICD significantly mitigates both object-level and attribute-level\nhallucinations. Moreover, our method not only addresses hallucinations but also\nsignificantly enhances the general perception and recognition capabilities of\nLVLMs.\n","authors":["Xintong Wang","Jingheng Pan","Liang Ding","Chris Biemann"],"pdf_url":"https://arxiv.org/pdf/2403.18715v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.03123v3","updated":"2024-03-27T16:03:32Z","published":"2023-04-13T16:01:28Z","title":"ChatGPT Needs SPADE (Sustainability, PrivAcy, Digital divide, and\n  Ethics) Evaluation: A Review","summary":"  ChatGPT is another large language model (LLM) vastly available for the\nconsumers on their devices but due to its performance and ability to converse\neffectively, it has gained a huge popularity amongst research as well as\nindustrial community. Recently, many studies have been published to show the\neffectiveness, efficiency, integration, and sentiments of chatGPT and other\nLLMs. In contrast, this study focuses on the important aspects that are mostly\noverlooked, i.e. sustainability, privacy, digital divide, and ethics and\nsuggests that not only chatGPT but every subsequent entry in the category of\nconversational bots should undergo Sustainability, PrivAcy, Digital divide, and\nEthics (SPADE) evaluation. This paper discusses in detail the issues and\nconcerns raised over chatGPT in line with aforementioned characteristics. We\nalso discuss the recent EU AI Act briefly in accordance with the SPADE\nevaluation. We support our hypothesis by some preliminary data collection and\nvisualizations along with hypothesized facts. We also suggest mitigations and\nrecommendations for each of the concerns. Furthermore, we also suggest some\npolicies and recommendations for EU AI policy act concerning ethics, digital\ndivide, and sustainability.\n","authors":["Sunder Ali Khowaja","Parus Khuwaja","Kapal Dev","Weizheng Wang","Lewis Nkenyereye"],"pdf_url":"https://arxiv.org/pdf/2305.03123v3.pdf","comment":"29 pages, 8 figures, 4 tables"},{"id":"http://arxiv.org/abs/2403.18711v1","updated":"2024-03-27T15:58:25Z","published":"2024-03-27T15:58:25Z","title":"SAT-NGP : Unleashing Neural Graphics Primitives for Fast Relightable\n  Transient-Free 3D reconstruction from Satellite Imagery","summary":"  Current stereo-vision pipelines produce high accuracy 3D reconstruction when\nusing multiple pairs or triplets of satellite images. However, these pipelines\nare sensitive to the changes between images that can occur as a result of\nmulti-date acquisitions. Such variations are mainly due to variable shadows,\nreflexions and transient objects (cars, vegetation). To take such changes into\naccount, Neural Radiance Fields (NeRF) have recently been applied to multi-date\nsatellite imagery. However, Neural methods are very compute-intensive, taking\ndozens of hours to learn, compared with minutes for standard stereo-vision\npipelines. Following the ideas of Instant Neural Graphics Primitives we propose\nto use an efficient sampling strategy and multi-resolution hash encoding to\naccelerate the learning. Our model, Satellite Neural Graphics Primitives\n(SAT-NGP) decreases the learning time to 15 minutes while maintaining the\nquality of the 3D reconstruction.\n","authors":["Camille Billouard","Dawa Derksen","Emmanuelle Sarrazin","Bruno Vallet"],"pdf_url":"https://arxiv.org/pdf/2403.18711v1.pdf","comment":"5 pages, 3 figures, 1 table; Accepted to International Geoscience and\n  Remote Sensing Symposium (IGARSS) 2024; Code available at\n  https://github.com/Ellimac0/SAT-NGP"},{"id":"http://arxiv.org/abs/2401.15120v2","updated":"2024-03-27T15:49:52Z","published":"2024-01-26T03:44:58Z","title":"Incorporating simulated spatial context information improves the\n  effectiveness of contrastive learning models","summary":"  Visual learning often occurs in a specific context, where an agent acquires\nskills through exploration and tracking of its location in a consistent\nenvironment. The historical spatial context of the agent provides a similarity\nsignal for self-supervised contrastive learning. We present a unique approach,\ntermed Environmental Spatial Similarity (ESS), that complements existing\ncontrastive learning methods. Using images from simulated, photorealistic\nenvironments as an experimental setting, we demonstrate that ESS outperforms\ntraditional instance discrimination approaches. Moreover, sampling additional\ndata from the same environment substantially improves accuracy and provides new\naugmentations. ESS allows remarkable proficiency in room classification and\nspatial prediction tasks, especially in unfamiliar environments. This learning\nparadigm has the potential to enable rapid visual learning in agents operating\nin new environments with unique visual characteristics. Potentially\ntransformative applications span from robotics to space exploration. Our proof\nof concept demonstrates improved efficiency over methods that rely on\nextensive, disconnected datasets.\n","authors":["Lizhen Zhu","James Z. Wang","Wonseuk Lee","Brad Wyble"],"pdf_url":"https://arxiv.org/pdf/2401.15120v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.11800v3","updated":"2024-03-27T15:48:29Z","published":"2024-02-19T03:08:02Z","title":"Stochastic Approximation with Delayed Updates: Finite-Time Rates under\n  Markovian Sampling","summary":"  Motivated by applications in large-scale and multi-agent reinforcement\nlearning, we study the non-asymptotic performance of stochastic approximation\n(SA) schemes with delayed updates under Markovian sampling. While the effect of\ndelays has been extensively studied for optimization, the manner in which they\ninteract with the underlying Markov process to shape the finite-time\nperformance of SA remains poorly understood. In this context, our first main\ncontribution is to show that under time-varying bounded delays, the delayed SA\nupdate rule guarantees exponentially fast convergence of the \\emph{last\niterate} to a ball around the SA operator's fixed point. Notably, our bound is\n\\emph{tight} in its dependence on both the maximum delay $\\tau_{max}$, and the\nmixing time $\\tau_{mix}$. To achieve this tight bound, we develop a novel\ninductive proof technique that, unlike various existing delayed-optimization\nanalyses, relies on establishing uniform boundedness of the iterates. As such,\nour proof may be of independent interest. Next, to mitigate the impact of the\nmaximum delay on the convergence rate, we provide the first finite-time\nanalysis of a delay-adaptive SA scheme under Markovian sampling. In particular,\nwe show that the exponent of convergence of this scheme gets scaled down by\n$\\tau_{avg}$, as opposed to $\\tau_{max}$ for the vanilla delayed SA rule; here,\n$\\tau_{avg}$ denotes the average delay across all iterations. Moreover, the\nadaptive scheme requires no prior knowledge of the delay sequence for step-size\ntuning. Our theoretical findings shed light on the finite-time effects of\ndelays for a broad class of algorithms, including TD learning, Q-learning, and\nstochastic gradient descent under Markovian sampling.\n","authors":["Arman Adibi","Nicolo Dal Fabbro","Luca Schenato","Sanjeev Kulkarni","H. Vincent Poor","George J. Pappas","Hamed Hassani","Aritra Mitra"],"pdf_url":"https://arxiv.org/pdf/2402.11800v3.pdf","comment":"Accepted to the 27th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2024!"},{"id":"http://arxiv.org/abs/2403.18699v1","updated":"2024-03-27T15:48:16Z","published":"2024-03-27T15:48:16Z","title":"Contrastive Learning with Orthonormal Anchors (CLOA)","summary":"  This study focuses on addressing the instability issues prevalent in\ncontrastive learning, specifically examining the InfoNCE loss function and its\nderivatives. We reveal a critical observation that these loss functions exhibit\na restrictive behavior, leading to a convergence phenomenon where embeddings\ntend to merge into a singular point. This \"over-fusion\" effect detrimentally\naffects classification accuracy in subsequent supervised-learning tasks.\nThrough theoretical analysis, we demonstrate that embeddings, when equalized or\nconfined to a rank-1 linear subspace, represent a local minimum for InfoNCE. In\nresponse to this challenge, our research introduces an innovative strategy that\nleverages the same or fewer labeled data than typically used in the fine-tuning\nphase. The loss we proposed, Orthonormal Anchor Regression Loss, is designed to\ndisentangle embedding clusters, significantly enhancing the distinctiveness of\neach embedding while simultaneously ensuring their aggregation into dense,\nwell-defined clusters. Our method demonstrates remarkable improvements with\njust a fraction of the conventional label requirements, as evidenced by our\nresults on CIFAR10 and CIFAR100 datasets.\n","authors":["Huanran Li","Daniel Pimentel-Alarcón"],"pdf_url":"https://arxiv.org/pdf/2403.18699v1.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2303.12091v3","updated":"2024-03-27T15:44:25Z","published":"2023-03-21T09:07:15Z","title":"Adaptive Negative Evidential Deep Learning for Open-set Semi-supervised\n  Learning","summary":"  Semi-supervised learning (SSL) methods assume that labeled data, unlabeled\ndata and test data are from the same distribution. Open-set semi-supervised\nlearning (Open-set SSL) considers a more practical scenario, where unlabeled\ndata and test data contain new categories (outliers) not observed in labeled\ndata (inliers). Most previous works focused on outlier detection via binary\nclassifiers, which suffer from insufficient scalability and inability to\ndistinguish different types of uncertainty. In this paper, we propose a novel\nframework, Adaptive Negative Evidential Deep Learning (ANEDL) to tackle these\nlimitations. Concretely, we first introduce evidential deep learning (EDL) as\nan outlier detector to quantify different types of uncertainty, and design\ndifferent uncertainty metrics for self-training and inference. Furthermore, we\npropose a novel adaptive negative optimization strategy, making EDL more\ntailored to the unlabeled dataset containing both inliers and outliers. As\ndemonstrated empirically, our proposed method outperforms existing\nstate-of-the-art methods across four datasets.\n","authors":["Yang Yu","Danruo Deng","Furui Liu","Yueming Jin","Qi Dou","Guangyong Chen","Pheng-Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2303.12091v3.pdf","comment":"Accepted by AAAI2024"},{"id":"http://arxiv.org/abs/2403.18690v1","updated":"2024-03-27T15:41:23Z","published":"2024-03-27T15:41:23Z","title":"Annolid: Annotate, Segment, and Track Anything You Need","summary":"  Annolid is a deep learning-based software package designed for the\nsegmentation, labeling, and tracking of research targets within video files,\nfocusing primarily on animal behavior analysis. Based on state-of-the-art\ninstance segmentation methods, Annolid now harnesses the Cutie video object\nsegmentation model to achieve resilient, markerless tracking of multiple\nanimals from single annotated frames, even in environments in which they may be\npartially or entirely concealed by environmental features or by one another.\nOur integration of Segment Anything and Grounding-DINO strategies additionally\nenables the automatic masking and segmentation of recognizable animals and\nobjects by text command, removing the need for manual annotation. Annolid's\ncomprehensive approach to object segmentation flexibly accommodates a broad\nspectrum of behavior analysis applications, enabling the classification of\ndiverse behavioral states such as freezing, digging, pup huddling, and social\ninteractions in addition to the tracking of animals and their body parts.\n","authors":["Chen Yang","Thomas A. Cleland"],"pdf_url":"https://arxiv.org/pdf/2403.18690v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18681v1","updated":"2024-03-27T15:24:54Z","published":"2024-03-27T15:24:54Z","title":"TransFusion: Contrastive Learning with Transformers","summary":"  This paper proposes a novel framework, TransFusion, designed to make the\nprocess of contrastive learning more analytical and explainable. TransFusion\nconsists of attention blocks whose softmax being replaced by ReLU, and its\nfinal block's weighted-sum operation is truncated to leave the adjacency matrix\nas the output. The model is trained by minimizing the Jensen-Shannon Divergence\nbetween its output and the target affinity matrix, which indicates whether each\npair of samples belongs to the same or different classes. The main contribution\nof TransFusion lies in defining a theoretical limit for answering two\nfundamental questions in the field: the maximum level of data augmentation and\nthe minimum batch size required for effective contrastive learning.\nFurthermore, experimental results indicate that TransFusion successfully\nextracts features that isolate clusters from complex real-world data, leading\nto improved classification accuracy in downstream tasks.\n","authors":["Huanran Li","Daniel Pimentel-Alarcón"],"pdf_url":"https://arxiv.org/pdf/2403.18681v1.pdf","comment":"17 pages, 4 figures,"},{"id":"http://arxiv.org/abs/2403.18668v1","updated":"2024-03-27T15:11:07Z","published":"2024-03-27T15:11:07Z","title":"Aiming for Relevance","summary":"  Vital signs are crucial in intensive care units (ICUs). They are used to\ntrack the patient's state and to identify clinically significant changes.\nPredicting vital sign trajectories is valuable for early detection of adverse\nevents. However, conventional machine learning metrics like RMSE often fail to\ncapture the true clinical relevance of such predictions. We introduce novel\nvital sign prediction performance metrics that align with clinical contexts,\nfocusing on deviations from clinical norms, overall trends, and trend\ndeviations. These metrics are derived from empirical utility curves obtained in\na previous study through interviews with ICU clinicians. We validate the\nmetrics' usefulness using simulated and real clinical datasets (MIMIC and\neICU). Furthermore, we employ these metrics as loss functions for neural\nnetworks, resulting in models that excel in predicting clinically significant\nevents. This research paves the way for clinically relevant machine learning\nmodel evaluation and optimization, promising to improve ICU patient care. 10\npages, 9 figures.\n","authors":["Bar Eini Porat","Danny Eytan","Uri Shalit"],"pdf_url":"https://arxiv.org/pdf/2403.18668v1.pdf","comment":"10 pages, 9 figures, AMIA Informatics 2024"},{"id":"http://arxiv.org/abs/2403.17219v2","updated":"2024-03-27T15:08:31Z","published":"2024-03-25T21:48:22Z","title":"SeSaMe: A Framework to Simulate Self-Reported Ground Truth for Mental\n  Health Sensing Studies","summary":"  Advances in mobile and wearable technologies have enabled the potential to\npassively monitor a person's mental, behavioral, and affective health. These\napproaches typically rely on longitudinal collection of self-reported outcomes,\ne.g., depression, stress, and anxiety, to train machine learning (ML) models.\nHowever, the need to continuously self-report adds a significant burden on the\nparticipants, often resulting in attrition, missing labels, or insincere\nresponses. In this work, we introduce the Scale Scores Simulation using Mental\nModels (SeSaMe) framework to alleviate participants' burden in digital mental\nhealth studies. By leveraging pre-trained large language models (LLMs), SeSaMe\nenables the simulation of participants' responses on psychological scales. In\nSeSaMe, researchers can prompt LLMs with information on participants' internal\nbehavioral dispositions, enabling LLMs to construct mental models of\nparticipants to simulate their responses on psychological scales. We\ndemonstrate an application of SeSaMe, where we use GPT-4 to simulate responses\non one scale using responses from another as behavioral information. We also\nevaluate the alignment between human and SeSaMe-simulated responses to\npsychological scales. Then, we present experiments to inspect the utility of\nSeSaMe-simulated responses as ground truth in training ML models by replicating\nestablished depression and anxiety screening tasks from a previous study. Our\nresults indicate SeSaMe to be a promising approach, but its alignment may vary\nacross scales and specific prediction objectives. We also observed that model\nperformance with simulated data was on par with using the real data for\ntraining in most evaluation scenarios. We conclude by discussing the potential\nimplications of SeSaMe in addressing some challenges researchers face with\nground-truth collection in passive sensing studies.\n","authors":["Akshat Choube","Vedant Das Swain","Varun Mishra"],"pdf_url":"https://arxiv.org/pdf/2403.17219v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18659v1","updated":"2024-03-27T15:03:33Z","published":"2024-03-27T15:03:33Z","title":"INEXA: Interactive and Explainable Process Model Abstraction Through\n  Object-Centric Process Mining","summary":"  Process events are recorded by multiple information systems at different\ngranularity levels. Based on the resulting event logs, process models are\ndiscovered at different granularity levels, as well. Events stored at a\nfine-grained granularity level, for example, may hinder the discovered process\nmodel to be displayed due the high number of resulting model elements. The\ndiscovered process model of a real-world manufacturing process, for example,\nconsists of 1,489 model elements and over 2,000 arcs. Existing process model\nabstraction techniques could help reducing the size of the model, but would\ndisconnect it from the underlying event log. Existing event abstraction\ntechniques do neither support the analysis of mixed granularity levels, nor\ninteractive exploration of a suitable granularity level. To enable the\nexploration of discovered process models at different granularity levels, we\npropose INEXA, an interactive, explainable process model abstraction method\nthat keeps the link to the event log. As a starting point, INEXA aggregates\nlarge process models to a \"displayable\" size, e.g., for the manufacturing use\ncase to a process model with 58 model elements. Then, the process analyst can\nexplore granularity levels interactively, while applied abstractions are\nautomatically traced in the event log for explainability.\n","authors":["Janik-Vasily Benzin","Gyunam Park","Juergen Mangler","Stefanie Rinderle-Ma"],"pdf_url":"https://arxiv.org/pdf/2403.18659v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13374v3","updated":"2024-03-27T14:57:54Z","published":"2024-03-20T08:15:08Z","title":"Byzantine-resilient Federated Learning With Adaptivity to Data\n  Heterogeneity","summary":"  This paper deals with federated learning (FL) in the presence of malicious\nByzantine attacks and data heterogeneity. A novel Robust Average Gradient\nAlgorithm (RAGA) is proposed, which leverages the geometric median for\naggregation and can freely select the round number for local updating.\nDifferent from most existing resilient approaches, which perform convergence\nanalysis based on strongly-convex loss function or homogeneously distributed\ndataset, we conduct convergence analysis for not only strongly-convex but also\nnon-convex loss function over heterogeneous dataset. According to our\ntheoretical analysis, as long as the fraction of dataset from malicious users\nis less than half, RAGA can achieve convergence at rate\n$\\mathcal{O}({1}/{T^{2/3- \\delta}})$ where $T$ is the iteration number and\n$\\delta \\in (0, 2/3)$ for non-convex loss function, and at linear rate for\nstrongly-convex loss function. Moreover, stationary point or global optimal\nsolution is proved to obtainable as data heterogeneity vanishes. Experimental\nresults corroborate the robustness of RAGA to Byzantine attacks and verifies\nthe advantage of RAGA over baselines on convergence performance under various\nintensity of Byzantine attacks, for heterogeneous dataset.\n","authors":["Shiyuan Zuo","Xingrun Yan","Rongfei Fan","Han Hu","Hangguan Shan","Tony Q. S. Quek"],"pdf_url":"https://arxiv.org/pdf/2403.13374v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.17251v2","updated":"2024-03-27T14:48:48Z","published":"2023-03-30T09:29:53Z","title":"Demystifying Misconceptions in Social Bots Research","summary":"  Research on social bots aims at advancing knowledge and providing solutions\nto one of the most debated forms of online manipulation. Yet, social bot\nresearch is plagued by widespread biases, hyped results, and misconceptions\nthat set the stage for ambiguities, unrealistic expectations, and seemingly\nirreconcilable findings. Overcoming such issues is instrumental towards\nensuring reliable solutions and reaffirming the validity of the scientific\nmethod. In this contribution, we review some recent results in social bots\nresearch, highlighting and revising factual errors as well as methodological\nand conceptual biases. More importantly, we demystify common misconceptions,\naddressing fundamental points on how social bots research is discussed. Our\nanalysis surfaces the need to discuss research about online disinformation and\nmanipulation in a rigorous, unbiased, and responsible way. This article\nbolsters such effort by identifying and refuting common fallacious arguments\nused by both proponents and opponents of social bots research, as well as\nproviding directions toward sound methodologies for future research in the\nfield.\n","authors":["Stefano Cresci","Kai-Cheng Yang","Angelo Spognardi","Roberto Di Pietro","Filippo Menczer","Marinella Petrocchi"],"pdf_url":"https://arxiv.org/pdf/2303.17251v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16451v3","updated":"2024-03-27T14:36:21Z","published":"2024-03-25T06:30:54Z","title":"DeepMachining: Online Prediction of Machining Errors of Lathe Machines","summary":"  We describe DeepMachining, a deep learning-based AI system for online\nprediction of machining errors of lathe machine operations. We have built and\nevaluated DeepMachining based on manufacturing data from factories.\nSpecifically, we first pretrain a deep learning model for a given lathe\nmachine's operations to learn the salient features of machining states. Then,\nwe fine-tune the pretrained model to adapt to specific machining tasks. We\ndemonstrate that DeepMachining achieves high prediction accuracy for multiple\ntasks that involve different workpieces and cutting tools. To the best of our\nknowledge, this work is one of the first factory experiments using pre-trained\ndeep-learning models to predict machining errors of lathe machines.\n","authors":["Xiang-Li Lu","Hwai-Jung Hsu","Che-Wei Chou","H. T. Kung","Chen-Hsin Lee"],"pdf_url":"https://arxiv.org/pdf/2403.16451v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.13284v2","updated":"2024-03-27T14:30:44Z","published":"2024-02-19T09:07:59Z","title":"Structure Guided Large Language Model for SQL Generation","summary":"  Generating accurate Structured Querying Language (SQL) is a long-standing\nproblem, especially in matching users' semantic queries with structured\ndatabases and then generating structured SQL. Existing models typically input\nqueries and database schemas into the LLM and rely on the LLM to perform\nsemantic-structure matching and generate structured SQL. However, such\nsolutions overlook the structural information within user queries and\ndatabases, which can be utilized to enhance the generation of structured SQL.\nThis oversight can lead to inaccurate or unexecutable SQL generation. To fully\nexploit the structure, we propose a structure-to-SQL framework, which leverages\nthe inherent structure information to improve the SQL generation of LLMs.\nSpecifically, we introduce our Structure Guided SQL~(SGU-SQL) generation model.\nSGU-SQL first links user queries and databases in a structure-enhanced manner.\nIt then decomposes complicated linked structures with grammar trees to guide\nthe LLM to generate the SQL step by step. Extensive experiments on two\nbenchmark datasets illustrate that SGU-SQL can outperform sixteen SQL\ngeneration baselines.\n","authors":["Qinggang Zhang","Junnan Dong","Hao Chen","Wentao Li","Feiran Huang","Xiao Huang"],"pdf_url":"https://arxiv.org/pdf/2402.13284v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18607v1","updated":"2024-03-27T14:25:02Z","published":"2024-03-27T14:25:02Z","title":"Spikewhisper: Temporal Spike Backdoor Attacks on Federated Neuromorphic\n  Learning over Low-power Devices","summary":"  Federated neuromorphic learning (FedNL) leverages event-driven spiking neural\nnetworks and federated learning frameworks to effectively execute intelligent\nanalysis tasks over amounts of distributed low-power devices but also perform\nvulnerability to poisoning attacks. The threat of backdoor attacks on\ntraditional deep neural networks typically comes from time-invariant data.\nHowever, in FedNL, unknown threats may be hidden in time-varying spike signals.\nIn this paper, we start to explore a novel vulnerability of FedNL-based systems\nwith the concept of time division multiplexing, termed Spikewhisper, which\nallows attackers to evade detection as much as possible, as multiple malicious\nclients can imperceptibly poison with different triggers at different\ntimeslices. In particular, the stealthiness of Spikewhisper is derived from the\ntime-domain divisibility of global triggers, in which each malicious client\npastes only one local trigger to a certain timeslice in the neuromorphic\nsample, and also the polarity and motion of each local trigger can be\nconfigured by attackers. Extensive experiments based on two different\nneuromorphic datasets demonstrate that the attack success rate of Spikewispher\nis higher than the temporally centralized attacks. Besides, it is validated\nthat the effect of Spikewispher is sensitive to the trigger duration.\n","authors":["Hanqing Fu","Gaolei Li","Jun Wu","Jianhua Li","Xi Lin","Kai Zhou","Yuchen Liu"],"pdf_url":"https://arxiv.org/pdf/2403.18607v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18600v1","updated":"2024-03-27T14:22:40Z","published":"2024-03-27T14:22:40Z","title":"RAP: Retrieval-Augmented Planner for Adaptive Procedure Planning in\n  Instructional Videos","summary":"  Procedure Planning in instructional videos entails generating a sequence of\naction steps based on visual observations of the initial and target states.\nDespite the rapid progress in this task, there remain several critical\nchallenges to be solved: (1) Adaptive procedures: Prior works hold an\nunrealistic assumption that the number of action steps is known and fixed,\nleading to non-generalizable models in real-world scenarios where the sequence\nlength varies. (2) Temporal relation: Understanding the step temporal relation\nknowledge is essential in producing reasonable and executable plans. (3)\nAnnotation cost: Annotating instructional videos with step-level labels (i.e.,\ntimestamp) or sequence-level labels (i.e., action category) is demanding and\nlabor-intensive, limiting its generalizability to large-scale datasets.In this\nwork, we propose a new and practical setting, called adaptive procedure\nplanning in instructional videos, where the procedure length is not fixed or\npre-determined. To address these challenges we introduce Retrieval-Augmented\nPlanner (RAP) model. Specifically, for adaptive procedures, RAP adaptively\ndetermines the conclusion of actions using an auto-regressive model\narchitecture. For temporal relation, RAP establishes an external memory module\nto explicitly retrieve the most relevant state-action pairs from the training\nvideos and revises the generated procedures. To tackle high annotation cost,\nRAP utilizes a weakly-supervised learning manner to expand the training dataset\nto other task-relevant, unannotated videos by generating pseudo labels for\naction steps. Experiments on CrossTask and COIN benchmarks show the superiority\nof RAP over traditional fixed-length models, establishing it as a strong\nbaseline solution for adaptive procedure planning.\n","authors":["Ali Zare","Yulei Niu","Hammad Ayyubi","Shih-fu Chang"],"pdf_url":"https://arxiv.org/pdf/2403.18600v1.pdf","comment":"23 pages, 6 figures, 12 tables"},{"id":"http://arxiv.org/abs/2403.18593v1","updated":"2024-03-27T14:18:09Z","published":"2024-03-27T14:18:09Z","title":"Homogeneous Tokenizer Matters: Homogeneous Visual Tokenizer for Remote\n  Sensing Image Understanding","summary":"  The tokenizer, as one of the fundamental components of large models, has long\nbeen overlooked or even misunderstood in visual tasks. One key factor of the\ngreat comprehension power of the large language model is that natural language\ntokenizers utilize meaningful words or subwords as the basic elements of\nlanguage. In contrast, mainstream visual tokenizers, represented by patch-based\nmethods such as Patch Embed, rely on meaningless rectangular patches as basic\nelements of vision, which cannot serve as effectively as words or subwords in\nlanguage. Starting from the essence of the tokenizer, we defined semantically\nindependent regions (SIRs) for vision. We designed a simple HOmogeneous visual\ntOKenizer: HOOK. HOOK mainly consists of two modules: the Object Perception\nModule (OPM) and the Object Vectorization Module (OVM). To achieve homogeneity,\nthe OPM splits the image into 4*4 pixel seeds and then utilizes the attention\nmechanism to perceive SIRs. The OVM employs cross-attention to merge seeds\nwithin the same SIR. To achieve adaptability, the OVM defines a variable number\nof learnable vectors as cross-attention queries, allowing for the adjustment of\ntoken quantity. We conducted experiments on the NWPU-RESISC45, WHU-RS19\nclassification dataset, and GID5 segmentation dataset for sparse and dense\ntasks. The results demonstrate that the visual tokens obtained by HOOK\ncorrespond to individual objects, which demonstrates homogeneity. HOOK\noutperformed Patch Embed by 6\\% and 10\\% in the two tasks and achieved\nstate-of-the-art performance compared to the baselines used for comparison.\nCompared to Patch Embed, which requires more than one hundred tokens for one\nimage, HOOK requires only 6 and 8 tokens for sparse and dense tasks,\nrespectively, resulting in efficiency improvements of 1.5 to 2.8 times. The\ncode is available at https://github.com/GeoX-Lab/Hook.\n","authors":["Run Shao","Zhaoyang Zhang","Chao Tao","Yunsheng Zhang","Chengli Peng","Haifeng Li"],"pdf_url":"https://arxiv.org/pdf/2403.18593v1.pdf","comment":"20 pages, 8 figures, 6 tables"},{"id":"http://arxiv.org/abs/2306.09459v3","updated":"2024-03-27T14:02:58Z","published":"2023-06-15T19:29:08Z","title":"Recurrent Action Transformer with Memory","summary":"  Recently, the use of transformers in offline reinforcement learning has\nbecome a rapidly developing area. This is due to their ability to treat the\nagent's trajectory in the environment as a sequence, thereby reducing the\npolicy learning problem to sequence modeling. In environments where the agent's\ndecisions depend on past events, it is essential to capture both the event\nitself and the decision point in the context of the model. However, the\nquadratic complexity of the attention mechanism limits the potential for\ncontext expansion. One solution to this problem is to enhance transformers with\nmemory mechanisms. In this paper, we propose the Recurrent Action Transformer\nwith Memory (RATE) - a model that incorporates recurrent memory. To evaluate\nour model, we conducted extensive experiments on both memory-intensive\nenvironments (VizDoom-Two-Color, T-Maze) and classic Atari games and MuJoCo\ncontrol environments. The results show that the use of memory can significantly\nimprove performance in memory-intensive environments while maintaining or\nimproving results in classic environments. We hope that our findings will\nstimulate research on memory mechanisms for transformers applicable to offline\nreinforcement learning.\n","authors":["Alexey Staroverov","Egor Cherepanov","Dmitry Yudin","Alexey K. Kovalev","Aleksandr I. Panov"],"pdf_url":"https://arxiv.org/pdf/2306.09459v3.pdf","comment":"15 pages, 11 figures"},{"id":"http://arxiv.org/abs/2309.11427v2","updated":"2024-03-27T14:02:57Z","published":"2023-09-20T16:01:45Z","title":"Generative Pre-Training of Time-Series Data for Unsupervised Fault\n  Detection in Semiconductor Manufacturing","summary":"  This paper introduces TRACE-GPT, which stands for Time-seRies\nAnomaly-detection with Convolutional Embedding and Generative Pre-trained\nTransformers. TRACE-GPT is designed to pre-train univariate time-series sensor\ndata and detect faults on unlabeled datasets in semiconductor manufacturing. In\nsemiconductor industry, classifying abnormal time-series sensor data from\nnormal data is important because it is directly related to wafer defect.\nHowever, small, unlabeled, and even mixed training data without enough\nanomalies make classification tasks difficult. In this research, we capture\nfeatures of time-series data with temporal convolutional embedding and\nGenerative Pre-trained Transformer (GPT) to classify abnormal sequences from\nnormal sequences using cross entropy loss. We prove that our model shows better\nperformance than previous unsupervised models with both an open dataset, the\nUniversity of California Riverside (UCR) time-series classification archive,\nand the process log of our Chemical Vapor Deposition (CVD) equipment. Our model\nhas the highest F1 score at Equal Error Rate (EER) across all datasets and is\nonly 0.026 below the supervised state-of-the-art baseline on the open dataset.\n","authors":["Sewoong Lee","JinKyou Choi","Min Su Kim"],"pdf_url":"https://arxiv.org/pdf/2309.11427v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.09283v3","updated":"2024-03-27T13:55:14Z","published":"2024-02-14T16:14:03Z","title":"Attacks, Defenses and Evaluations for LLM Conversation Safety: A Survey","summary":"  Large Language Models (LLMs) are now commonplace in conversation\napplications. However, their risks of misuse for generating harmful responses\nhave raised serious societal concerns and spurred recent research on LLM\nconversation safety. Therefore, in this survey, we provide a comprehensive\noverview of recent studies, covering three critical aspects of LLM conversation\nsafety: attacks, defenses, and evaluations. Our goal is to provide a structured\nsummary that enhances understanding of LLM conversation safety and encourages\nfurther investigation into this important subject. For easy reference, we have\ncategorized all the studies mentioned in this survey according to our taxonomy,\navailable at: https://github.com/niconi19/LLM-conversation-safety.\n","authors":["Zhichen Dong","Zhanhui Zhou","Chao Yang","Jing Shao","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2402.09283v3.pdf","comment":"Accepted to NAACL 2024"},{"id":"http://arxiv.org/abs/2403.18570v1","updated":"2024-03-27T13:51:26Z","published":"2024-03-27T13:51:26Z","title":"Physics-Informed Graph Neural Networks for Water Distribution Systems","summary":"  Water distribution systems (WDS) are an integral part of critical\ninfrastructure which is pivotal to urban development. As 70% of the world's\npopulation will likely live in urban environments in 2050, efficient simulation\nand planning tools for WDS play a crucial role in reaching UN's sustainable\ndevelopmental goal (SDG) 6 - \"Clean water and sanitation for all\". In this\nrealm, we propose a novel and efficient machine learning emulator, more\nprecisely, a physics-informed deep learning (DL) model, for hydraulic state\nestimation in WDS. Using a recursive approach, our model only needs a few graph\nconvolutional neural network (GCN) layers and employs an innovative algorithm\nbased on message passing. Unlike conventional machine learning tasks, the model\nuses hydraulic principles to infer two additional hydraulic state features in\nthe process of reconstructing the available ground truth feature in an\nunsupervised manner. To the best of our knowledge, this is the first DL\napproach to emulate the popular hydraulic simulator EPANET, utilizing no\nadditional information. Like most DL models and unlike the hydraulic simulator,\nour model demonstrates vastly faster emulation times that do not increase\ndrastically with the size of the WDS. Moreover, we achieve high accuracy on the\nground truth and very similar results compared to the hydraulic simulator as\ndemonstrated through experiments on five real-world WDS datasets.\n","authors":["Inaam Ashraf","Janine Strotherm","Luca Hermes","Barbara Hammer"],"pdf_url":"https://arxiv.org/pdf/2403.18570v1.pdf","comment":"Extended version of the paper with the same title published at\n  Proceedings of the AAAI Conference on Artificial Intelligence 2024"},{"id":"http://arxiv.org/abs/2403.18569v1","updated":"2024-03-27T13:50:13Z","published":"2024-03-27T13:50:13Z","title":"PDNNet: PDN-Aware GNN-CNN Heterogeneous Network for Dynamic IR Drop\n  Prediction","summary":"  IR drop on the power delivery network (PDN) is closely related to PDN's\nconfiguration and cell current consumption. As the integrated circuit (IC)\ndesign is growing larger, dynamic IR drop simulation becomes computationally\nunaffordable and machine learning based IR drop prediction has been explored as\na promising solution. Although CNN-based methods have been adapted to IR drop\nprediction task in several works, the shortcomings of overlooking PDN\nconfiguration is non-negligible. In this paper, we consider not only how to\nproperly represent cell-PDN relation, but also how to model IR drop following\nits physical nature in the feature aggregation procedure. Thus, we propose a\nnovel graph structure, PDNGraph, to unify the representations of the PDN\nstructure and the fine-grained cell-PDN relation. We further propose a\ndual-branch heterogeneous network, PDNNet, incorporating two parallel GNN-CNN\nbranches to favorably capture the above features during the learning process.\nSeveral key designs are presented to make the dynamic IR drop prediction highly\neffective and interpretable. We are the first work to apply graph structure to\ndeep-learning based dynamic IR drop prediction method. Experiments show that\nPDNNet outperforms the state-of-the-art CNN-based methods by up to 39.3%\nreduction in prediction error and achieves 545x speedup compared to the\ncommercial tool, which demonstrates the superiority of our method.\n","authors":["Yuxiang Zhao","Zhuomin Chai","Xun Jiang","Yibo Lin","Runsheng Wang","Ru Huang"],"pdf_url":"https://arxiv.org/pdf/2403.18569v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.09700v2","updated":"2024-03-27T13:42:25Z","published":"2024-03-05T22:19:21Z","title":"Shapley Values-Powered Framework for Fair Reward Split in Content\n  Produced by GenAI","summary":"  It is evident that, currently, generative models are surpassed in quality by\nhuman professionals. However, with the advancements in Artificial Intelligence,\nthis gap will narrow, leading to scenarios where individuals who have dedicated\nyears of their lives to mastering a skill become obsolete due to their high\ncosts, which are inherently linked to the time they require to complete a task\n-- a task that AI could accomplish in minutes or seconds. To avoid future\nsocial upheavals, we must, even now, contemplate how to fairly assess the\ncontributions of such individuals in training generative models and how to\ncompensate them for the reduction or complete loss of their incomes. In this\nwork, we propose a method to structure collaboration between model developers\nand data providers. To achieve this, we employ Shapley Values to quantify the\ncontribution of artist(s) in an image generated by the Stable Diffusion-v1.5\nmodel and to equitably allocate the reward among them.\n","authors":["Alex Glinsky","Alexey Sokolsky"],"pdf_url":"https://arxiv.org/pdf/2403.09700v2.pdf","comment":"36 pages, 32 figures"},{"id":"http://arxiv.org/abs/2310.00117v4","updated":"2024-03-27T13:38:00Z","published":"2023-09-29T20:11:15Z","title":"ABScribe: Rapid Exploration & Organization of Multiple Writing\n  Variations in Human-AI Co-Writing Tasks using Large Language Models","summary":"  Exploring alternative ideas by rewriting text is integral to the writing\nprocess. State-of-the-art Large Language Models (LLMs) can simplify writing\nvariation generation. However, current interfaces pose challenges for\nsimultaneous consideration of multiple variations: creating new variations\nwithout overwriting text can be difficult, and pasting them sequentially can\nclutter documents, increasing workload and disrupting writers' flow. To tackle\nthis, we present ABScribe, an interface that supports rapid, yet visually\nstructured, exploration and organization of writing variations in human-AI\nco-writing tasks. With ABScribe, users can swiftly modify variations using LLM\nprompts, which are auto-converted into reusable buttons. Variations are stored\nadjacently within text fields for rapid in-place comparisons using mouse-over\ninteractions on a popup toolbar. Our user study with 12 writers shows that\nABScribe significantly reduces task workload (d = 1.20, p < 0.001), enhances\nuser perceptions of the revision process (d = 2.41, p < 0.001) compared to a\npopular baseline workflow, and provides insights into how writers explore\nvariations using LLMs.\n","authors":["Mohi Reza","Nathan Laundry","Ilya Musabirov","Peter Dushniku","Zhi Yuan \"Michael\" Yu","Kashish Mittal","Tovi Grossman","Michael Liut","Anastasia Kuzminykh","Joseph Jay Williams"],"pdf_url":"https://arxiv.org/pdf/2310.00117v4.pdf","comment":"CHI 2024"},{"id":"http://arxiv.org/abs/2403.18547v1","updated":"2024-03-27T13:25:43Z","published":"2024-03-27T13:25:43Z","title":"Neural Architecture Search for Sentence Classification with BERT","summary":"  Pre training of language models on large text corpora is common practice in\nNatural Language Processing. Following, fine tuning of these models is\nperformed to achieve the best results on a variety of tasks. In this paper we\nquestion the common practice of only adding a single output layer as a\nclassification head on top of the network. We perform an AutoML search to find\narchitectures that outperform the current single layer at only a small compute\ncost. We validate our classification architecture on a variety of NLP\nbenchmarks from the GLUE dataset.\n","authors":["Philip Kenneweg","Sarah Schröder","Barbara Hammer"],"pdf_url":"https://arxiv.org/pdf/2403.18547v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18546v1","updated":"2024-03-27T13:24:58Z","published":"2024-03-27T13:24:58Z","title":"Efficient Heatmap-Guided 6-Dof Grasp Detection in Cluttered Scenes","summary":"  Fast and robust object grasping in clutter is a crucial component of\nrobotics. Most current works resort to the whole observed point cloud for 6-Dof\ngrasp generation, ignoring the guidance information excavated from global\nsemantics, thus limiting high-quality grasp generation and real-time\nperformance. In this work, we show that the widely used heatmaps are\nunderestimated in the efficiency of 6-Dof grasp generation. Therefore, we\npropose an effective local grasp generator combined with grasp heatmaps as\nguidance, which infers in a global-to-local semantic-to-point way.\nSpecifically, Gaussian encoding and the grid-based strategy are applied to\npredict grasp heatmaps as guidance to aggregate local points into graspable\nregions and provide global semantic information. Further, a novel non-uniform\nanchor sampling mechanism is designed to improve grasp accuracy and diversity.\nBenefiting from the high-efficiency encoding in the image space and focusing on\npoints in local graspable regions, our framework can perform high-quality grasp\ndetection in real-time and achieve state-of-the-art results. In addition, real\nrobot experiments demonstrate the effectiveness of our method with a success\nrate of 94% and a clutter completion rate of 100%. Our code is available at\nhttps://github.com/THU-VCLab/HGGD.\n","authors":["Siang Chen","Wei Tang","Pengwei Xie","Wenming Yang","Guijin Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18546v1.pdf","comment":"Extensive results on GraspNet-1B dataset"},{"id":"http://arxiv.org/abs/2403.18537v1","updated":"2024-03-27T13:12:57Z","published":"2024-03-27T13:12:57Z","title":"A Path Towards Legal Autonomy: An interoperable and explainable approach\n  to extracting, transforming, loading and computing legal information using\n  large language models, expert systems and Bayesian networks","summary":"  Legal autonomy - the lawful activity of artificial intelligence agents - can\nbe achieved in one of two ways. It can be achieved either by imposing\nconstraints on AI actors such as developers, deployers and users, and on AI\nresources such as data, or by imposing constraints on the range and scope of\nthe impact that AI agents can have on the environment. The latter approach\ninvolves encoding extant rules concerning AI driven devices into the software\nof AI agents controlling those devices (e.g., encoding rules about limitations\non zones of operations into the agent software of an autonomous drone device).\nThis is a challenge since the effectivity of such an approach requires a method\nof extracting, loading, transforming and computing legal information that would\nbe both explainable and legally interoperable, and that would enable AI agents\nto reason about the law. In this paper, we sketch a proof of principle for such\na method using large language models (LLMs), expert legal systems known as\nlegal decision paths, and Bayesian networks. We then show how the proposed\nmethod could be applied to extant regulation in matters of autonomous cars,\nsuch as the California Vehicle Code.\n","authors":["Axel Constant","Hannes Westermann","Bryan Wilson","Alex Kiefer","Ines Hipolito","Sylvain Pronovost","Steven Swanson","Mahault Albarracin","Maxwell J. D. Ramstead"],"pdf_url":"https://arxiv.org/pdf/2403.18537v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18536v1","updated":"2024-03-27T13:12:41Z","published":"2024-03-27T13:12:41Z","title":"A Novel Behavior-Based Recommendation System for E-commerce","summary":"  The majority of existing recommender systems rely on user ratings, which are\nlimited by the lack of user collaboration and the sparsity problem. To address\nthese issues, this study proposes a behavior-based recommender system that\nleverages customers' natural behaviors, such as browsing and clicking, on\ne-commerce platforms. The proposed recommendation system involves clustering\nactive customers, determining neighborhoods, collecting similar users,\ncalculating product reputation based on similar users, and recommending\nhigh-reputation products. To overcome the complexity of customer behaviors and\ntraditional clustering methods, an unsupervised clustering approach based on\nproduct categories is developed to enhance the recommendation methodology. This\nstudy makes notable contributions in several aspects. Firstly, a groundbreaking\nbehavior-based recommendation methodology is developed, incorporating customer\nbehavior to generate accurate and tailored recommendations leading to improved\ncustomer satisfaction and engagement. Secondly, an original unsupervised\nclustering method, focusing on product categories, enables more precise\nclustering and facilitates accurate recommendations. Finally, an approach to\ndetermine neighborhoods for active customers within clusters is established,\nensuring grouping of customers with similar behavioral patterns to enhance\nrecommendation accuracy and relevance. The proposed recommendation methodology\nand clustering method contribute to improved recommendation performance,\noffering valuable insights for researchers and practitioners in the field of\ne-commerce recommendation systems. Additionally, the proposed method\noutperforms benchmark methods in experiments conducted using a behavior dataset\nfrom the well-known e-commerce site Alibaba.\n","authors":["Reza Barzegar Nozari","Mahdi Divsalar","Sepehr Akbarzadeh Abkenar","Mohammadreza Fadavi Amiri","Ali Divsalar"],"pdf_url":"https://arxiv.org/pdf/2403.18536v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.10365v3","updated":"2024-03-27T12:53:12Z","published":"2023-03-18T08:48:16Z","title":"CroSel: Cross Selection of Confident Pseudo Labels for Partial-Label\n  Learning","summary":"  Partial-label learning (PLL) is an important weakly supervised learning\nproblem, which allows each training example to have a candidate label set\ninstead of a single ground-truth label. Identification-based methods have been\nwidely explored to tackle label ambiguity issues in PLL, which regard the true\nlabel as a latent variable to be identified. However, identifying the true\nlabels accurately and completely remains challenging, causing noise in pseudo\nlabels during model training. In this paper, we propose a new method called\nCroSel, which leverages historical predictions from the model to identify true\nlabels for most training examples. First, we introduce a cross selection\nstrategy, which enables two deep models to select true labels of partially\nlabeled data for each other. Besides, we propose a novel consistency\nregularization term called co-mix to avoid sample waste and tiny noise caused\nby false selection. In this way, CroSel can pick out the true labels of most\nexamples with high precision. Extensive experiments demonstrate the superiority\nof CroSel, which consistently outperforms previous state-of-the-art methods on\nbenchmark datasets. Additionally, our method achieves over 90\\% accuracy and\nquantity for selecting true labels on CIFAR-type datasets under various\nsettings.\n","authors":["Shiyu Tian","Hongxin Wei","Yiqun Wang","Lei Feng"],"pdf_url":"https://arxiv.org/pdf/2303.10365v3.pdf","comment":"Accepted by CVPR 2024"},{"id":"http://arxiv.org/abs/2403.18519v1","updated":"2024-03-27T12:50:27Z","published":"2024-03-27T12:50:27Z","title":"Improving Line Search Methods for Large Scale Neural Network Training","summary":"  In recent studies, line search methods have shown significant improvements in\nthe performance of traditional stochastic gradient descent techniques,\neliminating the need for a specific learning rate schedule. In this paper, we\nidentify existing issues in state-of-the-art line search methods, propose\nenhancements, and rigorously evaluate their effectiveness. We test these\nmethods on larger datasets and more complex data domains than before.\nSpecifically, we improve the Armijo line search by integrating the momentum\nterm from ADAM in its search direction, enabling efficient large-scale\ntraining, a task that was previously prone to failure using Armijo line search\nmethods. Our optimization approach outperforms both the previous Armijo\nimplementation and tuned learning rate schedules for Adam. Our evaluation\nfocuses on Transformers and CNNs in the domains of NLP and image data. Our work\nis publicly available as a Python package, which provides a hyperparameter free\nPytorch optimizer.\n","authors":["Philip Kenneweg","Tristan Kenneweg","Barbara Hammer"],"pdf_url":"https://arxiv.org/pdf/2403.18519v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18506v1","updated":"2024-03-27T12:35:23Z","published":"2024-03-27T12:35:23Z","title":"Faster Convergence for Transformer Fine-tuning with Line Search Methods","summary":"  Recent works have shown that line search methods greatly increase performance\nof traditional stochastic gradient descent methods on a variety of datasets and\narchitectures [1], [2]. In this work we succeed in extending line search\nmethods to the novel and highly popular Transformer architecture and dataset\ndomains in natural language processing. More specifically, we combine the\nArmijo line search with the Adam optimizer and extend it by subdividing the\nnetworks architecture into sensible units and perform the line search\nseparately on these local units. Our optimization method outperforms the\ntraditional Adam optimizer and achieves significant performance improvements\nfor small data sets or small training budgets, while performing equal or better\nfor other tested cases. Our work is publicly available as a python package,\nwhich provides a hyperparameter-free pytorch optimizer that is compatible with\narbitrary network architectures.\n","authors":["Philip Kenneweg","Leonardo Galli","Tristan Kenneweg","Barbara Hammer"],"pdf_url":"https://arxiv.org/pdf/2403.18506v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.04698v3","updated":"2024-03-27T12:24:17Z","published":"2023-11-08T14:10:19Z","title":"Challenging Common Paradigms in Multi-Task Learning","summary":"  While multi-task learning (MTL) has gained significant attention in recent\nyears, its underlying mechanisms remain poorly understood. Recent methods did\nnot yield consistent performance improvements over single task learning (STL)\nbaselines, underscoring the importance of gaining more profound insights about\nchallenges specific to MTL. In our study, we challenge paradigms in MTL in the\ncontext of STL: First, the impact of the choice of optimizer has only been\nmildly investigated in MTL. We show the pivotal role of common STL tools such\nas the Adam optimizer in MTL empirically in various experiments. To further\ninvestigate Adam's effectiveness, we theoretical derive a partial loss-scale\ninvariance under mild assumptions. Second, the notion of gradient conflicts has\noften been phrased as a specific problem in MTL. We delve into the role of\ngradient conflicts in MTL and compare it to STL. For angular gradient alignment\nwe find no evidence that this is a unique problem in MTL. We emphasize\ndifferences in gradient magnitude as the main distinguishing factor. Lastly, we\ncompare the transferability of features learned through MTL and STL on common\nimage corruptions, and find light evidence that MTL can lead to superior\ntransferability. Overall, we find surprising similarities between STL and MTL\nsuggesting to consider methods from both fields in a broader context.\n","authors":["Cathrin Elich","Lukas Kirchdorfer","Jan M. Köhler","Lukas Schott"],"pdf_url":"https://arxiv.org/pdf/2311.04698v3.pdf","comment":"-"},{"id":"http://arxiv.org/abs/2403.15114v2","updated":"2024-03-27T12:13:42Z","published":"2024-03-22T11:16:11Z","title":"Solving a Real-World Package Delivery Routing Problem Using Quantum\n  Annealers","summary":"  Research focused on the conjunction between quantum computing and routing\nproblems has been very prolific in recent years. Most of the works revolve\naround classical problems such as the Traveling Salesman Problem or the Vehicle\nRouting Problem. Even though working on these problems is valuable, it is also\nundeniable that their academic-oriented nature falls short of real-world\nrequirements. The main objective of this research is to present a solving\nmethod for realistic instances, avoiding problem relaxations or technical\nshortcuts. Instead, a quantum-classical hybrid solver has been developed,\ncoined Q4RPD, that considers a set of real constraints such as a heterogeneous\nfleet of vehicles, priority deliveries, and capacities characterized by two\nvalues: weight and dimensions of the packages. Q4RPD resorts to the Leap\nConstrained Quadratic Model Hybrid Solver of D-Wave. To demonstrate the\napplication of Q4RPD, an experimentation composed of six different instances\nhas been conducted, aiming to serve as illustrative examples.\n","authors":["Eneko Osaba","Esther Villar-Rodriguez","Antón Asla"],"pdf_url":"https://arxiv.org/pdf/2403.15114v2.pdf","comment":"15 pages, 11 figures and 4 tables. Paper submitted for review in\n  Scientific Reports"},{"id":"http://arxiv.org/abs/2403.18489v1","updated":"2024-03-27T12:01:51Z","published":"2024-03-27T12:01:51Z","title":"Impact of Employing Weather Forecast Data as Input to the Estimation of\n  Evapotranspiration by Deep Neural Network Models","summary":"  Reference Evapotranspiration (ET0) is a key parameter for designing smart\nirrigation scheduling, since it is related by a coefficient to the water needs\nof a crop. The United Nations Food and Agriculture Organization, proposed a\nstandard method for ET0 computation (FAO56PM), based on the parameterization of\nthe Penman-Monteith equation, that is widely adopted in the literature. To\ncompute ET0 using the FAO56-PM method, four main weather parameters are needed:\ntemperature, humidity, wind, and solar radiation (SR). One way to make daily\nET0 estimations for future days is to use freely available weather forecast\nservices (WFSs), where many meteorological parameters are estimated up to the\nnext 15 days. A problem with this method is that currently, SR is not provided\nas a free forecast parameter on most of those online services or, normally,\nsuch forecasts present a financial cost penalty. For this reason, several ET0\nestimation models using machine and deep learning were developed and presented\nin the literature, that use as input features a reduced set of carefully\nselected weather parameters, that are compatible with common freely available\nWFSs. However, most studies on this topic have only evaluated model performance\nusing data from weather stations (WSs), without considering the effect of using\nweather forecast data. In this study, the performance of authors' previous\nmodels is evaluated when using weather forecast data from two online WFSs, in\nthe following scenarios: (i) direct ET0 estimation by an ANN model, and (ii)\nestimate SR by ANN model, and then use that estimation for ET0 computation,\nusing the FAO56-PM method. Employing data collected from two WFSs and a WS\nlocated in Vale do Lobo, Portugal, the latter approach achieved the best\nresult, with a coefficient of determination (R2) ranging between 0.893 and\n0.667, when considering forecasts up to 15 days.\n","authors":["Pedro J. Vaz","Gabriela Schütz","Carlos Guerrero","Pedro J. S. Cardoso"],"pdf_url":"https://arxiv.org/pdf/2403.18489v1.pdf","comment":"A partial version of the work submitted to ESRE/INTERNATIONAL\n  CONFERENCE ON ENVIRONMENTAL SCIENCES AND RENEWABLE ENERGY"},{"id":"http://arxiv.org/abs/2403.18486v1","updated":"2024-03-27T11:58:45Z","published":"2024-03-27T11:58:45Z","title":"Synthesizing EEG Signals from Event-Related Potential Paradigms with\n  Conditional Diffusion Models","summary":"  Data scarcity in the brain-computer interface field can be alleviated through\nthe use of generative models, specifically diffusion models. While diffusion\nmodels have previously been successfully applied to electroencephalogram (EEG)\ndata, existing models lack flexibility w.r.t.~sampling or require alternative\nrepresentations of the EEG data. To overcome these limitations, we introduce a\nnovel approach to conditional diffusion models that utilizes classifier-free\nguidance to directly generate subject-, session-, and class-specific EEG data.\nIn addition to commonly used metrics, domain-specific metrics are employed to\nevaluate the specificity of the generated samples. The results indicate that\nthe proposed model can generate EEG data that resembles real data for each\nsubject, session, and class.\n","authors":["Guido Klein","Pierre Guetschel","Gianluigi Silvestri","Michael Tangermann"],"pdf_url":"https://arxiv.org/pdf/2403.18486v1.pdf","comment":"submitted to 9th Graz BCI conference, 6 pages, 3 figures, first\n  figure is split into two subfigures, 1 table"},{"id":"http://arxiv.org/abs/2311.12028v2","updated":"2024-03-27T11:43:28Z","published":"2023-11-20T18:59:51Z","title":"Hourglass Tokenizer for Efficient Transformer-Based 3D Human Pose\n  Estimation","summary":"  Transformers have been successfully applied in the field of video-based 3D\nhuman pose estimation. However, the high computational costs of these video\npose transformers (VPTs) make them impractical on resource-constrained devices.\nIn this paper, we present a plug-and-play pruning-and-recovering framework,\ncalled Hourglass Tokenizer (HoT), for efficient transformer-based 3D human pose\nestimation from videos. Our HoT begins with pruning pose tokens of redundant\nframes and ends with recovering full-length tokens, resulting in a few pose\ntokens in the intermediate transformer blocks and thus improving the model\nefficiency. To effectively achieve this, we propose a token pruning cluster\n(TPC) that dynamically selects a few representative tokens with high semantic\ndiversity while eliminating the redundancy of video frames. In addition, we\ndevelop a token recovering attention (TRA) to restore the detailed\nspatio-temporal information based on the selected tokens, thereby expanding the\nnetwork output to the original full-length temporal resolution for fast\ninference. Extensive experiments on two benchmark datasets (i.e., Human3.6M and\nMPI-INF-3DHP) demonstrate that our method can achieve both high efficiency and\nestimation accuracy compared to the original VPT models. For instance, applying\nto MotionBERT and MixSTE on Human3.6M, our HoT can save nearly 50% FLOPs\nwithout sacrificing accuracy and nearly 40% FLOPs with only 0.2% accuracy drop,\nrespectively. Code and models are available at\nhttps://github.com/NationalGAILab/HoT.\n","authors":["Wenhao Li","Mengyuan Liu","Hong Liu","Pichao Wang","Jialun Cai","Nicu Sebe"],"pdf_url":"https://arxiv.org/pdf/2311.12028v2.pdf","comment":"Accepted by CVPR 2024, Open Sourced"},{"id":"http://arxiv.org/abs/2403.16432v2","updated":"2024-03-27T11:37:58Z","published":"2024-03-25T05:27:35Z","title":"$\\textit{LinkPrompt}$: Natural and Universal Adversarial Attacks on\n  Prompt-based Language Models","summary":"  Prompt-based learning is a new language model training paradigm that adapts\nthe Pre-trained Language Models (PLMs) to downstream tasks, which revitalizes\nthe performance benchmarks across various natural language processing (NLP)\ntasks. Instead of using a fixed prompt template to fine-tune the model, some\nresearch demonstrates the effectiveness of searching for the prompt via\noptimization. Such prompt optimization process of prompt-based learning on PLMs\nalso gives insight into generating adversarial prompts to mislead the model,\nraising concerns about the adversarial vulnerability of this paradigm. Recent\nstudies have shown that universal adversarial triggers (UATs) can be generated\nto alter not only the predictions of the target PLMs but also the prediction of\ncorresponding Prompt-based Fine-tuning Models (PFMs) under the prompt-based\nlearning paradigm. However, UATs found in previous works are often unreadable\ntokens or characters and can be easily distinguished from natural texts with\nadaptive defenses. In this work, we consider the naturalness of the UATs and\ndevelop $\\textit{LinkPrompt}$, an adversarial attack algorithm to generate UATs\nby a gradient-based beam search algorithm that not only effectively attacks the\ntarget PLMs and PFMs but also maintains the naturalness among the trigger\ntokens. Extensive results demonstrate the effectiveness of\n$\\textit{LinkPrompt}$, as well as the transferability of UATs generated by\n$\\textit{LinkPrompt}$ to open-sourced Large Language Model (LLM) Llama2 and\nAPI-accessed LLM GPT-3.5-turbo.\n","authors":["Yue Xu","Wenjie Wang"],"pdf_url":"https://arxiv.org/pdf/2403.16432v2.pdf","comment":"Accepted to the main conference of NAACL2024"},{"id":"http://arxiv.org/abs/2311.07838v3","updated":"2024-03-27T11:36:46Z","published":"2023-11-14T01:38:02Z","title":"LLatrieval: LLM-Verified Retrieval for Verifiable Generation","summary":"  Verifiable generation aims to let the large language model (LLM) generate\ntext with supporting documents, which enables the user to flexibly verify the\nanswer and makes the LLM's output more reliable. Retrieval plays a crucial role\nin verifiable generation. Specifically, the retrieved documents not only\nsupplement knowledge to help the LLM generate correct answers, but also serve\nas supporting evidence for the user to verify the LLM's output. However, the\nwidely used retrievers become the bottleneck of the entire pipeline and limit\nthe overall performance. Their capabilities are usually inferior to LLMs since\nthey often have much fewer parameters than the large language model and have\nnot been demonstrated to scale well to the size of LLMs. If the retriever does\nnot correctly find the supporting documents, the LLM can not generate the\ncorrect and verifiable answer, which overshadows the LLM's remarkable\nabilities. To address these limitations, we propose \\LLatrieval (Large Language\nModel Verified Retrieval), where the LLM updates the retrieval result until it\nverifies that the retrieved documents can sufficiently support answering the\nquestion. Thus, the LLM can iteratively provide feedback to retrieval and\nfacilitate the retrieval result to fully support verifiable generation.\nExperiments show that LLatrieval significantly outperforms extensive baselines\nand achieves state-of-the-art results.\n","authors":["Xiaonan Li","Changtai Zhu","Linyang Li","Zhangyue Yin","Tianxiang Sun","Xipeng Qiu"],"pdf_url":"https://arxiv.org/pdf/2311.07838v3.pdf","comment":"Accepted by NAACL 2024 (Main Conference)"},{"id":"http://arxiv.org/abs/2403.18469v1","updated":"2024-03-27T11:28:57Z","published":"2024-03-27T11:28:57Z","title":"Density-guided Translator Boosts Synthetic-to-Real Unsupervised Domain\n  Adaptive Segmentation of 3D Point Clouds","summary":"  3D synthetic-to-real unsupervised domain adaptive segmentation is crucial to\nannotating new domains. Self-training is a competitive approach for this task,\nbut its performance is limited by different sensor sampling patterns (i.e.,\nvariations in point density) and incomplete training strategies. In this work,\nwe propose a density-guided translator (DGT), which translates point density\nbetween domains, and integrates it into a two-stage self-training pipeline\nnamed DGT-ST. First, in contrast to existing works that simultaneously conduct\ndata generation and feature/output alignment within unstable adversarial\ntraining, we employ the non-learnable DGT to bridge the domain gap at the input\nlevel. Second, to provide a well-initialized model for self-training, we\npropose a category-level adversarial network in stage one that utilizes the\nprototype to prevent negative transfer. Finally, by leveraging the designs\nabove, a domain-mixed self-training method with source-aware consistency loss\nis proposed in stage two to narrow the domain gap further. Experiments on two\nsynthetic-to-real segmentation tasks (SynLiDAR $\\rightarrow$ semanticKITTI and\nSynLiDAR $\\rightarrow$ semanticPOSS) demonstrate that DGT-ST outperforms\nstate-of-the-art methods, achieving 9.4$\\%$ and 4.3$\\%$ mIoU improvements,\nrespectively. Code is available at \\url{https://github.com/yuan-zm/DGT-ST}.\n","authors":["Zhimin Yuan","Wankang Zeng","Yanfei Su","Weiquan Liu","Ming Cheng","Yulan Guo","Cheng Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18469v1.pdf","comment":"CVPR2024"},{"id":"http://arxiv.org/abs/2311.10522v4","updated":"2024-03-27T11:18:51Z","published":"2023-11-17T13:43:43Z","title":"Enhancing Object Coherence in Layout-to-Image Synthesis","summary":"  Layout-to-image synthesis is an emerging technique in conditional image\ngeneration. It aims to generate complex scenes, where users require fine\ncontrol over the layout of the objects in a scene. However, it remains\nchallenging to control the object coherence, including semantic coherence\n(e.g., the cat looks at the flowers or not) and physical coherence (e.g., the\nhand and the racket should not be misaligned). In this paper, we propose a\nnovel diffusion model with effective global semantic fusion (GSF) and\nself-similarity feature enhancement modules to guide the object coherence for\nthis task. For semantic coherence, we argue that the image caption contains\nrich information for defining the semantic relationship within the objects in\nthe images. Instead of simply employing cross-attention between captions and\ngenerated images, which addresses the highly relevant layout restriction and\nsemantic coherence separately and thus leads to unsatisfying results shown in\nour experiments, we develop GSF to fuse the supervision from the layout\nrestriction and semantic coherence requirement and exploit it to guide the\nimage synthesis process. Moreover, to improve the physical coherence, we\ndevelop a Self-similarity Coherence Attention (SCA) module to explicitly\nintegrate local contextual physical coherence into each pixel's generation\nprocess. Specifically, we adopt a self-similarity map to encode the coherence\nrestrictions and employ it to extract coherent features from text embedding.\nThrough visualization of our self-similarity map, we explore the essence of\nSCA, revealing that its effectiveness is not only in capturing reliable\nphysical coherence patterns but also in enhancing complex texture generation.\nExtensive experiments demonstrate the superiority of our proposed method in\nboth image generation quality and controllability.\n","authors":["Yibin Wang","Weizhong Zhang","Jianwei Zheng","Cheng Jin"],"pdf_url":"https://arxiv.org/pdf/2311.10522v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18459v1","updated":"2024-03-27T11:18:01Z","published":"2024-03-27T11:18:01Z","title":"CoBOS: Constraint-Based Online Scheduler for Human-Robot Collaboration","summary":"  Assembly processes involving humans and robots are challenging scenarios\nbecause the individual activities and access to shared workspace have to be\ncoordinated. Fixed robot programs leave no room to diverge from a fixed\nprotocol. Working on such a process can be stressful for the user and lead to\nineffective behavior or failure. We propose a novel approach of online\nconstraint-based scheduling in a reactive execution control framework\nfacilitating behavior trees called CoBOS. This allows the robot to adapt to\nuncertain events such as delayed activity completions and activity selection\n(by the human). The user will experience less stress as the robotic coworkers\nadapt their behavior to best complement the human-selected activities to\ncomplete the common task. In addition to the improved working conditions, our\nalgorithm leads to increased efficiency, even in highly uncertain scenarios. We\nevaluate our algorithm using a probabilistic simulation study with 56000\nexperiments. We outperform all baselines by a margin of 4-10%. Initial real\nrobot experiments using a Franka Emika Panda robot and human tracking based on\nHTC Vive VR gloves look promising.\n","authors":["Marina Ionova","Jan Kristof Behrens"],"pdf_url":"https://arxiv.org/pdf/2403.18459v1.pdf","comment":"7 pages, 8 figures"},{"id":"http://arxiv.org/abs/2403.18451v1","updated":"2024-03-27T11:11:06Z","published":"2024-03-27T11:11:06Z","title":"CoRAST: Towards Foundation Model-Powered Correlated Data Analysis in\n  Resource-Constrained CPS and IoT","summary":"  Foundation models (FMs) emerge as a promising solution to harness distributed\nand diverse environmental data by leveraging prior knowledge to understand the\ncomplicated temporal and spatial correlations within heterogeneous datasets.\nUnlike distributed learning frameworks such as federated learning, which often\nstruggle with multimodal data, FMs can transform diverse inputs into\nembeddings. This process facilitates the integration of information from\nvarious modalities and the application of prior learning to new domains.\nHowever, deploying FMs in resource-constrained edge systems poses significant\nchallenges. To this end, we introduce CoRAST, a novel learning framework that\nutilizes FMs for enhanced analysis of distributed, correlated heterogeneous\ndata. Utilizing a server-based FM, CoRAST can exploit existing environment\ninformation to extract temporal, spatial, and cross-modal correlations among\nsensor data. This enables CoRAST to offer context-aware insights for localized\nclient tasks through FM-powered global representation learning. Our evaluation\non real-world weather dataset demonstrates CoRAST's ability to exploit\ncorrelated heterogeneous data through environmental representation learning to\nreduce the forecast errors by up to 50.3% compared to the baselines.\n","authors":["Yi Hu","Jinhang Zuo","Alanis Zhao","Bob Iannucci","Carlee Joe-Wong"],"pdf_url":"https://arxiv.org/pdf/2403.18451v1.pdf","comment":"accepted and to be published in 2024 IEEE International Workshop on\n  Foundation Models for Cyber-Physical Systems & Internet of Things (FMSys)"},{"id":"http://arxiv.org/abs/2403.18425v1","updated":"2024-03-27T10:26:42Z","published":"2024-03-27T10:26:42Z","title":"U-Sketch: An Efficient Approach for Sketch to Image Diffusion Models","summary":"  Diffusion models have demonstrated remarkable performance in text-to-image\nsynthesis, producing realistic and high resolution images that faithfully\nadhere to the corresponding text-prompts. Despite their great success, they\nstill fall behind in sketch-to-image synthesis tasks, where in addition to\ntext-prompts, the spatial layout of the generated images has to closely follow\nthe outlines of certain reference sketches. Employing an MLP latent edge\npredictor to guide the spatial layout of the synthesized image by predicting\nedge maps at each denoising step has been recently proposed. Despite yielding\npromising results, the pixel-wise operation of the MLP does not take into\naccount the spatial layout as a whole, and demands numerous denoising\niterations to produce satisfactory images, leading to time inefficiency. To\nthis end, we introduce U-Sketch, a framework featuring a U-Net type latent edge\npredictor, which is capable of efficiently capturing both local and global\nfeatures, as well as spatial correlations between pixels. Moreover, we propose\nthe addition of a sketch simplification network that offers the user the choice\nof preprocessing and simplifying input sketches for enhanced outputs. The\nexperimental results, corroborated by user feedback, demonstrate that our\nproposed U-Net latent edge predictor leads to more realistic results, that are\nbetter aligned with the spatial outlines of the reference sketches, while\ndrastically reducing the number of required denoising steps and, consequently,\nthe overall execution time.\n","authors":["Ilias Mitsouras","Eleftherios Tsonis","Paraskevi Tzouveli","Athanasios Voulodimos"],"pdf_url":"https://arxiv.org/pdf/2403.18425v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.01739v2","updated":"2024-03-27T10:21:24Z","published":"2024-01-29T12:05:02Z","title":"OpenMoE: An Early Effort on Open Mixture-of-Experts Language Models","summary":"  To help the open-source community have a better understanding of\nMixture-of-Experts (MoE) based large language models (LLMs), we train and\nrelease OpenMoE, a series of fully open-sourced and reproducible decoder-only\nMoE LLMs, ranging from 650M to 34B parameters and trained on up to over 1T\ntokens. Our investigation confirms that MoE-based LLMs can offer a more\nfavorable cost-effectiveness trade-off than dense LLMs, highlighting the\npotential effectiveness for future LLM development.\n  One more important contribution of this study is an in-depth analysis of the\nrouting mechanisms within our OpenMoE models, leading to three significant\nfindings: Context-Independent Specialization, Early Routing Learning, and\nDrop-towards-the-End. We discovered that routing decisions in MoE models are\npredominantly based on token IDs, with minimal context relevance. The\ntoken-to-expert assignments are determined early in the pre-training phase and\nremain largely unchanged. This imperfect routing can result in performance\ndegradation, particularly in sequential tasks like multi-turn conversations,\nwhere tokens appearing later in a sequence are more likely to be dropped.\nFinally, we rethink our design based on the above-mentioned observations and\nanalysis. To facilitate future MoE LLM development, we propose potential\nstrategies for mitigating the issues we found and further improving\noff-the-shelf MoE LLM designs.\n","authors":["Fuzhao Xue","Zian Zheng","Yao Fu","Jinjie Ni","Zangwei Zheng","Wangchunshu Zhou","Yang You"],"pdf_url":"https://arxiv.org/pdf/2402.01739v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18421v1","updated":"2024-03-27T10:18:21Z","published":"2024-03-27T10:18:21Z","title":"BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text","summary":"  Models such as GPT-4 and Med-PaLM 2 have demonstrated impressive performance\non a wide variety of biomedical NLP tasks. However, these models have hundreds\nof billions of parameters, are computationally expensive to run, require users\nto send their input data over the internet, and are trained on unknown data\nsources. Can smaller, more targeted models compete? To address this question,\nwe build and release BioMedLM, a 2.7 billion parameter GPT-style autoregressive\nmodel trained exclusively on PubMed abstracts and full articles. When\nfine-tuned, BioMedLM can produce strong multiple-choice biomedical\nquestion-answering results competitive with much larger models, such as\nachieving a score of 57.3% on MedMCQA (dev) and 69.0% on the MMLU Medical\nGenetics exam. BioMedLM can also be fine-tuned to produce useful answers to\npatient questions on medical topics. This demonstrates that smaller models can\npotentially serve as transparent, privacy-preserving, economical and\nenvironmentally friendly foundations for particular NLP applications, such as\nin biomedicine. The model is available on the Hugging Face Hub:\nhttps://huggingface.co/stanford-crfm/BioMedLM.\n","authors":["Elliot Bolton","Abhinav Venigalla","Michihiro Yasunaga","David Hall","Betty Xiong","Tony Lee","Roxana Daneshjou","Jonathan Frankle","Percy Liang","Michael Carbin","Christopher D. Manning"],"pdf_url":"https://arxiv.org/pdf/2403.18421v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2311.01191v2","updated":"2024-03-27T10:12:31Z","published":"2023-11-02T12:36:19Z","title":"VIGraph: Generative Self-supervised Learning for Class-Imbalanced Node\n  Classification","summary":"  Class imbalance in graph data presents significant challenges for node\nclassification. While existing methods, such as SMOTE-based approaches,\npartially mitigate this issue, they still exhibit limitations in constructing\nimbalanced graphs. Generative self-supervised learning (SSL) methods,\nexemplified by graph autoencoders (GAEs), offer a promising solution by\ndirectly generating minority nodes from the data itself, yet their potential\nremains underexplored. In this paper, we delve into the shortcomings of\nSMOTE-based approaches in the construction of imbalanced graphs. Furthermore,\nwe introduce VIGraph, a simple yet effective generative SSL approach that\nrelies on the Variational GAE as the fundamental model. VIGraph strictly\nadheres to the concept of imbalance when constructing imbalanced graphs and\ninnovatively leverages the variational inference (VI) ability of Variational\nGAE to generate nodes for minority classes. VIGraph introduces comprehensive\ntraining strategies, including cross-view contrastive learning at the decoding\nphase to capture semantic knowledge, adjacency matrix reconstruction to\npreserve graph structure, and alignment strategy to ensure stable training.\nVIGraph can generate high-quality nodes directly usable for classification,\neliminating the need to integrate the generated nodes back to the graph as well\nas additional retraining found in SMOTE-based methods. We conduct extensive\nexperiments, results from which demonstrate the superiority and generality of\nour approach.\n","authors":["Yulan Hu","Sheng Ouyang","Zhirui Yang","Yong Liu"],"pdf_url":"https://arxiv.org/pdf/2311.01191v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18407v1","updated":"2024-03-27T09:49:37Z","published":"2024-03-27T09:49:37Z","title":"A Channel-ensemble Approach: Unbiased and Low-variance Pseudo-labels is\n  Critical for Semi-supervised Classification","summary":"  Semi-supervised learning (SSL) is a practical challenge in computer vision.\nPseudo-label (PL) methods, e.g., FixMatch and FreeMatch, obtain the State Of\nThe Art (SOTA) performances in SSL. These approaches employ a\nthreshold-to-pseudo-label (T2L) process to generate PLs by truncating the\nconfidence scores of unlabeled data predicted by the self-training method.\nHowever, self-trained models typically yield biased and high-variance\npredictions, especially in the scenarios when a little labeled data are\nsupplied. To address this issue, we propose a lightweight channel-based\nensemble method to effectively consolidate multiple inferior PLs into the\ntheoretically guaranteed unbiased and low-variance one. Importantly, our\napproach can be readily extended to any SSL framework, such as FixMatch or\nFreeMatch. Experimental results demonstrate that our method significantly\noutperforms state-of-the-art techniques on CIFAR10/100 in terms of\neffectiveness and efficiency.\n","authors":["Jiaqi Wu","Junbiao Pang","Baochang Zhang","Qingming Huang"],"pdf_url":"https://arxiv.org/pdf/2403.18407v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18406v1","updated":"2024-03-27T09:48:23Z","published":"2024-03-27T09:48:23Z","title":"An Image Grid Can Be Worth a Video: Zero-shot Video Question Answering\n  Using a VLM","summary":"  Stimulated by the sophisticated reasoning capabilities of recent Large\nLanguage Models (LLMs), a variety of strategies for bridging video modality\nhave been devised. A prominent strategy involves Video Language Models\n(VideoLMs), which train a learnable interface with video data to connect\nadvanced vision encoders with LLMs. Recently, an alternative strategy has\nsurfaced, employing readily available foundation models, such as VideoLMs and\nLLMs, across multiple stages for modality bridging. In this study, we introduce\na simple yet novel strategy where only a single Vision Language Model (VLM) is\nutilized. Our starting point is the plain insight that a video comprises a\nseries of images, or frames, interwoven with temporal information. The essence\nof video comprehension lies in adeptly managing the temporal aspects along with\nthe spatial details of each frame. Initially, we transform a video into a\nsingle composite image by arranging multiple frames in a grid layout. The\nresulting single image is termed as an image grid. This format, while\nmaintaining the appearance of a solitary image, effectively retains temporal\ninformation within the grid structure. Therefore, the image grid approach\nenables direct application of a single high-performance VLM without\nnecessitating any video-data training. Our extensive experimental analysis\nacross ten zero-shot video question answering benchmarks, including five\nopen-ended and five multiple-choice benchmarks, reveals that the proposed Image\nGrid Vision Language Model (IG-VLM) surpasses the existing methods in nine out\nof ten benchmarks.\n","authors":["Wonkyun Kim","Changin Choi","Wonseok Lee","Wonjong Rhee"],"pdf_url":"https://arxiv.org/pdf/2403.18406v1.pdf","comment":"Our code is available at https://github.com/imagegridworth/IG-VLM"},{"id":"http://arxiv.org/abs/2403.18405v1","updated":"2024-03-27T09:46:56Z","published":"2024-03-27T09:46:56Z","title":"Leveraging Large Language Models for Relevance Judgments in Legal Case\n  Retrieval","summary":"  Collecting relevant judgments for legal case retrieval is a challenging and\ntime-consuming task. Accurately judging the relevance between two legal cases\nrequires a considerable effort to read the lengthy text and a high level of\ndomain expertise to extract Legal Facts and make juridical judgments. With the\nadvent of advanced large language models, some recent studies have suggested\nthat it is promising to use LLMs for relevance judgment. Nonetheless, the\nmethod of employing a general large language model for reliable relevance\njudgments in legal case retrieval is yet to be thoroughly explored. To fill\nthis research gap, we devise a novel few-shot workflow tailored to the relevant\njudgment of legal cases. The proposed workflow breaks down the annotation\nprocess into a series of stages, imitating the process employed by human\nannotators and enabling a flexible integration of expert reasoning to enhance\nthe accuracy of relevance judgments. By comparing the relevance judgments of\nLLMs and human experts, we empirically show that we can obtain reliable\nrelevance judgments with the proposed workflow. Furthermore, we demonstrate the\ncapacity to augment existing legal case retrieval models through the synthesis\nof data generated by the large language model.\n","authors":["Shengjie Ma","Chong Chen","Qi Chu","Jiaxin Mao"],"pdf_url":"https://arxiv.org/pdf/2403.18405v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18397v1","updated":"2024-03-27T09:35:56Z","published":"2024-03-27T09:35:56Z","title":"Colour and Brush Stroke Pattern Recognition in Abstract Art using\n  Modified Deep Convolutional Generative Adversarial Networks","summary":"  Abstract Art is an immensely popular, discussed form of art that often has\nthe ability to depict the emotions of an artist. Many researchers have made\nattempts to study abstract art in the form of edge detection, brush stroke and\nemotion recognition algorithms using machine and deep learning. This papers\ndescribes the study of a wide distribution of abstract paintings using\nGenerative Adversarial Neural Networks(GAN). GANs have the ability to learn and\nreproduce a distribution enabling researchers and scientists to effectively\nexplore and study the generated image space. However, the challenge lies in\ndeveloping an efficient GAN architecture that overcomes common training\npitfalls. This paper addresses this challenge by introducing a modified-DCGAN\n(mDCGAN) specifically designed for high-quality artwork generation. The\napproach involves a thorough exploration of the modifications made, delving\ninto the intricate workings of DCGANs, optimisation techniques, and\nregularisation methods aimed at improving stability and realism in art\ngeneration enabling effective study of generated patterns. The proposed mDCGAN\nincorporates meticulous adjustments in layer configurations and architectural\nchoices, offering tailored solutions to the unique demands of art generation\nwhile effectively combating issues like mode collapse and gradient vanishing.\nFurther this paper explores the generated latent space by performing random\nwalks to understand vector relationships between brush strokes and colours in\nthe abstract art space and a statistical analysis of unstable outputs after a\ncertain period of GAN training and compare its significant difference. These\nfindings validate the effectiveness of the proposed approach, emphasising its\npotential to revolutionise the field of digital art generation and digital art\necosystem.\n","authors":["Srinitish Srinivasan","Varenya Pathak"],"pdf_url":"https://arxiv.org/pdf/2403.18397v1.pdf","comment":"28 pages, 5 tables, 7 figures"},{"id":"http://arxiv.org/abs/2403.18388v1","updated":"2024-03-27T09:25:20Z","published":"2024-03-27T09:25:20Z","title":"FTBC: Forward Temporal Bias Correction for Optimizing ANN-SNN Conversion","summary":"  Spiking Neural Networks (SNNs) offer a promising avenue for energy-efficient\ncomputing compared with Artificial Neural Networks (ANNs), closely mirroring\nbiological neural processes. However, this potential comes with inherent\nchallenges in directly training SNNs through spatio-temporal backpropagation --\nstemming from the temporal dynamics of spiking neurons and their discrete\nsignal processing -- which necessitates alternative ways of training, most\nnotably through ANN-SNN conversion. In this work, we introduce a lightweight\nForward Temporal Bias Correction (FTBC) technique, aimed at enhancing\nconversion accuracy without the computational overhead. We ground our method on\nprovided theoretical findings that through proper temporal bias calibration the\nexpected error of ANN-SNN conversion can be reduced to be zero after each time\nstep. We further propose a heuristic algorithm for finding the temporal bias\nonly in the forward pass, thus eliminating the computational burden of\nbackpropagation and we evaluate our method on CIFAR-10/100 and ImageNet\ndatasets, achieving a notable increase in accuracy on all datasets. Codes are\nreleased at a GitHub repository.\n","authors":["Xiaofeng Wu","Velibor Bojkovic","Bin Gu","Kun Suo","Kai Zou"],"pdf_url":"https://arxiv.org/pdf/2403.18388v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14864v2","updated":"2024-03-27T09:24:55Z","published":"2024-03-21T22:18:59Z","title":"Learning Quadruped Locomotion Using Differentiable Simulation","summary":"  While most recent advancements in legged robot control have been driven by\nmodel-free reinforcement learning, we explore the potential of differentiable\nsimulation. Differentiable simulation promises faster convergence and more\nstable training by computing low-variant first-order gradients using the robot\nmodel, but so far, its use for legged robot control has remained limited to\nsimulation. The main challenge with differentiable simulation lies in the\ncomplex optimization landscape of robotic tasks due to discontinuities in\ncontact-rich environments, e.g., quadruped locomotion. This work proposes a\nnew, differentiable simulation framework to overcome these challenges. The key\nidea involves decoupling the complex whole-body simulation, which may exhibit\ndiscontinuities due to contact, into two separate continuous domains.\nSubsequently, we align the robot state resulting from the simplified model with\na more precise, non-differentiable simulator to maintain sufficient simulation\naccuracy. Our framework enables learning quadruped walking in minutes using a\nsingle simulated robot without any parallelization. When augmented with GPU\nparallelization, our approach allows the quadruped robot to master diverse\nlocomotion skills, including trot, pace, bound, and gallop, on challenging\nterrains in minutes. Additionally, our policy achieves robust locomotion\nperformance in the real world zero-shot. To the best of our knowledge, this\nwork represents the first demonstration of using differentiable simulation for\ncontrolling a real quadruped robot. This work provides several important\ninsights into using differentiable simulations for legged locomotion in the\nreal world.\n","authors":["Yunlong Song","Sangbae Kim","Davide Scaramuzza"],"pdf_url":"https://arxiv.org/pdf/2403.14864v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18383v1","updated":"2024-03-27T09:21:07Z","published":"2024-03-27T09:21:07Z","title":"Generative Multi-modal Models are Good Class-Incremental Learners","summary":"  In class-incremental learning (CIL) scenarios, the phenomenon of catastrophic\nforgetting caused by the classifier's bias towards the current task has long\nposed a significant challenge. It is mainly caused by the characteristic of\ndiscriminative models. With the growing popularity of the generative\nmulti-modal models, we would explore replacing discriminative models with\ngenerative ones for CIL. However, transitioning from discriminative to\ngenerative models requires addressing two key challenges. The primary challenge\nlies in transferring the generated textual information into the classification\nof distinct categories. Additionally, it requires formulating the task of CIL\nwithin a generative framework. To this end, we propose a novel generative\nmulti-modal model (GMM) framework for class-incremental learning. Our approach\ndirectly generates labels for images using an adapted generative model. After\nobtaining the detailed text, we use a text encoder to extract text features and\nemploy feature matching to determine the most similar label as the\nclassification prediction. In the conventional CIL settings, we achieve\nsignificantly better results in long-sequence task scenarios. Under the\nFew-shot CIL setting, we have improved by at least 14\\% accuracy over all the\ncurrent state-of-the-art methods with significantly less forgetting. Our code\nis available at \\url{https://github.com/DoubleClass/GMM}.\n","authors":["Xusheng Cao","Haori Lu","Linlan Huang","Xialei Liu","Ming-Ming Cheng"],"pdf_url":"https://arxiv.org/pdf/2403.18383v1.pdf","comment":"Accepted at CVPR 2024"},{"id":"http://arxiv.org/abs/2403.18381v1","updated":"2024-03-27T09:19:13Z","published":"2024-03-27T09:19:13Z","title":"Improving Attributed Text Generation of Large Language Models via\n  Preference Learning","summary":"  Large language models have been widely adopted in natural language\nprocessing, yet they face the challenge of generating unreliable content.\nRecent works aim to reduce misinformation and hallucinations by resorting to\nattribution as a means to provide evidence (i.e., citations). However, current\nattribution methods usually focus on the retrieval stage and automatic\nevaluation that neglect mirroring the citation mechanisms in human scholarly\nwriting to bolster credibility. In this paper, we address these challenges by\nmodelling the attribution task as preference learning and introducing an\nAutomatic Preference Optimization (APO) framework. First, we create a curated\ncollection for post-training with 6,330 examples by collecting and filtering\nfrom existing datasets. Second, considering the high cost of labelling\npreference data, we further propose an automatic method to synthesize\nattribution preference data resulting in 95,263 pairs. Moreover, inspired by\nthe human citation process, we further propose a progressive preference\noptimization method by leveraging fine-grained information. Extensive\nexperiments on three datasets (i.e., ASQA, StrategyQA, and ELI5) demonstrate\nthat APO achieves state-of-the-art citation F1 with higher answer quality.\n","authors":["Dongfang Li","Zetian Sun","Baotian Hu","Zhenyu Liu","Xinshuo Hu","Xuebo Liu","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.18381v1.pdf","comment":"23 pages, 15 tables, 2 figures"},{"id":"http://arxiv.org/abs/2403.18379v1","updated":"2024-03-27T09:17:50Z","published":"2024-03-27T09:17:50Z","title":"IIP-Mixer:Intra-Inter Patch Mixing Architecture for Battery Remaining\n  Useful Life Prediction","summary":"  Accurately estimating the Remaining Useful Life (RUL) of lithium-ion\nbatteries is crucial for maintaining the safe and stable operation of\nrechargeable battery management systems. However, this task is often\nchallenging due to the complex temporal dynamics involved. Recently,\nattention-based networks, such as Transformers and Informer, have been the\npopular architecture in time series forecasting. Despite their effectiveness,\nthese models with abundant parameters necessitate substantial training time to\nunravel temporal patterns. To tackle these challenges, we propose a simple\nMLP-Mixer-based architecture named 'Intra-Inter Patch Mixer' (IIP-Mixer), which\nis an architecture based exclusively on multi-layer perceptrons (MLPs),\nextracting information by mixing operations along both intra-patch and\ninter-patch dimensions for battery RUL prediction. The proposed IIP-Mixer\ncomprises parallel dual-head mixer layers: the intra-patch mixing MLP,\ncapturing local temporal patterns in the short-term period, and the inter-patch\nmixing MLP, capturing global temporal patterns in the long-term period.\nNotably, to address the varying importance of features in RUL prediction, we\nintroduce a weighted loss function in the MLP-Mixer-based architecture, marking\nthe first time such an approach has been employed. Our experiments demonstrate\nthat IIP-Mixer achieves competitive performance in battery RUL prediction,\noutperforming other popular time-series frameworks\n","authors":["Guangzai Ye","Li Feng","Jianlan Guo","Yuqiang Chen"],"pdf_url":"https://arxiv.org/pdf/2403.18379v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.10997v5","updated":"2024-03-27T09:16:57Z","published":"2023-12-18T07:47:33Z","title":"Retrieval-Augmented Generation for Large Language Models: A Survey","summary":"  Large Language Models (LLMs) showcase impressive capabilities but encounter\nchallenges like hallucination, outdated knowledge, and non-transparent,\nuntraceable reasoning processes. Retrieval-Augmented Generation (RAG) has\nemerged as a promising solution by incorporating knowledge from external\ndatabases. This enhances the accuracy and credibility of the generation,\nparticularly for knowledge-intensive tasks, and allows for continuous knowledge\nupdates and integration of domain-specific information. RAG synergistically\nmerges LLMs' intrinsic knowledge with the vast, dynamic repositories of\nexternal databases. This comprehensive review paper offers a detailed\nexamination of the progression of RAG paradigms, encompassing the Naive RAG,\nthe Advanced RAG, and the Modular RAG. It meticulously scrutinizes the\ntripartite foundation of RAG frameworks, which includes the retrieval, the\ngeneration and the augmentation techniques. The paper highlights the\nstate-of-the-art technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG systems.\nFurthermore, this paper introduces up-to-date evaluation framework and\nbenchmark. At the end, this article delineates the challenges currently faced\nand points out prospective avenues for research and development.\n","authors":["Yunfan Gao","Yun Xiong","Xinyu Gao","Kangxiang Jia","Jinliu Pan","Yuxi Bi","Yi Dai","Jiawei Sun","Meng Wang","Haofen Wang"],"pdf_url":"https://arxiv.org/pdf/2312.10997v5.pdf","comment":"Ongoing Work"},{"id":"http://arxiv.org/abs/2312.08533v4","updated":"2024-03-27T09:11:48Z","published":"2023-12-13T21:46:09Z","title":"World Models via Policy-Guided Trajectory Diffusion","summary":"  World models are a powerful tool for developing intelligent agents. By\npredicting the outcome of a sequence of actions, world models enable policies\nto be optimised via on-policy reinforcement learning (RL) using synthetic data,\ni.e. in \"in imagination\". Existing world models are autoregressive in that they\ninterleave predicting the next state with sampling the next action from the\npolicy. Prediction error inevitably compounds as the trajectory length grows.\nIn this work, we propose a novel world modelling approach that is not\nautoregressive and generates entire on-policy trajectories in a single pass\nthrough a diffusion model. Our approach, Policy-Guided Trajectory Diffusion\n(PolyGRAD), leverages a denoising model in addition to the gradient of the\naction distribution of the policy to diffuse a trajectory of initially random\nstates and actions into an on-policy synthetic trajectory. We analyse the\nconnections between PolyGRAD, score-based generative models, and\nclassifier-guided diffusion models. Our results demonstrate that PolyGRAD\noutperforms state-of-the-art baselines in terms of trajectory prediction error\nfor short trajectories, with the exception of autoregressive diffusion. For\nshort trajectories, PolyGRAD obtains similar errors to autoregressive\ndiffusion, but with lower computational requirements. For long trajectories,\nPolyGRAD obtains comparable performance to baselines. Our experiments\ndemonstrate that PolyGRAD enables performant policies to be trained via\non-policy RL in imagination for MuJoCo continuous control domains. Thus,\nPolyGRAD introduces a new paradigm for accurate on-policy world modelling\nwithout autoregressive sampling.\n","authors":["Marc Rigter","Jun Yamada","Ingmar Posner"],"pdf_url":"https://arxiv.org/pdf/2312.08533v4.pdf","comment":"Published in TMLR, March 2024"},{"id":"http://arxiv.org/abs/2403.10158v2","updated":"2024-03-27T08:57:20Z","published":"2024-03-15T10:01:19Z","title":"Functional Graph Convolutional Networks: A unified multi-task and\n  multi-modal learning framework to facilitate health and social-care insights","summary":"  This paper introduces a novel Functional Graph Convolutional Network (funGCN)\nframework that combines Functional Data Analysis and Graph Convolutional\nNetworks to address the complexities of multi-task and multi-modal learning in\ndigital health and longitudinal studies. With the growing importance of health\nsolutions to improve health care and social support, ensure healthy lives, and\npromote well-being at all ages, funGCN offers a unified approach to handle\nmultivariate longitudinal data for multiple entities and ensures\ninterpretability even with small sample sizes. Key innovations include\ntask-specific embedding components that manage different data types, the\nability to perform classification, regression, and forecasting, and the\ncreation of a knowledge graph for insightful data interpretation. The efficacy\nof funGCN is validated through simulation experiments and a real-data\napplication.\n","authors":["Tobia Boschi","Francesca Bonin","Rodrigo Ordonez-Hurtado","Cécile Rousseau","Alessandra Pascale","John Dinsmore"],"pdf_url":"https://arxiv.org/pdf/2403.10158v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18364v1","updated":"2024-03-27T08:57:15Z","published":"2024-03-27T08:57:15Z","title":"Intent-Aware DRL-Based Uplink Dynamic Scheduler for 5G-NR","summary":"  We investigate the problem of supporting Industrial Internet of Things user\nequipment (IIoT UEs) with intent (i.e., requested quality of service (QoS)) and\nrandom traffic arrival. A deep reinforcement learning (DRL) based centralized\ndynamic scheduler for time-frequency resources is proposed to learn how to\nschedule the available communication resources among the IIoT UEs. The proposed\nscheduler leverages an RL framework to adapt to the dynamic changes in the\nwireless communication system and traffic arrivals. Moreover, a graph-based\nreduction scheme is proposed to reduce the state and action space of the RL\nframework to allow fast convergence and a better learning strategy. Simulation\nresults demonstrate the effectiveness of the proposed intelligent scheduler in\nguaranteeing the expressed intent of IIoT UEs compared to several traditional\nscheduling schemes, such as round-robin, semi-static, and heuristic approaches.\nThe proposed scheduler also outperforms the contention-free and\ncontention-based schemes in maximizing the number of successfully computed\ntasks.\n","authors":["Salwa Mostafa","Mateus P. Mota","Alvaro Valcarce","Mehdi Bennis"],"pdf_url":"https://arxiv.org/pdf/2403.18364v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.03325v2","updated":"2024-03-27T08:54:35Z","published":"2023-10-05T05:41:21Z","title":"Learning Concept-Based Causal Transition and Symbolic Reasoning for\n  Visual Planning","summary":"  Visual planning simulates how humans make decisions to achieve desired goals\nin the form of searching for visual causal transitions between an initial\nvisual state and a final visual goal state. It has become increasingly\nimportant in egocentric vision with its advantages in guiding agents to perform\ndaily tasks in complex environments. In this paper, we propose an interpretable\nand generalizable visual planning framework consisting of i) a novel\nSubstitution-based Concept Learner (SCL) that abstracts visual inputs into\ndisentangled concept representations, ii) symbol abstraction and reasoning that\nperforms task planning via the self-learned symbols, and iii) a Visual Causal\nTransition model (ViCT) that grounds visual causal transitions to semantically\nsimilar real-world actions. Given an initial state, we perform goal-conditioned\nvisual planning with a symbolic reasoning method fueled by the learned\nrepresentations and causal transitions to reach the goal state. To verify the\neffectiveness of the proposed model, we collect a large-scale visual planning\ndataset based on AI2-THOR, dubbed as CCTP. Extensive experiments on this\nchallenging dataset demonstrate the superior performance of our method in\nvisual task planning. Empirically, we show that our framework can generalize to\nunseen task trajectories, unseen object categories, and real-world data.\nFurther details of this work are provided at\nhttps://fqyqc.github.io/ConTranPlan/.\n","authors":["Yilue Qian","Peiyu Yu","Ying Nian Wu","Yao Su","Wei Wang","Lifeng Fan"],"pdf_url":"https://arxiv.org/pdf/2310.03325v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.02151v2","updated":"2024-03-27T08:43:28Z","published":"2023-05-03T14:33:23Z","title":"Identifying the Correlation Between Language Distance and Cross-Lingual\n  Transfer in a Multilingual Representation Space","summary":"  Prior research has investigated the impact of various linguistic features on\ncross-lingual transfer performance. In this study, we investigate the manner in\nwhich this effect can be mapped onto the representation space. While past\nstudies have focused on the impact on cross-lingual alignment in multilingual\nlanguage models during fine-tuning, this study examines the absolute evolution\nof the respective language representation spaces produced by MLLMs. We place a\nspecific emphasis on the role of linguistic characteristics and investigate\ntheir inter-correlation with the impact on representation spaces and\ncross-lingual transfer performance. Additionally, this paper provides\npreliminary evidence of how these findings can be leveraged to enhance transfer\nto linguistically distant languages.\n","authors":["Fred Philippy","Siwen Guo","Shohreh Haddadan"],"pdf_url":"https://arxiv.org/pdf/2305.02151v2.pdf","comment":"SIGTYP Workshop 2023 (co-located with EACL 2023)"},{"id":"http://arxiv.org/abs/2403.18351v1","updated":"2024-03-27T08:42:47Z","published":"2024-03-27T08:42:47Z","title":"Generating Diverse Agricultural Data for Vision-Based Farming\n  Applications","summary":"  We present a specialized procedural model for generating synthetic\nagricultural scenes, focusing on soybean crops, along with various weeds. This\nmodel is capable of simulating distinct growth stages of these plants, diverse\nsoil conditions, and randomized field arrangements under varying lighting\nconditions. The integration of real-world textures and environmental factors\ninto the procedural generation process enhances the photorealism and\napplicability of the synthetic data. Our dataset includes 12,000 images with\nsemantic labels, offering a comprehensive resource for computer vision tasks in\nprecision agriculture, such as semantic segmentation for autonomous weed\ncontrol. We validate our model's effectiveness by comparing the synthetic data\nagainst real agricultural images, demonstrating its potential to significantly\naugment training data for machine learning models in agriculture. This approach\nnot only provides a cost-effective solution for generating high-quality,\ndiverse data but also addresses specific needs in agricultural vision tasks\nthat are not fully covered by general-purpose models.\n","authors":["Mikolaj Cieslak","Umabharathi Govindarajan","Alejandro Garcia","Anuradha Chandrashekar","Torsten Hädrich","Aleksander Mendoza-Drosik","Dominik L. Michels","Sören Pirk","Chia-Chun Fu","Wojciech Pałubicki"],"pdf_url":"https://arxiv.org/pdf/2403.18351v1.pdf","comment":"10 pages, 8 figures, 3 tables"},{"id":"http://arxiv.org/abs/2403.18347v1","updated":"2024-03-27T08:38:56Z","published":"2024-03-27T08:38:56Z","title":"A Quantum Fuzzy-based Approach for Real-Time Detection of Solar Coronal\n  Holes","summary":"  The detection and analysis of the solar coronal holes (CHs) is an important\nfield of study in the domain of solar physics. Mainly, it is required for the\nproper prediction of the geomagnetic storms which directly or indirectly affect\nvarious space and ground-based systems. For the detection of CHs till date, the\nsolar scientist depends on manual hand-drawn approaches. However, with the\nadvancement of image processing technologies, some automated image segmentation\nmethods have been used for the detection of CHs. In-spite of this, fast and\naccurate detection of CHs are till a major issues. Here in this work, a novel\nquantum computing-based fast fuzzy c-mean technique has been developed for fast\ndetection of the CHs region. The task has been carried out in two stages, in\nfirst stage the solar image has been segmented using a quantum computing based\nfast fuzzy c-mean (QCFFCM) and in the later stage the CHs has been extracted\nout from the segmented image based on image morphological operation. In the\nwork, quantum computing has been used to optimize the cost function of the fast\nfuzzy c-mean (FFCM) algorithm, where quantum approximate optimization algorithm\n(QAOA) has been used to optimize the quadratic part of the cost function. The\nproposed method has been tested for 193 \\AA{} SDO/AIA full-disk solar image\ndatasets and has been compared with the existing techniques. The outcome shows\nthe comparable performance of the proposed method with the existing one within\na very lesser time.\n","authors":["Sanmoy Bandyopadhyay","Suman Kundu"],"pdf_url":"https://arxiv.org/pdf/2403.18347v1.pdf","comment":"14 pages, 5 figures, 3 tables"},{"id":"http://arxiv.org/abs/2403.18344v1","updated":"2024-03-27T08:34:55Z","published":"2024-03-27T08:34:55Z","title":"LC-LLM: Explainable Lane-Change Intention and Trajectory Predictions\n  with Large Language Models","summary":"  To ensure safe driving in dynamic environments, autonomous vehicles should\npossess the capability to accurately predict the lane change intentions of\nsurrounding vehicles in advance and forecast their future trajectories.\nExisting motion prediction approaches have ample room for improvement,\nparticularly in terms of long-term prediction accuracy and interpretability. In\nthis paper, we address these challenges by proposing LC-LLM, an explainable\nlane change prediction model that leverages the strong reasoning capabilities\nand self-explanation abilities of Large Language Models (LLMs). Essentially, we\nreformulate the lane change prediction task as a language modeling problem,\nprocessing heterogeneous driving scenario information in natural language as\nprompts for input into the LLM and employing a supervised fine-tuning technique\nto tailor the LLM specifically for our lane change prediction task. This allows\nus to utilize the LLM's powerful common sense reasoning abilities to understand\ncomplex interactive information, thereby improving the accuracy of long-term\npredictions. Furthermore, we incorporate explanatory requirements into the\nprompts in the inference stage. Therefore, our LC-LLM model not only can\npredict lane change intentions and trajectories but also provides explanations\nfor its predictions, enhancing the interpretability. Extensive experiments on\nthe large-scale highD dataset demonstrate the superior performance and\ninterpretability of our LC-LLM in lane change prediction task. To the best of\nour knowledge, this is the first attempt to utilize LLMs for predicting lane\nchange behavior. Our study shows that LLMs can encode comprehensive interaction\ninformation for driving behavior understanding.\n","authors":["Mingxing Peng","Xusen Guo","Xianda Chen","Meixin Zhu","Kehua Chen"," Hao"," Yang","Xuesong Wang","Yinhai Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18344v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18338v1","updated":"2024-03-27T08:25:28Z","published":"2024-03-27T08:25:28Z","title":"mALBERT: Is a Compact Multilingual BERT Model Still Worth It?","summary":"  Within the current trend of Pretained Language Models (PLM), emerge more and\nmore criticisms about the ethical andecological impact of such models. In this\narticle, considering these critical remarks, we propose to focus on\nsmallermodels, such as compact models like ALBERT, which are more ecologically\nvirtuous than these PLM. However,PLMs enable huge breakthroughs in Natural\nLanguage Processing tasks, such as Spoken and Natural LanguageUnderstanding,\nclassification, Question--Answering tasks. PLMs also have the advantage of\nbeing multilingual, and,as far as we know, a multilingual version of compact\nALBERT models does not exist. Considering these facts, wepropose the free\nrelease of the first version of a multilingual compact ALBERT model,\npre-trained using Wikipediadata, which complies with the ethical aspect of such\na language model. We also evaluate the model against classicalmultilingual PLMs\nin classical NLP tasks. Finally, this paper proposes a rare study on the\nsubword tokenizationimpact on language performances.\n","authors":["Christophe Servan","Sahar Ghannay","Sophie Rosset"],"pdf_url":"https://arxiv.org/pdf/2403.18338v1.pdf","comment":"The 2024 Joint International Conference on Computational Linguistics,\n  Language Resources and Evaluation, May 2024, Torino, Italy"},{"id":"http://arxiv.org/abs/2403.18327v1","updated":"2024-03-27T08:08:00Z","published":"2024-03-27T08:08:00Z","title":"Can LLMs Converse Formally? Automatically Assessing LLMs in Translating\n  and Interpreting Formal Specifications","summary":"  Stakeholders often describe system requirements using natural language which\nare then converted to formal syntax by a domain-expert leading to increased\ndesign costs. This paper assesses the capabilities of Large Language Models\n(LLMs) in converting between natural language descriptions and formal\nspecifications. Existing work has evaluated the capabilities of LLMs in\ngenerating formal syntax such as source code but such experiments are typically\nhand-crafted and use problems that are likely to be in the training set of\nLLMs, and often require human-annotated datasets. We propose an approach that\ncan use two copies of an LLM in conjunction with an off-the-shelf verifier to\nautomatically evaluate its translation abilities without any additional human\ninput. Our approach generates formal syntax using language grammars to\nautomatically generate a dataset. We conduct an empirical evaluation to measure\nthe accuracy of this translation task and show that SOTA LLMs cannot adequately\nsolve this task, limiting their current utility in the design of complex\nsystems.\n","authors":["Rushang Karia","Daksh Dobhal","Daniel Bramblett","Pulkit Verma","Siddharth Srivastava"],"pdf_url":"https://arxiv.org/pdf/2403.18327v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18314v1","updated":"2024-03-27T07:34:44Z","published":"2024-03-27T07:34:44Z","title":"Chinese Offensive Language Detection:Current Status and Future\n  Directions","summary":"  Despite the considerable efforts being made to monitor and regulate\nuser-generated content on social media platforms, the pervasiveness of\noffensive language, such as hate speech or cyberbullying, in the digital space\nremains a significant challenge. Given the importance of maintaining a\ncivilized and respectful online environment, there is an urgent and growing\nneed for automatic systems capable of detecting offensive speech in real time.\nHowever, developing effective systems for processing languages such as Chinese\npresents a significant challenge, owing to the language's complex and nuanced\nnature, which makes it difficult to process automatically. This paper provides\na comprehensive overview of offensive language detection in Chinese, examining\ncurrent benchmarks and approaches and highlighting specific models and tools\nfor addressing the unique challenges of detecting offensive language in this\ncomplex language. The primary objective of this survey is to explore the\nexisting techniques and identify potential avenues for further research that\ncan address the cultural and linguistic complexities of Chinese.\n","authors":["Yunze Xiao","Houda Bouamor","Wajdi Zaghouani"],"pdf_url":"https://arxiv.org/pdf/2403.18314v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18310v1","updated":"2024-03-27T07:22:32Z","published":"2024-03-27T07:22:32Z","title":"A thermodynamically consistent physics-informed deep learning material\n  model for short fiber/polymer nanocomposites","summary":"  This work proposes a physics-informed deep learning (PIDL)-based constitutive\nmodel for investigating the viscoelastic-viscoplastic behavior of short\nfiber-reinforced nanoparticle-filled epoxies under various ambient conditions.\nThe deep-learning model is trained to enforce thermodynamic principles, leading\nto a thermodynamically consistent constitutive model. To accomplish this, a\nlong short-term memory network is combined with a feed-forward neural network\nto predict internal variables required for characterizing the internal\ndissipation of the nanocomposite materials. In addition, another feed-forward\nneural network is used to indicate the free-energy function, which enables\ndefining the thermodynamic state of the entire system. The PIDL model is\ninitially developed for the three-dimensional case by generating synthetic data\nfrom a classical constitutive model. The model is then trained by extracting\nthe data directly from cyclic loading-unloading experimental tests. Numerical\nexamples show that the PIDL model can accurately predict the mechanical\nbehavior of epoxy-based nanocomposites for different volume fractions of fibers\nand nanoparticles under various hygrothermal conditions.\n","authors":["Betim Bahtiri","Behrouz Arash","Sven Scheffler","Maximilian Jux","Raimund Rolfes"],"pdf_url":"https://arxiv.org/pdf/2403.18310v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2305.08102"},{"id":"http://arxiv.org/abs/2307.09136v2","updated":"2024-03-27T07:16:28Z","published":"2023-07-18T10:34:21Z","title":"The Effects of Mixed Sample Data Augmentation are Class Dependent","summary":"  Mixed Sample Data Augmentation (MSDA) techniques, such as Mixup, CutMix, and\nPuzzleMix, have been widely acknowledged for enhancing performance in a variety\nof tasks. A previous study reported the class dependency of traditional data\naugmentation (DA), where certain classes benefit disproportionately compared to\nothers. This paper reveals a class dependent effect of MSDA, where some classes\nexperience improved performance while others experience degraded performance.\nThis research addresses the issue of class dependency in MSDA and proposes an\nalgorithm to mitigate it. The approach involves training on a mixture of MSDA\nand non-MSDA data, which not only mitigates the negative impact on the affected\nclasses, but also improves overall accuracy. Furthermore, we provide in-depth\nanalysis and discussion of why MSDA introduced class dependencies and which\nclasses are most likely to have them.\n","authors":["Haeil Lee","Hansang Lee","Junmo Kim"],"pdf_url":"https://arxiv.org/pdf/2307.09136v2.pdf","comment":"21 pages, 18 figures, Overall Revision"},{"id":"http://arxiv.org/abs/2402.18920v5","updated":"2024-03-27T07:16:21Z","published":"2024-02-29T07:26:23Z","title":"Spectral Meets Spatial: Harmonising 3D Shape Matching and Interpolation","summary":"  Although 3D shape matching and interpolation are highly interrelated, they\nare often studied separately and applied sequentially to relate different 3D\nshapes, thus resulting in sub-optimal performance. In this work we present a\nunified framework to predict both point-wise correspondences and shape\ninterpolation between 3D shapes. To this end, we combine the deep functional\nmap framework with classical surface deformation models to map shapes in both\nspectral and spatial domains. On the one hand, by incorporating spatial maps,\nour method obtains more accurate and smooth point-wise correspondences compared\nto previous functional map methods for shape matching. On the other hand, by\nintroducing spectral maps, our method gets rid of commonly used but\ncomputationally expensive geodesic distance constraints that are only valid for\nnear-isometric shape deformations. Furthermore, we propose a novel test-time\nadaptation scheme to capture both pose-dominant and shape-dominant\ndeformations. Using different challenging datasets, we demonstrate that our\nmethod outperforms previous state-of-the-art methods for both shape matching\nand interpolation, even compared to supervised approaches.\n","authors":["Dongliang Cao","Marvin Eisenberger","Nafie El Amrani","Daniel Cremers","Florian Bernard"],"pdf_url":"https://arxiv.org/pdf/2402.18920v5.pdf","comment":"accepted by CVPR2024"},{"id":"http://arxiv.org/abs/2306.12609v2","updated":"2024-03-27T07:11:30Z","published":"2023-06-22T00:12:30Z","title":"Towards Regulatable AI Systems: Technical Gaps and Policy Opportunities","summary":"  There is increasing attention being given to how to regulate AI systems. As\ngoverning bodies grapple with what values to encapsulate into regulation, we\nconsider the technical half of the question: To what extent can AI experts vet\nan AI system for adherence to regulatory requirements? We investigate this\nquestion through the lens of two public sector procurement checklists,\nidentifying what we can do now, what should be possible with technical\ninnovation, and what requirements need a more interdisciplinary approach.\n","authors":["Xudong Shen","Hannah Brown","Jiashu Tao","Martin Strobel","Yao Tong","Akshay Narayan","Harold Soh","Finale Doshi-Velez"],"pdf_url":"https://arxiv.org/pdf/2306.12609v2.pdf","comment":"scheduled for publication in the Communications of the ACM, titled\n  \"Directions of Technical Innovation for Regulatable AI Systems\""},{"id":"http://arxiv.org/abs/2310.17072v3","updated":"2024-03-27T07:04:58Z","published":"2023-10-26T00:28:37Z","title":"MMP++: Motion Manifold Primitives with Parametric Curve Models","summary":"  Motion Manifold Primitives (MMP), a manifold-based approach for encoding\nbasic motion skills, can produce diverse trajectories, enabling the system to\nadapt to unseen constraints. Nonetheless, we argue that current MMP models lack\ncrucial functionalities of movement primitives, such as temporal and via-points\nmodulation, found in traditional approaches. This shortfall primarily stems\nfrom MMP's reliance on discrete-time trajectories. To overcome these\nlimitations, we introduce Motion Manifold Primitives++ (MMP++), a new model\nthat integrates the strengths of both MMP and traditional methods by\nincorporating parametric curve representations into the MMP framework.\nFurthermore, we identify a significant challenge with MMP++: performance\ndegradation due to geometric distortions in the latent space, meaning that\nsimilar motions are not closely positioned. To address this, Isometric Motion\nManifold Primitives++ (IMMP++) is proposed to ensure the latent space\naccurately preserves the manifold's geometry. Our experimental results across\nvarious applications, including 2-DoF planar motions, 7-DoF robot arm motions,\nand SE(3) trajectory planning, show that MMP++ and IMMP++ outperform existing\nmethods in trajectory generation tasks, achieving substantial improvements in\nsome cases. Moreover, they enable the modulation of latent coordinates and\nvia-points, thereby allowing efficient online adaptation to dynamic\nenvironments.\n","authors":["Yonghyeon Lee"],"pdf_url":"https://arxiv.org/pdf/2310.17072v3.pdf","comment":"12 pages. This work has been submitted to the IEEE for possible\n  publication"},{"id":"http://arxiv.org/abs/2403.18305v1","updated":"2024-03-27T06:59:39Z","published":"2024-03-27T06:59:39Z","title":"A Recommender System for NFT Collectibles with Item Feature","summary":"  Recommender systems have been actively studied and applied in various domains\nto deal with information overload. Although there are numerous studies on\nrecommender systems for movies, music, and e-commerce, comparatively less\nattention has been paid to the recommender system for NFTs despite the\ncontinuous growth of the NFT market. This paper presents a recommender system\nfor NFTs that utilizes a variety of data sources, from NFT transaction records\nto external item features, to generate precise recommendations that cater to\nindividual preferences. We develop a data-efficient graph-based recommender\nsystem to efficiently capture the complex relationship between each item and\nusers and generate node(item) embeddings which incorporate both node feature\ninformation and graph structure. Furthermore, we exploit inputs beyond\nuser-item interactions, such as image feature, text feature, and price feature.\nNumerical experiments verify the performance of the graph-based recommender\nsystem improves significantly after utilizing all types of item features as\nside information, thereby outperforming all other baselines.\n","authors":["Minjoo Choi","Seonmi Kim","Yejin Kim","Youngbin Lee","Joohwan Hong","Yongjae Lee"],"pdf_url":"https://arxiv.org/pdf/2403.18305v1.pdf","comment":"Presented at the AAAI 2023 Bridge on AI for Financial Services\n  (https://sites.google.com/view/aaai-ai-fin/home)"},{"id":"http://arxiv.org/abs/2302.06912v4","updated":"2024-03-27T06:57:30Z","published":"2023-02-14T08:56:50Z","title":"Regret-Based Defense in Adversarial Reinforcement Learning","summary":"  Deep Reinforcement Learning (DRL) policies have been shown to be vulnerable\nto small adversarial noise in observations. Such adversarial noise can have\ndisastrous consequences in safety-critical environments. For instance, a\nself-driving car receiving adversarially perturbed sensory observations about\nnearby signs (e.g., a stop sign physically altered to be perceived as a speed\nlimit sign) or objects (e.g., cars altered to be recognized as trees) can be\nfatal. Existing approaches for making RL algorithms robust to an\nobservation-perturbing adversary have focused on reactive approaches that\niteratively improve against adversarial examples generated at each iteration.\nWhile such approaches have been shown to provide improvements over regular RL\nmethods, they are reactive and can fare significantly worse if certain\ncategories of adversarial examples are not generated during training. To that\nend, we pursue a more proactive approach that relies on directly optimizing a\nwell-studied robustness measure, regret instead of expected value. We provide a\nprincipled approach that minimizes maximum regret over a \"neighborhood\" of\nobservations to the received \"observation\". Our regret criterion can be used to\nmodify existing value- and policy-based Deep RL methods. We demonstrate that\nour approaches provide a significant improvement in performance across a wide\nvariety of benchmarks against leading approaches for robust Deep RL.\n","authors":["Roman Belaire","Pradeep Varakantham","Thanh Nguyen","David Lo"],"pdf_url":"https://arxiv.org/pdf/2302.06912v4.pdf","comment":"Accepted at AAMAS 2024"},{"id":"http://arxiv.org/abs/2403.18301v1","updated":"2024-03-27T06:55:23Z","published":"2024-03-27T06:55:23Z","title":"Selective Mixup Fine-Tuning for Optimizing Non-Decomposable Objectives","summary":"  The rise in internet usage has led to the generation of massive amounts of\ndata, resulting in the adoption of various supervised and semi-supervised\nmachine learning algorithms, which can effectively utilize the colossal amount\nof data to train models. However, before deploying these models in the real\nworld, these must be strictly evaluated on performance measures like worst-case\nrecall and satisfy constraints such as fairness. We find that current\nstate-of-the-art empirical techniques offer sub-optimal performance on these\npractical, non-decomposable performance objectives. On the other hand, the\ntheoretical techniques necessitate training a new model from scratch for each\nperformance objective. To bridge the gap, we propose SelMix, a selective\nmixup-based inexpensive fine-tuning technique for pre-trained models, to\noptimize for the desired objective. The core idea of our framework is to\ndetermine a sampling distribution to perform a mixup of features between\nsamples from particular classes such that it optimizes the given objective. We\ncomprehensively evaluate our technique against the existing empirical and\ntheoretically principled methods on standard benchmark datasets for imbalanced\nclassification. We find that proposed SelMix fine-tuning significantly improves\nthe performance for various practical non-decomposable objectives across\nbenchmarks.\n","authors":["Shrinivas Ramasubramanian","Harsh Rangwani","Sho Takemori","Kunal Samanta","Yuhei Umeda","Venkatesh Babu Radhakrishnan"],"pdf_url":"https://arxiv.org/pdf/2403.18301v1.pdf","comment":"ICLR 2024 SpotLight"},{"id":"http://arxiv.org/abs/2403.18296v1","updated":"2024-03-27T06:46:59Z","published":"2024-03-27T06:46:59Z","title":"GeNet: A Graph Neural Network-based Anti-noise Task-Oriented Semantic\n  Communication Paradigm","summary":"  Traditional approaches to semantic communication tasks rely on the knowledge\nof the signal-to-noise ratio (SNR) to mitigate channel noise. However, these\nmethods necessitate training under specific SNR conditions, entailing\nconsiderable time and computational resources. In this paper, we propose GeNet,\na Graph Neural Network (GNN)-based paradigm for semantic communication aimed at\ncombating noise, thereby facilitating Task-Oriented Communication (TOC). We\npropose a novel approach where we first transform the input data image into\ngraph structures. Then we leverage a GNN-based encoder to extract semantic\ninformation from the source data. This extracted semantic information is then\ntransmitted through the channel. At the receiver's end, a GNN-based decoder is\nutilized to reconstruct the relevant semantic information from the source data\nfor TOC. Through experimental evaluation, we show GeNet's effectiveness in\nanti-noise TOC while decoupling the SNR dependency. We further evaluate GeNet's\nperformance by varying the number of nodes, revealing its versatility as a new\nparadigm for semantic communication. Additionally, we show GeNet's robustness\nto geometric transformations by testing it with different rotation angles,\nwithout resorting to data augmentation.\n","authors":["Chunhang Zheng","Kechao Cai"],"pdf_url":"https://arxiv.org/pdf/2403.18296v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17421v2","updated":"2024-03-27T06:28:53Z","published":"2024-03-26T06:34:23Z","title":"MA4DIV: Multi-Agent Reinforcement Learning for Search Result\n  Diversification","summary":"  The objective of search result diversification (SRD) is to ensure that\nselected documents cover as many different subtopics as possible. Existing\nmethods primarily utilize a paradigm of \"greedy selection\", i.e., selecting one\ndocument with the highest diversity score at a time. These approaches tend to\nbe inefficient and are easily trapped in a suboptimal state. In addition, some\nother methods aim to approximately optimize the diversity metric, such as\n$\\alpha$-NDCG, but the results still remain suboptimal. To address these\nchallenges, we introduce Multi-Agent reinforcement learning (MARL) for search\nresult DIVersity, which called MA4DIV. In this approach, each document is an\nagent and the search result diversification is modeled as a cooperative task\namong multiple agents. This approach allows for directly optimizing the\ndiversity metrics, such as $\\alpha$-NDCG, while achieving high training\nefficiency. We conducted preliminary experiments on public TREC datasets to\ndemonstrate the effectiveness and potential of MA4DIV. Considering the limited\nnumber of queries in public TREC datasets, we construct a large-scale dataset\nfrom industry sources and show that MA4DIV achieves substantial improvements in\nboth effectiveness and efficiency than existing baselines on a industrial scale\ndataset.\n","authors":["Yiqun Chen","Jiaxin Mao","Yi Zhang","Dehong Ma","Long Xia","Jun Fan","Daiting Shi","Zhicong Cheng","Simiu Gu","Dawei Yin"],"pdf_url":"https://arxiv.org/pdf/2403.17421v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18286v1","updated":"2024-03-27T06:25:40Z","published":"2024-03-27T06:25:40Z","title":"Few-Shot Recalibration of Language Models","summary":"  Recent work has uncovered promising ways to extract well-calibrated\nconfidence estimates from language models (LMs), where the model's confidence\nscore reflects how likely it is to be correct. However, while LMs may appear\nwell-calibrated over broad distributions, this often hides significant\nmiscalibration within narrower slices (e.g., systemic over-confidence in math\ncan balance out systemic under-confidence in history, yielding perfect\ncalibration in aggregate). To attain well-calibrated confidence estimates for\nany slice of a distribution, we propose a new framework for few-shot\nslice-specific recalibration. Specifically, we train a recalibration model that\ntakes in a few unlabeled examples from any given slice and predicts a curve\nthat remaps confidence scores to be more accurate for that slice. Our trained\nmodel can recalibrate for arbitrary new slices, without using any labeled data\nfrom that slice. This enables us to identify domain-specific confidence\nthresholds above which the LM's predictions can be trusted, and below which it\nshould abstain. Experiments show that our few-shot recalibrator consistently\noutperforms existing calibration methods, for instance improving calibration\nerror for PaLM2-Large on MMLU by 16%, as compared to temperature scaling.\n","authors":["Xiang Lisa Li","Urvashi Khandelwal","Kelvin Guu"],"pdf_url":"https://arxiv.org/pdf/2403.18286v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2403.16512v2","updated":"2024-03-27T06:25:10Z","published":"2024-03-25T07:55:29Z","title":"LLMs Are Few-Shot In-Context Low-Resource Language Learners","summary":"  In-context learning (ICL) empowers large language models (LLMs) to perform\ndiverse tasks in underrepresented languages using only short in-context\ninformation, offering a crucial avenue for narrowing the gap between\nhigh-resource and low-resource languages. Nonetheless, there is only a handful\nof works explored ICL for low-resource languages with most of them focusing on\nrelatively high-resource languages, such as French and Spanish. In this work,\nwe extensively study ICL and its cross-lingual variation (X-ICL) on 25\nlow-resource and 7 relatively higher-resource languages. Our study not only\nassesses the effectiveness of ICL with LLMs in low-resource languages but also\nidentifies the shortcomings of in-context label alignment, and introduces a\nmore effective alternative: query alignment. Moreover, we provide valuable\ninsights into various facets of ICL for low-resource languages. Our study\nconcludes the significance of few-shot in-context information on enhancing the\nlow-resource understanding quality of LLMs through semantically relevant\ninformation by closing the language gap in the target language and aligning the\nsemantics between the targeted low-resource and the high-resource language that\nthe model is proficient in. Our work highlights the importance of advancing ICL\nresearch, particularly for low-resource languages.\n","authors":["Samuel Cahyawijaya","Holy Lovenia","Pascale Fung"],"pdf_url":"https://arxiv.org/pdf/2403.16512v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15472v2","updated":"2024-03-27T06:22:41Z","published":"2024-03-20T15:47:28Z","title":"Enhancing Programming Education with ChatGPT: A Case Study on Student\n  Perceptions and Interactions in a Python Course","summary":"  The integration of ChatGPT as a supportive tool in education, notably in\nprogramming courses, addresses the unique challenges of programming education\nby providing assistance with debugging, code generation, and explanations.\nDespite existing research validating ChatGPT's effectiveness, its application\nin university-level programming education and a detailed understanding of\nstudent interactions and perspectives remain limited. This paper explores\nChatGPT's impact on learning in a Python programming course tailored for\nfirst-year students over eight weeks. By analyzing responses from surveys,\nopen-ended questions, and student-ChatGPT dialog data, we aim to provide a\ncomprehensive view of ChatGPT's utility and identify both its advantages and\nlimitations as perceived by students. Our study uncovers a generally positive\nreception toward ChatGPT and offers insights into its role in enhancing the\nprogramming education experience. These findings contribute to the broader\ndiscourse on AI's potential in education, suggesting paths for future research\nand application.\n","authors":["Boxaun Ma","Li Chen","Shin'ichi Konomi"],"pdf_url":"https://arxiv.org/pdf/2403.15472v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18278v1","updated":"2024-03-27T06:13:39Z","published":"2024-03-27T06:13:39Z","title":"Identification and Uses of Deep Learning Backbones via Pattern Mining","summary":"  Deep learning is extensively used in many areas of data mining as a black-box\nmethod with impressive results. However, understanding the core mechanism of\nhow deep learning makes predictions is a relatively understudied problem. Here\nwe explore the notion of identifying a backbone of deep learning for a given\ngroup of instances. A group here can be instances of the same class or even\nmisclassified instances of the same class. We view each instance for a given\ngroup as activating a subset of neurons and attempt to find a subgraph of\nneurons associated with a given concept/group. We formulate this problem as a\nset cover style problem and show it is intractable and presents a highly\nconstrained integer linear programming (ILP) formulation. As an alternative, we\nexplore a coverage-based heuristic approach related to pattern mining, and show\nit converges to a Pareto equilibrium point of the ILP formulation.\nExperimentally we explore these backbones to identify mistakes and improve\nperformance, explanation, and visualization. We demonstrate application-based\nresults using several challenging data sets, including Bird Audio Detection\n(BAD) Challenge and Labeled Faces in the Wild (LFW), as well as the classic\nMNIST data.\n","authors":["Michael Livanos","Ian Davidson"],"pdf_url":"https://arxiv.org/pdf/2403.18278v1.pdf","comment":"9 pages, 6 figures, published SIAM SDM24"},{"id":"http://arxiv.org/abs/2403.07711v2","updated":"2024-03-27T06:02:38Z","published":"2024-03-12T14:53:56Z","title":"SSM Meets Video Diffusion Models: Efficient Video Generation with\n  Structured State Spaces","summary":"  Given the remarkable achievements in image generation through diffusion\nmodels, the research community has shown increasing interest in extending these\nmodels to video generation. Recent diffusion models for video generation have\npredominantly utilized attention layers to extract temporal features. However,\nattention layers are limited by their memory consumption, which increases\nquadratically with the length of the sequence. This limitation presents\nsignificant challenges when attempting to generate longer video sequences using\ndiffusion models. To overcome this challenge, we propose leveraging state-space\nmodels (SSMs). SSMs have recently gained attention as viable alternatives due\nto their linear memory consumption relative to sequence length. In the\nexperiments, we first evaluate our SSM-based model with UCF101, a standard\nbenchmark of video generation. In addition, to investigate the potential of\nSSMs for longer video generation, we perform an experiment using the MineRL\nNavigate dataset, varying the number of frames to 64, 200, and 400. In these\nsettings, our SSM-based model can considerably save memory consumption for\nlonger sequences, while maintaining competitive FVD scores to the\nattention-based models. Our codes are available at\nhttps://github.com/shim0114/SSM-Meets-Video-Diffusion-Models.\n","authors":["Yuta Oshima","Shohei Taniguchi","Masahiro Suzuki","Yutaka Matsuo"],"pdf_url":"https://arxiv.org/pdf/2403.07711v2.pdf","comment":"Accepted as workshop paper at ICLR 2024"},{"id":"http://arxiv.org/abs/2305.14258v2","updated":"2024-03-27T05:45:37Z","published":"2023-05-23T17:11:33Z","title":"Weakly Supervised AUC Optimization: A Unified Partial AUC Approach","summary":"  Since acquiring perfect supervision is usually difficult, real-world machine\nlearning tasks often confront inaccurate, incomplete, or inexact supervision,\ncollectively referred to as weak supervision. In this work, we present WSAUC, a\nunified framework for weakly supervised AUC optimization problems, which covers\nnoisy label learning, positive-unlabeled learning, multi-instance learning, and\nsemi-supervised learning scenarios. Within the WSAUC framework, we first frame\nthe AUC optimization problems in various weakly supervised scenarios as a\ncommon formulation of minimizing the AUC risk on contaminated sets, and\ndemonstrate that the empirical risk minimization problems are consistent with\nthe true AUC. Then, we introduce a new type of partial AUC, specifically, the\nreversed partial AUC (rpAUC), which serves as a robust training objective for\nAUC maximization in the presence of contaminated labels. WSAUC offers a\nuniversal solution for AUC optimization in various weakly supervised scenarios\nby maximizing the empirical rpAUC. Theoretical and experimental results under\nmultiple settings support the effectiveness of WSAUC on a range of weakly\nsupervised AUC optimization tasks.\n","authors":["Zheng Xie","Yu Liu","Hao-Yuan He","Ming Li","Zhi-Hua Zhou"],"pdf_url":"https://arxiv.org/pdf/2305.14258v2.pdf","comment":"Accepted by IEEE TPAMI"},{"id":"http://arxiv.org/abs/2403.18267v1","updated":"2024-03-27T05:41:50Z","published":"2024-03-27T05:41:50Z","title":"DSF-GAN: DownStream Feedback Generative Adversarial Network","summary":"  Utility and privacy are two crucial measurements of the quality of synthetic\ntabular data. While significant advancements have been made in privacy\nmeasures, generating synthetic samples with high utility remains challenging.\nTo enhance the utility of synthetic samples, we propose a novel architecture\ncalled the DownStream Feedback Generative Adversarial Network (DSF-GAN). This\napproach incorporates feedback from a downstream prediction model during\ntraining to augment the generator's loss function with valuable information.\nThus, DSF-GAN utilizes a downstream prediction task to enhance the utility of\nsynthetic samples. To evaluate our method, we tested it using two popular\ndatasets. Our experiments demonstrate improved model performance when training\non synthetic samples generated by DSF-GAN, compared to those generated by the\nsame GAN architecture without feedback. The evaluation was conducted on the\nsame validation set comprising real samples. All code and datasets used in this\nresearch will be made openly available for ease of reproduction.\n","authors":["Oriel Perets","Nadav Rappoport"],"pdf_url":"https://arxiv.org/pdf/2403.18267v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18258v1","updated":"2024-03-27T05:10:38Z","published":"2024-03-27T05:10:38Z","title":"Enhancing Generative Class Incremental Learning Performance with Model\n  Forgetting Approach","summary":"  This study presents a novel approach to Generative Class Incremental Learning\n(GCIL) by introducing the forgetting mechanism, aimed at dynamically managing\nclass information for better adaptation to streaming data. GCIL is one of the\nhot topics in the field of computer vision, and this is considered one of the\ncrucial tasks in society, specifically the continual learning of generative\nmodels. The ability to forget is a crucial brain function that facilitates\ncontinual learning by selectively discarding less relevant information for\nhumans. However, in the field of machine learning models, the concept of\nintentionally forgetting has not been extensively investigated. In this study\nwe aim to bridge this gap by incorporating the forgetting mechanisms into GCIL,\nthereby examining their impact on the models' ability to learn in continual\nlearning. Through our experiments, we have found that integrating the\nforgetting mechanisms significantly enhances the models' performance in\nacquiring new knowledge, underscoring the positive role that strategic\nforgetting plays in the process of continual learning.\n","authors":["Taro Togo","Ren Togo","Keisuke Maeda","Takahiro Ogawa","Miki Haseyama"],"pdf_url":"https://arxiv.org/pdf/2403.18258v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.09131v2","updated":"2024-03-27T05:02:55Z","published":"2024-03-14T06:49:16Z","title":"ProSwitch: Knowledge-Guided Language Model Fine-Tuning to Generate\n  Professional and Non-Professional Styled Text","summary":"  Large Language Models (LLMs) have demonstrated efficacy in various linguistic\napplications, including text summarization and controlled text generation.\nHowever, studies into their capacity of switching between styles via\nfine-tuning remain underexplored. This study concentrates on textual\nprofessionalism and introduces a novel methodology, named ProSwitch, which\nequips a language model with the ability to produce both professional and\nnon-professional responses through knowledge-guided instruction tuning.\nProSwitch unfolds across three phases: data preparation for gathering domain\nknowledge and training corpus; instruction tuning for optimizing language\nmodels with multiple levels of instruction formats; and comprehensive\nevaluation for assessing the professionalism discrimination and reference-based\nquality of generated text. Comparative analysis of ProSwitch against both\ngeneral and specialized language models reveals that our approach outperforms\nbaselines in switching between professional and non-professional text\ngeneration.\n","authors":["Chang Zong","Yuyan Chen","Weiming Lu","Jian Shao","Yueting Zhuang"],"pdf_url":"https://arxiv.org/pdf/2403.09131v2.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2403.18256v1","updated":"2024-03-27T04:56:48Z","published":"2024-03-27T04:56:48Z","title":"Manipulating Neural Path Planners via Slight Perturbations","summary":"  Data-driven neural path planners are attracting increasing interest in the\nrobotics community. However, their neural network components typically come as\nblack boxes, obscuring their underlying decision-making processes. Their\nblack-box nature exposes them to the risk of being compromised via the\ninsertion of hidden malicious behaviors. For example, an attacker may hide\nbehaviors that, when triggered, hijack a delivery robot by guiding it to a\nspecific (albeit wrong) destination, trapping it in a predefined region, or\ninducing unnecessary energy expenditure by causing the robot to repeatedly\ncircle a region. In this paper, we propose a novel approach to specify and\ninject a range of hidden malicious behaviors, known as backdoors, into neural\npath planners. Our approach provides a concise but flexible way to define these\nbehaviors, and we show that hidden behaviors can be triggered by slight\nperturbations (e.g., inserting a tiny unnoticeable object), that can\nnonetheless significantly compromise their integrity. We also discuss potential\ntechniques to identify these backdoors aimed at alleviating such risks. We\ndemonstrate our approach on both sampling-based and search-based neural path\nplanners.\n","authors":["Zikang Xiong","Suresh Jagannathan"],"pdf_url":"https://arxiv.org/pdf/2403.18256v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18252v1","updated":"2024-03-27T04:49:23Z","published":"2024-03-27T04:49:23Z","title":"Beyond Embeddings: The Promise of Visual Table in Multi-Modal Models","summary":"  Visual representation learning has been a cornerstone in computer vision,\nevolving from supervised learning with human-annotated labels to aligning\nimage-text pairs from the Internet. Despite recent advancements in multi-modal\nlarge language models (MLLMs), the visual representations they rely on, such as\nCLIP embeddings, often lack access to external world knowledge critical for\nreal-world visual reasoning. In this work, we propose Visual Table, a novel\nvisual representation tailored for MLLMs. It provides hierarchical text\ndescriptions of holistic visual scenes, consisting of a scene description and\nmultiple object-centric descriptions that encompass categories, attributes, and\nknowledge at instance level. We further develop a scalable generator for visual\ntable generation and train it on small-scale annotations from GPT4V. Extensive\nevaluations demonstrate that, with generated visual tables as additional visual\nrepresentations, our model can consistently outperform the state-of-the-art\n(SOTA) MLLMs across diverse benchmarks. When visual tables serve as standalone\nvisual representations, our model can closely match or even beat the SOTA MLLMs\nthat are built on CLIP visual embeddings. Our code is available at\nhttps://github.com/LaVi-Lab/Visual-Table.\n","authors":["Yiwu Zhong","Zi-Yuan Hu","Michael R. Lyu","Liwei Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18252v1.pdf","comment":"Project page: https://github.com/LaVi-Lab/Visual-Table"},{"id":"http://arxiv.org/abs/2403.18243v1","updated":"2024-03-27T04:20:18Z","published":"2024-03-27T04:20:18Z","title":"Boosting Conversational Question Answering with Fine-Grained\n  Retrieval-Augmentation and Self-Check","summary":"  Retrieval-Augmented Generation (RAG) aims to generate more reliable and\naccurate responses, by augmenting large language models (LLMs) with the\nexternal vast and dynamic knowledge. Most previous work focuses on using RAG\nfor single-round question answering, while how to adapt RAG to the complex\nconversational setting wherein the question is interdependent on the preceding\ncontext is not well studied. In this paper, we propose a conversation-level RAG\napproach, which incorporates fine-grained retrieval augmentation and self-check\nfor conversational question answering (CQA). In particular, our approach\nconsists of three components, namely conversational question refiner,\nfine-grained retriever and self-check based response generator, which work\ncollaboratively for question understanding and relevant information acquisition\nin conversational settings. Extensive experiments demonstrate the great\nadvantages of our approach over the state-of-the-art baselines. Moreover, we\nalso release a Chinese CQA dataset with new features including reformulated\nquestion, extracted keyword, retrieved paragraphs and their helpfulness, which\nfacilitates further researches in RAG enhanced CQA.\n","authors":["Linhao Ye","Zhikai Lei","Jianghao Yin","Qin Chen","Jie Zhou","Liang He"],"pdf_url":"https://arxiv.org/pdf/2403.18243v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18241v1","updated":"2024-03-27T04:09:34Z","published":"2024-03-27T04:09:34Z","title":"NeuSDFusion: A Spatial-Aware Generative Model for 3D Shape Completion,\n  Reconstruction, and Generation","summary":"  3D shape generation aims to produce innovative 3D content adhering to\nspecific conditions and constraints. Existing methods often decompose 3D shapes\ninto a sequence of localized components, treating each element in isolation\nwithout considering spatial consistency. As a result, these approaches exhibit\nlimited versatility in 3D data representation and shape generation, hindering\ntheir ability to generate highly diverse 3D shapes that comply with the\nspecified constraints. In this paper, we introduce a novel spatial-aware 3D\nshape generation framework that leverages 2D plane representations for enhanced\n3D shape modeling. To ensure spatial coherence and reduce memory usage, we\nincorporate a hybrid shape representation technique that directly learns a\ncontinuous signed distance field representation of the 3D shape using\northogonal 2D planes. Additionally, we meticulously enforce spatial\ncorrespondences across distinct planes using a transformer-based autoencoder\nstructure, promoting the preservation of spatial relationships in the generated\n3D shapes. This yields an algorithm that consistently outperforms\nstate-of-the-art 3D shape generation methods on various tasks, including\nunconditional shape generation, multi-modal shape completion, single-view\nreconstruction, and text-to-shape synthesis.\n","authors":["Ruikai Cui","Weizhe Liu","Weixuan Sun","Senbo Wang","Taizhang Shang","Yang Li","Xibin Song","Han Yan","Zhennan Wu","Shenzhou Chen","Hongdong Li","Pan Ji"],"pdf_url":"https://arxiv.org/pdf/2403.18241v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18230v1","updated":"2024-03-27T03:33:32Z","published":"2024-03-27T03:33:32Z","title":"Large Language Models Need Consultants for Reasoning: Becoming an Expert\n  in a Complex Human System Through Behavior Simulation","summary":"  Large language models (LLMs), in conjunction with various reasoning\nreinforcement methodologies, have demonstrated remarkable capabilities\ncomparable to humans in fields such as mathematics, law, coding, common sense,\nand world knowledge. In this paper, we delve into the reasoning abilities of\nLLMs within complex human systems. We propose a novel reasoning framework,\ntermed ``Mosaic Expert Observation Wall'' (MEOW) exploiting\ngenerative-agents-based simulation technique. In the MEOW framework, simulated\ndata are utilized to train an expert model concentrating ``experience'' about a\nspecific task in each independent time of simulation. It is the accumulated\n``experience'' through the simulation that makes for an expert on a task in a\ncomplex human system. We conduct the experiments within a communication game\nthat mirrors real-world security scenarios. The results indicate that our\nproposed methodology can cooperate with existing methodologies to enhance the\nreasoning abilities of LLMs in complex human systems.\n","authors":["Chuwen Wang","Shirong Zeng","Cheng Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18230v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16427v3","updated":"2024-03-27T03:27:24Z","published":"2024-03-25T05:12:18Z","title":"Re2LLM: Reflective Reinforcement Large Language Model for Session-based\n  Recommendation","summary":"  Large Language Models (LLMs) are emerging as promising approaches to enhance\nsession-based recommendation (SBR), where both prompt-based and\nfine-tuning-based methods have been widely investigated to align LLMs with SBR.\nHowever, the former methods struggle with optimal prompts to elicit the correct\nreasoning of LLMs due to the lack of task-specific feedback, leading to\nunsatisfactory recommendations. Although the latter methods attempt to\nfine-tune LLMs with domain-specific knowledge, they face limitations such as\nhigh computational costs and reliance on open-source backbones. To address such\nissues, we propose a Reflective Reinforcement Large Language Model (Re2LLM) for\nSBR, guiding LLMs to focus on specialized knowledge essential for more accurate\nrecommendations effectively and efficiently. In particular, we first design the\nReflective Exploration Module to effectively extract knowledge that is readily\nunderstandable and digestible by LLMs. To be specific, we direct LLMs to\nexamine recommendation errors through self-reflection and construct a knowledge\nbase (KB) comprising hints capable of rectifying these errors. To efficiently\nelicit the correct reasoning of LLMs, we further devise the Reinforcement\nUtilization Module to train a lightweight retrieval agent. It learns to select\nhints from the constructed KB based on the task-specific feedback, where the\nhints can serve as guidance to help correct LLMs reasoning for better\nrecommendations. Extensive experiments on multiple real-world datasets\ndemonstrate that our method consistently outperforms state-of-the-art methods.\n","authors":["Ziyan Wang","Yingpeng Du","Zhu Sun","Haoyan Chua","Kaidong Feng","Wenya Wang","Jie Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.16427v3.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2403.18223v1","updated":"2024-03-27T03:25:45Z","published":"2024-03-27T03:25:45Z","title":"A Transformer-Based Framework for Payload Malware Detection and\n  Classification","summary":"  As malicious cyber threats become more sophisticated in breaching computer\nnetworks, the need for effective intrusion detection systems (IDSs) becomes\ncrucial. Techniques such as Deep Packet Inspection (DPI) have been introduced\nto allow IDSs analyze the content of network packets, providing more context\nfor identifying potential threats. IDSs traditionally rely on using\nanomaly-based and signature-based detection techniques to detect unrecognized\nand suspicious activity. Deep learning techniques have shown great potential in\nDPI for IDSs due to their efficiency in learning intricate patterns from the\npacket content being transmitted through the network. In this paper, we propose\na revolutionary DPI algorithm based on transformers adapted for the purpose of\ndetecting malicious traffic with a classifier head. Transformers learn the\ncomplex content of sequence data and generalize them well to similar scenarios\nthanks to their self-attention mechanism. Our proposed method uses the raw\npayload bytes that represent the packet contents and is deployed as\nman-in-the-middle. The payload bytes are used to detect malicious packets and\nclassify their types. Experimental results on the UNSW-NB15 and CIC-IOT23\ndatasets demonstrate that our transformer-based model is effective in\ndistinguishing malicious from benign traffic in the test dataset, attaining an\naverage accuracy of 79\\% using binary classification and 72\\% on the\nmulti-classification experiment, both using solely payload bytes.\n","authors":["Kyle Stein","Arash Mahyari","Guillermo Francia III","Eman El-Sheikh"],"pdf_url":"https://arxiv.org/pdf/2403.18223v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18219v1","updated":"2024-03-27T03:07:18Z","published":"2024-03-27T03:07:18Z","title":"From Two-Dimensional to Three-Dimensional Environment with Q-Learning:\n  Modeling Autonomous Navigation with Reinforcement Learning and no Libraries","summary":"  Reinforcement learning (RL) algorithms have become indispensable tools in\nartificial intelligence, empowering agents to acquire optimal decision-making\npolicies through interactions with their environment and feedback mechanisms.\nThis study explores the performance of RL agents in both two-dimensional (2D)\nand three-dimensional (3D) environments, aiming to research the dynamics of\nlearning across different spatial dimensions. A key aspect of this\ninvestigation is the absence of pre-made libraries for learning, with the\nalgorithm developed exclusively through computational mathematics. The\nmethodological framework centers on RL principles, employing a Q-learning agent\nclass and distinct environment classes tailored to each spatial dimension. The\nresearch aims to address the question: How do reinforcement learning agents\nadapt and perform in environments of varying spatial dimensions, particularly\nin 2D and 3D settings? Through empirical analysis, the study evaluates agents'\nlearning trajectories and adaptation processes, revealing insights into the\nefficacy of RL algorithms in navigating complex, multi-dimensional spaces.\nReflections on the findings prompt considerations for future research,\nparticularly in understanding the dynamics of learning in higher-dimensional\nenvironments.\n","authors":["Ergon Cugler de Moraes Silva"],"pdf_url":"https://arxiv.org/pdf/2403.18219v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04357v5","updated":"2024-03-27T03:06:13Z","published":"2023-06-07T11:40:07Z","title":"Dial-MAE: ConTextual Masked Auto-Encoder for Retrieval-based Dialogue\n  Systems","summary":"  Dialogue response selection aims to select an appropriate response from\nseveral candidates based on a given user and system utterance history. Most\nexisting works primarily focus on post-training and fine-tuning tailored for\ncross-encoders. However, there are no post-training methods tailored for dense\nencoders in dialogue response selection. We argue that when the current\nlanguage model, based on dense dialogue systems (such as BERT), is employed as\na dense encoder, it separately encodes dialogue context and response, leading\nto a struggle to achieve the alignment of both representations. Thus, we\npropose Dial-MAE (Dialogue Contextual Masking Auto-Encoder), a straightforward\nyet effective post-training technique tailored for dense encoders in dialogue\nresponse selection. Dial-MAE uses an asymmetric encoder-decoder architecture to\ncompress the dialogue semantics into dense vectors, which achieves better\nalignment between the features of the dialogue context and response. Our\nexperiments have demonstrated that Dial-MAE is highly effective, achieving\nstate-of-the-art performance on two commonly evaluated benchmarks.\n","authors":["Zhenpeng Su","Xing Wu","Wei Zhou","Guangyuan Ma","Songlin Hu"],"pdf_url":"https://arxiv.org/pdf/2306.04357v5.pdf","comment":"This paper has been accepted by NAACL 2024"},{"id":"http://arxiv.org/abs/2403.18218v1","updated":"2024-03-27T03:04:21Z","published":"2024-03-27T03:04:21Z","title":"Leveraging Large Language Models for Fuzzy String Matching in Political\n  Science","summary":"  Fuzzy string matching remains a key issue when political scientists combine\ndata from different sources. Existing matching methods invariably rely on\nstring distances, such as Levenshtein distance and cosine similarity. As such,\nthey are inherently incapable of matching strings that refer to the same entity\nwith different names such as ''JP Morgan'' and ''Chase Bank'', ''DPRK'' and\n''North Korea'', ''Chuck Fleischmann (R)'' and ''Charles Fleischmann (R)''. In\nthis letter, we propose to use large language models to entirely sidestep this\nproblem in an easy and intuitive manner. Extensive experiments show that our\nproposed methods can improve the state of the art by as much as 39% in terms of\naverage precision while being substantially easier and more intuitive to use by\npolitical scientists. Moreover, our results are robust against various\ntemperatures. We further note that enhanced prompting can lead to additional\nperformance improvements.\n","authors":["Yu Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18218v1.pdf","comment":"7 pages, 2 figures, 1 table;"},{"id":"http://arxiv.org/abs/2403.00868v2","updated":"2024-03-27T03:03:00Z","published":"2024-03-01T04:39:16Z","title":"SoftTiger: A Clinical Foundation Model for Healthcare Workflows","summary":"  We introduce SoftTiger, a clinical large language model (CLaM) designed as a\nfoundation model for healthcare workflows. The narrative and unstructured\nnature of clinical notes is a major obstacle for healthcare intelligentization.\nWe address a critical problem of structuring clinical notes into clinical data,\naccording to international interoperability standards. We collect and annotate\ndata for three subtasks, namely, international patient summary, clinical\nimpression and medical encounter. We then supervised fine-tuned a\nstate-of-the-art LLM using public and credentialed clinical data. The training\nis orchestrated in a way that the target model can first support basic clinical\ntasks such as abbreviation expansion and temporal information extraction, and\nthen learn to perform more complex downstream clinical tasks. Moreover, we\naddress several modeling challenges in the healthcare context, e.g., extra long\ncontext window. Our blind pairwise evaluation shows that SoftTiger outperforms\nother popular open-source models and GPT-3.5, comparable to Gemini-pro, with a\nmild gap from GPT-4. We believe that LLMs may become a step-stone towards\nhealthcare digitalization and democratization. Therefore, we publicly release\nSoftTiger models at scales of 13 billion and 70 billion parameters, as well as\ndatasets and code for our innovative scalable evaluation, hopefully, making a\nsignificant contribution to the healthcare industry.\n","authors":["Ye Chen","Igor Couto","Wei Cai","Cong Fu","Bruno Dorneles"],"pdf_url":"https://arxiv.org/pdf/2403.00868v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.17304v2","updated":"2024-03-27T02:59:57Z","published":"2024-02-27T08:27:15Z","title":"Probing Multimodal Large Language Models for Global and Local Semantic\n  Representations","summary":"  The advancement of Multimodal Large Language Models (MLLMs) has greatly\naccelerated the development of applications in understanding integrated texts\nand images. Recent works leverage image-caption datasets to train MLLMs,\nachieving state-of-the-art performance on image-to-text tasks. However, there\nare few studies exploring which layers of MLLMs make the most effort to the\nglobal image information, which plays vital roles in multimodal comprehension\nand generation. In this study, we find that the intermediate layers of models\ncan encode more global semantic information, whose representation vectors\nperform better on visual-language entailment tasks, rather than the topmost\nlayers. We further probe models regarding local semantic representations\nthrough object recognition tasks. We find that the topmost layers may\nexcessively focus on local information, leading to a diminished ability to\nencode global information. Our code and data are released via\nhttps://github.com/kobayashikanna01/probing_MLLM_rep.\n","authors":["Mingxu Tao","Quzhe Huang","Kun Xu","Liwei Chen","Yansong Feng","Dongyan Zhao"],"pdf_url":"https://arxiv.org/pdf/2402.17304v2.pdf","comment":"Accepted by LREC-COLING 2024 as a short paper (Camera Ready)"},{"id":"http://arxiv.org/abs/2304.06427v2","updated":"2024-03-27T02:58:26Z","published":"2023-04-13T11:46:32Z","title":"In-Distribution and Out-of-Distribution Self-supervised ECG\n  Representation Learning for Arrhythmia Detection","summary":"  This paper presents a systematic investigation into the effectiveness of\nSelf-Supervised Learning (SSL) methods for Electrocardiogram (ECG) arrhythmia\ndetection. We begin by conducting a novel analysis of the data distributions on\nthree popular ECG-based arrhythmia datasets: PTB-XL, Chapman, and Ribeiro. To\nthe best of our knowledge, our study is the first to quantitatively explore and\ncharacterize these distributions in the area. We then perform a comprehensive\nset of experiments using different augmentations and parameters to evaluate the\neffectiveness of various SSL methods, namely SimCRL, BYOL, and SwAV, for ECG\nrepresentation learning, where we observe the best performance achieved by\nSwAV. Furthermore, our analysis shows that SSL methods achieve highly\ncompetitive results to those achieved by supervised state-of-the-art methods.\nTo further assess the performance of these methods on both In-Distribution (ID)\nand Out-of-Distribution (OOD) ECG data, we conduct cross-dataset training and\ntesting experiments. Our comprehensive experiments show almost identical\nresults when comparing ID and OOD schemes, indicating that SSL techniques can\nlearn highly effective representations that generalize well across different\nOOD datasets. This finding can have major implications for ECG-based arrhythmia\ndetection. Lastly, to further analyze our results, we perform detailed\nper-disease studies on the performance of the SSL methods on the three\ndatasets.\n","authors":["Sahar Soltanieh","Javad Hashemi","Ali Etemad"],"pdf_url":"https://arxiv.org/pdf/2304.06427v2.pdf","comment":"This paper has been published in the IEEE Journal of Biomedical and\n  Health Informatics (JBHI). Copyright IEEE. Please cite as: S. Soltanieh, J.\n  Hashemi and A. Etemad, \"In-Distribution and Out-of-Distribution\n  Self-Supervised ECG Representation Learning for Arrhythmia Detection,\" in\n  IEEE Journal of Biomedical and Health Informatics, vol. 28, no. 2, pp.\n  789-800, Feb. 2024"},{"id":"http://arxiv.org/abs/2403.18212v1","updated":"2024-03-27T02:46:09Z","published":"2024-03-27T02:46:09Z","title":"Preference-Based Planning in Stochastic Environments: From\n  Partially-Ordered Temporal Goals to Most Preferred Policies","summary":"  Human preferences are not always represented via complete linear orders: It\nis natural to employ partially-ordered preferences for expressing incomparable\noutcomes. In this work, we consider decision-making and probabilistic planning\nin stochastic systems modeled as Markov decision processes (MDPs), given a\npartially ordered preference over a set of temporally extended goals.\nSpecifically, each temporally extended goal is expressed using a formula in\nLinear Temporal Logic on Finite Traces (LTL$_f$). To plan with the partially\nordered preference, we introduce order theory to map a preference over temporal\ngoals to a preference over policies for the MDP. Accordingly, a most preferred\npolicy under a stochastic ordering induces a stochastic nondominated\nprobability distribution over the finite paths in the MDP. To synthesize a most\npreferred policy, our technical approach includes two key steps. In the first\nstep, we develop a procedure to transform a partially ordered preference over\ntemporal goals into a computational model, called preference automaton, which\nis a semi-automaton with a partial order over acceptance conditions. In the\nsecond step, we prove that finding a most preferred policy is equivalent to\ncomputing a Pareto-optimal policy in a multi-objective MDP that is constructed\nfrom the original MDP, the preference automaton, and the chosen stochastic\nordering relation. Throughout the paper, we employ running examples to\nillustrate the proposed preference specification and solution approaches. We\ndemonstrate the efficacy of our algorithm using these examples, providing\ndetailed analysis, and then discuss several potential future directions.\n","authors":["Hazhar Rahmani","Abhishek N. Kulkarni","Jie Fu"],"pdf_url":"https://arxiv.org/pdf/2403.18212v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2209.12267"},{"id":"http://arxiv.org/abs/2403.18209v1","updated":"2024-03-27T02:41:52Z","published":"2024-03-27T02:41:52Z","title":"Long and Short-Term Constraints Driven Safe Reinforcement Learning for\n  Autonomous Driving","summary":"  Reinforcement learning (RL) has been widely used in decision-making tasks,\nbut it cannot guarantee the agent's safety in the training process due to the\nrequirements of interaction with the environment, which seriously limits its\nindustrial applications such as autonomous driving. Safe RL methods are\ndeveloped to handle this issue by constraining the expected safety violation\ncosts as a training objective, but they still permit unsafe state occurrence,\nwhich is unacceptable in autonomous driving tasks. Moreover, these methods are\ndifficult to achieve a balance between the cost and return expectations, which\nleads to learning performance degradation for the algorithms. In this paper, we\npropose a novel algorithm based on the long and short-term constraints (LSTC)\nfor safe RL. The short-term constraint aims to guarantee the short-term state\nsafety that the vehicle explores, while the long-term constraint ensures the\noverall safety of the vehicle throughout the decision-making process. In\naddition, we develop a safe RL method with dual-constraint optimization based\non the Lagrange multiplier to optimize the training process for end-to-end\nautonomous driving. Comprehensive experiments were conducted on the MetaDrive\nsimulator. Experimental results demonstrate that the proposed method achieves\nhigher safety in continuous state and action tasks, and exhibits higher\nexploration performance in long-distance decision-making tasks compared with\nstate-of-the-art methods.\n","authors":["Xuemin Hu","Pan Chen","Yijun Wen","Bo Tang","Long Chen"],"pdf_url":"https://arxiv.org/pdf/2403.18209v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17456v2","updated":"2024-03-27T02:39:26Z","published":"2024-03-26T07:41:54Z","title":"Imitating Cost-Constrained Behaviors in Reinforcement Learning","summary":"  Complex planning and scheduling problems have long been solved using various\noptimization or heuristic approaches. In recent years, imitation learning that\naims to learn from expert demonstrations has been proposed as a viable\nalternative to solving these problems. Generally speaking, imitation learning\nis designed to learn either the reward (or preference) model or directly the\nbehavioral policy by observing the behavior of an expert. Existing work in\nimitation learning and inverse reinforcement learning has focused on imitation\nprimarily in unconstrained settings (e.g., no limit on fuel consumed by the\nvehicle). However, in many real-world domains, the behavior of an expert is\ngoverned not only by reward (or preference) but also by constraints. For\ninstance, decisions on self-driving delivery vehicles are dependent not only on\nthe route preferences/rewards (depending on past demand data) but also on the\nfuel in the vehicle and the time available. In such problems, imitation\nlearning is challenging as decisions are not only dictated by the reward model\nbut are also dependent on a cost-constrained model. In this paper, we provide\nmultiple methods that match expert distributions in the presence of trajectory\ncost constraints through (a) Lagrangian-based method; (b) Meta-gradients to\nfind a good trade-off between expected return and minimizing constraint\nviolation; and (c) Cost-violation-based alternating gradient. We empirically\nshow that leading imitation learning approaches imitate cost-constrained\nbehaviors poorly and our meta-gradient-based approach achieves the best\nperformance.\n","authors":["Qian Shao","Pradeep Varakantham","Shih-Fen Cheng"],"pdf_url":"https://arxiv.org/pdf/2403.17456v2.pdf","comment":"Accepted to the 34th International Conference on Automated Planning\n  and Scheduling (ICAPS-24)"},{"id":"http://arxiv.org/abs/2403.18208v1","updated":"2024-03-27T02:39:23Z","published":"2024-03-27T02:39:23Z","title":"An Evolutionary Network Architecture Search Framework with Adaptive\n  Multimodal Fusion for Hand Gesture Recognition","summary":"  Hand gesture recognition (HGR) based on multimodal data has attracted\nconsiderable attention owing to its great potential in applications. Various\nmanually designed multimodal deep networks have performed well in multimodal\nHGR (MHGR), but most of existing algorithms require a lot of expert experience\nand time-consuming manual trials. To address these issues, we propose an\nevolutionary network architecture search framework with the adaptive multimodel\nfusion (AMF-ENAS). Specifically, we design an encoding space that\nsimultaneously considers fusion positions and ratios of the multimodal data,\nallowing for the automatic construction of multimodal networks with different\narchitectures through decoding. Additionally, we consider three input streams\ncorresponding to intra-modal surface electromyography (sEMG), intra-modal\naccelerometer (ACC), and inter-modal sEMG-ACC. To automatically adapt to\nvarious datasets, the ENAS framework is designed to automatically search a MHGR\nnetwork with appropriate fusion positions and ratios. To the best of our\nknowledge, this is the first time that ENAS has been utilized in MHGR to tackle\nissues related to the fusion position and ratio of multimodal data.\nExperimental results demonstrate that AMF-ENAS achieves state-of-the-art\nperformance on the Ninapro DB2, DB3, and DB7 datasets.\n","authors":["Yizhang Xia","Shihao Song","Zhanglu Hou","Junwen Xu","Juan Zou","Yuan Liu","Shengxiang Yang"],"pdf_url":"https://arxiv.org/pdf/2403.18208v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18205v1","updated":"2024-03-27T02:31:54Z","published":"2024-03-27T02:31:54Z","title":"Exploring the Privacy Protection Capabilities of Chinese Large Language\n  Models","summary":"  Large language models (LLMs), renowned for their impressive capabilities in\nvarious tasks, have significantly advanced artificial intelligence. Yet, these\nadvancements have raised growing concerns about privacy and security\nimplications. To address these issues and explain the risks inherent in these\nmodels, we have devised a three-tiered progressive framework tailored for\nevaluating privacy in language systems. This framework consists of\nprogressively complex and in-depth privacy test tasks at each tier. Our primary\nobjective is to comprehensively evaluate the sensitivity of large language\nmodels to private information, examining how effectively they discern, manage,\nand safeguard sensitive data in diverse scenarios. This systematic evaluation\nhelps us understand the degree to which these models comply with privacy\nprotection guidelines and the effectiveness of their inherent safeguards\nagainst privacy breaches. Our observations indicate that existing Chinese large\nlanguage models universally show privacy protection shortcomings. It seems that\nat the moment this widespread issue is unavoidable and may pose corresponding\nprivacy risks in applications based on these models.\n","authors":["Yuqi Yang","Xiaowen Huang","Jitao Sang"],"pdf_url":"https://arxiv.org/pdf/2403.18205v1.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2403.18203v1","updated":"2024-03-27T02:24:38Z","published":"2024-03-27T02:24:38Z","title":"EndToEndML: An Open-Source End-to-End Pipeline for Machine Learning\n  Applications","summary":"  Artificial intelligence (AI) techniques are widely applied in the life\nsciences. However, applying innovative AI techniques to understand and\ndeconvolute biological complexity is hindered by the learning curve for life\nscience scientists to understand and use computing languages. An open-source,\nuser-friendly interface for AI models, that does not require programming skills\nto analyze complex biological data will be extremely valuable to the\nbioinformatics community. With easy access to different sequencing technologies\nand increased interest in different 'omics' studies, the number of biological\ndatasets being generated has increased and analyzing these high-throughput\ndatasets is computationally demanding. The majority of AI libraries today\nrequire advanced programming skills as well as machine learning, data\npreprocessing, and visualization skills. In this research, we propose a\nweb-based end-to-end pipeline that is capable of preprocessing, training,\nevaluating, and visualizing machine learning (ML) models without manual\nintervention or coding expertise. By integrating traditional machine learning\nand deep neural network models with visualizations, our library assists in\nrecognizing, classifying, clustering, and predicting a wide range of\nmulti-modal, multi-sensor datasets, including images, languages, and\none-dimensional numerical data, for drug discovery, pathogen classification,\nand medical diagnostics.\n","authors":["Nisha Pillai","Athish Ram Das","Moses Ayoola","Ganga Gireesan","Bindu Nanduri","Mahalingam Ramkumar"],"pdf_url":"https://arxiv.org/pdf/2403.18203v1.pdf","comment":"2024 7th International Conference on Information and Computer\n  Technologies (ICICT)"},{"id":"http://arxiv.org/abs/2303.13300v3","updated":"2024-03-27T02:23:29Z","published":"2023-03-23T14:37:35Z","title":"The Innovation Paradox: Concept Space Expansion with Diminishing\n  Originality and the Promise of Creative AI","summary":"  Innovation, typically spurred by reusing, recombining, and synthesizing\nexisting concepts, is expected to result in an exponential growth of the\nconcept space over time. However, our statistical analysis of TechNet, which is\na comprehensive technology semantic network encompassing over four million\nconcepts derived from patent texts, reveals a linear rather than exponential\nexpansion of the overall technological concept space. Moreover, there is a\nnotable decline in the originality of newly created concepts. These trends can\nbe attributed to the constraints of human cognitive abilities to innovate\nbeyond an ever-growing space of prior art, among other factors. Integrating\ncreative artificial intelligence (CAI) into the innovation process holds the\npotential to overcome these limitations and alter the observed trends in the\nfuture.\n","authors":["Serhad Sarica","Jianxi Luo"],"pdf_url":"https://arxiv.org/pdf/2303.13300v3.pdf","comment":"Forthcoming on the Design Science"},{"id":"http://arxiv.org/abs/2403.00154v2","updated":"2024-03-27T02:21:03Z","published":"2024-02-29T22:11:20Z","title":"LLMs in Political Science: Heralding a New Era of Visual Analysis","summary":"  Interest is increasing among political scientists in leveraging the extensive\ninformation available in images. However, the challenge of interpreting these\nimages lies in the need for specialized knowledge in computer vision and access\nto specialized hardware. As a result, image analysis has been limited to a\nrelatively small group within the political science community. This landscape\ncould potentially change thanks to the rise of large language models (LLMs).\nThis paper aims to raise awareness of the feasibility of using Gemini for image\ncontent analysis. A retrospective analysis was conducted on a corpus of 688\nimages. Content reports were elicited from Gemini for each image and then\nmanually evaluated by the authors. We find that Gemini is highly accurate in\nperforming object detection, which is arguably the most common and fundamental\ntask in image analysis for political scientists. Equally important, we show\nthat it is easy to implement as the entire command consists of a single prompt\nin natural language; it is fast to run and should meet the time budget of most\nresearchers; and it is free to use and does not require any specialized\nhardware. In addition, we illustrate how political scientists can leverage\nGemini for other image understanding tasks, including face identification,\nsentiment analysis, and caption generation. Our findings suggest that Gemini\nand other similar LLMs have the potential to drastically stimulate and\naccelerate image research in political science and social sciences more\nbroadly.\n","authors":["Yu Wang"],"pdf_url":"https://arxiv.org/pdf/2403.00154v2.pdf","comment":"7 pages, 3 tables"},{"id":"http://arxiv.org/abs/2403.18196v1","updated":"2024-03-27T02:13:20Z","published":"2024-03-27T02:13:20Z","title":"Looking Beyond What You See: An Empirical Analysis on Subgroup\n  Intersectional Fairness for Multi-label Chest X-ray Classification Using\n  Social Determinants of Racial Health Inequities","summary":"  There has been significant progress in implementing deep learning models in\ndisease diagnosis using chest X- rays. Despite these advancements, inherent\nbiases in these models can lead to disparities in prediction accuracy across\nprotected groups. In this study, we propose a framework to achieve accurate\ndiagnostic outcomes and ensure fairness across intersectional groups in\nhigh-dimensional chest X- ray multi-label classification. Transcending\ntraditional protected attributes, we consider complex interactions within\nsocial determinants, enabling a more granular benchmark and evaluation of\nfairness. We present a simple and robust method that involves retraining the\nlast classification layer of pre-trained models using a balanced dataset across\ngroups. Additionally, we account for fairness constraints and integrate\nclass-balanced fine-tuning for multi-label settings. The evaluation of our\nmethod on the MIMIC-CXR dataset demonstrates that our framework achieves an\noptimal tradeoff between accuracy and fairness compared to baseline methods.\n","authors":["Dana Moukheiber","Saurabh Mahindre","Lama Moukheiber","Mira Moukheiber","Mingchen Gao"],"pdf_url":"https://arxiv.org/pdf/2403.18196v1.pdf","comment":"ICCV CVAMD 2023"},{"id":"http://arxiv.org/abs/2403.18195v1","updated":"2024-03-27T02:08:12Z","published":"2024-03-27T02:08:12Z","title":"SCANet: Correcting LEGO Assembly Errors with Self-Correct Assembly\n  Network","summary":"  Autonomous assembly in robotics and 3D vision presents significant\nchallenges, particularly in ensuring assembly correctness. Presently,\npredominant methods such as MEPNet focus on assembling components based on\nmanually provided images. However, these approaches often fall short in\nachieving satisfactory results for tasks requiring long-term planning.\nConcurrently, we observe that integrating a self-correction module can\npartially alleviate such issues. Motivated by this concern, we introduce the\nsingle-step assembly error correction task, which involves identifying and\nrectifying misassembled components. To support research in this area, we\npresent the LEGO Error Correction Assembly Dataset (LEGO-ECA), comprising\nmanual images for assembly steps and instances of assembly failures.\nAdditionally, we propose the Self-Correct Assembly Network (SCANet), a novel\nmethod to address this task. SCANet treats assembled components as queries,\ndetermining their correctness in manual images and providing corrections when\nnecessary. Finally, we utilize SCANet to correct the assembly results of\nMEPNet. Experimental results demonstrate that SCANet can identify and correct\nMEPNet's misassembled results, significantly improving the correctness of\nassembly. Our code and dataset are available at\nhttps://github.com/Yaser-wyx/SCANet.\n","authors":["Yuxuan Wan","Kaichen Zhou","jinhong Chen","Hao Dong"],"pdf_url":"https://arxiv.org/pdf/2403.18195v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16915v3","updated":"2024-03-27T01:53:36Z","published":"2024-03-25T16:32:50Z","title":"Coarse-Tuning for Ad-hoc Document Retrieval Using Pre-trained Language\n  Models","summary":"  Fine-tuning in information retrieval systems using pre-trained language\nmodels (PLM-based IR) requires learning query representations and\nquery-document relations, in addition to downstream task-specific learning.\nThis study introduces coarse-tuning as an intermediate learning stage that\nbridges pre-training and fine-tuning. By learning query representations and\nquery-document relations in coarse-tuning, we aim to reduce the load of\nfine-tuning and improve the learning effect of downstream IR tasks. We propose\nQuery-Document Pair Prediction (QDPP) for coarse-tuning, which predicts the\nappropriateness of query-document pairs. Evaluation experiments show that the\nproposed method significantly improves MRR and/or nDCG@5 in four ad-hoc\ndocument retrieval datasets. Furthermore, the results of the query prediction\ntask suggested that coarse-tuning facilitated learning of query representation\nand query-document relations.\n","authors":["Atsushi Keyaki","Ribeka Keyaki"],"pdf_url":"https://arxiv.org/pdf/2403.16915v3.pdf","comment":"Accepted at LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2402.15764v2","updated":"2024-03-27T01:23:58Z","published":"2024-02-24T08:40:30Z","title":"Look Before You Leap: Problem Elaboration Prompting Improves\n  Mathematical Reasoning in Large Language Models","summary":"  Large language models (LLMs) still grapple with complex tasks like\nmathematical reasoning. Despite significant efforts invested in improving\nprefix prompts or reasoning process, the crucial role of problem context might\nhave been neglected. Accurate recognition of inputs is fundamental for solving\nmathematical tasks, as ill-formed problems could potentially mislead LLM's\nreasoning. In this study, we propose a new approach named Problem Elaboration\nPrompting (PEP) to enhance the mathematical capacities of LLMs. Specifically,\nPEP decomposes and elucidates the problem context before reasoning, therefore\nenhancing the context modeling and parsing efficiency. Experiments across\ndatasets and models demonstrate promising performances: (1) PEP demonstrates an\noverall enhancement in various mathematical tasks. For instance, with the\nGPT-3.5 model, PEP exhibits improvements of 9.93% and 8.80% on GSM8k through\ngreedy decoding and self-consistency, respectively. (2) PEP can be easily\nimplemented and integrated with other prompting methods. (3) PEP shows\nparticular strength in handling distraction problems.\n","authors":["Haoran Liao","Jidong Tian","Shaohua Hu","Hao He","Yaohui Jin"],"pdf_url":"https://arxiv.org/pdf/2402.15764v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18183v1","updated":"2024-03-27T01:21:48Z","published":"2024-03-27T01:21:48Z","title":"Can AI Models Appreciate Document Aesthetics? An Exploration of\n  Legibility and Layout Quality in Relation to Prediction Confidence","summary":"  A well-designed document communicates not only through its words but also\nthrough its visual eloquence. Authors utilize aesthetic elements such as\ncolors, fonts, graphics, and layouts to shape the perception of information.\nThoughtful document design, informed by psychological insights, enhances both\nthe visual appeal and the comprehension of the content. While state-of-the-art\ndocument AI models demonstrate the benefits of incorporating layout and image\ndata, it remains unclear whether the nuances of document aesthetics are\neffectively captured. To bridge the gap between human cognition and AI\ninterpretation of aesthetic elements, we formulated hypotheses concerning AI\nbehavior in document understanding tasks, specifically anchored in document\ndesign principles. With a focus on legibility and layout quality, we tested\nfour aspects of aesthetic effects: noise, font-size contrast, alignment, and\ncomplexity, on model confidence using correlational analysis. The results and\nobservations highlight the value of model analysis rooted in document design\ntheories. Our work serves as a trailhead for further studies and we advocate\nfor continued research in this topic to deepen our understanding of how AI\ninterprets document aesthetics.\n","authors":["Hsiu-Wei Yang","Abhinav Agrawal","Pavlos Fragkogiannis","Shubham Nitin Mulay"],"pdf_url":"https://arxiv.org/pdf/2403.18183v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01421v3","updated":"2024-03-27T00:38:33Z","published":"2023-02-02T21:21:14Z","title":"Follower Agnostic Methods for Stackelberg Games","summary":"  In this paper, we present an efficient algorithm to solve online Stackelberg\ngames, featuring multiple followers, in a follower-agnostic manner. Unlike\nprevious works, our approach works even when leader has no knowledge about the\nfollowers' utility functions or strategy space. Our algorithm introduces a\nunique gradient estimator, leveraging specially designed strategies to probe\nfollowers. In a departure from traditional assumptions of optimal play, we\nmodel followers' responses using a convergent adaptation rule, allowing for\nrealistic and dynamic interactions. The leader constructs the gradient\nestimator solely based on observations of followers' actions. We provide both\nnon-asymptotic convergence rates to stationary points of the leader's objective\nand demonstrate asymptotic convergence to a \\emph{local Stackelberg\nequilibrium}. To validate the effectiveness of our algorithm, we use this\nalgorithm to solve the problem of incentive design on a large-scale\ntransportation network, showcasing its robustness even when the leader lacks\naccess to followers' demand.\n","authors":["Chinmay Maheshwari","James Cheng","S. Shankar Sasty","Lillian Ratliff","Eric Mazumdar"],"pdf_url":"https://arxiv.org/pdf/2302.01421v3.pdf","comment":"31 pages"},{"id":"http://arxiv.org/abs/2403.18167v1","updated":"2024-03-27T00:23:03Z","published":"2024-03-27T00:23:03Z","title":"Mechanisms of non-factual hallucinations in language models","summary":"  State-of-the-art language models (LMs) sometimes generate non-factual\nhallucinations that misalign with world knowledge. Despite extensive efforts to\ndetect and mitigate hallucinations, understanding their internal mechanisms\nremains elusive. Our study investigates the mechanistic causes of\nhallucination, specifically non-factual ones where the LM incorrectly predicts\nobject attributes in response to subject-relation queries. With causal\nmediation analysis and embedding space projection, we identify two general\nmechanistic causes of hallucinations shared across LMs of various scales and\ndesigns: 1) insufficient subject attribute knowledge in lower layer MLPs, and\n2) failing to select the correct object attribute in upper layer attention\nheads and MLPs. These two mechanisms exhibit varying degrees of subject-object\nassociation, predictive uncertainty and perturbation robustness. Additionally,\nwe scrutinize LM pre-training checkpoints, revealing distinct learning dynamics\nfor the two mechanistic causes of hallucinations. We also highlight how\nattribution features from our causal analysis can effectively construct\nhallucination detectors. Our work proposes a mechanistic understanding of LM\nfactual errors.\n","authors":["Lei Yu","Meng Cao","Jackie Chi Kit Cheung","Yue Dong"],"pdf_url":"https://arxiv.org/pdf/2403.18167v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.10812v2","updated":"2024-03-27T00:15:16Z","published":"2023-12-17T20:39:54Z","title":"Learning to Act without Actions","summary":"  Pre-training large models on vast amounts of web data has proven to be an\neffective approach for obtaining powerful, general models in domains such as\nlanguage and vision. However, this paradigm has not yet taken hold in\nreinforcement learning. This is because videos, the most abundant form of\nembodied behavioral data on the web, lack the action labels required by\nexisting methods for imitating behavior from demonstrations. We introduce\nLatent Action Policies (LAPO), a method for recovering latent action\ninformation, and thereby latent-action policies, world models, and inverse\ndynamics models, purely from videos. LAPO is the first method able to recover\nthe structure of the true action space just from observed dynamics, even in\nchallenging procedurally-generated environments. LAPO enables training\nlatent-action policies that can be rapidly fine-tuned into expert-level\npolicies, either offline using a small action-labeled dataset, or online with\nrewards. LAPO takes a first step towards pre-training powerful, generalist\npolicies and world models on the vast amounts of videos readily available on\nthe web.\n","authors":["Dominik Schmidt","Minqi Jiang"],"pdf_url":"https://arxiv.org/pdf/2312.10812v2.pdf","comment":"Accepted at ICLR 2024 (spotlight). The code can be found at\n  http://github.com/schmidtdominik/LAPO"}],"Optimization and Control":[{"id":"http://arxiv.org/abs/2312.07394v2","updated":"2024-03-27T17:10:45Z","published":"2023-12-12T16:08:28Z","title":"On model predictive control with sampled-data input for output tracking\n  with prescribed performance","summary":"  We propose a model predictive control (MPC) scheme with sampled-data input\nwhich ensures output-reference tracking within prescribed error bounds for\nrelative-degree-one systems. Hereby, we explicitly deduce bounds on the\nrequired maximal control input and sampling frequency such that the MPC scheme\nis both initially and recursively feasible. A key feature of the proposed\napproach is that neither terminal conditions nor a sufficiently-large\nprediction horizon are imposed, rendering the MPC scheme computationally\nefficient. We illustrate the MPC algorithm via a numerical example of a\ntorsional oscillator.\n","authors":["Dario Dennstädt","Lukas Lanza","Karl Worthmann"],"pdf_url":"https://arxiv.org/pdf/2312.07394v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18767v1","updated":"2024-03-27T17:05:06Z","published":"2024-03-27T17:05:06Z","title":"The best approximation pair problem relative to two subsets in a normed\n  space","summary":"  In the classical best approximation pair (BAP) problem, one is given two\nnonempty, closed, convex and disjoint subsets in a finite- or an\ninfinite-dimensional Hilbert space, and the goal is to find a pair of points,\neach from each subset, which realizes the distance between the subsets. This\nproblem, which has a long history, has found applications in science and\ntechnology. We discuss the problem in more general normed spaces and with\npossibly non-convex subsets, and focus our attention on the issues of\nuniqueness and existence of the solution to the problem. To the best of our\nknowledge these fundamental issues have not received much attention. In\nparticular, we present several sufficient geometric conditions for the (at\nmost) uniqueness of a BAP relative to these subsets. These conditions are\nrelated to the structure of the boundaries of the subsets, their relative\norientation, and the structure of the unit sphere of the space. In addition, we\npresent many sufficient conditions for the existence of a BAP, possibly without\nconvexity . Our results allow us to significantly extend the horizon of the\nrecent alternating simultaneous Halpern-Lions-Wittmann-Bauschke (A-S-HLWB)\nalgorithm [Censor, Mansour and Reem, The alternating simultaneous\nHalpern-Lions-Wittmann-Bauschke algorithm for finding the best approximation\npair for two disjoint intersections of convex sets, arXiv:2304.09600 (2023)]\nfor solving the BAP problem.\n","authors":["Daniel Reem","Yair Censor"],"pdf_url":"https://arxiv.org/pdf/2403.18767v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.06180v2","updated":"2024-03-27T16:45:26Z","published":"2022-01-17T02:30:25Z","title":"Nonlinear Control Allocation: A Learning Based Approach","summary":"  Modern aircraft are designed with redundant control effectors to cater for\nfault tolerance and maneuverability requirements. This leads to aircraft being\nover-actuated and requires control allocation schemes to distribute the control\ncommands among control effectors. Traditionally, optimization-based control\nallocation schemes are used; however, for nonlinear allocation problems, these\nmethods require large computational resources. In this work, an artificial\nneural network (ANN) based nonlinear control allocation scheme is proposed. The\nproposed scheme is composed of learning the inverse of the control\neffectiveness map through ANN, and then implementing it as an allocator instead\nof solving an online optimization problem. Stability conditions are presented\nfor closed-loop systems incorporating the allocator, and computational\nchallenges are explored with piece-wise linear effectiveness functions and\nANN-based allocators. To demonstrate the efficacy of the proposed scheme, it is\ncompared with a standard quadratic programming-based method for control\nallocation.\n","authors":["Hafiz Zeeshan Iqbal Khan","Surrayya Mobeen","Jahanzeb Rajput","Jamshed Riaz"],"pdf_url":"https://arxiv.org/pdf/2201.06180v2.pdf","comment":"submitted to IEEE Conference on Decision and Control (CDC), 2024"},{"id":"http://arxiv.org/abs/2403.18744v1","updated":"2024-03-27T16:43:08Z","published":"2024-03-27T16:43:08Z","title":"A nonsmooth Frank-Wolfe algorithm through a dual cutting-plane approach","summary":"  An extension of the Frank-Wolfe Algorithm (FWA), also known as Conditional\nGradient algorithm, is proposed. In its standard form, the FWA allows to solve\nconstrained optimization problems involving $\\beta$-smooth cost functions,\ncalling at each iteration a Linear Minimization Oracle. More specifically, the\noracle solves a problem obtained by linearization of the original cost\nfunction. The algorithm designed and investigated in this article, named\nDualized Level-Set (DLS) algorithm, extends the FWA and allows to address a\nclass of nonsmooth costs, involving in particular support functions. The key\nidea behind the construction of the DLS method is a general interpretation of\nthe FWA as a cutting-plane algorithm, from the dual point of view. The DLS\nalgorithm essentially results from a dualization of a specific cutting-plane\nalgorithm, based on projections on some level sets. The DLS algorithm generates\na sequence of primal-dual candidates, and we prove that the corresponding\nprimal-dual gap converges with a rate of $O(1/\\sqrt{t})$.\n","authors":["Guilherme Mazanti","Thibault Moquet","Laurent Pfeiffer"],"pdf_url":"https://arxiv.org/pdf/2403.18744v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18707v1","updated":"2024-03-27T15:56:35Z","published":"2024-03-27T15:56:35Z","title":"Connections between Reachability and Time Optimality","summary":"  This paper presents the concept of an equivalence relation between the set of\noptimal control problems. By leveraging this concept, we show that the boundary\nof the reachability set can be constructed by the solutions of time optimal\nproblems. Alongside, a more generalized equivalence theorem is presented\ntogether. The findings facilitate the use of solution structures from a certain\nclass of optimal control problems to address problems in corresponding\nequivalent classes. As a byproduct, we state and prove the construction methods\nof the reachability sets of three-dimensional curves with prescribed curvature\nbound. The findings are twofold: Firstly, we prove that any boundary point of\nthe reachability set, with the terminal direction taken into account, can be\naccessed via curves of H, CSC, CCC, or their respective subsegments, where H\ndenotes a helicoidal arc, C a circular arc with maximum curvature, and S a\nstraight segment. Secondly, we show that any boundary point of the reachability\nset, without considering the terminal direction, can be accessed by curves of\nCC, CS, or their respective subsegments. These findings extend the developments\npresented in literature regarding planar curves, or Dubins car dynamics, into\nspatial curves in $\\mathbb{R}^3$. For higher dimensions, we confirm that the\nproblem of identifying the reachability set of curvature bounded paths subsumes\nthe well-known Markov-Dubins problem. These advancements in understanding the\nreachability of curvature bounded paths in $\\mathbb{R}^3$ hold significant\npractical implications, particularly in the contexts of mission planning\nproblems and time optimal guidance.\n","authors":["Juho Bae","Ji Hoon Bai","Byung-Yoon Lee","Jun-Yong Lee","Chang-Hun Lee"],"pdf_url":"https://arxiv.org/pdf/2403.18707v1.pdf","comment":"Submitted to Automatica"},{"id":"http://arxiv.org/abs/2403.18705v1","updated":"2024-03-27T15:54:55Z","published":"2024-03-27T15:54:55Z","title":"Conditional Wasserstein Distances with Applications in Bayesian OT Flow\n  Matching","summary":"  In inverse problems, many conditional generative models approximate the\nposterior measure by minimizing a distance between the joint measure and its\nlearned approximation. While this approach also controls the distance between\nthe posterior measures in the case of the Kullback--Leibler divergence, this is\nin general not hold true for the Wasserstein distance. In this paper, we\nintroduce a conditional Wasserstein distance via a set of restricted couplings\nthat equals the expected Wasserstein distance of the posteriors. Interestingly,\nthe dual formulation of the conditional Wasserstein-1 flow resembles losses in\nthe conditional Wasserstein GAN literature in a quite natural way. We derive\ntheoretical properties of the conditional Wasserstein distance, characterize\nthe corresponding geodesics and velocity fields as well as the flow ODEs.\nSubsequently, we propose to approximate the velocity fields by relaxing the\nconditional Wasserstein distance. Based on this, we propose an extension of OT\nFlow Matching for solving Bayesian inverse problems and demonstrate its\nnumerical advantages on an inverse problem and class-conditional image\ngeneration.\n","authors":["Jannis Chemseddine","Paul Hagemann","Christian Wald","Gabriele Steidl"],"pdf_url":"https://arxiv.org/pdf/2403.18705v1.pdf","comment":"This paper supersedes arXiv:2310.13433"},{"id":"http://arxiv.org/abs/2402.11800v3","updated":"2024-03-27T15:48:29Z","published":"2024-02-19T03:08:02Z","title":"Stochastic Approximation with Delayed Updates: Finite-Time Rates under\n  Markovian Sampling","summary":"  Motivated by applications in large-scale and multi-agent reinforcement\nlearning, we study the non-asymptotic performance of stochastic approximation\n(SA) schemes with delayed updates under Markovian sampling. While the effect of\ndelays has been extensively studied for optimization, the manner in which they\ninteract with the underlying Markov process to shape the finite-time\nperformance of SA remains poorly understood. In this context, our first main\ncontribution is to show that under time-varying bounded delays, the delayed SA\nupdate rule guarantees exponentially fast convergence of the \\emph{last\niterate} to a ball around the SA operator's fixed point. Notably, our bound is\n\\emph{tight} in its dependence on both the maximum delay $\\tau_{max}$, and the\nmixing time $\\tau_{mix}$. To achieve this tight bound, we develop a novel\ninductive proof technique that, unlike various existing delayed-optimization\nanalyses, relies on establishing uniform boundedness of the iterates. As such,\nour proof may be of independent interest. Next, to mitigate the impact of the\nmaximum delay on the convergence rate, we provide the first finite-time\nanalysis of a delay-adaptive SA scheme under Markovian sampling. In particular,\nwe show that the exponent of convergence of this scheme gets scaled down by\n$\\tau_{avg}$, as opposed to $\\tau_{max}$ for the vanilla delayed SA rule; here,\n$\\tau_{avg}$ denotes the average delay across all iterations. Moreover, the\nadaptive scheme requires no prior knowledge of the delay sequence for step-size\ntuning. Our theoretical findings shed light on the finite-time effects of\ndelays for a broad class of algorithms, including TD learning, Q-learning, and\nstochastic gradient descent under Markovian sampling.\n","authors":["Arman Adibi","Nicolo Dal Fabbro","Luca Schenato","Sanjeev Kulkarni","H. Vincent Poor","George J. Pappas","Hamed Hassani","Aritra Mitra"],"pdf_url":"https://arxiv.org/pdf/2402.11800v3.pdf","comment":"Accepted to the 27th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2024!"},{"id":"http://arxiv.org/abs/2403.06708v3","updated":"2024-03-27T15:27:16Z","published":"2024-03-11T13:33:31Z","title":"Tikhonov Regularization for Stochastic Non-Smooth Convex Optimization in\n  Hilbert Spaces","summary":"  To solve non-smooth convex optimization problems with a noisy gradient input,\nwe analyze the global behavior of subgradient-like flows under stochastic\nerrors. The objective function is composite, being equal to the sum of two\nconvex functions, one being differentiable and the other potentially\nnon-smooth. We then use stochastic differential inclusions where the drift term\nis minus the subgradient of the objective function, and the diffusion term is\neither bounded or square-integrable. In this context, under Lipschitz's\ncontinuity of the differentiable term and a growth condition of the non-smooth\nterm, our first main result shows almost sure weak convergence of the\ntrajectory process towards a minimizer of the objective function. Then, using\nTikhonov regularization with a properly tuned vanishing parameter, we can\nobtain almost sure strong convergence of the trajectory towards the minimum\nnorm solution. We find an explicit tuning of this parameter when our objective\nfunction satisfies a local error-bound inequality. We also provide a\ncomprehensive complexity analysis by establishing several new pointwise and\nergodic convergence rates in expectation for the convex and strongly convex\ncase.\n","authors":["Rodrigo Maulen-Soto","Jalal Fadili","Hedy Attouch"],"pdf_url":"https://arxiv.org/pdf/2403.06708v3.pdf","comment":"34 pages, 2 tables. arXiv admin note: text overlap with\n  arXiv:2207.02750"},{"id":"http://arxiv.org/abs/2307.00975v3","updated":"2024-03-27T14:54:53Z","published":"2023-07-03T12:45:38Z","title":"Fast Convergence of Inertial Multiobjective Gradient-like Systems with\n  Asymptotic Vanishing Damping","summary":"  We present a new gradient-like dynamical system related to unconstrained\nconvex smooth multiobjective optimization which involves inertial effects and\nasymptotic vanishing damping. To the best of our knowledge, this system is the\nfirst inertial gradient-like system for multiobjective optimization problems\nincluding asymptotic vanishing damping, expanding the ideas laid out in [H.\nAttouch and G. Garrigos, Multiobjective optimization: an inertial approach to\nPareto optima, preprint, arXiv:1506.02823, 201]. We prove existence of\nsolutions to this system in finite dimensions and further prove that its\nbounded solutions converge weakly to weakly Pareto optimal points. In addition,\nwe obtain a convergence rate of order $O(t^{-2})$ for the function values\nmeasured with a merit function. This approach presents a good basis for the\ndevelopment of fast gradient methods for multiobjective optimization.\n","authors":["Konstantin Sonntag","Sebastian Peitz"],"pdf_url":"https://arxiv.org/pdf/2307.00975v3.pdf","comment":"25 pages, 3 Figures"},{"id":"http://arxiv.org/abs/2403.18618v1","updated":"2024-03-27T14:32:30Z","published":"2024-03-27T14:32:30Z","title":"Accelerating preconditioned ADMM via degenerate proximal point mappings","summary":"  In this paper, we aim to accelerate a preconditioned alternating direction\nmethod of multipliers (pADMM), whose proximal terms are convex quadratic\nfunctions, for solving linearly constrained convex optimization problems. To\nachieve this, we first reformulate the pADMM into a form of proximal point\nmethod (PPM) with a positive semidefinite preconditioner which can be\ndegenerate due to the lack of strong convexity of the proximal terms in the\npADMM. Then we accelerate the pADMM by accelerating the reformulated degenerate\nPPM (dPPM). Specifically, we first propose an accelerated dPPM by integrating\nthe Halpern iteration and the fast Krasnosel'ski\\u{i}-Mann iteration into it,\nachieving asymptotic $o(1/k)$ and non-asymptotic $O(1/k)$ convergence rates.\nSubsequently, building upon the accelerated dPPM, we develop an accelerated\npADMM algorithm that exhibits both asymptotic $o(1/k)$ and non-asymptotic\n$O(1/k)$ nonergodic convergence rates concerning the Karush-Kuhn-Tucker\nresidual and the primal objective function value gap. Preliminary numerical\nexperiments validate the theoretical findings, demonstrating that the\naccelerated pADMM outperforms the pADMM in solving convex quadratic programming\nproblems.\n","authors":["Defeng Sun","Yancheng Yuan","Guojun Zhang","Xinyuan Zhao"],"pdf_url":"https://arxiv.org/pdf/2403.18618v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.16075v4","updated":"2024-03-27T14:29:24Z","published":"2023-07-29T20:57:34Z","title":"Redesigning Large-Scale Multimodal Transit Networks with Shared\n  Autonomous Mobility Services","summary":"  This study addresses a large-scale multimodal transit network design problem,\nwith Shared Autonomous Mobility Services (SAMS) as both transit feeders and an\norigin-to-destination mode. The framework captures spatial demand and modal\ncharacteristics, considers intermodal transfers and express services,\ndetermines transit infrastructure investment and path flows, and generates\ntransit routes. A system-optimal multimodal transit network is designed with\nminimum total door-to-door generalized costs of users and operators, satisfying\ntransit origin-destination demand within a pre-set infrastructure budget.\nFirstly, the geography, demand, and modes in each zone are characterized with\ncontinuous approximation. The decisions of network link investment and\nmultimodal path flows in zonal connection optimization are formulated as a\nminimum-cost multi-commodity network flow (MCNF) problem and solved efficiently\nwith a mixed-integer linear programming (MILP) solver. Subsequently, the route\ngeneration problem is solved by expanding the MCNF formulation to minimize\nintramodal transfers. The model is illustrated through a set of experiments\nwith the Chicago network comprised of 50 zones and seven modes, under three\nscenarios. The computational results present savings in traveler journey time\nand operator cost demonstrating the potential benefits of collaboration between\nmultimodal transit systems and SAMS.\n","authors":["Max T. M. Ng","Hani S. Mahmassani","Ömer Verbas","Taner Cokyasar","Roman Engelhardt"],"pdf_url":"https://arxiv.org/pdf/2307.16075v4.pdf","comment":"48 pages, 18 figures, accepted for publication in Transportation\n  Research Part C: Emerging Technologies, and presentation in the 25th\n  International Symposium on Transportation and Traffic Theory (ISTTT25)"},{"id":"http://arxiv.org/abs/2403.18571v1","updated":"2024-03-27T13:52:41Z","published":"2024-03-27T13:52:41Z","title":"Bootstrapping Guarantees: Stability and Performance Analysis for Dynamic\n  Encrypted Control","summary":"  Encrypted dynamic controllers that operate for an unlimited time have been a\nchallenging subject of research. The fundamental difficulty is the accumulation\nof errors and scaling factors in the internal state during operation.\nBootstrapping, a technique commonly employed in fully homomorphic\ncryptosystems, can be used to avoid overflows in the controller state but can\npotentially introduce significant numerical errors. In this paper, we analyze\ndynamic encrypted control with explicit consideration of bootstrapping. By\nrecognizing the bootstrapping errors occurring in the controller's state as an\nuncertainty in the robust control framework, we can provide stability and\nperformance guarantees for the whole encrypted control system. Further, the\nconservatism of the stability and performance test is reduced by using a lifted\nversion of the control system.\n","authors":["Sebastian Schlor","Frank Allgöwer"],"pdf_url":"https://arxiv.org/pdf/2403.18571v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18557v1","updated":"2024-03-27T13:39:06Z","published":"2024-03-27T13:39:06Z","title":"Stability Properties of the Impulsive Goodwin's Oscillator in 1-cycle","summary":"  The Impulsive Goodwin's Oscillator (IGO) is a mathematical model of a hybrid\nclosed-loop system. It arises by closing a special kind of continuous linear\npositive time-invariant system with impulsive feedback, which employs both\namplitude and frequency pulse modulation. The structure of IGO precludes the\nexistence of equilibria, and all its solutions are oscillatory. With its origin\nin mathematical biology, the IGO also presents a control paradigm useful in a\nwide range of applications, in particular dosing of chemicals and medicines.\nSince the pulse modulation feedback mechanism introduces significant\nnonlinearity and non-smoothness in the closedloop dynamics, conventional\ncontroller design methods fail to apply. However, the hybrid dynamics of IGO\nreduce to a nonlinear, time-invariant discrete-time system, exhibiting a\none-to-one correspondence between periodic solutions of the original IGO and\nthose of the discrete-time system. The paper proposes a design approach that\nleverages the linearization of the equivalent discrete-time dynamics in the\nvicinity of a fixed point. A simple and efficient local stability condition of\nthe 1-cycle in terms of the characteristics of the amplitude and frequency\nmodulation functions is obtained.\n","authors":["Anton V. Proskurnikov","Alexander Medvedev"],"pdf_url":"https://arxiv.org/pdf/2403.18557v1.pdf","comment":"submitted to IEEE CDC 2024"},{"id":"http://arxiv.org/abs/2208.02767v2","updated":"2024-03-27T13:38:31Z","published":"2022-08-04T16:58:02Z","title":"Parabolic PDE-constrained optimal control under uncertainty with\n  entropic risk measure using quasi-Monte Carlo integration","summary":"  We study the application of a tailored quasi-Monte Carlo (QMC) method to a\nclass of optimal control problems subject to parabolic partial differential\nequation (PDE) constraints under uncertainty: the state in our setting is the\nsolution of a parabolic PDE with a random thermal diffusion coefficient,\nsteered by a control function. To account for the presence of uncertainty in\nthe optimal control problem, the objective function is composed with a risk\nmeasure. We focus on two risk measures, both involving high-dimensional\nintegrals over the stochastic variables: the expected value and the (nonlinear)\nentropic risk measure. The high-dimensional integrals are computed numerically\nusing specially designed QMC methods and, under moderate assumptions on the\ninput random field, the error rate is shown to be essentially linear,\nindependently of the stochastic dimension of the problem -- and thereby\nsuperior to ordinary Monte Carlo methods. Numerical results demonstrate the\neffectiveness of our method.\n","authors":["Philipp A. Guth","Vesa Kaarnioja","Frances Y. Kuo","Claudia Schillings","Ian H. Sloan"],"pdf_url":"https://arxiv.org/pdf/2208.02767v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18556v1","updated":"2024-03-27T13:37:12Z","published":"2024-03-27T13:37:12Z","title":"Numerical optimisation of Dirac eigenvalues","summary":"  Motivated by relativistic materials, we develop a numerical scheme to support\nexisting or state new conjectures in the spectral optimisation of eigenvalues\nof the Dirac operator, subject to infinite-mass boundary conditions. We study\nthe optimality of the regular polygon (respectively, disk) among all polygons\nof a given number of sides (respectively, arbitrary sets), subject to area or\nperimeter constraints. We consider the three lowest positive eigenvalues and\ntheir ratios. Roughly, we find results analogous to known or expected for the\nDirichlet Laplacian, except for the third eigenvalue which does not need to be\nminimised by the regular polygon (respectively, the disk) for all masses. In\naddition to the numerical results, a new, mass-dependent upper bound to the\nlowest eigenvalue in rectangles is proved and its extension to arbitrary\nquadrilaterals is conjectured.\n","authors":["Pedro R. S. Antunes","Francisco Bento","David Krejcirik"],"pdf_url":"https://arxiv.org/pdf/2403.18556v1.pdf","comment":"19 pages, 26 figures"},{"id":"http://arxiv.org/abs/2403.18552v1","updated":"2024-03-27T13:32:12Z","published":"2024-03-27T13:32:12Z","title":"Generalized convergence of the deep BSDE method: a step towards\n  fully-coupled FBSDEs and applications in stochastic control","summary":"  We are concerned with high-dimensional coupled FBSDE systems approximated by\nthe deep BSDE method of Han et al. (2018). It was shown by Han and Long (2020)\nthat the errors induced by the deep BSDE method admit a posteriori estimate\ndepending on the loss function, whenever the backward equation only couples\ninto the forward diffusion through the Y process. We generalize this result to\nfully-coupled drift coefficients, and give sufficient conditions for\nconvergence under standard assumptions. The resulting conditions are directly\nverifiable for any equation. Consequently, unlike in earlier theory, our\nconvergence analysis enables the treatment of FBSDEs stemming from stochastic\noptimal control problems. In particular, we provide a theoretical justification\nfor the non-convergence of the deep BSDE method observed in recent literature,\nand present direct guidelines for when convergence can be guaranteed in\npractice. Our theoretical findings are supported by several numerical\nexperiments in high-dimensional settings.\n","authors":["Balint Negyesi","Zhipeng Huang","Cornelis W. Oosterlee"],"pdf_url":"https://arxiv.org/pdf/2403.18552v1.pdf","comment":"25 pages, 3 figures, 1 table"},{"id":"http://arxiv.org/abs/2403.18528v1","updated":"2024-03-27T13:00:10Z","published":"2024-03-27T13:00:10Z","title":"Limited Attention Allocation in a Stochastic Linear Quadratic System\n  with Multiplicative Noise","summary":"  This study addresses limited attention allocation in a stochastic linear\nquadratic system with multiplicative noise. Our approach enables strategic\nresource allocation to enhance noise estimation and improve control decisions.\nWe provide analytical optimal control and propose a numerical method for\noptimal attention allocation. Additionally, we apply our ffndings to dynamic\nmean-variance portfolio selection, showing effective resource allocation across\ntime periods and factors, providing valuable insights for investors.\n","authors":["Xiangyu Cui","Jianjun Gao","Lingjie Kong"],"pdf_url":"https://arxiv.org/pdf/2403.18528v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18527v1","updated":"2024-03-27T13:00:06Z","published":"2024-03-27T13:00:06Z","title":"Wirtinger gradient descent methods for low-dose Poisson phase retrieval","summary":"  The problem of phase retrieval has many applications in the field of optical\nimaging. Motivated by imaging experiments with biological specimens, we\nprimarily consider the setting of low-dose illumination where Poisson noise\nplays the dominant role. In this paper, we discuss gradient descent algorithms\nbased on different loss functions adapted to data affected by Poisson noise, in\nparticular in the low-dose regime. Starting from the maximum log-likelihood\nfunction for the Poisson distribution, we investigate different regularizations\nand approximations of the problem to design an algorithm that meets the\nrequirements that are faced in applications. In the course of this, we focus on\nlow-count measurements. For all suggested loss functions, we study the\nconvergence of the respective gradient descent algorithms to stationary points\nand find constant step sizes that guarantee descent of the loss in each\niteration. Numerical experiments in the low-dose regime are performed to\ncorroborate the theoretical observations.\n","authors":["Benedikt Diederichs","Frank Filbir","Patricia Römer"],"pdf_url":"https://arxiv.org/pdf/2403.18527v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18517v1","updated":"2024-03-27T12:49:14Z","published":"2024-03-27T12:49:14Z","title":"Efficient Algorithms for Regularized Nonnegative Scale-invariant\n  Low-rank Approximation Models","summary":"  Regularized nonnegative low-rank approximations such as sparse Nonnegative\nMatrix Factorization or sparse Nonnegative Tucker Decomposition are an\nimportant branch of dimensionality reduction models with enhanced\ninterpretability. However, from a practical perspective, the choice of\nregularizers and regularization coefficients, as well as the design of\nefficient algorithms, is challenging because of the multifactor nature of these\nmodels and the lack of theory to back these choices. This paper aims at\nimproving upon these issues. By studying a more general model called the\nHomogeneous Regularized Scale-Invariant, we prove that the scale-invariance\ninherent to low-rank approximation models causes an implicit regularization\nwith both unexpected beneficial and detrimental effects. This observation\nallows to better understand the effect of regularization functions in low-rank\napproximation models, to guide the choice of the regularization\nhyperparameters, and to design balancing strategies to enhance the convergence\nspeed of dedicated optimization algorithms. Some of these results were already\nknown but restricted to specific instances of regularized low-rank\napproximations. We also derive a generic Majorization Minimization algorithm\nthat handles many regularized nonnegative low-rank approximations, with\nconvergence guarantees. We showcase our contributions on sparse Nonnegative\nMatrix Factorization, ridge-regularized Canonical Polyadic decomposition and\nsparse Nonnegative Tucker Decomposition.\n","authors":["Jeremy E. Cohen","Valentin Leplat"],"pdf_url":"https://arxiv.org/pdf/2403.18517v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.02032v2","updated":"2024-03-27T09:48:31Z","published":"2023-09-05T08:21:31Z","title":"A novel strong duality-based reformulation for trilevel infrastructure\n  models in energy systems development","summary":"  We explore the class of trilevel equilibrium problems with a focus on\nenergy-environmental applications and present a novel single-level\nreformulation for such problems, based on strong duality. To the best of our\nknowledge, only one alternative single-level reformulation for trilevel\nproblems exists. This reformulation uses a representation of the bottom-level\nsolution set, whereas we propose a reformulation based on strong duality. Our\nnovel reformulation is compared to this existing formulation, discussing both\nmodel sizes and computational performance. In particular, we apply this\ntrilevel framework to a power market model, exploring the possibilities of an\ninternational policymaker in reducing emissions of the system. Using the\nproposed methods, we are able to obtain globally optimal solutions for a\nfive-node case study representing the Nordic countries and assess the impact of\na carbon tax on the electricity production portfolio.\n","authors":["Olli Herrala","Steven A. Gabriel","Fabricio Oliveira","Tommi Ekholm"],"pdf_url":"https://arxiv.org/pdf/2309.02032v2.pdf","comment":"22 pages, 4 figures"},{"id":"http://arxiv.org/abs/2403.18400v1","updated":"2024-03-27T09:41:51Z","published":"2024-03-27T09:41:51Z","title":"Reweighted Quasi Norm Regularized Low-Rank Factorization for Matrix\n  Robust PCA","summary":"  Robust Principal Component Analysis (RPCA) and its associated non-convex\nrelaxation methods constitute a significant component of matrix completion\nproblems, wherein matrix factorization strategies effectively reduce\ndimensionality and enhance computational speed. However, some non-convex\nfactorization forms lack theoretical guarantees. This paper proposes a novel\nstrategy in non-convex quasi-norm representation, introducing a method to\nobtain weighted matrix quasi-norm factorization forms. Especially, explicit\nbilinear factor matrix factorization formulations for the weighted logarithmic\nnorm and weighted Schatten-$q$ quasi norms with $q=1, 1/2, 2/3$ are provided,\nalong with the establishment of corresponding matrix completion models. An\nAlternating Direction Method of Multipliers (ADMM) framework algorithm is\nemployed for solving, and convergence results of the algorithm are presented.\n","authors":["Zhenzhi Qin","Liping Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.18400v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18398v1","updated":"2024-03-27T09:37:12Z","published":"2024-03-27T09:37:12Z","title":"Adaptive Economic Model Predictive Control for linear systems with\n  performance guarantees","summary":"  We present a model predictive control (MPC) formulation to directly optimize\neconomic criteria for linear constrained systems subject to disturbances and\nuncertain model parameters. The proposed formulation combines a certainty\nequivalent economic MPC with a simple least-squares parameter adaptation. For\nthe resulting adaptive economic MPC scheme, we derive strong asymptotic and\ntransient performance guarantees. We provide a numerical example involving\nbuilding temperature control and demonstrate performance benefits of online\nparameter adaptation.\n","authors":["Maximilian Degner","Raffaele Soloperto","Melanie N. Zeilinger","John Lygeros","Johannes Köhler"],"pdf_url":"https://arxiv.org/pdf/2403.18398v1.pdf","comment":"8 pages, 3 figures, submitted to IEEE CDC 2024"},{"id":"http://arxiv.org/abs/2403.18386v1","updated":"2024-03-27T09:22:02Z","published":"2024-03-27T09:22:02Z","title":"Distributed Feedback Optimization of Linear Multi-agent Systems","summary":"  Feedback optimization is an increasingly popular control paradigm to optimize\ndynamical systems, accounting for control objectives that concern the system's\noperation at steady-state. Existing feedback optimization techniques heavily\nrely on centralized system and controller architectures, and thus suffer from\nscalability and privacy issues when systems become large-scale. In this paper,\nwe propose and study a distributed architecture for feedback optimization, in\nwhich each agent updates its local control state by combining the average of\nits neighbors with a local negative-gradient step. Under convexity and\nsmoothness assumptions, we establish convergence of the control method to a\nfixed point. By reinforcing the assumptions to restricted strong convexity of\nthe cost, we show that our algorithm converges linearly to a neighborhood of\nthe optimal point, where the size of the neighborhood depends on the choice of\nthe stepsize. Simulations corroborate the theoretical results.\n","authors":["Amir Mehrnoosh","Gianluca Bianchin"],"pdf_url":"https://arxiv.org/pdf/2403.18386v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2403.18368v1","updated":"2024-03-27T08:58:41Z","published":"2024-03-27T08:58:41Z","title":"The Mercer-Young Theorem for Matrix-Valued Kernels on Separable Metric\n  Spaces","summary":"  We generalize the characterization theorem going back to Mercer and Young,\nwhich states that a symmetric and continuous kernel is positive definite if and\nonly if it is integrally positive definite. More precisely, we extend the\nresult from real-valued kernels on compact intervals to matrix-valued kernels\non separable metric spaces. We also demonstrate the applications of the\ngeneralized theorem to the field of convex optimization.\n","authors":["Eyal Neuman","Sturmius Tuschmann"],"pdf_url":"https://arxiv.org/pdf/2403.18368v1.pdf","comment":"12 pages, 2 figures"},{"id":"http://arxiv.org/abs/2403.18363v1","updated":"2024-03-27T08:57:07Z","published":"2024-03-27T08:57:07Z","title":"Computing safe bicycle routes -- Berechnung sicherer Fahrradwege","summary":"  The safety of streets is difficult to quantify numerically. However, it is\npossible to sort streets regarding their safety into ordered categories, like\nsafe, neutral and unsafe. In this paper we model the computation of safe\nbicycle routes as an optimization problem with ordinal coefficients. We\ndescribe an appropriate optimality concept for ordinal optimization problems\nand introduce a solution strategy for ordinal routing problems. Furthermore, we\nintroduce a concept to incorporate safety preferences by introducing weights\nsuch that longer path with a higher safety rating are preferred. We apply the\nconcept of ordinal routing to compute safe bicycle routes in Stuttgart,\nGermany, based on dates from OpenStreetMaps. We show that the choice of the\nweights does not only represent the trade-off of safety vs. path length, but\nhas also an impact on the number of alternative solutions and thus on the\ncomputation time.\n  --\n  Die Sicherheit von Wegen ist nur eingeschr\\\"ankt messbar und daher schwierig\nzu quantifizieren. Dahingegen ist es verh\\\"altnism\\\"a{\\ss}ig leicht Wege\nbez\\\"uglich ihrer Sicherheit in geordnete Kategorien, wie beispielsweise\nsicher, neutral und gef\\\"ahrlich einzuordnen. In diesem Beitrag werden\nOptimierungsprobleme mit geordneten Kategorien formuliert und Optimalit\\\"at\nf\\\"ur diese definiert. Daraus wird eine L\\\"osungsstrategie f\\\"ur solche\nProbleme abgeleitet. Dar\\\"uber hinaus wird erkl\\\"art, wie die Abgrenzung\nzwischen den Kategorien erh\\\"oht werden kann, sodass l\\\"angere aber daf\\\"ur\nsicherere Wege mit Hilfe von Gewichten berechnet werden k\\\"onnen. Diese\ntheoretischen Ergebnisse werden in der Praxis angewendet und es werden auf\nGrundlage von Daten von OpenStreetMaps sichere Fahrradwege in Stuttgart\nberechnet. Dabei zeigt sich, dass eine gute Wahl der Gewichte zu weniger\nL\\\"osungen und k\\\"urzeren Rechenzeiten f\\\"uhrt.\n","authors":["Julia Sudhoff Santos","Lars Kroll"],"pdf_url":"https://arxiv.org/pdf/2403.18363v1.pdf","comment":"13 pages in German"},{"id":"http://arxiv.org/abs/2403.14396v2","updated":"2024-03-27T08:45:49Z","published":"2024-03-21T13:40:50Z","title":"Infinite horizon McKean-Vlasov FBSDEs and applications to mean field\n  control problems","summary":"  In this paper, we study a class of infinite horizon fully coupled\nMcKean-Vlasov forward-backward stochastic differential equations (FBSDEs). We\npropose a generalized monotonicity condition involving two flexible functions.\nUnder this condition, we establish the well-posedness results for infinite\nhorizon McKean-Vlasov FBSDEs by the method of continuation, including the\nunique solvability, an estimate of the solution, and the related continuous\ndependence property of the solution on the coefficients. Based on the\nsolvability result, we study an infinite horizon mean field control problem.\nMoreover, by choosing appropriate form of the flexible functions, we can\neliminate the different phenomenon between the linear-quadratic (LQ) problems\non infinite horizon and finite horizon proposed in Wei and Yu (SIAM J. Control\nOptim. 59: 2594-2623, 2021).\n","authors":["Tianjiao Hua","Peng Luo"],"pdf_url":"https://arxiv.org/pdf/2403.14396v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17850v2","updated":"2024-03-27T08:45:49Z","published":"2024-03-26T16:38:13Z","title":"A Mixed-Integer Linear Program to create the shifts in a supermarket","summary":"  The shift design and the personnel scheduling problem is known to be a\ndifficult problem. It is a real-world problem which has lots of applications in\nthe organization of companies. Solutions are usually found by dividing the\nproblem in two steps: first the shifts are created, then the employees are\nassigned to them by respecting a bunch of constraints. The assignment of\ndifferent tasks increases the complexity, since we have to consider the skills\nof the single employee necessary to perform any activity. In this paper we\npresent a mixed-integer linear programming formulation which models together\nthe shift creation and the construction of rosters for employees, with the\nobjective of minimizing the amount of uncovered demand. Finally we provide the\nresults for three real-world instances, confirming that this approach is\npromising.\n","authors":["Nicolo Gusmeroli","Andrea Bettinelli"],"pdf_url":"https://arxiv.org/pdf/2403.17850v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18320v1","updated":"2024-03-27T07:46:57Z","published":"2024-03-27T07:46:57Z","title":"Online Prediction for Streaming Tensor Time Series","summary":"  Real-time prediction plays a vital role in various control systems, such as\ntraffic congestion control and wireless channel resource allocation. In these\nscenarios, the predictor usually needs to track the evolution of the latent\nstatistical patterns in the modern high-dimensional streaming time series\ncontinuously and quickly, which presents new challenges for traditional\nprediction methods. This paper proposes a novel algorithm based on tensor\nfactorization to predict streaming tensor time series online. The proposed\nalgorithm updates the predictor in a low-complexity online manner to adapt to\nthe time-evolving data. Additionally, an automatically adaptive version of the\nalgorithm is presented to mitigate the negative impact of stale data.\nSimulation results demonstrate that our proposed methods achieve prediction\naccuracy similar to that of conventional offline tensor prediction methods,\nwhile being much faster than them during long-term online prediction.\nTherefore, our proposed algorithm provides an effective and efficient solution\nfor the online prediction of streaming tensor time series.\n","authors":["Zhenting Luan","Haoning Wang","Liping Zhang","Shansuo Liang","Wei Han"],"pdf_url":"https://arxiv.org/pdf/2403.18320v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18297v1","updated":"2024-03-27T06:50:51Z","published":"2024-03-27T06:50:51Z","title":"A Mean Field Game of Sequential Testing","summary":"  We introduce a mean field game for a family of filtering problems related to\nthe classic sequential testing of the drift of a Brownian motion. To the best\nof our knowledge this work presents the first treatment of mean field filtering\ngames with stopping and an unobserved common noise in the literature. We show\nthat the game is well-posed, characterize the solution, and establish the\nexistence of an equilibrium under certain assumptions. We also perform\nnumerical studies for several examples of interest.\n","authors":["Steven Campbell","Yuchong Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.18297v1.pdf","comment":"51 pages, 3 figures"},{"id":"http://arxiv.org/abs/2403.18285v1","updated":"2024-03-27T06:25:23Z","published":"2024-03-27T06:25:23Z","title":"Stability and convergence of the penalty formulation for nonlinear\n  magnetostatics","summary":"  The magnetostatic field distribution in a nonlinear medium amounts to the\nunique minimizer of the magnetic coenergy over all fields that can be generated\nby the same current. This is a nonlinear saddlepoint problem whose numerical\nsolution can in principle be achieved by mixed finite element methods and\nappropriate nonlinear solvers. The saddlepoint structure, however, makes the\nsolution cumbersome. A remedy is to split the magnetic field into a known\nsource field and the gradient of a scalar potential which is governed by a\nconvex minimization problem. The penalty approach avoids the use of artificial\npotentials and Lagrange multipliers and leads to an unconstrained convex\nminimization problem involving a large parameter. We provide a rigorous\njustification of the penalty approach by deriving error estimates for the\napproximation due to penalization. We further highlight the close connections\nto the Lagrange-multiplier and scalar potential approach. The theoretical\nresults are illustrated by numerical tests for a typical benchmark problem\n","authors":["Herbert Egger","Felix Engertsberger","Klaus Roppert"],"pdf_url":"https://arxiv.org/pdf/2403.18285v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18284v1","updated":"2024-03-27T06:21:31Z","published":"2024-03-27T06:21:31Z","title":"A new dual spectral projected gradient method for log-determinant\n  semidefinite programming with hidden clustering structures","summary":"  In this paper, we propose a new efficient method for a sparse Gaussian\ngraphical model with hidden clustering structures by extending a dual spectral\nprojected gradient (DSPG) method proposed by Nakagaki et al.~(2020). We\nestablish the global convergence of the proposed method to an optimal solution,\nand we show that the projection onto the feasible region can be solved with a\nlow computational complexity by the use of the pool-adjacent-violators\nalgorithm. Numerical experiments on synthesis data and real data demonstrate\nthe efficiency of the proposed method. The proposed method takes 0.91 seconds\nto achieve a similar solution to the direct application of the DSPG method\nwhich takes 4361 seconds.\n","authors":["Charles Namchaisiri","Tianxiang Liu","Makoto Yamashita"],"pdf_url":"https://arxiv.org/pdf/2403.18284v1.pdf","comment":"21 pages, 3 figures"},{"id":"http://arxiv.org/abs/2312.12558v2","updated":"2024-03-27T05:48:21Z","published":"2023-12-19T19:53:58Z","title":"Sample Efficient Reinforcement Learning with Partial Dynamics Knowledge","summary":"  The problem of sample complexity of online reinforcement learning is often\nstudied in the literature without taking into account any partial knowledge\nabout the system dynamics that could potentially accelerate the learning\nprocess. In this paper, we study the sample complexity of online Q-learning\nmethods when some prior knowledge about the dynamics is available or can be\nlearned efficiently. We focus on systems that evolve according to an additive\ndisturbance model of the form $S_{h+1} = f(S_h, A_h) + W_h$, where $f$\nrepresents the underlying system dynamics, and $W_h$ are unknown disturbances\nindependent of states and actions. In the setting of finite episodic Markov\ndecision processes with $S$ states, $A$ actions, and episode length $H$, we\npresent an optimistic Q-learning algorithm that achieves\n$\\tilde{\\mathcal{O}}(\\text{Poly}(H)\\sqrt{T})$ regret under perfect knowledge of\n$f$, where $T$ is the total number of interactions with the system. This is in\ncontrast to the typical $\\tilde{\\mathcal{O}}(\\text{Poly}(H)\\sqrt{SAT})$ regret\nfor existing Q-learning methods. Further, if only a noisy estimate $\\hat{f}$ of\n$f$ is available, our method can learn an approximately optimal policy in a\nnumber of samples that is independent of the cardinalities of state and action\nspaces. The sub-optimality gap depends on the approximation error $\\hat{f}-f$,\nas well as the Lipschitz constant of the corresponding optimal value function.\nOur approach does not require modeling of the transition probabilities and\nenjoys the same memory complexity as model-free methods.\n","authors":["Meshal Alharbi","Mardavij Roozbehani","Munther Dahleh"],"pdf_url":"https://arxiv.org/pdf/2312.12558v2.pdf","comment":"Published in the 38th Annual AAAI Conference on Artificial\n  Intelligence"},{"id":"http://arxiv.org/abs/2403.18235v1","updated":"2024-03-27T03:50:14Z","published":"2024-03-27T03:50:14Z","title":"An Execution-time-certified QP Algorithm for $\\ell_1$ penalty-based\n  Soft-constrained MPC","summary":"  Providing an execution time certificate and handling possible infeasibility\nin closed-loop are two pressing requirements of Model Predictive Control (MPC).\nTo simultaneously meet these two requirements, this paper uses $\\ell_1$\npenalty-based soft-constrained MPC formulation and innovatively transforms the\nresulting non-smooth QP into a box-constrained QP, which is solved by our\npreviously proposed direct and execution-time certified algorithm with only\ndimension-dependent (data-independent) and exact number of iterations [1]. This\napproach not only overcomes the limitation of our previously proposed algorithm\n[1], only applicable to input-constrained MPC, but also enjoys exact recovery\nfeature (exactly recover the same solution when the original problem is\nfeasible) of $\\ell_1$ penalty-based soft-constrained MPC formulation without\nsuffering numerical difficulty of the resulting non-smoothness. Other various\nreal-time QP applications, not limited to MPC, will also benefit from our QP\nalgorithm with execution-time certificate and global feasibility.\n","authors":["Liang Wu","Richard D. Braatz"],"pdf_url":"https://arxiv.org/pdf/2403.18235v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2403.18213v1","updated":"2024-03-27T02:51:35Z","published":"2024-03-27T02:51:35Z","title":"Long-Term Mine Planning with Large Neighbourhood Search","summary":"  We present a Large Neighbourhood Search based approach for solving complex\nlong-term open-pit mine planning problems. An initial feasible solution,\ngenerated by a sliding windows heuristic, is improved through repeated solves\nof a restricted mixed integer program. Each iteration leaves only a subset of\nthe variables in our planning model free to take on new values. We form these\nsubsets through the use of a novel path-based neighbourhood structure, and\nneighbourhood formation strategies that exploit the structure of the planning\nmodel. We show that our method is able to find near-optimal solutions to\nproblems that cannot be solved by an off-the-shelf solver in a reasonable time,\nor with reasonable computational resources.\n","authors":["Michelle Blom","Adrian R. Pearce","Pascal Cote"],"pdf_url":"https://arxiv.org/pdf/2403.18213v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18184v1","updated":"2024-03-27T01:24:26Z","published":"2024-03-27T01:24:26Z","title":"Topology Optimization for the Full-Cell Design of Porous Electrodes in\n  Electrochemical Energy Storage Devices","summary":"  In this paper, we introduce a density-based topology optimization framework\nto design porous electrodes for maximum energy storage. We simulate the full\ncell with a model that incorporates electronic potential, ionic potential, and\nelectrolyte concentration. The system consists of three materials, namely pure\nliquid electrolyte and the porous solids of the anode and cathode, for which we\ndetermine the optimal placement. We use separate electronic potentials to model\neach electrode, which allow interdigitated designs. As the result, a\npenalization is required to ensure that the anode and cathode do not touch,\ni.e. causing a short circuit. We compare multiple 2D designs generated for\ndifferent fixed conditions, e.g. material properties. A 3D design with complex\nchannel and interlocking structure is also created. All optimized designs are\nfar superior to the traditional monolithic electrode design with respect to\nenergy storage metrics. We observe up to 750% increase in energy storage for\ncases with slow effective ionic diffusion within the porous electrode.\n","authors":["Hanyu Li","Giovanna Bucci","Nicholas W. Brady","Nicholas R. Cross","Victoria M. Ehlinger","Tiras Y. Lin","Miguel Salazar de Troya","Daniel Tortorelli","Marcus A. Worsley","Thomas Roy"],"pdf_url":"https://arxiv.org/pdf/2403.18184v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18176v1","updated":"2024-03-27T01:05:45Z","published":"2024-03-27T01:05:45Z","title":"Mistake, Manipulation and Margin Guarantees in Online Strategic\n  Classification","summary":"  We consider an online strategic classification problem where each arriving\nagent can manipulate their true feature vector to obtain a positive predicted\nlabel, while incurring a cost that depends on the amount of manipulation. The\nlearner seeks to predict the agent's true label given access to only the\nmanipulated features. After the learner releases their prediction, the agent's\ntrue label is revealed. Previous algorithms such as the strategic perceptron\nguarantee finitely many mistakes under a margin assumption on agents' true\nfeature vectors. However, these are not guaranteed to encourage agents to be\ntruthful. Promoting truthfulness is intimately linked to obtaining adequate\nmargin on the predictions, thus we provide two new algorithms aimed at\nrecovering the maximum margin classifier in the presence of strategic agent\nbehavior. We prove convergence, finite mistake and finite manipulation\nguarantees for a variety of agent cost structures. We also provide generalized\nversions of the strategic perceptron with mistake guarantees for different\ncosts. Our numerical study on real and synthetic data demonstrates that the new\nalgorithms outperform previous ones in terms of margin, number of manipulation\nand number of mistakes.\n","authors":["Lingqing Shen","Nam Ho-Nguyen","Khanh-Hung Giang-Tran","Fatma Kılınç-Karzan"],"pdf_url":"https://arxiv.org/pdf/2403.18176v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01421v3","updated":"2024-03-27T00:38:33Z","published":"2023-02-02T21:21:14Z","title":"Follower Agnostic Methods for Stackelberg Games","summary":"  In this paper, we present an efficient algorithm to solve online Stackelberg\ngames, featuring multiple followers, in a follower-agnostic manner. Unlike\nprevious works, our approach works even when leader has no knowledge about the\nfollowers' utility functions or strategy space. Our algorithm introduces a\nunique gradient estimator, leveraging specially designed strategies to probe\nfollowers. In a departure from traditional assumptions of optimal play, we\nmodel followers' responses using a convergent adaptation rule, allowing for\nrealistic and dynamic interactions. The leader constructs the gradient\nestimator solely based on observations of followers' actions. We provide both\nnon-asymptotic convergence rates to stationary points of the leader's objective\nand demonstrate asymptotic convergence to a \\emph{local Stackelberg\nequilibrium}. To validate the effectiveness of our algorithm, we use this\nalgorithm to solve the problem of incentive design on a large-scale\ntransportation network, showcasing its robustness even when the leader lacks\naccess to followers' demand.\n","authors":["Chinmay Maheshwari","James Cheng","S. Shankar Sasty","Lillian Ratliff","Eric Mazumdar"],"pdf_url":"https://arxiv.org/pdf/2302.01421v3.pdf","comment":"31 pages"},{"id":"http://arxiv.org/abs/2210.11634v4","updated":"2024-03-27T00:27:26Z","published":"2022-10-18T16:41:04Z","title":"A Polynomial-time Algorithm for the Large Scale of Airplane Refueling\n  Problem","summary":"  Airplane refueling problem is a nonlinear unconstrained optimization problem\nwith $n!$ feasible solutions. Given a fleet of $n$ airplanes with mid-air\nrefueling technique, the question is to find the best refueling policy to make\nthe last remaining airplane travels the farthest. In order to deal with the\nlarge scale of airplanes refueling instances, we proposed the definition of\nsequential feasible solution by employing the refueling properties of data\nstructure. We proved that if an airplanes refueling instance has feasible\nsolutions, it must have the sequential feasible solutions; and the optimal\nfeasible solution must be the optimal sequential feasible solution. Then we\nproposed the sequential search algorithm which consists of two steps. The first\nstep of the sequential search algorithm aims to seek out all of the sequential\nfeasible solutions. When the input size of $n$ is greater than an index number,\nwe proved that the number of the sequential feasible solutions will change to\ngrow at a polynomial rate. The second step of the sequential search algorithm\naims to search for the maximal sequential feasible solution by bubble sorting\nall of the sequential feasible solutions. Moreover, we built an efficient\ncomputability scheme, according to which we could forecast within a polynomial\ntime the computational complexity of the sequential search algorithm that runs\non any given airplanes refueling instance. Thus we could provide a\ncomputational strategy for decision makers or algorithm users by considering\nwith their available computing resources.\n","authors":["Jinchuan Cui","Xiaoya Li"],"pdf_url":"https://arxiv.org/pdf/2210.11634v4.pdf","comment":"18 pages, 2 figures"},{"id":"http://arxiv.org/abs/2403.18166v1","updated":"2024-03-27T00:21:49Z","published":"2024-03-27T00:21:49Z","title":"Incentive-Compatible Vertiport Reservation in Advanced Air Mobility: An\n  Auction-Based Approach","summary":"  The rise of advanced air mobility (AAM) is expected to become a\nmultibillion-dollar industry in the near future. Market-based mechanisms are\ntouted to be an integral part of AAM operations, which comprise heterogeneous\noperators with private valuations. In this work, we study the problem of\ndesigning a mechanism to coordinate the movement of electric vertical take-off\nand landing (eVTOL) aircraft, operated by multiple operators each having\nheterogeneous valuations associated with their fleet, between vertiports, while\nenforcing the arrival, departure, and parking constraints at vertiports.\nParticularly, we propose an incentive-compatible and individually rational\nvertiport reservation mechanism that maximizes a social welfare metric, which\nencapsulates the objective of maximizing the overall valuations of all\noperators while minimizing the congestion at vertiports. Additionally, we\nimprove the computational tractability of designing the reservation mechanism\nby proposing a mixed binary linear programming approach that is based on\nconstructing network flow graph corresponding to the underlying problem.\n","authors":["Pan-Yang Su","Chinmay Maheshwari","Victoria Tuck","Shankar Sastry"],"pdf_url":"https://arxiv.org/pdf/2403.18166v1.pdf","comment":"26 pages, 2 figures, 1 table"},{"id":"http://arxiv.org/abs/2403.18164v1","updated":"2024-03-27T00:16:17Z","published":"2024-03-27T00:16:17Z","title":"Incentive Designs for Learning Agents to Stabilize Coupled Exogenous\n  Systems","summary":"  We consider a large population of learning agents noncooperatively selecting\nstrategies from a common set, influencing the dynamics of an exogenous system\n(ES) we seek to stabilize at a desired equilibrium. Our approach is to design a\ndynamic payoff mechanism capable of shaping the population's strategy profile,\nthus affecting the ES's state, by offering incentives for specific strategies\nwithin budget limits. Employing system-theoretic passivity concepts, we\nestablish conditions under which a payoff mechanism can be systematically\nconstructed to ensure the global asymptotic stabilization of the ES's\nequilibrium. In comparison to previous approaches originally studied in the\ncontext of the so-called epidemic population games, the method proposed here\nallows for more realistic epidemic models and other types of ES, such as\npredator-prey dynamics. Stabilization is established with the support of a\nLyapunov function, which provides useful bounds on the transients.\n","authors":["Jair Certório","Nuno C. Martins","Richard J. La","Murat Arcak"],"pdf_url":"https://arxiv.org/pdf/2403.18164v1.pdf","comment":"8 pages, 3 figures"}],"Systems and Control":[{"id":"http://arxiv.org/abs/2302.13483v4","updated":"2024-03-27T17:38:27Z","published":"2023-02-27T02:42:27Z","title":"CrystalBox: Future-Based Explanations for Input-Driven Deep RL Systems","summary":"  We present CrystalBox, a novel, model-agnostic, posthoc explainability\nframework for Deep Reinforcement Learning (DRL) controllers in the large family\nof input-driven environments which includes computer systems. We combine the\nnatural decomposability of reward functions in input-driven environments with\nthe explanatory power of decomposed returns. We propose an efficient algorithm\nto generate future-based explanations across both discrete and continuous\ncontrol environments. Using applications such as adaptive bitrate streaming and\ncongestion control, we demonstrate CrystalBox's capability to generate\nhigh-fidelity explanations. We further illustrate its higher utility across\nthree practical use cases: contrastive explanations, network observability, and\nguided reward design, as opposed to prior explainability techniques that\nidentify salient features.\n","authors":["Sagar Patel","Sangeetha Abdu Jyothi","Nina Narodytska"],"pdf_url":"https://arxiv.org/pdf/2302.13483v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13967v3","updated":"2024-03-27T17:28:46Z","published":"2023-11-23T12:31:28Z","title":"Unconstrained learning of networked nonlinear systems via free\n  parametrization of stable interconnected operators","summary":"  This paper characterizes a new parametrization of nonlinear networked\nincrementally $L_2$-bounded operators in discrete time. The distinctive novelty\nis that our parametrization is \\emph{free} -- that is, a sparse large-scale\noperator with bounded incremental $L_2$ gain is obtained for any choice of the\nreal values of our parameters. This property allows one to freely search over\noptimal parameters via unconstrained gradient descent, enabling direct\napplications in large-scale optimal control and system identification. Further,\nwe can embed prior knowledge about the interconnection topology and stability\nproperties of the system directly into the large-scale distributed operator we\ndesign. Our approach is extremely general in that it can seamlessly encapsulate\nand interconnect state-of-the-art Neural Network (NN) parametrizations of\nstable dynamical systems. To demonstrate the effectiveness of this approach, we\nprovide a simulation example showcasing the identification of a networked\nnonlinear system. The results underscore the superiority of our free\nparametrizations over standard NN-based identification methods where a prior\nover the system topology and local stability properties are not enforced.\n","authors":["Leonardo Massai","Danilo Saccani","Luca Furieri","Giancarlo Ferrari-Trecate"],"pdf_url":"https://arxiv.org/pdf/2311.13967v3.pdf","comment":"Full version of the paper to appear at ECC 2024"},{"id":"http://arxiv.org/abs/2201.06180v2","updated":"2024-03-27T16:45:26Z","published":"2022-01-17T02:30:25Z","title":"Nonlinear Control Allocation: A Learning Based Approach","summary":"  Modern aircraft are designed with redundant control effectors to cater for\nfault tolerance and maneuverability requirements. This leads to aircraft being\nover-actuated and requires control allocation schemes to distribute the control\ncommands among control effectors. Traditionally, optimization-based control\nallocation schemes are used; however, for nonlinear allocation problems, these\nmethods require large computational resources. In this work, an artificial\nneural network (ANN) based nonlinear control allocation scheme is proposed. The\nproposed scheme is composed of learning the inverse of the control\neffectiveness map through ANN, and then implementing it as an allocator instead\nof solving an online optimization problem. Stability conditions are presented\nfor closed-loop systems incorporating the allocator, and computational\nchallenges are explored with piece-wise linear effectiveness functions and\nANN-based allocators. To demonstrate the efficacy of the proposed scheme, it is\ncompared with a standard quadratic programming-based method for control\nallocation.\n","authors":["Hafiz Zeeshan Iqbal Khan","Surrayya Mobeen","Jahanzeb Rajput","Jamshed Riaz"],"pdf_url":"https://arxiv.org/pdf/2201.06180v2.pdf","comment":"submitted to IEEE Conference on Decision and Control (CDC), 2024"},{"id":"http://arxiv.org/abs/2403.18739v1","updated":"2024-03-27T16:32:32Z","published":"2024-03-27T16:32:32Z","title":"Usage-Specific Survival Modeling Based on Operational Data and Neural\n  Networks","summary":"  Accurate predictions of when a component will fail are crucial when planning\nmaintenance, and by modeling the distribution of these failure times, survival\nmodels have shown to be particularly useful in this context. The presented\nmethodology is based on conventional neural network-based survival models that\nare trained using data that is continuously gathered and stored at specific\ntimes, called snapshots. An important property of this type of training data is\nthat it can contain more than one snapshot from a specific individual which\nresults in that standard maximum likelihood training can not be directly\napplied since the data is not independent. However, the papers show that if the\ndata is in a specific format where all snapshot times are the same for all\nindividuals, called homogeneously sampled, maximum likelihood training can be\napplied and produce desirable results. In many cases, the data is not\nhomogeneously sampled and in this case, it is proposed to resample the data to\nmake it homogeneously sampled. How densely the dataset is sampled turns out to\nbe an important parameter; it should be chosen large enough to produce good\nresults, but this also increases the size of the dataset which makes training\nslow. To reduce the number of samples needed during training, the paper also\nproposes a technique to, instead of resampling the dataset once before the\ntraining starts, randomly resample the dataset at the start of each epoch\nduring the training. The proposed methodology is evaluated on both a simulated\ndataset and an experimental dataset of starter battery failures. The results\nshow that if the data is homogeneously sampled the methodology works as\nintended and produces accurate survival models. The results also show that\nrandomly resampling the dataset on each epoch is an effective way to reduce the\nsize of the training data.\n","authors":["Olov Holmer","Mattias Krysander","Erik Frisk"],"pdf_url":"https://arxiv.org/pdf/2403.18739v1.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2401.07494v3","updated":"2024-03-27T16:06:34Z","published":"2024-01-15T06:26:53Z","title":"Input Convex Lipschitz RNN: A Fast and Robust Approach for Engineering\n  Tasks","summary":"  Computational efficiency and non-adversarial robustness are critical factors\nin real-world engineering applications. Yet, conventional neural networks often\nfall short in addressing both simultaneously, or even separately. Drawing\ninsights from natural physical systems and existing literature, it is known\nthat an input convex architecture enhances computational efficiency, while a\nLipschitz-constrained architecture bolsters non-adversarial robustness. By\nleveraging the strengths of convexity and Lipschitz continuity, we develop a\nnovel network architecture, termed Input Convex Lipschitz Recurrent Neural\nNetworks. This model is explicitly designed for fast and robust\noptimization-based tasks and outperforms existing recurrent units across a\nspectrum of engineering tasks in terms of computational efficiency and\nnon-adversarial robustness, including real-world solar irradiance prediction\nfor Solar PV system planning at LHT Holdings in Singapore and real-time Model\nPredictive Control optimization for a nonlinear chemical reactor.\n","authors":["Zihao Wang","P S Pravin","Zhe Wu"],"pdf_url":"https://arxiv.org/pdf/2401.07494v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18707v1","updated":"2024-03-27T15:56:35Z","published":"2024-03-27T15:56:35Z","title":"Connections between Reachability and Time Optimality","summary":"  This paper presents the concept of an equivalence relation between the set of\noptimal control problems. By leveraging this concept, we show that the boundary\nof the reachability set can be constructed by the solutions of time optimal\nproblems. Alongside, a more generalized equivalence theorem is presented\ntogether. The findings facilitate the use of solution structures from a certain\nclass of optimal control problems to address problems in corresponding\nequivalent classes. As a byproduct, we state and prove the construction methods\nof the reachability sets of three-dimensional curves with prescribed curvature\nbound. The findings are twofold: Firstly, we prove that any boundary point of\nthe reachability set, with the terminal direction taken into account, can be\naccessed via curves of H, CSC, CCC, or their respective subsegments, where H\ndenotes a helicoidal arc, C a circular arc with maximum curvature, and S a\nstraight segment. Secondly, we show that any boundary point of the reachability\nset, without considering the terminal direction, can be accessed by curves of\nCC, CS, or their respective subsegments. These findings extend the developments\npresented in literature regarding planar curves, or Dubins car dynamics, into\nspatial curves in $\\mathbb{R}^3$. For higher dimensions, we confirm that the\nproblem of identifying the reachability set of curvature bounded paths subsumes\nthe well-known Markov-Dubins problem. These advancements in understanding the\nreachability of curvature bounded paths in $\\mathbb{R}^3$ hold significant\npractical implications, particularly in the contexts of mission planning\nproblems and time optimal guidance.\n","authors":["Juho Bae","Ji Hoon Bai","Byung-Yoon Lee","Jun-Yong Lee","Chang-Hun Lee"],"pdf_url":"https://arxiv.org/pdf/2403.18707v1.pdf","comment":"Submitted to Automatica"},{"id":"http://arxiv.org/abs/2403.18703v1","updated":"2024-03-27T15:52:54Z","published":"2024-03-27T15:52:54Z","title":"Fpga-Based Neural Thrust Controller for UAVs","summary":"  The advent of unmanned aerial vehicles (UAVs) has improved a variety of\nfields by providing a versatile, cost-effective and accessible platform for\nimplementing state-of-the-art algorithms. To accomplish a broader range of\ntasks, there is a growing need for enhanced on-board computing to cope with\nincreasing complexity and dynamic environmental conditions. Recent advances\nhave seen the application of Deep Neural Networks (DNNs), particularly in\ncombination with Reinforcement Learning (RL), to improve the adaptability and\nperformance of UAVs, especially in unknown environments. However, the\ncomputational requirements of DNNs pose a challenge to the limited computing\nresources available on many UAVs. This work explores the use of Field\nProgrammable Gate Arrays (FPGAs) as a viable solution to this challenge,\noffering flexibility, high performance, energy and time efficiency. We propose\na novel hardware board equipped with an Artix-7 FPGA for a popular open-source\nmicro-UAV platform. We successfully validate its functionality by implementing\nan RL-based low-level controller using real-world experiments.\n","authors":["Sharif Azem","David Scheunert","Mengguang Li","Jonas Gehrunger","Kai Cui","Christian Hochberger","Heinz Koepp"],"pdf_url":"https://arxiv.org/pdf/2403.18703v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.11800v3","updated":"2024-03-27T15:48:29Z","published":"2024-02-19T03:08:02Z","title":"Stochastic Approximation with Delayed Updates: Finite-Time Rates under\n  Markovian Sampling","summary":"  Motivated by applications in large-scale and multi-agent reinforcement\nlearning, we study the non-asymptotic performance of stochastic approximation\n(SA) schemes with delayed updates under Markovian sampling. While the effect of\ndelays has been extensively studied for optimization, the manner in which they\ninteract with the underlying Markov process to shape the finite-time\nperformance of SA remains poorly understood. In this context, our first main\ncontribution is to show that under time-varying bounded delays, the delayed SA\nupdate rule guarantees exponentially fast convergence of the \\emph{last\niterate} to a ball around the SA operator's fixed point. Notably, our bound is\n\\emph{tight} in its dependence on both the maximum delay $\\tau_{max}$, and the\nmixing time $\\tau_{mix}$. To achieve this tight bound, we develop a novel\ninductive proof technique that, unlike various existing delayed-optimization\nanalyses, relies on establishing uniform boundedness of the iterates. As such,\nour proof may be of independent interest. Next, to mitigate the impact of the\nmaximum delay on the convergence rate, we provide the first finite-time\nanalysis of a delay-adaptive SA scheme under Markovian sampling. In particular,\nwe show that the exponent of convergence of this scheme gets scaled down by\n$\\tau_{avg}$, as opposed to $\\tau_{max}$ for the vanilla delayed SA rule; here,\n$\\tau_{avg}$ denotes the average delay across all iterations. Moreover, the\nadaptive scheme requires no prior knowledge of the delay sequence for step-size\ntuning. Our theoretical findings shed light on the finite-time effects of\ndelays for a broad class of algorithms, including TD learning, Q-learning, and\nstochastic gradient descent under Markovian sampling.\n","authors":["Arman Adibi","Nicolo Dal Fabbro","Luca Schenato","Sanjeev Kulkarni","H. Vincent Poor","George J. Pappas","Hamed Hassani","Aritra Mitra"],"pdf_url":"https://arxiv.org/pdf/2402.11800v3.pdf","comment":"Accepted to the 27th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2024!"},{"id":"http://arxiv.org/abs/2403.18695v1","updated":"2024-03-27T15:44:25Z","published":"2024-03-27T15:44:25Z","title":"An Efficient Risk-aware Branch MPC for Automated Driving that is Robust\n  to Uncertain Vehicle Behaviors","summary":"  One of the critical challenges in automated driving is ensuring safety of\nautomated vehicles despite the unknown behavior of the other vehicles. Although\nmotion prediction modules are able to generate a probability distribution\nassociated with various behavior modes, their probabilistic estimates are often\ninaccurate, thus leading to a possibly unsafe trajectory. To overcome this\nchallenge, we propose a risk-aware motion planning framework that appropriately\naccounts for the ambiguity in the estimated probability distribution. We\nformulate the risk-aware motion planning problem as a min-max optimization\nproblem and develop an efficient iterative method by incorporating a\nregularization term in the probability update step. Via extensive numerical\nstudies, we validate the convergence of our method and demonstrate its\nadvantages compared to the state-of-the-art approaches.\n","authors":["Luyao Zhang","George Pantazis","Shaohang Han","Sergio Grammatico"],"pdf_url":"https://arxiv.org/pdf/2403.18695v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18664v1","updated":"2024-03-27T15:08:00Z","published":"2024-03-27T15:08:00Z","title":"Neural Network-Based Piecewise Survival Models","summary":"  In this paper, a family of neural network-based survival models is presented.\nThe models are specified based on piecewise definitions of the hazard function\nand the density function on a partitioning of the time; both constant and\nlinear piecewise definitions are presented, resulting in a family of four\nmodels. The models can be seen as an extension of the commonly used\ndiscrete-time and piecewise exponential models and thereby add flexibility to\nthis set of standard models. Using a simulated dataset the models are shown to\nperform well compared to the highly expressive, state-of-the-art energy-based\nmodel, while only requiring a fraction of the computation time.\n","authors":["Olov Holmer","Erik Frisk","Mattias Krysander"],"pdf_url":"https://arxiv.org/pdf/2403.18664v1.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2403.18650v1","updated":"2024-03-27T14:58:11Z","published":"2024-03-27T14:58:11Z","title":"MPC-CBF with Adaptive Safety Margins for Safety-critical Teleoperation\n  over Imperfect Network Connections","summary":"  The paper focuses on the design of a control strategy for safety-critical\nremote teleoperation. The main goal is to make the controlled system track the\ndesired velocity specified by an operator while avoiding obstacles despite\ncommunication delays. Control Barrier Functions (CBFs) are used to define the\nsafety constraints that the system has to respect to avoid obstacles, while\nModel Predictive Control (MPC) provides the framework for adjusting the desired\ninput, taking the constraints into account. The resulting input is sent to the\nremote system, where appropriate low-level velocity controllers translate it\ninto system-specific commands. The main novelty of the paper is a method to\nmake the CBFs robust against the uncertainties caused by the network delays\naffecting the system's state and do so in a less conservative manner. The\nresults show how the proposed method successfully solves the safety-critical\nteleoperation problem, making the controlled systems avoid obstacles with\ndifferent types of network delay. The controller has also been tested in\nsimulation and on a real manipulator, demonstrating its general applicability\nwhen reliable low-level velocity controllers are available.\n","authors":["Riccardo Periotto","Mina Ferizbegovic","Fernando S. Barbosa","Roberto C. Sundin"],"pdf_url":"https://arxiv.org/pdf/2403.18650v1.pdf","comment":"Accepted for publication in the 2024 European Control Conference\n  (ECC)"},{"id":"http://arxiv.org/abs/2403.18649v1","updated":"2024-03-27T14:56:44Z","published":"2024-03-27T14:56:44Z","title":"Addressing Data Annotation Challenges in Multiple Sensors: A Solution\n  for Scania Collected Datasets","summary":"  Data annotation in autonomous vehicles is a critical step in the development\nof Deep Neural Network (DNN) based models or the performance evaluation of the\nperception system. This often takes the form of adding 3D bounding boxes on\ntime-sequential and registered series of point-sets captured from active\nsensors like Light Detection and Ranging (LiDAR) and Radio Detection and\nRanging (RADAR). When annotating multiple active sensors, there is a need to\nmotion compensate and translate the points to a consistent coordinate frame and\ntimestamp respectively. However, highly dynamic objects pose a unique\nchallenge, as they can appear at different timestamps in each sensor's data.\nWithout knowing the speed of the objects, their position appears to be\ndifferent in different sensor outputs. Thus, even after motion compensation,\nhighly dynamic objects are not matched from multiple sensors in the same frame,\nand human annotators struggle to add unique bounding boxes that capture all\nobjects. This article focuses on addressing this challenge, primarily within\nthe context of Scania collected datasets. The proposed solution takes a track\nof an annotated object as input and uses the Moving Horizon Estimation (MHE) to\nrobustly estimate its speed. The estimated speed profile is utilized to correct\nthe position of the annotated box and add boxes to object clusters missed by\nthe original annotation.\n","authors":["Ajinkya Khoche","Aron Asefaw","Alejandro Gonzalez","Bogdan Timus","Sina Sharif Mansouri","Patric Jensfelt"],"pdf_url":"https://arxiv.org/pdf/2403.18649v1.pdf","comment":"Accepted to European Control Conference 2024"},{"id":"http://arxiv.org/abs/2403.18632v1","updated":"2024-03-27T14:38:22Z","published":"2024-03-27T14:38:22Z","title":"Optimal Control Synthesis of Markov Decision Processes for Efficiency\n  with Surveillance Tasks","summary":"  We investigate the problem of optimal control synthesis for Markov Decision\nProcesses (MDPs), addressing both qualitative and quantitative objectives.\nSpecifically, we require the system to fulfill a qualitative surveillance task\nin the sense that a specific region of interest can be visited infinitely often\nwith probability one. Furthermore, to quantify the performance of the system,\nwe consider the concept of efficiency, which is defined as the ratio between\nrewards and costs. This measure is more general than the standard long-run\naverage reward metric as it aims to maximize the reward obtained per unit cost.\nOur objective is to synthesize a control policy that ensures the surveillance\ntask while maximizes the efficiency. We provide an effective approach to\nsynthesize a stationary control policy achieving $\\epsilon$-optimality by\nintegrating state classifications of MDPs and perturbation analysis in a novel\nmanner. Our results generalize existing works on efficiency-optimal control\nsynthesis for MDP by incorporating qualitative surveillance tasks. A robot\nmotion planning case study is provided to illustrate the proposed algorithm.\n","authors":["Yu Chen","Xuanyuan Yin","Shaoyuan Li","Xiang Yin"],"pdf_url":"https://arxiv.org/pdf/2403.18632v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.16075v4","updated":"2024-03-27T14:29:24Z","published":"2023-07-29T20:57:34Z","title":"Redesigning Large-Scale Multimodal Transit Networks with Shared\n  Autonomous Mobility Services","summary":"  This study addresses a large-scale multimodal transit network design problem,\nwith Shared Autonomous Mobility Services (SAMS) as both transit feeders and an\norigin-to-destination mode. The framework captures spatial demand and modal\ncharacteristics, considers intermodal transfers and express services,\ndetermines transit infrastructure investment and path flows, and generates\ntransit routes. A system-optimal multimodal transit network is designed with\nminimum total door-to-door generalized costs of users and operators, satisfying\ntransit origin-destination demand within a pre-set infrastructure budget.\nFirstly, the geography, demand, and modes in each zone are characterized with\ncontinuous approximation. The decisions of network link investment and\nmultimodal path flows in zonal connection optimization are formulated as a\nminimum-cost multi-commodity network flow (MCNF) problem and solved efficiently\nwith a mixed-integer linear programming (MILP) solver. Subsequently, the route\ngeneration problem is solved by expanding the MCNF formulation to minimize\nintramodal transfers. The model is illustrated through a set of experiments\nwith the Chicago network comprised of 50 zones and seven modes, under three\nscenarios. The computational results present savings in traveler journey time\nand operator cost demonstrating the potential benefits of collaboration between\nmultimodal transit systems and SAMS.\n","authors":["Max T. M. Ng","Hani S. Mahmassani","Ömer Verbas","Taner Cokyasar","Roman Engelhardt"],"pdf_url":"https://arxiv.org/pdf/2307.16075v4.pdf","comment":"48 pages, 18 figures, accepted for publication in Transportation\n  Research Part C: Emerging Technologies, and presentation in the 25th\n  International Symposium on Transportation and Traffic Theory (ISTTT25)"},{"id":"http://arxiv.org/abs/2403.18588v1","updated":"2024-03-27T14:11:32Z","published":"2024-03-27T14:11:32Z","title":"From Virtual Reality to the Emerging Discipline of Perception\n  Engineering","summary":"  This paper makes the case that a powerful new discipline, which we term\nperception engineering, is steadily emerging. It follows from a progression of\nideas that involve creating illusions, from historical paintings and film, to\nvideo games and virtual reality in modern times. Rather than creating physical\nartifacts such as bridges, airplanes, or computers, perception engineers create\nillusory perceptual experiences. The scope is defined over any agent that\ninteracts with the physical world, including both biological organisms (humans,\nanimals) and engineered systems (robots, autonomous systems). The key idea is\nthat an agent, called a producer, alters the environment with the intent to\nalter the perceptual experience of another agent, called a receiver. Most\nimportantly, the paper introduces a precise mathematical formulation of this\nprocess, based on the von Neumann-Morgenstern notion of information, to help\nscope and define the discipline. It is then applied to the cases of engineered\nand biological agents with discussion of its implications on existing fields\nsuch as virtual reality, robotics, and even social media. Finally, open\nchallenges and opportunities for involvement are identified.\n","authors":["Steven M. LaValle","Evan G. Center","Timo Ojala","Matti Pouke","Nicoletta Prencipe","Basak Sakcak","Markku Suomalainen","Kalle G. Timperi","Vadim K. Weinstein"],"pdf_url":"https://arxiv.org/pdf/2403.18588v1.pdf","comment":"30 pages, 5 figures"},{"id":"http://arxiv.org/abs/2403.18571v1","updated":"2024-03-27T13:52:41Z","published":"2024-03-27T13:52:41Z","title":"Bootstrapping Guarantees: Stability and Performance Analysis for Dynamic\n  Encrypted Control","summary":"  Encrypted dynamic controllers that operate for an unlimited time have been a\nchallenging subject of research. The fundamental difficulty is the accumulation\nof errors and scaling factors in the internal state during operation.\nBootstrapping, a technique commonly employed in fully homomorphic\ncryptosystems, can be used to avoid overflows in the controller state but can\npotentially introduce significant numerical errors. In this paper, we analyze\ndynamic encrypted control with explicit consideration of bootstrapping. By\nrecognizing the bootstrapping errors occurring in the controller's state as an\nuncertainty in the robust control framework, we can provide stability and\nperformance guarantees for the whole encrypted control system. Further, the\nconservatism of the stability and performance test is reduced by using a lifted\nversion of the control system.\n","authors":["Sebastian Schlor","Frank Allgöwer"],"pdf_url":"https://arxiv.org/pdf/2403.18571v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18564v1","updated":"2024-03-27T13:45:45Z","published":"2024-03-27T13:45:45Z","title":"Formal Verification with Constrained Polynomial Logical Zonotope","summary":"  In this paper, we propose using constrained polynomial logical zonotopes for\nformal verification of logical systems. We perform reachability analysis to\ncompute the set of states that could be reached. To do this, we utilize a\nrecently introduced set representation called polynomial logical zonotopes for\nperforming computationally efficient and exact reachability analysis on logical\nsystems. Notably, polynomial logical zonotopes address the \"curse of\ndimensionality\" when analyzing the reachability of logical systems since the\nset representation can represent 2^n binary vectors using n generators. After\nfinishing the reachability analysis, the formal verification involves verifying\nwhether the intersection of the calculated reachable set and the unsafe set is\nempty or not. However, polynomial logical zonotopes are not closed under\nintersections. To address this, we formulate constrained polynomial logical\nzonotopes, which maintain the computational efficiency and exactness of\npolynomial logical zonotopes for reachability analysis while supporting exact\nintersections. Furthermore, we present an extensive empirical study\nillustrating and verifying the benefits of using constrained polynomial logical\nzonotopes for the formal verification of logical systems.\n","authors":["Ahmad Hafez","Frank J. Jiang","Karl H. Johansson","Amr Alanwar"],"pdf_url":"https://arxiv.org/pdf/2403.18564v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18561v1","updated":"2024-03-27T13:42:19Z","published":"2024-03-27T13:42:19Z","title":"A Dynamic Programming Approach for Road Traffic Estimation","summary":"  We consider a road network represented by a directed graph. We assume to\ncollect many measurements of traffic flows on all the network arcs, or on a\nsubset of them. We assume that the users are divided into different groups.\nEach group follows a different path. The flows of all user groups are modeled\nas a set of independent Poisson processes. Our focus is estimating the paths\nfollowed by each user group, and the means of the associated Poisson processes.\nWe present a possible solution based on a Dynamic Programming algorithm. The\nmethod relies on the knowledge of high order cumulants. We discuss the\ntheoretical properties of the introduced method. Finally, we present some\nnumerical tests on well-known benchmark networks, using synthetic data.\n","authors":["Mattia Laurini","Irene Saccani","Stefano Ardizzoni","Luca Consolini","Marco Locatelli"],"pdf_url":"https://arxiv.org/pdf/2403.18561v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18557v1","updated":"2024-03-27T13:39:06Z","published":"2024-03-27T13:39:06Z","title":"Stability Properties of the Impulsive Goodwin's Oscillator in 1-cycle","summary":"  The Impulsive Goodwin's Oscillator (IGO) is a mathematical model of a hybrid\nclosed-loop system. It arises by closing a special kind of continuous linear\npositive time-invariant system with impulsive feedback, which employs both\namplitude and frequency pulse modulation. The structure of IGO precludes the\nexistence of equilibria, and all its solutions are oscillatory. With its origin\nin mathematical biology, the IGO also presents a control paradigm useful in a\nwide range of applications, in particular dosing of chemicals and medicines.\nSince the pulse modulation feedback mechanism introduces significant\nnonlinearity and non-smoothness in the closedloop dynamics, conventional\ncontroller design methods fail to apply. However, the hybrid dynamics of IGO\nreduce to a nonlinear, time-invariant discrete-time system, exhibiting a\none-to-one correspondence between periodic solutions of the original IGO and\nthose of the discrete-time system. The paper proposes a design approach that\nleverages the linearization of the equivalent discrete-time dynamics in the\nvicinity of a fixed point. A simple and efficient local stability condition of\nthe 1-cycle in terms of the characteristics of the amplitude and frequency\nmodulation functions is obtained.\n","authors":["Anton V. Proskurnikov","Alexander Medvedev"],"pdf_url":"https://arxiv.org/pdf/2403.18557v1.pdf","comment":"submitted to IEEE CDC 2024"},{"id":"http://arxiv.org/abs/2403.18539v1","updated":"2024-03-27T13:14:29Z","published":"2024-03-27T13:14:29Z","title":"Safe and Robust Reinforcement-Learning: Principles and Practice","summary":"  Reinforcement Learning (RL) has shown remarkable success in solving\nrelatively complex tasks, yet the deployment of RL systems in real-world\nscenarios poses significant challenges related to safety and robustness. This\npaper aims to identify and further understand those challenges thorough the\nexploration of the main dimensions of the safe and robust RL landscape,\nencompassing algorithmic, ethical, and practical considerations. We conduct a\ncomprehensive review of methodologies and open problems that summarizes the\nefforts in recent years to address the inherent risks associated with RL\napplications.\n  After discussing and proposing definitions for both safe and robust RL, the\npaper categorizes existing research works into different algorithmic approaches\nthat enhance the safety and robustness of RL agents. We examine techniques such\nas uncertainty estimation, optimisation methodologies, exploration-exploitation\ntrade-offs, and adversarial training. Environmental factors, including\nsim-to-real transfer and domain adaptation, are also scrutinized to understand\nhow RL systems can adapt to diverse and dynamic surroundings. Moreover, human\ninvolvement is an integral ingredient of the analysis, acknowledging the broad\nset of roles that humans can take in this context.\n  Importantly, to aid practitioners in navigating the complexities of safe and\nrobust RL implementation, this paper introduces a practical checklist derived\nfrom the synthesized literature. The checklist encompasses critical aspects of\nalgorithm design, training environment considerations, and ethical guidelines.\nIt will serve as a resource for developers and policymakers alike to ensure the\nresponsible deployment of RL systems in many application domains.\n","authors":["Taku Yamagata","Raul Santos-Rodriguez"],"pdf_url":"https://arxiv.org/pdf/2403.18539v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.10483v2","updated":"2024-03-27T13:11:53Z","published":"2023-08-21T05:54:57Z","title":"Aggregate Model of District Heating Network for Integrated Energy\n  Dispatch: A Physically Informed Data-Driven Approach","summary":"  The district heating network (DHN) is essential in enhancing the operational\nflexibility of integrated energy systems (IES). Yet, it is hard to obtain an\naccurate and concise DHN model for the operation owing to complicated network\nfeatures and imperfect measurements. Considering this, this paper proposes a\nphysical-ly informed data-driven aggregate model (AGM) for the DHN, providing a\nconcise description of the source-load relationship of DHN without exposing\nnetwork details. First, we derive the analytical relationship between the state\nvariables of the source and load nodes of the DHN, offering a physical\nfundament for the AGM. Second, we propose a physics-informed estimator for the\nAGM that is robust to low-quality measurements, in which the physical\nconstraints associated with the parameter normalization and sparsity are\nembedded to improve the accuracy and robustness. Finally, we propose a\nphysics-enhanced algorithm to solve the nonlinear estimator with non-closed\nconstraints efficiently. Simulation results verify the effectiveness of the\nproposed method.\n","authors":["Shuai Lu","Zihang Gao","Yong Sun","Suhan Zhang","Baoju Li","Chengliang Hao","Yijun Xu","Wei Gu"],"pdf_url":"https://arxiv.org/pdf/2308.10483v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17392v2","updated":"2024-03-27T12:10:00Z","published":"2024-03-26T05:23:12Z","title":"Natural-artificial hybrid swarm: Cyborg-insect group navigation in\n  unknown obstructed soft terrain","summary":"  Navigating multi-robot systems in complex terrains has always been a\nchallenging task. This is due to the inherent limitations of traditional robots\nin collision avoidance, adaptation to unknown environments, and sustained\nenergy efficiency. In order to overcome these limitations, this research\nproposes a solution by integrating living insects with miniature electronic\ncontrollers to enable robotic-like programmable control, and proposing a novel\ncontrol algorithm for swarming. Although these creatures, called cyborg\ninsects, have the ability to instinctively avoid collisions with neighbors and\nobstacles while adapting to complex terrains, there is a lack of literature on\nthe control of multi-cyborg systems. This research gap is due to the difficulty\nin coordinating the movements of a cyborg system under the presence of insects'\ninherent individual variability in their reactions to control input. In\nresponse to this issue, we propose a novel swarm navigation algorithm\naddressing these challenges. The effectiveness of the algorithm is demonstrated\nthrough an experimental validation in which a cyborg swarm was successfully\nnavigated through an unknown sandy field with obstacles and hills. This\nresearch contributes to the domain of swarm robotics and showcases the\npotential of integrating biological organisms with robotics and control theory\nto create more intelligent autonomous systems with real-world applications.\n","authors":["Yang Bai","Phuoc Thanh Tran Ngoc","Huu Duoc Nguyen","Duc Long Le","Quang Huy Ha","Kazuki Kai","Yu Xiang See To","Yaosheng Deng","Jie Song","Naoki Wakamiya","Hirotaka Sato","Masaki Ogura"],"pdf_url":"https://arxiv.org/pdf/2403.17392v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.08787v2","updated":"2024-03-27T11:06:49Z","published":"2023-11-15T08:59:05Z","title":"Polygonal Cone Control Barrier Functions (PolyC2BF) for safe navigation\n  in cluttered environments","summary":"  In fields such as mining, search and rescue, and archaeological exploration,\nensuring real-time, collision-free navigation of robots in confined, cluttered\nenvironments is imperative. Despite the value of established path planning\nalgorithms, they often face challenges in convergence rates and handling\ndynamic infeasibilities. Alternative techniques like collision cones struggle\nto accurately represent complex obstacle geometries. This paper introduces a\nnovel category of control barrier functions, known as Polygonal Cone Control\nBarrier Function (PolyC2BF), which addresses overestimation and computational\ncomplexity issues. The proposed PolyC2BF, formulated as a Quadratic Programming\n(QP) problem, proves effective in facilitating collision-free movement of\nmultiple robots in complex environments. The efficacy of this approach is\nfurther demonstrated through PyBullet simulations on quadruped (unicycle\nmodel), and crazyflie 2.1 (quadrotor model) in cluttered environments.\n","authors":["Manan Tayal","Shishir Kolathaya"],"pdf_url":"https://arxiv.org/pdf/2311.08787v2.pdf","comment":"6 Pages, 6 Figures. Accepted at European Control Conference (ECC)\n  2024. arXiv admin note: text overlap with arXiv:2303.15871"},{"id":"http://arxiv.org/abs/2402.01216v2","updated":"2024-03-27T10:25:07Z","published":"2024-02-02T08:39:39Z","title":"Robust Commutation Design: Applied to Switched Reluctance Motors","summary":"  Switched Reluctance Motors (SRMs) are cost-effective electric actuators that\nutilize magnetic reluctance to generate torque, with torque ripple arising from\nunaccounted manufacturing defects in the rotor tooth geometry. This paper aims\nto design a versatile, resource-efficient commutation function for accurate\ncontrol of a range of SRMs, mitigating torque ripple despite manufacturing\nvariations across SRMs and individual rotor teeth. The developed commutation\nfunction optimally distributes current between coils by leveraging the variance\nin the torque-current-angle model and is designed with few parameters for easy\nintegration on affordable hardware. Monte Carlo simulations and experimental\nresults show a tracking error reduction of up to 31% and 11%, respectively. The\ndeveloped approach is beneficial for applications using a single driver for\nmultiple systems and those constrained by memory or modeling effort, providing\nan economical solution for improved tracking performance and reduced acoustic\nnoise.\n","authors":["Max van Meer","Gert Witvoet","Tom Oomen"],"pdf_url":"https://arxiv.org/pdf/2402.01216v2.pdf","comment":"6 pages, 7 figures. Final version"},{"id":"http://arxiv.org/abs/2309.07798v2","updated":"2024-03-27T10:23:01Z","published":"2023-09-14T15:36:59Z","title":"Enhancing Performance, Calibration Time and Efficiency in Brain-Machine\n  Interfaces through Transfer Learning and Wearable EEG Technology","summary":"  Brain-machine interfaces (BMIs) have emerged as a transformative force in\nassistive technologies, empowering individuals with motor impairments by\nenabling device control and facilitating functional recovery. However, the\npersistent challenge of inter-session variability poses a significant hurdle,\nrequiring time-consuming calibration at every new use. Compounding this issue,\nthe low comfort level of current devices further restricts their usage. To\naddress these challenges, we propose a comprehensive solution that combines a\ntiny CNN-based Transfer Learning (TL) approach with a comfortable, wearable EEG\nheadband. The novel wearable EEG device features soft dry electrodes placed on\nthe headband and is capable of on-board processing. We acquire multiple\nsessions of motor-movement EEG data and achieve up to 96% inter-session\naccuracy using TL, greatly reducing the calibration time and improving\nusability. By executing the inference on the edge every 100ms, the system is\nestimated to achieve 30h of battery life. The comfortable BMI setup with tiny\nCNN and TL paves the way to future on-device continual learning, essential for\ntackling inter-session variability and improving usability.\n","authors":["Xiaying Wang","Lan Mei","Victor Kartsch","Andrea Cossettini","Luca Benini"],"pdf_url":"https://arxiv.org/pdf/2309.07798v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18422v1","updated":"2024-03-27T10:21:07Z","published":"2024-03-27T10:21:07Z","title":"Feedback Linearizable Discretizations of Second Order Mechanical Systems\n  using Retraction Maps","summary":"  Mechanical systems, in nature, are often described by a set of\ncontinuous-time, nonlinear, second-order differential equations (SODEs). This\nhas motivated designs of various control laws implemented on digital\ncontrollers, consequently requiring numerical discretization schemes. Feedback\nlinearizability of such sampled systems depends on the discretization scheme or\nmap choice. In this article, we utilize retraction maps and their lifts to\nconstruct feedback linearizable discretizations for SODEs, which can be applied\nto various mechanical systems.\n","authors":["Shreyas N. B.","David Martin Diego","Ravi Banavar"],"pdf_url":"https://arxiv.org/pdf/2403.18422v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18413v1","updated":"2024-03-27T10:01:14Z","published":"2024-03-27T10:01:14Z","title":"HyRRT-Connect: A Bidirectional Rapidly-Exploring Random Trees Motion\n  Planning Algorithm for Hybrid Systems","summary":"  This paper proposes a bidirectional rapidly-exploring random trees (RRT)\nalgorithm to solve the motion planning problem for hybrid systems. The proposed\nalgorithm, called HyRRT-Connect, propagates in both forward and backward\ndirections in hybrid time until an overlap between the forward and backward\npropagation results is detected. Then, HyRRT-Connect constructs a motion plan\nthrough the reversal and concatenation of functions defined on hybrid time\ndomains, ensuring the motion plan thoroughly satisfies the given hybrid\ndynamics. To address the potential discontinuity along the flow caused by\ntolerating some distance between the forward and backward partial motion plans,\nwe reconstruct the backward partial motion plan by a forward-in-hybrid-time\nsimulation from the final state of the forward partial motion plan. By applying\nthe reversed input of the backward partial motion plan, the reconstruction\nprocess effectively eliminates the discontinuity and ensures that as the\ntolerance distance decreases to zero, the distance between the endpoint of the\nreconstructed motion plan and the final state set approaches zero. The proposed\nalgorithm is applied to an actuated bouncing ball example and a walking robot\nexample so as to highlight its generality and computational improvement.\n","authors":["Nan Wang","Ricardo G. Sanfelice"],"pdf_url":"https://arxiv.org/pdf/2403.18413v1.pdf","comment":"Accepted by the 8th IFAC International Conference on Analysis and\n  Design of Hybrid Systems (ADHS 2024)"},{"id":"http://arxiv.org/abs/2403.18398v1","updated":"2024-03-27T09:37:12Z","published":"2024-03-27T09:37:12Z","title":"Adaptive Economic Model Predictive Control for linear systems with\n  performance guarantees","summary":"  We present a model predictive control (MPC) formulation to directly optimize\neconomic criteria for linear constrained systems subject to disturbances and\nuncertain model parameters. The proposed formulation combines a certainty\nequivalent economic MPC with a simple least-squares parameter adaptation. For\nthe resulting adaptive economic MPC scheme, we derive strong asymptotic and\ntransient performance guarantees. We provide a numerical example involving\nbuilding temperature control and demonstrate performance benefits of online\nparameter adaptation.\n","authors":["Maximilian Degner","Raffaele Soloperto","Melanie N. Zeilinger","John Lygeros","Johannes Köhler"],"pdf_url":"https://arxiv.org/pdf/2403.18398v1.pdf","comment":"8 pages, 3 figures, submitted to IEEE CDC 2024"},{"id":"http://arxiv.org/abs/2403.18371v1","updated":"2024-03-27T09:08:06Z","published":"2024-03-27T09:08:06Z","title":"Multivariable control of modular multilevel converters with convergence\n  and safety guarantees","summary":"  Well-designed current control is a key factor in ensuring the efficient and\nsafe operation of modular multilevel converters (MMCs). Even though this\ncontrol problem involves multiple control objectives, conventional current\ncontrol schemes are comprised of independently designed decoupled controllers,\ne.g., proportional-integral (PI) or proportional-resonant (PR). Due to the\nbilinearity of the MMC dynamics, tuning PI and PR controllers so that good\nperformance and constraint satisfaction are guaranteed is quite challenging.\nThis challenge becomes more relevant in an AC/AC MMC configuration due to the\ncomplexity of tracking the single-phase sinusoidal components of the MMC\noutput. In this paper, we propose a method to design a multivariable\ncontroller, i.e., a static feedback gain, to regulate the MMC currents. We use\na physics-informed transformation to model the MMC dynamics linearly and\nsynthesise the proposed controller. We use this linear model to formulate a\nlinear matrix inequality that computes a feedback gain that guarantees safe and\neffective operation, including (i) limited tracking error, (ii) stability, and\n(iii) meeting all constraints. To test the efficacy of our method, we examine\nits performance in a direct AC/AC MMC simulated in Simulink/PLECS and in a\nscaled-down AC/AC MMC prototype to investigate the ultra-fast charging of\nelectric vehicles.\n","authors":["Victor Daniel Reyes Dreke","Ygor Pereira Marca","Maurice Roes","Mircea Lazar"],"pdf_url":"https://arxiv.org/pdf/2403.18371v1.pdf","comment":"Submitted to IEEE Open Journal of the Industrial Electronics"},{"id":"http://arxiv.org/abs/2403.18275v1","updated":"2024-03-27T06:02:55Z","published":"2024-03-27T06:02:55Z","title":"Differentially Private Dual Gradient Tracking for Distributed Resource\n  Allocation","summary":"  This paper investigates privacy issues in distributed resource allocation\nover directed networks, where each agent holds a private cost function and\noptimizes its decision subject to a global coupling constraint through local\ninteraction with other agents. Conventional methods for resource allocation\nover directed networks require all agents to transmit their original data to\nneighbors, which poses the risk of disclosing sensitive and private\ninformation. To address this issue, we propose an algorithm called\ndifferentially private dual gradient tracking (DP-DGT) for distributed resource\nallocation, which obfuscates the exchanged messages using independent Laplacian\nnoise. Our algorithm ensures that the agents' decisions converge to a\nneighborhood of the optimal solution almost surely. Furthermore, without the\nassumption of bounded gradients, we prove that the cumulative differential\nprivacy loss under the proposed algorithm is finite even when the number of\niterations goes to infinity. To the best of our knowledge, we are the first to\nsimultaneously achieve these two goals in distributed resource allocation\nproblems over directed networks. Finally, numerical simulations on economic\ndispatch problems within the IEEE 14-bus system illustrate the effectiveness of\nour proposed algorithm.\n","authors":["Wei Huo","Xiaomeng Chen","Lingying Huang","Karl Henrik Johansson","Ling Shi"],"pdf_url":"https://arxiv.org/pdf/2403.18275v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18254v1","updated":"2024-03-27T04:54:23Z","published":"2024-03-27T04:54:23Z","title":"Differentially Private Distributed Nonconvex Stochastic Optimization\n  with Quantized Communications","summary":"  This paper proposes a new distributed nonconvex stochastic optimization\nalgorithm that can achieve privacy protection, communication efficiency and\nconvergence simultaneously. Specifically, each node adds time-varying privacy\nnoises to its local state to avoid information leakage, and then quantizes its\nnoise-perturbed state before transmitting to improve communication efficiency.\nBy employing the subsampling method controlled through the sample-size\nparameter, the proposed algorithm reduces the impact of privacy noises, and\nenhances the differential privacy level. When the global cost function\nsatisfies the Polyak-Lojasiewicz condition, the mean and high-probability\nconvergence rate and the oracle complexity of the proposed algorithm are given.\nImportantly, the proposed algorithm achieves both the mean convergence and a\nfinite cumulative differential privacy budget over infinite iterations as the\nsample-size goes to infinity. A numerical example of the distributed training\non the \"MNIST\" dataset is given to show the effectiveness of the algorithm.\n","authors":["Jialong Chen","Jimin Wang","Ji-Feng Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.18254v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18250v1","updated":"2024-03-27T04:46:33Z","published":"2024-03-27T04:46:33Z","title":"Linear Hybrid Asymmetrical Load-Modulated Balanced Amplifier with\n  Multi-Band Reconfigurability and Antenna-VSWR Resilience","summary":"  This paper presents the first-ever highly linear and load-insensitive\nthree-way load-modulation power amplifier (PA) based on reconfigurable hybrid\nasymmetrical load modulated balanced amplifier (H-ALMBA). Through proper\namplitude and phase controls, the carrier, control amplifier (CA), and two\npeaking balanced amplifiers (BA1 and BA2) can form a linear high-order load\nmodulation over wide bandwidth. Moreover, it is theoretically unveiled that the\nload modulation behavior of H-ALMBA can be insensitive to load mismatch by\nleveraging bias reconfiguration and the intrinsic load-insensitivity of\nbalanced topology. Specifically, the PA's linearity and efficiency profiles can\nbe maintained against arbitrary load mismatch through $Z_\\mathrm{L}$-dependent\nreconfiguration of CA supply voltage ($V_\\mathrm{DD,CA}$) and turning-on\nsequence of BA1 and BA2. Based on the proposed theory, an RF-input linear\nH-ALMBA is developed with GaN transistors and wideband quadrature hybrids. Over\nthe design bandwidth from $1.7$-$2.9$ GHz, an efficiency of $56.8\\%$$-$$72.9\\%$\nat peak power and $49.8\\%$$-$$61.2\\%$ at $10$-dB PBO are measured together with\nlinear AMAM and AMPM responses. In modulated evaluation with 4G LTE signal, an\nEVM of $3.1\\%$, ACPR of $-39$ dB, and average efficiency of up to $52\\%$ are\nmeasured. Moreover, the reconfigurable H-ALMBA experimentally maintains an\nexcellent average efficiency and linearity against arbitrary load mismatch at\n$2:1$ VSWR, and this mismatch-resilient operation can be achieved at any\nin-band frequencies. The overall measured performance favorably outperforms the\nstate-of-the-art.\n","authors":["Jiachen Guo","Yuchen Cao","Kenle Chen"],"pdf_url":"https://arxiv.org/pdf/2403.18250v1.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2401.11542v2","updated":"2024-03-27T04:39:26Z","published":"2024-01-21T16:51:07Z","title":"Nigel -- Mechatronic Design and Robust Sim2Real Control of an\n  Over-Actuated Autonomous Vehicle","summary":"  Simulation to reality (sim2real) transfer from a dynamics and controls\nperspective usually involves re-tuning or adapting the designed algorithms to\nsuit real-world operating conditions, which often violates the performance\nguarantees established originally. This work presents a generalizable framework\nfor achieving reliable sim2real transfer of autonomy-oriented control systems\nusing multi-model multi-objective robust optimal control synthesis, which lends\nwell to uncertainty handling and disturbance rejection with theoretical\nguarantees. Particularly, this work is centered around a novel\nactuation-redundant scaled autonomous vehicle called Nigel, with independent\nall-wheel drive and independent all-wheel steering architecture, whose enhanced\nconfiguration space bodes well for robust control applications. To this end, we\npresent the mechatronic design, dynamics modeling, parameter identification,\nand robust stabilizing as well as tracking control of Nigel using the proposed\nframework, with exhaustive experimentation and benchmarking in simulation as\nwell as real-world settings.\n","authors":["Chinmay Vilas Samak","Tanmay Vilas Samak","Javad Mohammadpour Velni","Venkat Narayan Krovi"],"pdf_url":"https://arxiv.org/pdf/2401.11542v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18235v1","updated":"2024-03-27T03:50:14Z","published":"2024-03-27T03:50:14Z","title":"An Execution-time-certified QP Algorithm for $\\ell_1$ penalty-based\n  Soft-constrained MPC","summary":"  Providing an execution time certificate and handling possible infeasibility\nin closed-loop are two pressing requirements of Model Predictive Control (MPC).\nTo simultaneously meet these two requirements, this paper uses $\\ell_1$\npenalty-based soft-constrained MPC formulation and innovatively transforms the\nresulting non-smooth QP into a box-constrained QP, which is solved by our\npreviously proposed direct and execution-time certified algorithm with only\ndimension-dependent (data-independent) and exact number of iterations [1]. This\napproach not only overcomes the limitation of our previously proposed algorithm\n[1], only applicable to input-constrained MPC, but also enjoys exact recovery\nfeature (exactly recover the same solution when the original problem is\nfeasible) of $\\ell_1$ penalty-based soft-constrained MPC formulation without\nsuffering numerical difficulty of the resulting non-smoothness. Other various\nreal-time QP applications, not limited to MPC, will also benefit from our QP\nalgorithm with execution-time certificate and global feasibility.\n","authors":["Liang Wu","Richard D. Braatz"],"pdf_url":"https://arxiv.org/pdf/2403.18235v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2403.18200v1","updated":"2024-03-27T02:21:20Z","published":"2024-03-27T02:21:20Z","title":"Fault-tolerant properties of scale-free linear protocols for\n  synchronization of homogeneous multi-agent systems","summary":"  Originally, protocols were designed for multi-agent systems (MAS) using\ninformation about the network. However, in many cases there is no or only\nlimited information available about the network. Recently, there has been a\nfocus on scale-free synchronization of multi-agent systems (MAS). In this case,\nthe protocol is designed without any prior information about the network. As\nlong as the network contains a directed spanning tree, the scale-free protocol\nguarantees that the network achieves synchronization.\n  If there is no directed spanning tree for the network then synchronization\ncannot be achieved. But what happens when these scale-free protocols are\napplied to such a network where the directed spanning tree no longer exists?\nThe latter might arise if, for instance, a fault occurs in one of more crucial\nlinks. This paper establishes that the network decomposes into a number of\nbasic bicomponents which achieves synchronization among all nodes in this basic\nbicomponent. On the other hand, nodes which are not part of any basic\nbicomponent converge to a weighted average of the synchronized trajectories of\nthe basic bicomponents. The weights are independent of the initial conditions\nand are independent of the designed protocol.\n","authors":["Anton A. Stoorvogel","Ali Saberi","Zhenwei Liu"],"pdf_url":"https://arxiv.org/pdf/2403.18200v1.pdf","comment":"The article was submitted to IEEE Transactions on Automatic Control\n  for review at March 27th, 2024"},{"id":"http://arxiv.org/abs/2403.16488v3","updated":"2024-03-27T01:30:16Z","published":"2024-03-25T07:16:08Z","title":"Ensuring Disturbance Rejection Performance by Synthesizing\n  Grid-Following and Grid-Forming Inverters in Power Systems","summary":"  To satisfy dynamic requirements of power systems, it is imperative for\ngrid-tied inverters to ensure good disturbance rejection performance (DRP)\nunder variable grid conditions. This letter discovers and theoretically proves\nthat for general networks, synthesizing grid-following (GFL) inverters and\ngrid-forming (GFM) inverters can always more effectively ensure the DRP of\nmultiple inverters, as compared to homogeneous inverter-based systems that\nsolely utilize either GFL or GFM inverters. The synthesis of GFL inverters and\nGFM inverters can concurrently increase the smallest eigenvalue and decrease\nthe largest eigenvalue of the network grounded Laplacian matrix. This can be\nequivalent to rematching the proper short-circuit ratio (SCR) for GFL and GFM\ninverters, thereby ensuring the DRP of inverters both in weak and strong grids.\nThe results reveal the necessity of synthesizing diverse inverter control\nschemes from the network-based perspective. Sensitivity function-based tests\nand real-time simulations validate our results.\n","authors":["Fuyilong Ma","Huanhai Xin","Zhiyi Li","Linbin Huang"],"pdf_url":"https://arxiv.org/pdf/2403.16488v3.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2403.18166v1","updated":"2024-03-27T00:21:49Z","published":"2024-03-27T00:21:49Z","title":"Incentive-Compatible Vertiport Reservation in Advanced Air Mobility: An\n  Auction-Based Approach","summary":"  The rise of advanced air mobility (AAM) is expected to become a\nmultibillion-dollar industry in the near future. Market-based mechanisms are\ntouted to be an integral part of AAM operations, which comprise heterogeneous\noperators with private valuations. In this work, we study the problem of\ndesigning a mechanism to coordinate the movement of electric vertical take-off\nand landing (eVTOL) aircraft, operated by multiple operators each having\nheterogeneous valuations associated with their fleet, between vertiports, while\nenforcing the arrival, departure, and parking constraints at vertiports.\nParticularly, we propose an incentive-compatible and individually rational\nvertiport reservation mechanism that maximizes a social welfare metric, which\nencapsulates the objective of maximizing the overall valuations of all\noperators while minimizing the congestion at vertiports. Additionally, we\nimprove the computational tractability of designing the reservation mechanism\nby proposing a mixed binary linear programming approach that is based on\nconstructing network flow graph corresponding to the underlying problem.\n","authors":["Pan-Yang Su","Chinmay Maheshwari","Victoria Tuck","Shankar Sastry"],"pdf_url":"https://arxiv.org/pdf/2403.18166v1.pdf","comment":"26 pages, 2 figures, 1 table"},{"id":"http://arxiv.org/abs/2403.18164v1","updated":"2024-03-27T00:16:17Z","published":"2024-03-27T00:16:17Z","title":"Incentive Designs for Learning Agents to Stabilize Coupled Exogenous\n  Systems","summary":"  We consider a large population of learning agents noncooperatively selecting\nstrategies from a common set, influencing the dynamics of an exogenous system\n(ES) we seek to stabilize at a desired equilibrium. Our approach is to design a\ndynamic payoff mechanism capable of shaping the population's strategy profile,\nthus affecting the ES's state, by offering incentives for specific strategies\nwithin budget limits. Employing system-theoretic passivity concepts, we\nestablish conditions under which a payoff mechanism can be systematically\nconstructed to ensure the global asymptotic stabilization of the ES's\nequilibrium. In comparison to previous approaches originally studied in the\ncontext of the so-called epidemic population games, the method proposed here\nallows for more realistic epidemic models and other types of ES, such as\npredator-prey dynamics. Stabilization is established with the support of a\nLyapunov function, which provides useful bounds on the transients.\n","authors":["Jair Certório","Nuno C. Martins","Richard J. La","Murat Arcak"],"pdf_url":"https://arxiv.org/pdf/2403.18164v1.pdf","comment":"8 pages, 3 figures"},{"id":"http://arxiv.org/abs/2403.18163v1","updated":"2024-03-27T00:12:51Z","published":"2024-03-27T00:12:51Z","title":"A Study of Three Influencer Archetypes for the Control of Opinion Spread\n  in Time-Varying Social Networks","summary":"  In this work we consider the impact of information spread in time-varying\nsocial networks, where agents request to follow other agents with aligned\nopinions while dropping ties to neighbors whose posts are too dissimilar to\ntheir own views. Opinion control and rhetorical influence has a very long\nhistory, employing various methods including education, persuasion, propaganda,\nmarketing, and manipulation through mis-, dis-, and mal-information. The\nautomation of opinion controllers, however, has only recently become easily\ndeployable at a wide scale, with the advent of large language models (LLMs) and\ngenerative AI that can translate the quantified commands from opinion\ncontrollers into actual content with the appropriate nuance. Automated agents\nin social networks can be deployed for various purposes, such as breaking up\necho chambers, bridging valuable new connections between agents, or shaping the\nopinions of a target population -- and all of these raise important ethical\nconcerns that deserve serious attention and thoughtful discussion and debate.\nThis paper attempts to contribute to this discussion by considering three\narchetypal influencing styles observed by human drivers in these settings,\ncomparing and contrasting the impact of these different control methods on the\nopinions of agents in the network. We will demonstrate the efficacy of current\ngenerative AI for generating nuanced content consistent with the command signal\nfrom automatic opinion controllers like these, and we will report on frameworks\nfor approaching the relevant ethical considerations.\n","authors":["Michael DeBuse","Sean Warnick"],"pdf_url":"https://arxiv.org/pdf/2403.18163v1.pdf","comment":"Submission to IEEE 2024 Conference on Decision and Control. 8 pages,\n  7 figures, 1 table"}]}}